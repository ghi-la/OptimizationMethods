{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3 - Optimization Methods\n",
    "## Matteo Ghilardini\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: programming problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup the environment:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the required libraries in the jupiter notebook environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Users/ghila/.pyenv/versions/3.10.12/lib/python3.10/site-packages (2.2.3)\n",
      "Requirement already satisfied: matplotlib in /Users/ghila/.pyenv/versions/3.10.12/lib/python3.10/site-packages (3.10.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/ghila/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/ghila/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/ghila/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from matplotlib) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/ghila/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/ghila/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /Users/ghila/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/ghila/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/ghila/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/ghila/.pyenv/versions/3.10.12/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from math import factorial, pow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Problem 1** (Bell curve fitting)\n",
    "To find the bell curve that bests fit the data, we will find the parameters $x$ that minimise the mean squared error:\n",
    "$$\n",
    "f(x) = \\frac{1}{N}\\sum^N_{i=1}(m(z^{(i)};x)-y^{(i)})^2\n",
    "$$\n",
    "i.e., we will solve the problem:\n",
    "$$\n",
    "\\min_{x\\in \\R ^2}f(x)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Import the file `dataset1.csv` (available under _‘Assignment 3’_ on iCorsi) and store its content into an numpy `nd.array`. This file is a table containing 100 rows and 2 columns, representing 100 data points with 2 coordinates.  \n",
    "Hint: import this table with numpy into an array with `np.loadtxt` with argument `skiprows=2` and `delimiter=\",\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = np.loadtxt(\"dataset1.csv\", skiprows=2, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Plot this point cloud as in Figure 1, with the first column on the x-axis and the second column one the y-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = dataset1[:, 0] # First column from the dataset\n",
    "g = dataset1[:, 1] # Second column from the dataset\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(x, g, color='blue')\n",
    "plt.xlabel(\"z\")\n",
    "plt.ylabel(\"g(z)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Write a function that computes $f(x)$ defined above for any given $x = (x1, x2)$. This function must also take as argument the array containing the data points. Evaluate $f$ at $x = (1, 0.5)$ and $x = (0.5, 1)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering that \n",
    "$$\n",
    "f(x) = \\frac{1}{N}\\sum^N_{i=1}(m(z^{(i)};x)-y^{(i)})^2\n",
    "$$\n",
    "and that $m(z;x)$ is defined as:\n",
    "$$\n",
    "m(z;x) = exp(-\\frac{(z-y)^2}{x_2})\n",
    "$$\n",
    "The code that computes $f(x)$ for a given $x$ over the `dataset` is the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f(x) with x=(1, 0.5) = 0.11204289613814822\n",
      "f(x) with x=(0.5, 1) = 0.15009253657239355\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def f(x, dataset):\n",
    "    x1, x2 = float(x[0]), float(x[1])   # Ensure x1 and x2 are floats\n",
    "    z = dataset[:, 0]                   # First column from the dataset\n",
    "    g = dataset[:, 1]                   # Second column from the dataset\n",
    "    N = len(z)                          # Number of elements in the dataset\n",
    "\n",
    "    m_zx = np.exp(-((z - x1) ** 2) / x2)        # Compute m(z; x)\n",
    "    f_x = (1 / N) * np.sum((m_zx - g) ** 2)     # Compute f(x)\n",
    "\n",
    "    return f_x\n",
    "\n",
    "\n",
    "dataset1 = np.loadtxt(\"dataset1.csv\", skiprows=2, delimiter=\",\")\n",
    "\n",
    "print('f(x) with x=(1, 0.5) =', f([1, 0.5], dataset1))\n",
    "print('f(x) with x=(0.5, 1) =', f([0.5, 1], dataset1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Show that\n",
    "$$\n",
    "\\bigtriangledown f(x) = \\frac{2}{N}\\sum^N_{i=1}\\frac{z^{(i)}-y}{x_2}\\exp(-\\frac{(z^{(i)}-y)^2}{x_2}) (\\exp(-\\frac{(z^{(i)}-y)^2}{x_2})-y^{(i)}).\n",
    "\\begin{bmatrix}\n",
    "   2 \\\\\n",
    "   \\frac{z^{(i)}-y}{x_2}\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since $f(x) = \\frac{1}{N}\\sum^N_{i=1}(m(z^{(i)};x)-y^{(i)})^2$ and $m(z;x) = exp(-\\frac{(z-y)^2}{x_2})$, we know that $f(x)$ is defined as:\n",
    "$$\n",
    "f(x) = \\frac{1}{N}\\sum^N_{i=1}(exp(-\\frac{(z-x_1)^2}{x_2})-y^{(i)})^2\n",
    "$$\n",
    "\n",
    "The gradient $\\bigtriangledown f(x)$ is defined as\n",
    "$$\n",
    "\\bigtriangledown f(x) = (\\frac{\\partial f}{\\partial x_1}, \\frac{\\partial f}{\\partial x_2})\n",
    "$$\n",
    "and so, we compute:\n",
    "- **Partial derivate wrt $x_1$**:\n",
    "    - we start having\n",
    "        $$\n",
    "        \\frac{\\partial f}{\\partial x_1} = \\frac{2}{N}\\sum^N_{i=1}(exp(-\\frac{(z^{(i)}-x_1)^2}{x_2})-y^{(i)})\n",
    "        $$\n",
    "    - then consider (for semplicity) \n",
    "        $$g(x_1) = -\\frac{(z^{(i)}-x_1)^2}{x_2}$$ \n",
    "        and it follows that \n",
    "        $$g'(x_1)=\\frac{2\\cdot(z^{(i)}-x_1)}{x_2}$$\n",
    "    - we have \n",
    "        $$\\frac{d}{d x_1} \\exp(g(x_1)) = \\exp(g(x_1))\\cdot g'(x_1)$$\n",
    "        and so\n",
    "        $$\\frac{d}{d x_1} \\exp(-\\frac{(z^{(i)}-x_1)^2}{x_2}) = \\exp(-\\frac{(z^{(i)}-x_1)^2}{x_2})\\cdot 2\\frac{(z^{(i)}-x_1)}{x_2}$$\n",
    "    - resulting at the end as\n",
    "        $$\n",
    "            \\frac{\\partial f}{\\partial x_1} = \\frac{2}{N}\\sum^N_{i=1}(exp(-\\frac{(z-x_1)^2}{x_2})-y^{(i)}) \\cdot \\exp(-\\frac{(z^{(i)}-x_1)^2}{x_2})\\cdot 2\\frac{(z^{(i)}-x_1)}{x_2}\n",
    "        $$\n",
    "        that matches the given formula for $\\bigtriangledown f(x)$\n",
    "\n",
    "- **Partial derivate wrt $x_2$**\n",
    "    - we start having\n",
    "        $$\n",
    "        \\frac{\\partial f}{\\partial x_2} = \\frac{2}{N}\\sum^N_{i=1}(exp(-\\frac{(z^{(i)}-x_1)^2}{x_2})-y^{(i)})\n",
    "        $$\n",
    "    - then consider (for semplicity) \n",
    "        $$g(x_2) = -\\frac{(z^{(i)}-x_1)^2}{x_2}$$ \n",
    "        and it follows that \n",
    "        $$g'(x_2) = \\frac{(z^{(i)}-x_1)^2}{x_2^2}$$\n",
    "    - we have \n",
    "        $$\\frac{d}{dx_2} \\exp(g(x_2)) = \\exp(g(x_2)) \\cdot g'(x_2)$$\n",
    "        and so\n",
    "        $$\\frac{d}{dx_2} \\exp\\left(-\\frac{(z^{(i)}-x_1)^2}{x_2}\\right) = \\exp\\left(-\\frac{(z^{(i)}-x_1)^2}{x_2}\\right) \\cdot \\frac{(z^{(i)}-x_1)^2}{x_2^2}$$\n",
    "    - resulting at the end as\n",
    "        $$\n",
    "        \\frac{\\partial f}{\\partial x_2} =  \\frac{2}{N} \\sum^N_{i=1} \\left( \\exp\\left(-\\frac{(z^{(i)}-x_1)^2}{x_2}\\right) - y^{(i)} \\right) \\cdot \\exp\\left(-\\frac{(z^{(i)}-x_1)^2}{x_2}\\right) \\cdot \\frac{(z^{(i)}-x_1)^2}{x_2^2}\n",
    "        $$\n",
    "\n",
    "So at the end it results the following gradient vector:\n",
    "$$\n",
    "\\bigtriangledown f(x) =\n",
    "\\begin{bmatrix}\n",
    "    \\frac{2}{N} \\sum^N_{i=1} \\left( \\exp\\left(-\\frac{(z^{(i)}-x_1)^2}{x_2}\\right) - y^{(i)} \\right) \\cdot \\exp\\left(-\\frac{(z^{(i)}-x_1)^2}{x_2}\\right) \\cdot \\frac{2(z^{(i)}-x_1)}{x_2} \\\\\n",
    "    \\frac{2}{N} \\sum^N_{i=1} \\left( \\exp\\left(-\\frac{(z^{(i)}-x_1)^2}{x_2}\\right) - y^{(i)} \\right) \\cdot \\exp\\left(-\\frac{(z^{(i)}-x_1)^2}{x_2}\\right) \\cdot \\frac{(z^{(i)}-x_1)^2}{x_2^2}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "**The formula given in the exercise, actualy is not the gradient vector $\\bigtriangledown f(x)$, but is the formula of the partial derivate $\\frac{\\partial f}{\\partial x_1}$.**  \n",
    "I do not know whether this is a typo or whether I misinterpreted the exercise; when in doubt, I also calculated $\\frac{\\partial f}{\\partial x_2}$ since is needed for the following exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. Write a function that computes the gradient of $f$ for any given $x$ and evaluate $\\nabla f$ at $x = (1, 0.5)$ and $x = (0.5, 1)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient of f(x) with x=(1, 0.5) = [-0.15222549 -0.0578975 ]\n",
      "Gradient of f(x) with x=(0.5, 1) = [-0.09240185 -0.02646519]\n"
     ]
    }
   ],
   "source": [
    "def gradient_f(x, dataset):\n",
    "    x1, x2 = float(x[0]), float(x[1])   # Ensure x1 and x2 are floats\n",
    "    z = dataset[:, 0]                   # First column from the dataset\n",
    "    g = dataset[:, 1]                   # Second column from the dataset\n",
    "    N = len(z)                          # Number of elements in the dataset\n",
    "\n",
    "    m_zx = np.exp(-((z - x1) ** 2) / x2)    # Compute m(z; x)\n",
    "\n",
    "    grad_f_x1 = (2 / N) * np.sum((m_zx - g) * m_zx * (2 * (z - x1) / x2))           # Partial derivative of f(x) with respect to x1\n",
    "    grad_f_x2 = (2 / N) * np.sum((m_zx - g) * m_zx * ((z - x1) ** 2 / x2**2))       # Partial derivative of f(x) with respect to x2\n",
    "\n",
    "    return np.array([grad_f_x1, grad_f_x2])\n",
    "\n",
    "\n",
    "print('Gradient of f(x) with x=(1, 0.5) =', gradient_f([1, 0.5], dataset1))\n",
    "print('Gradient of f(x) with x=(0.5, 1) =', gradient_f([0.5, 1], dataset1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6. Write a function implementing the `Gradient Descent algorithm`. You can decide which arguments this function, but this function should also work the same on another data set (i.e., if someone provides another array containing another set of data points). Moreover, at each iteration $k$, you should print the value of $x^{(k)}$, $f(x^{(k)})$ and $||\\nabla f(x^{(k)})||$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(dataset, x_init, alpha, tol=1e-6, max_iter=1000):\n",
    "    x = np.array(x_init, dtype=float)  # Initialize the set of x values\n",
    "\n",
    "    for k in range(max_iter):\n",
    "        f_x = f(x, dataset)                     # Compute f(x)\n",
    "        grad = gradient_f(x, dataset)           # Compute gradient of f(x)\n",
    "        grad_norm = np.linalg.norm(grad)        # Compute norm of the gradient\n",
    "\n",
    "        print(\"Iteration\", k, \": x =\", x, \"f(x) =\", f_x, \"gradient norm =\", grad_norm)\n",
    "\n",
    "        # Check for convergence\n",
    "        if grad_norm < tol:\n",
    "            print(\"Completed in\", k, \"iterations\")\n",
    "            break\n",
    "\n",
    "        x -= alpha * grad # Next step\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7. Test this algorithm for a step size $\\alpha \\in \\{0.1, 1, 10, 100\\}$ starting from $x^{(0)} = (2, 5)$ and reports the results. Test also different starting points and comment (Remark: you need to choose $x^{(0)}_2 > 0$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------- Starting point: [2, 5] ---------------\n",
      "\n",
      "\tStep size: 0.1\n",
      "Iteration 0 : x = [2. 5.] f(x) = 0.04037643540736778 gradient norm = 0.017863549100416345\n",
      "Iteration 1 : x = [2.00115894 4.99864062] f(x) = 0.04034458229125371 gradient norm = 0.0177992917107646\n",
      "Iteration 2 : x = [2.00230804 4.99728131] f(x) = 0.04031295742836538 gradient norm = 0.017735820258451\n",
      "Iteration 3 : x = [2.00344736 4.99592207] f(x) = 0.04028155721861779 gradient norm = 0.017673127983072707\n",
      "Iteration 4 : x = [2.00457699 4.9945629 ] f(x) = 0.04025037811556948 gradient norm = 0.017611208130796873\n",
      "Iteration 5 : x = [2.00569699 4.9932038 ] f(x) = 0.04021941662569591 gradient norm = 0.01755005395519063\n",
      "Iteration 6 : x = [2.00680744 4.99184478] f(x) = 0.04018866930767094 gradient norm = 0.017489658718047738\n",
      "Iteration 7 : x = [2.00790841 4.99048583] f(x) = 0.0401581327716561 gradient norm = 0.017430015690211634\n",
      "Iteration 8 : x = [2.00899998 4.98912696] f(x) = 0.04012780367859776 gradient norm = 0.017371118152394432\n",
      "Iteration 9 : x = [2.01008222 4.98776816] f(x) = 0.04009767873953227 gradient norm = 0.017312959395991933\n",
      "Iteration 10 : x = [2.01115519 4.98640945] f(x) = 0.04006775471489878 gradient norm = 0.017255532723893914\n",
      "Iteration 11 : x = [2.01221897 4.98505081] f(x) = 0.040038028413860005 gradient norm = 0.017198831451289847\n",
      "Iteration 12 : x = [2.01327364 4.98369225] f(x) = 0.040008496693630546 gradient norm = 0.017142848906469364\n",
      "Iteration 13 : x = [2.01431925 4.98233377] f(x) = 0.039979156458813 gradient norm = 0.017087578431617335\n",
      "Iteration 14 : x = [2.01535589 4.98097538] f(x) = 0.03995000466074181 gradient norm = 0.017033013383603357\n",
      "Iteration 15 : x = [2.01638361 4.97961706] f(x) = 0.039921038296834514 gradient norm = 0.01697914713476505\n",
      "Iteration 16 : x = [2.0174025  4.97825883] f(x) = 0.039892254409950666 gradient norm = 0.016925973073685152\n",
      "Iteration 17 : x = [2.01841261 4.97690068] f(x) = 0.03986365008775831 gradient norm = 0.01687348460596199\n",
      "Iteration 18 : x = [2.01941401 4.97554262] f(x) = 0.039835222462107835 gradient norm = 0.016821675154972838\n",
      "Iteration 19 : x = [2.02040677 4.97418464] f(x) = 0.03980696870841323 gradient norm = 0.01677053816263019\n",
      "Iteration 20 : x = [2.02139097 4.97282675] f(x) = 0.039778886045040804 gradient norm = 0.0167200670901304\n",
      "Iteration 21 : x = [2.02236666 4.97146894] f(x) = 0.03975097173270503 gradient norm = 0.016670255418694453\n",
      "Iteration 22 : x = [2.0233339  4.97011122] f(x) = 0.03972322307387188 gradient norm = 0.016621096650300555\n",
      "Iteration 23 : x = [2.02429278 4.96875359] f(x) = 0.039695637412169145 gradient norm = 0.016572584308408196\n",
      "Iteration 24 : x = [2.02524335 4.96739604] f(x) = 0.03966821213180399 gradient norm = 0.01652471193867357\n",
      "Iteration 25 : x = [2.02618567 4.96603859] f(x) = 0.039640944656987705 gradient norm = 0.01647747310965578\n",
      "Iteration 26 : x = [2.02711981 4.96468122] f(x) = 0.039613832451367265 gradient norm = 0.01643086141351381\n",
      "Iteration 27 : x = [2.02804584 4.96332394] f(x) = 0.03958687301746407 gradient norm = 0.016384870466693745\n",
      "Iteration 28 : x = [2.02896381 4.96196675] f(x) = 0.03956006389611959 gradient norm = 0.016339493910606233\n",
      "Iteration 29 : x = [2.0298738  4.96060965] f(x) = 0.03953340266594773 gradient norm = 0.016294725412293553\n",
      "Iteration 30 : x = [2.03077586 4.95925264] f(x) = 0.039506886942794174 gradient norm = 0.016250558665086418\n",
      "Iteration 31 : x = [2.03167005 4.95789572] f(x) = 0.039480514379202435 gradient norm = 0.016206987389250048\n",
      "Iteration 32 : x = [2.03255644 4.9565389 ] f(x) = 0.03945428266388656 gradient norm = 0.016164005332619136\n",
      "Iteration 33 : x = [2.03343508 4.95518216] f(x) = 0.039428189521210535 gradient norm = 0.016121606271221813\n",
      "Iteration 34 : x = [2.03430605 4.95382552] f(x) = 0.03940223271067422 gradient norm = 0.01607978400989206\n",
      "Iteration 35 : x = [2.03516939 4.95246897] f(x) = 0.039376410026405864 gradient norm = 0.01603853238287053\n",
      "Iteration 36 : x = [2.03602517 4.95111251] f(x) = 0.039350719296661 gradient norm = 0.01599784525439344\n",
      "Iteration 37 : x = [2.03687345 4.94975614] f(x) = 0.03932515838332789 gradient norm = 0.015957716519269464\n",
      "Iteration 38 : x = [2.03771428 4.94839986] f(x) = 0.03929972518143913 gradient norm = 0.015918140103444264\n",
      "Iteration 39 : x = [2.03854773 4.94704368] f(x) = 0.03927441761868968 gradient norm = 0.015879109964552666\n",
      "Iteration 40 : x = [2.03937386 4.94568759] f(x) = 0.03924923365496111 gradient norm = 0.015840620092458044\n",
      "Iteration 41 : x = [2.04019271 4.94433159] f(x) = 0.039224171281851905 gradient norm = 0.015802664509779064\n",
      "Iteration 42 : x = [2.04100436 4.94297569] f(x) = 0.03919922852221408 gradient norm = 0.01576523727240339\n",
      "Iteration 43 : x = [2.04180885 4.94161988] f(x) = 0.03917440342969559 gradient norm = 0.015728332469988202\n",
      "Iteration 44 : x = [2.04260624 4.94026416] f(x) = 0.03914969408828895 gradient norm = 0.015691944226447648\n",
      "Iteration 45 : x = [2.04339659 4.93890853] f(x) = 0.03912509861188566 gradient norm = 0.015656066700426744\n",
      "Iteration 46 : x = [2.04417996 4.937553  ] f(x) = 0.03910061514383656 gradient norm = 0.015620694085761895\n",
      "Iteration 47 : x = [2.04495639 4.93619757] f(x) = 0.03907624185651797 gradient norm = 0.015585820611927807\n",
      "Iteration 48 : x = [2.04572595 4.93484222] f(x) = 0.03905197695090356 gradient norm = 0.015551440544470654\n",
      "Iteration 49 : x = [2.04648869 4.93348697] f(x) = 0.03902781865614197 gradient norm = 0.015517548185427605\n",
      "Iteration 50 : x = [2.04724466 4.93213181] f(x) = 0.03900376522914002 gradient norm = 0.015484137873732432\n",
      "Iteration 51 : x = [2.04799392 4.93077675] f(x) = 0.03897981495415155 gradient norm = 0.015451203985607183\n",
      "Iteration 52 : x = [2.04873651 4.92942178] f(x) = 0.03895596614237161 gradient norm = 0.015418740934940018\n",
      "Iteration 53 : x = [2.0494725 4.9280669] f(x) = 0.03893221713153638 gradient norm = 0.015386743173649\n",
      "Iteration 54 : x = [2.05020194 4.92671212] f(x) = 0.038908566285528245 gradient norm = 0.015355205192031877\n",
      "Iteration 55 : x = [2.05092488 4.92535743] f(x) = 0.0388850119939863 gradient norm = 0.01532412151910188\n",
      "Iteration 56 : x = [2.05164136 4.92400283] f(x) = 0.038861552671922185 gradient norm = 0.01529348672290946\n",
      "Iteration 57 : x = [2.05235145 4.92264833] f(x) = 0.03883818675934106 gradient norm = 0.015263295410850003\n",
      "Iteration 58 : x = [2.05305519 4.92129391] f(x) = 0.0388149127208678 gradient norm = 0.01523354222995752\n",
      "Iteration 59 : x = [2.05375263 4.91993959] f(x) = 0.03879172904537825 gradient norm = 0.015204221867184387\n",
      "Iteration 60 : x = [2.05444383 4.91858537] f(x) = 0.03876863424563561 gradient norm = 0.015175329049667143\n",
      "Iteration 61 : x = [2.05512883 4.91723123] f(x) = 0.03874562685793175 gradient norm = 0.015146858544978319\n",
      "Iteration 62 : x = [2.05580769 4.91587719] f(x) = 0.03872270544173345 gradient norm = 0.015118805161364459\n",
      "Iteration 63 : x = [2.05648044 4.91452324] f(x) = 0.03869986857933356 gradient norm = 0.015091163747970406\n",
      "Iteration 64 : x = [2.05714715 4.91316938] f(x) = 0.03867711487550703 gradient norm = 0.015063929195049766\n",
      "Iteration 65 : x = [2.05780786 4.91181562] f(x) = 0.03865444295717157 gradient norm = 0.015037096434161866\n",
      "Iteration 66 : x = [2.05846262 4.91046194] f(x) = 0.03863185147305318 gradient norm = 0.015010660438355014\n",
      "Iteration 67 : x = [2.05911147 4.90910836] f(x) = 0.038609339093356274 gradient norm = 0.014984616222336537\n",
      "Iteration 68 : x = [2.05975447 4.90775486] f(x) = 0.03858690450943831 gradient norm = 0.01495895884262928\n",
      "Iteration 69 : x = [2.06039165 4.90640146] f(x) = 0.03856454643348921 gradient norm = 0.014933683397714998\n",
      "Iteration 70 : x = [2.06102308 4.90504815] f(x) = 0.038542263598214985 gradient norm = 0.014908785028164655\n",
      "Iteration 71 : x = [2.06164879 4.90369493] f(x) = 0.0385200547565261 gradient norm = 0.014884258916755738\n",
      "Iteration 72 : x = [2.06226883 4.9023418 ] f(x) = 0.03849791868122995 gradient norm = 0.014860100288576763\n",
      "Iteration 73 : x = [2.06288324 4.90098876] f(x) = 0.03847585416472786 gradient norm = 0.014836304411119073\n",
      "Iteration 74 : x = [2.06349207 4.8996358 ] f(x) = 0.03845386001871633 gradient norm = 0.014812866594356152\n",
      "Iteration 75 : x = [2.06409537 4.89828294] f(x) = 0.03843193507389246 gradient norm = 0.01478978219081054\n",
      "Iteration 76 : x = [2.06469319 4.89693017] f(x) = 0.03841007817966361 gradient norm = 0.014767046595608598\n",
      "Iteration 77 : x = [2.06528555 4.89557748] f(x) = 0.03838828820386117 gradient norm = 0.014744655246523164\n",
      "Iteration 78 : x = [2.06587252 4.89422489] f(x) = 0.03836656403245839 gradient norm = 0.014722603624004375\n",
      "Iteration 79 : x = [2.06645413 4.89287238] f(x) = 0.03834490456929227 gradient norm = 0.014700887251198834\n",
      "Iteration 80 : x = [2.06703042 4.89151995] f(x) = 0.03832330873578946 gradient norm = 0.014679501693957289\n",
      "Iteration 81 : x = [2.06760145 4.89016762] f(x) = 0.038301775470695944 gradient norm = 0.014658442560830976\n",
      "Iteration 82 : x = [2.06816725 4.88881537] f(x) = 0.03828030372981078 gradient norm = 0.014637705503056816\n",
      "Iteration 83 : x = [2.06872786 4.88746321] f(x) = 0.038258892485723624 gradient norm = 0.014617286214531826\n",
      "Iteration 84 : x = [2.06928333 4.88611114] f(x) = 0.0382375407275559 gradient norm = 0.01459718043177663\n",
      "Iteration 85 : x = [2.06983369 4.88475915] f(x) = 0.03821624746070588 gradient norm = 0.014577383933888669\n",
      "Iteration 86 : x = [2.070379   4.88340725] f(x) = 0.038195011706597407 gradient norm = 0.014557892542484937\n",
      "Iteration 87 : x = [2.07091929 4.88205543] f(x) = 0.038173832502432184 gradient norm = 0.01453870212163474\n",
      "Iteration 88 : x = [2.0714546 4.8807037] f(x) = 0.038152708900945694 gradient norm = 0.014519808577782478\n",
      "Iteration 89 : x = [2.07198497 4.87935205] f(x) = 0.038131639970166734 gradient norm = 0.014501207859660864\n",
      "Iteration 90 : x = [2.07251045 4.87800048] f(x) = 0.03811062479318035 gradient norm = 0.014482895958194637\n",
      "Iteration 91 : x = [2.07303106 4.876649  ] f(x) = 0.03808966246789431 gradient norm = 0.01446486890639505\n",
      "Iteration 92 : x = [2.07354686 4.8752976 ] f(x) = 0.03806875210680889 gradient norm = 0.014447122779245408\n",
      "Iteration 93 : x = [2.07405789 4.87394629] f(x) = 0.038047892836790144 gradient norm = 0.014429653693577682\n",
      "Iteration 94 : x = [2.07456417 4.87259506] f(x) = 0.0380270837988464 gradient norm = 0.014412457807940749\n",
      "Iteration 95 : x = [2.07506575 4.87124391] f(x) = 0.03800632414790811 gradient norm = 0.014395531322460128\n",
      "Iteration 96 : x = [2.07556267 4.86989284] f(x) = 0.03798561305261086 gradient norm = 0.014378870478689689\n",
      "Iteration 97 : x = [2.07605496 4.86854185] f(x) = 0.03796494969508162 gradient norm = 0.014362471559455425\n",
      "Iteration 98 : x = [2.07654267 4.86719095] f(x) = 0.03794433327072819 gradient norm = 0.014346330888691573\n",
      "Iteration 99 : x = [2.07702583 4.86584012] f(x) = 0.037923762988031594 gradient norm = 0.014330444831269292\n",
      "Iteration 100 : x = [2.07750448 4.86448938] f(x) = 0.03790323806834175 gradient norm = 0.014314809792818114\n",
      "Iteration 101 : x = [2.07797865 4.86313871] f(x) = 0.037882757745676024 gradient norm = 0.014299422219540364\n",
      "Iteration 102 : x = [2.07844839 4.86178812] f(x) = 0.03786232126652077 gradient norm = 0.014284278598018814\n",
      "Iteration 103 : x = [2.07891372 4.86043762] f(x) = 0.037841927889635946 gradient norm = 0.014269375455017835\n",
      "Iteration 104 : x = [2.07937469 4.85908719] f(x) = 0.03782157688586245 gradient norm = 0.014254709357278104\n",
      "Iteration 105 : x = [2.07983133 4.85773684] f(x) = 0.03780126753793248 gradient norm = 0.014240276911305293\n",
      "Iteration 106 : x = [2.08028367 4.85638656] f(x) = 0.03778099914028266 gradient norm = 0.014226074763152768\n",
      "Iteration 107 : x = [2.08073176 4.85503637] f(x) = 0.03776077099886988 gradient norm = 0.014212099598198651\n",
      "Iteration 108 : x = [2.08117562 4.85368625] f(x) = 0.03774058243099006 gradient norm = 0.014198348140917376\n",
      "Iteration 109 : x = [2.08161529 4.8523362 ] f(x) = 0.03772043276509947 gradient norm = 0.01418481715464602\n",
      "Iteration 110 : x = [2.08205081 4.85098623] f(x) = 0.0377003213406388 gradient norm = 0.01417150344134551\n",
      "Iteration 111 : x = [2.08248221 4.84963634] f(x) = 0.037680247507859845 gradient norm = 0.014158403841357062\n",
      "Iteration 112 : x = [2.08290952 4.84828652] f(x) = 0.037660210627654844 gradient norm = 0.014145515233153933\n",
      "Iteration 113 : x = [2.08333278 4.84693678] f(x) = 0.03764021007138832 gradient norm = 0.014132834533088697\n",
      "Iteration 114 : x = [2.08375202 4.84558711] f(x) = 0.03762024522073142 gradient norm = 0.014120358695136347\n",
      "Iteration 115 : x = [2.08416728 4.84423752] f(x) = 0.03760031546749894 gradient norm = 0.014108084710633326\n",
      "Iteration 116 : x = [2.08457858 4.84288799] f(x) = 0.03758042021348855 gradient norm = 0.014096009608012692\n",
      "Iteration 117 : x = [2.08498596 4.84153854] f(x) = 0.037560558870322676 gradient norm = 0.01408413045253565\n",
      "Iteration 118 : x = [2.08538946 4.84018917] f(x) = 0.03754073085929264 gradient norm = 0.014072444346019604\n",
      "Iteration 119 : x = [2.08578909 4.83883986] f(x) = 0.037520935611205175 gradient norm = 0.014060948426562914\n",
      "Iteration 120 : x = [2.08618491 4.83749062] f(x) = 0.03750117256623137 gradient norm = 0.014049639868266607\n",
      "Iteration 121 : x = [2.08657693 4.83614146] f(x) = 0.03748144117375771 gradient norm = 0.014038515880953053\n",
      "Iteration 122 : x = [2.08696519 4.83479237] f(x) = 0.03746174089223967 gradient norm = 0.014027573709882049\n",
      "Iteration 123 : x = [2.08734972 4.83344334] f(x) = 0.03744207118905721 gradient norm = 0.01401681063546424\n",
      "Iteration 124 : x = [2.08773055 4.83209439] f(x) = 0.03742243154037269 gradient norm = 0.014006223972972126\n",
      "Iteration 125 : x = [2.08810771 4.8307455 ] f(x) = 0.037402821430990954 gradient norm = 0.0139958110722489\n",
      "Iteration 126 : x = [2.08848124 4.82939669] f(x) = 0.03738324035422139 gradient norm = 0.013985569317415205\n",
      "Iteration 127 : x = [2.08885115 4.82804794] f(x) = 0.037363687811742256 gradient norm = 0.013975496126573934\n",
      "Iteration 128 : x = [2.08921749 4.82669926] f(x) = 0.037344163313467016 gradient norm = 0.013965588951513326\n",
      "Iteration 129 : x = [2.08958028 4.82535064] f(x) = 0.03732466637741271 gradient norm = 0.013955845277408464\n",
      "Iteration 130 : x = [2.08993956 4.8240021 ] f(x) = 0.037305196529570414 gradient norm = 0.01394626262252131\n",
      "Iteration 131 : x = [2.09029534 4.82265362] f(x) = 0.037285753303777536 gradient norm = 0.013936838537899452\n",
      "Iteration 132 : x = [2.09064766 4.8213052 ] f(x) = 0.03726633624159229 gradient norm = 0.013927570607073681\n",
      "Iteration 133 : x = [2.09099656 4.81995685] f(x) = 0.037246944892169946 gradient norm = 0.013918456445754589\n",
      "Iteration 134 : x = [2.09134204 4.81860857] f(x) = 0.03722757881214098 gradient norm = 0.013909493701528245\n",
      "Iteration 135 : x = [2.09168416 4.81726035] f(x) = 0.037208237565491194 gradient norm = 0.013900680053551157\n",
      "Iteration 136 : x = [2.09202293 4.81591219] f(x) = 0.03718892072344363 gradient norm = 0.013892013212244588\n",
      "Iteration 137 : x = [2.09235838 4.8145641 ] f(x) = 0.037169627864342324 gradient norm = 0.01388349091898843\n",
      "Iteration 138 : x = [2.09269053 4.81321607] f(x) = 0.03715035857353781 gradient norm = 0.01387511094581466\n",
      "Iteration 139 : x = [2.09301943 4.8118681 ] f(x) = 0.03713111244327448 gradient norm = 0.013866871095100606\n",
      "Iteration 140 : x = [2.09334509 4.8105202 ] f(x) = 0.03711188907257957 gradient norm = 0.013858769199262022\n",
      "Iteration 141 : x = [2.09366754 4.80917235] f(x) = 0.037092688067154066 gradient norm = 0.013850803120446228\n",
      "Iteration 142 : x = [2.09398681 4.80782457] f(x) = 0.037073509039265 gradient norm = 0.013842970750225243\n",
      "Iteration 143 : x = [2.09430292 4.80647685] f(x) = 0.037054351607639764 gradient norm = 0.01383527000928922\n",
      "Iteration 144 : x = [2.0946159  4.80512919] f(x) = 0.03703521539736175 gradient norm = 0.01382769884714012\n",
      "Iteration 145 : x = [2.09492578 4.80378159] f(x) = 0.03701610003976788 gradient norm = 0.013820255241785808\n",
      "Iteration 146 : x = [2.09523258 4.80243405] f(x) = 0.0369970051723475 gradient norm = 0.013812937199434671\n",
      "Iteration 147 : x = [2.09553633 4.80108657] f(x) = 0.03697793043864302 gradient norm = 0.013805742754190796\n",
      "Iteration 148 : x = [2.09583705 4.79973914] f(x) = 0.03695887548815204 gradient norm = 0.013798669967749862\n",
      "Iteration 149 : x = [2.09613477 4.79839178] f(x) = 0.03693983997623097 gradient norm = 0.013791716929095818\n",
      "Iteration 150 : x = [2.09642952 4.79704447] f(x) = 0.036920823564000275 gradient norm = 0.013784881754198374\n",
      "Iteration 151 : x = [2.09672132 4.79569722] f(x) = 0.03690182591825096 gradient norm = 0.013778162585711469\n",
      "Iteration 152 : x = [2.09701019 4.79435002] f(x) = 0.03688284671135285 gradient norm = 0.013771557592672776\n",
      "Iteration 153 : x = [2.09729616 4.79300289] f(x) = 0.03686388562116402 gradient norm = 0.013765064970204252\n",
      "Iteration 154 : x = [2.09757925 4.7916558 ] f(x) = 0.03684494233094179 gradient norm = 0.013758682939213895\n",
      "Iteration 155 : x = [2.09785949 4.79030878] f(x) = 0.03682601652925509 gradient norm = 0.01375240974609874\n",
      "Iteration 156 : x = [2.0981369  4.78896181] f(x) = 0.036807107909898155 gradient norm = 0.013746243662449151\n",
      "Iteration 157 : x = [2.09841151 4.78761489] f(x) = 0.0367882161718057 gradient norm = 0.013740182984754486\n",
      "Iteration 158 : x = [2.09868333 4.78626803] f(x) = 0.03676934101896924 gradient norm = 0.013734226034110206\n",
      "Iteration 159 : x = [2.0989524  4.78492122] f(x) = 0.03675048216035489 gradient norm = 0.013728371155926485\n",
      "Iteration 160 : x = [2.09921873 4.78357447] f(x) = 0.03673163930982238 gradient norm = 0.013722616719638345\n",
      "Iteration 161 : x = [2.09948235 4.78222776] f(x) = 0.036712812186045385 gradient norm = 0.013716961118417425\n",
      "Iteration 162 : x = [2.09974328 4.78088111] f(x) = 0.03669400051243307 gradient norm = 0.013711402768885413\n",
      "Iteration 163 : x = [2.10000154 4.77953452] f(x) = 0.036675204017052904 gradient norm = 0.01370594011082915\n",
      "Iteration 164 : x = [2.10025716 4.77818797] f(x) = 0.036656422432554674 gradient norm = 0.013700571606917535\n",
      "Iteration 165 : x = [2.10051016 4.77684147] f(x) = 0.03663765549609575 gradient norm = 0.013695295742420217\n",
      "Iteration 166 : x = [2.10076056 4.77549503] f(x) = 0.036618902949267444 gradient norm = 0.013690111024928115\n",
      "Iteration 167 : x = [2.10100838 4.77414864] f(x) = 0.0366001645380226 gradient norm = 0.013685015984075836\n",
      "Iteration 168 : x = [2.10125365 4.77280229] f(x) = 0.03658144001260435 gradient norm = 0.013680009171266052\n",
      "Iteration 169 : x = [2.10149638 4.771456  ] f(x) = 0.03656272912747589 gradient norm = 0.013675089159395745\n",
      "Iteration 170 : x = [2.1017366  4.77010975] f(x) = 0.03654403164125154 gradient norm = 0.01367025454258457\n",
      "Iteration 171 : x = [2.10197432 4.76876356] f(x) = 0.036525347316628744 gradient norm = 0.013665503935905167\n",
      "Iteration 172 : x = [2.10220958 4.76741741] f(x) = 0.03650667592032118 gradient norm = 0.01366083597511553\n",
      "Iteration 173 : x = [2.10244239 4.76607131] f(x) = 0.03648801722299306 gradient norm = 0.013656249316393506\n",
      "Iteration 174 : x = [2.10267276 4.76472526] f(x) = 0.036469370999194284 gradient norm = 0.013651742636073388\n",
      "Iteration 175 : x = [2.10290073 4.76337925] f(x) = 0.03645073702729678 gradient norm = 0.013647314630384634\n",
      "Iteration 176 : x = [2.10312631 4.76203329] f(x) = 0.03643211508943176 gradient norm = 0.013642964015192778\n",
      "Iteration 177 : x = [2.10334953 4.76068738] f(x) = 0.03641350497142807 gradient norm = 0.013638689525742492\n",
      "Iteration 178 : x = [2.10357039 4.75934151] f(x) = 0.0363949064627514 gradient norm = 0.013634489916402889\n",
      "Iteration 179 : x = [2.10378893 4.75799569] f(x) = 0.036376319356444586 gradient norm = 0.013630363960415027\n",
      "Iteration 180 : x = [2.10400516 4.75664992] f(x) = 0.03635774344906882 gradient norm = 0.013626310449641632\n",
      "Iteration 181 : x = [2.1042191  4.75530418] f(x) = 0.036339178540645736 gradient norm = 0.01362232819431916\n",
      "Iteration 182 : x = [2.10443077 4.7539585 ] f(x) = 0.0363206244346005 gradient norm = 0.013618416022812\n",
      "Iteration 183 : x = [2.10464019 4.75261285] f(x) = 0.036302080937705865 gradient norm = 0.013614572781369074\n",
      "Iteration 184 : x = [2.10484738 4.75126725] f(x) = 0.0362835478600269 gradient norm = 0.013610797333882676\n",
      "Iteration 185 : x = [2.10505236 4.7499217 ] f(x) = 0.03626502501486693 gradient norm = 0.013607088561649605\n",
      "Iteration 186 : x = [2.10525514 4.74857618] f(x) = 0.03624651221871402 gradient norm = 0.013603445363134644\n",
      "Iteration 187 : x = [2.10545575 4.74723071] f(x) = 0.036228009291188516 gradient norm = 0.01359986665373634\n",
      "Iteration 188 : x = [2.10565421 4.74588528] f(x) = 0.03620951605499142 gradient norm = 0.013596351365555065\n",
      "Iteration 189 : x = [2.10585052 4.7445399 ] f(x) = 0.036191032335853426 gradient norm = 0.013592898447163501\n",
      "Iteration 190 : x = [2.10604472 4.74319455] f(x) = 0.036172557962485065 gradient norm = 0.013589506863379371\n",
      "Iteration 191 : x = [2.10623682 4.74184925] f(x) = 0.036154092766527354 gradient norm = 0.013586175595040528\n",
      "Iteration 192 : x = [2.10642683 4.74050398] f(x) = 0.03613563658250341 gradient norm = 0.013582903638782418\n",
      "Iteration 193 : x = [2.10661478 4.73915876] f(x) = 0.036117189247770846 gradient norm = 0.013579690006817817\n",
      "Iteration 194 : x = [2.10680068 4.73781357] f(x) = 0.036098750602474826 gradient norm = 0.013576533726718945\n",
      "Iteration 195 : x = [2.10698454 4.73646843] f(x) = 0.036080320489502014 gradient norm = 0.013573433841201925\n",
      "Iteration 196 : x = [2.1071664  4.73512332] f(x) = 0.0360618987544351 gradient norm = 0.01357038940791352\n",
      "Iteration 197 : x = [2.10734626 4.73377825] f(x) = 0.03604348524550825 gradient norm = 0.013567399499220258\n",
      "Iteration 198 : x = [2.10752414 4.73243322] f(x) = 0.03602507981356318 gradient norm = 0.013564463201999851\n",
      "Iteration 199 : x = [2.10770005 4.73108823] f(x) = 0.03600668231200582 gradient norm = 0.013561579617434934\n",
      "Iteration 200 : x = [2.10787402 4.72974328] f(x) = 0.035988292596763956 gradient norm = 0.01355874786080912\n",
      "Iteration 201 : x = [2.10804606 4.72839837] f(x) = 0.03596991052624529 gradient norm = 0.013555967061305364\n",
      "Iteration 202 : x = [2.10821619 4.72705349] f(x) = 0.035951535961296376 gradient norm = 0.013553236361806654\n",
      "Iteration 203 : x = [2.10838443 4.72570864] f(x) = 0.03593316876516205 gradient norm = 0.013550554918698937\n",
      "Iteration 204 : x = [2.10855078 4.72436384] f(x) = 0.035914808803445664 gradient norm = 0.01354792190167635\n",
      "Iteration 205 : x = [2.10871527 4.72301907] f(x) = 0.035896455944069865 gradient norm = 0.013545336493548792\n",
      "Iteration 206 : x = [2.10887791 4.72167434] f(x) = 0.035878110057238094 gradient norm = 0.013542797890051642\n",
      "Iteration 207 : x = [2.10903872 4.72032964] f(x) = 0.035859771015396655 gradient norm = 0.013540305299657836\n",
      "Iteration 208 : x = [2.10919771 4.71898497] f(x) = 0.03584143869319733 gradient norm = 0.013537857943392103\n",
      "Iteration 209 : x = [2.10935491 4.71764035] f(x) = 0.03582311296746082 gradient norm = 0.013535455054647535\n",
      "Iteration 210 : x = [2.10951031 4.71629575] f(x) = 0.03580479371714051 gradient norm = 0.013533095879004252\n",
      "Iteration 211 : x = [2.10966395 4.71495119] f(x) = 0.03578648082328706 gradient norm = 0.013530779674050385\n",
      "Iteration 212 : x = [2.10981583 4.71360666] f(x) = 0.03576817416901343 gradient norm = 0.013528505709205184\n",
      "Iteration 213 : x = [2.10996597 4.71226217] f(x) = 0.03574987363946046 gradient norm = 0.013526273265544349\n",
      "Iteration 214 : x = [2.11011439 4.71091771] f(x) = 0.035731579121763175 gradient norm = 0.013524081635627492\n",
      "Iteration 215 : x = [2.11026109 4.70957328] f(x) = 0.03571329050501741 gradient norm = 0.013521930123327787\n",
      "Iteration 216 : x = [2.1104061  4.70822889] f(x) = 0.03569500768024718 gradient norm = 0.013519818043663732\n",
      "Iteration 217 : x = [2.11054943 4.70688452] f(x) = 0.03567673054037247 gradient norm = 0.013517744722633052\n",
      "Iteration 218 : x = [2.1106911  4.70554019] f(x) = 0.035658458980177596 gradient norm = 0.013515709497048722\n",
      "Iteration 219 : x = [2.11083111 4.70419589] f(x) = 0.03564019289628003 gradient norm = 0.013513711714377045\n",
      "Iteration 220 : x = [2.11096948 4.70285163] f(x) = 0.03562193218709983 gradient norm = 0.013511750732577814\n",
      "Iteration 221 : x = [2.11110623 4.70150739] f(x) = 0.03560367675282948 gradient norm = 0.013509825919946625\n",
      "Iteration 222 : x = [2.11124137 4.70016318] f(x) = 0.03558542649540423 gradient norm = 0.013507936654959073\n",
      "Iteration 223 : x = [2.11137491 4.69881901] f(x) = 0.035567181318473 gradient norm = 0.013506082326117134\n",
      "Iteration 224 : x = [2.11150687 4.69747486] f(x) = 0.03554894112736967 gradient norm = 0.01350426233179745\n",
      "Iteration 225 : x = [2.11163726 4.69613074] f(x) = 0.03553070582908493 gradient norm = 0.013502476080101713\n",
      "Iteration 226 : x = [2.1117661  4.69478666] f(x) = 0.035512475332238454 gradient norm = 0.013500722988708878\n",
      "Iteration 227 : x = [2.11189339 4.6934426 ] f(x) = 0.035494249547051694 gradient norm = 0.013499002484729508\n",
      "Iteration 228 : x = [2.11201916 4.69209857] f(x) = 0.035476028385321 gradient norm = 0.013497314004561944\n",
      "Iteration 229 : x = [2.11214341 4.69075457] f(x) = 0.03545781176039126 gradient norm = 0.013495656993750452\n",
      "Iteration 230 : x = [2.11226616 4.6894106 ] f(x) = 0.0354395995871299 gradient norm = 0.013494030906845245\n",
      "Iteration 231 : x = [2.11238742 4.68806665] f(x) = 0.035421391781901373 gradient norm = 0.013492435207264446\n",
      "Iteration 232 : x = [2.1125072  4.68672274] f(x) = 0.03540318826254201 gradient norm = 0.01349086936715788\n",
      "Iteration 233 : x = [2.11262552 4.68537885] f(x) = 0.03538498894833539 gradient norm = 0.013489332867272734\n",
      "Iteration 234 : x = [2.11274238 4.68403499] f(x) = 0.03536679375998795 gradient norm = 0.01348782519682106\n",
      "Iteration 235 : x = [2.11285781 4.68269115] f(x) = 0.03534860261960515 gradient norm = 0.013486345853349091\n",
      "Iteration 236 : x = [2.11297181 4.68134735] f(x) = 0.035330415450668 gradient norm = 0.013484894342608373\n",
      "Iteration 237 : x = [2.1130844  4.68000356] f(x) = 0.03531223217800982 gradient norm = 0.013483470178428651\n",
      "Iteration 238 : x = [2.11319559 4.67865981] f(x) = 0.03529405272779361 gradient norm = 0.013482072882592532\n",
      "Iteration 239 : x = [2.11330539 4.67731608] f(x) = 0.035275877027489695 gradient norm = 0.013480701984711907\n",
      "Iteration 240 : x = [2.11341381 4.67597238] f(x) = 0.035257705005853714 gradient norm = 0.013479357022106076\n",
      "Iteration 241 : x = [2.11352086 4.6746287 ] f(x) = 0.035239536592904915 gradient norm = 0.01347803753968163\n",
      "Iteration 242 : x = [2.11362656 4.67328505] f(x) = 0.03522137171990502 gradient norm = 0.013476743089813944\n",
      "Iteration 243 : x = [2.11373092 4.67194142] f(x) = 0.03520321031933726 gradient norm = 0.013475473232230419\n",
      "Iteration 244 : x = [2.11383395 4.67059782] f(x) = 0.03518505232488569 gradient norm = 0.013474227533895333\n",
      "Iteration 245 : x = [2.11393566 4.66925424] f(x) = 0.03516689767141513 gradient norm = 0.013473005568896365\n",
      "Iteration 246 : x = [2.11403606 4.66791068] f(x) = 0.03514874629495116 gradient norm = 0.013471806918332673\n",
      "Iteration 247 : x = [2.11413517 4.66656715] f(x) = 0.035130598132660576 gradient norm = 0.013470631170204665\n",
      "Iteration 248 : x = [2.11423299 4.66522365] f(x) = 0.03511245312283218 gradient norm = 0.013469477919305249\n",
      "Iteration 249 : x = [2.11432953 4.66388016] f(x) = 0.035094311204857766 gradient norm = 0.013468346767112756\n",
      "Iteration 250 : x = [2.11442482 4.6625367 ] f(x) = 0.03507617231921363 gradient norm = 0.013467237321685284\n",
      "Iteration 251 : x = [2.11451885 4.66119327] f(x) = 0.03505803640744216 gradient norm = 0.013466149197556678\n",
      "Iteration 252 : x = [2.11461164 4.65984985] f(x) = 0.03503990341213388 gradient norm = 0.013465082015633968\n",
      "Iteration 253 : x = [2.11470321 4.65850646] f(x) = 0.03502177327690979 gradient norm = 0.0134640354030963\n",
      "Iteration 254 : x = [2.11479355 4.65716309] f(x) = 0.03500364594640387 gradient norm = 0.01346300899329534\n",
      "Iteration 255 : x = [2.11488268 4.65581975] f(x) = 0.034985521366246046 gradient norm = 0.01346200242565717\n",
      "Iteration 256 : x = [2.11497062 4.65447642] f(x) = 0.03496739948304529 gradient norm = 0.013461015345585567\n",
      "Iteration 257 : x = [2.11505737 4.65313312] f(x) = 0.03494928024437313 gradient norm = 0.013460047404366736\n",
      "Iteration 258 : x = [2.11514294 4.65178983] f(x) = 0.03493116359874733 gradient norm = 0.013459098259075439\n",
      "Iteration 259 : x = [2.11522734 4.65044657] f(x) = 0.03491304949561588 gradient norm = 0.013458167572482532\n",
      "Iteration 260 : x = [2.11531058 4.64910333] f(x) = 0.034894937885341294 gradient norm = 0.013457255012963814\n",
      "Iteration 261 : x = [2.11539268 4.64776012] f(x) = 0.03487682871918507 gradient norm = 0.013456360254410294\n",
      "Iteration 262 : x = [2.11547364 4.64641692] f(x) = 0.03485872194929255 gradient norm = 0.013455482976139762\n",
      "Iteration 263 : x = [2.11555348 4.64507374] f(x) = 0.03484061752867786 gradient norm = 0.013454622862809663\n",
      "Iteration 264 : x = [2.1156322  4.64373058] f(x) = 0.03482251541120931 gradient norm = 0.013453779604331298\n",
      "Iteration 265 : x = [2.11570981 4.64238744] f(x) = 0.03480441555159477 gradient norm = 0.01345295289578533\n",
      "Iteration 266 : x = [2.11578632 4.64104433] f(x) = 0.034786317905367584 gradient norm = 0.013452142437338449\n",
      "Iteration 267 : x = [2.11586174 4.63970123] f(x) = 0.0347682224288725 gradient norm = 0.013451347934161473\n",
      "Iteration 268 : x = [2.11593609 4.63835815] f(x) = 0.03475012907925191 gradient norm = 0.013450569096348505\n",
      "Iteration 269 : x = [2.11600936 4.63701509] f(x) = 0.034732037814432355 gradient norm = 0.01344980563883741\n",
      "Iteration 270 : x = [2.11608158 4.63567205] f(x) = 0.0347139485931112 gradient norm = 0.013449057281331483\n",
      "Iteration 271 : x = [2.11615274 4.63432903] f(x) = 0.034695861374743564 gradient norm = 0.013448323748222283\n",
      "Iteration 272 : x = [2.11622287 4.63298602] f(x) = 0.03467777611952944 gradient norm = 0.013447604768513623\n",
      "Iteration 273 : x = [2.11629196 4.63164304] f(x) = 0.034659692788401066 gradient norm = 0.013446900075746797\n",
      "Iteration 274 : x = [2.11636002 4.63030007] f(x) = 0.03464161134301049 gradient norm = 0.013446209407926844\n",
      "Iteration 275 : x = [2.11642707 4.62895713] f(x) = 0.03462353174571733 gradient norm = 0.013445532507450004\n",
      "Iteration 276 : x = [2.11649312 4.6276142 ] f(x) = 0.03460545395957675 gradient norm = 0.013444869121032281\n",
      "Iteration 277 : x = [2.11655817 4.62627128] f(x) = 0.034587377948327676 gradient norm = 0.013444218999639055\n",
      "Iteration 278 : x = [2.11662223 4.62492839] f(x) = 0.034569303676381134 gradient norm = 0.013443581898415831\n",
      "Iteration 279 : x = [2.11668532 4.62358551] f(x) = 0.03455123110880881 gradient norm = 0.013442957576620038\n",
      "Iteration 280 : x = [2.11674743 4.62224265] f(x) = 0.03453316021133189 gradient norm = 0.013442345797553835\n",
      "Iteration 281 : x = [2.11680858 4.62089981] f(x) = 0.03451509095030993 gradient norm = 0.013441746328498028\n",
      "Iteration 282 : x = [2.11686877 4.61955698] f(x) = 0.03449702329273002 gradient norm = 0.01344115894064694\n",
      "Iteration 283 : x = [2.11692802 4.61821417] f(x) = 0.03447895720619615 gradient norm = 0.01344058340904435\n",
      "Iteration 284 : x = [2.11698633 4.61687138] f(x) = 0.03446089265891863 gradient norm = 0.013440019512520359\n",
      "Iteration 285 : x = [2.11704372 4.6155286 ] f(x) = 0.03444282961970385 gradient norm = 0.0134394670336293\n",
      "Iteration 286 : x = [2.11710018 4.61418584] f(x) = 0.03442476805794406 gradient norm = 0.013438925758588603\n",
      "Iteration 287 : x = [2.11715573 4.6128431 ] f(x) = 0.034406707943607444 gradient norm = 0.013438395477218541\n",
      "Iteration 288 : x = [2.11721037 4.61150037] f(x) = 0.03438864924722828 gradient norm = 0.01343787598288305\n",
      "Iteration 289 : x = [2.11726412 4.61015766] f(x) = 0.0343705919398973 gradient norm = 0.013437367072431315\n",
      "Iteration 290 : x = [2.11731698 4.60881496] f(x) = 0.03435253599325222 gradient norm = 0.013436868546140427\n",
      "Iteration 291 : x = [2.11736896 4.60747228] f(x) = 0.03433448137946841 gradient norm = 0.013436380207658813\n",
      "Iteration 292 : x = [2.11742006 4.60612962] f(x) = 0.03431642807124967 gradient norm = 0.013435901863950633\n",
      "Iteration 293 : x = [2.1174703  4.60478697] f(x) = 0.034298376041819345 gradient norm = 0.01343543332524101\n",
      "Iteration 294 : x = [2.11751968 4.60344433] f(x) = 0.03428032526491137 gradient norm = 0.013434974404962146\n",
      "Iteration 295 : x = [2.11756821 4.60210171] f(x) = 0.03426227571476161 gradient norm = 0.013434524919700269\n",
      "Iteration 296 : x = [2.1176159 4.6007591] f(x) = 0.034244227366099195 gradient norm = 0.013434084689143437\n",
      "Iteration 297 : x = [2.11766275 4.59941651] f(x) = 0.03422618019413824 gradient norm = 0.013433653536030132\n",
      "Iteration 298 : x = [2.11770877 4.59807393] f(x) = 0.03420813417456949 gradient norm = 0.013433231286098723\n",
      "Iteration 299 : x = [2.11775397 4.59673137] f(x) = 0.03419008928355221 gradient norm = 0.013432817768037683\n",
      "Iteration 300 : x = [2.11779836 4.59538882] f(x) = 0.034172045497706166 gradient norm = 0.013432412813436604\n",
      "Iteration 301 : x = [2.11784194 4.59404629] f(x) = 0.03415400279410378 gradient norm = 0.013432016256738009\n",
      "Iteration 302 : x = [2.11788473 4.59270377] f(x) = 0.034135961150262385 gradient norm = 0.013431627935189908\n",
      "Iteration 303 : x = [2.11792672 4.59136126] f(x) = 0.03411792054413664 gradient norm = 0.01343124768879914\n",
      "Iteration 304 : x = [2.11796792 4.59001877] f(x) = 0.03409988095411105 gradient norm = 0.013430875360285413\n",
      "Iteration 305 : x = [2.11800835 4.58867629] f(x) = 0.03408184235899261 gradient norm = 0.013430510795036123\n",
      "Iteration 306 : x = [2.118048   4.58733383] f(x) = 0.03406380473800364 gradient norm = 0.013430153841061877\n",
      "Iteration 307 : x = [2.11808689 4.58599137] f(x) = 0.0340457680707746 gradient norm = 0.013429804348952693\n",
      "Iteration 308 : x = [2.11812502 4.58464894] f(x) = 0.03402773233733719 gradient norm = 0.013429462171834989\n",
      "Iteration 309 : x = [2.1181624  4.58330651] f(x) = 0.03400969751811746 gradient norm = 0.01342912716532917\n",
      "Iteration 310 : x = [2.11819904 4.5819641 ] f(x) = 0.03399166359392904 gradient norm = 0.013428799187507938\n",
      "Iteration 311 : x = [2.11823493 4.5806217 ] f(x) = 0.03397363054596657 gradient norm = 0.013428478098855275\n",
      "Iteration 312 : x = [2.1182701  4.57927931] f(x) = 0.03395559835579915 gradient norm = 0.013428163762226074\n",
      "Iteration 313 : x = [2.11830454 4.57793693] f(x) = 0.03393756700536393 gradient norm = 0.013427856042806434\n",
      "Iteration 314 : x = [2.11833826 4.57659457] f(x) = 0.03391953647695985 gradient norm = 0.013427554808074558\n",
      "Iteration 315 : x = [2.11837127 4.57525222] f(x) = 0.03390150675324141 gradient norm = 0.01342725992776235\n",
      "Iteration 316 : x = [2.11840358 4.57390989] f(x) = 0.03388347781721258 gradient norm = 0.013426971273817557\n",
      "Iteration 317 : x = [2.11843518 4.57256756] f(x) = 0.03386544965222088 gradient norm = 0.013426688720366575\n",
      "Iteration 318 : x = [2.11846609 4.57122525] f(x) = 0.03384742224195145 gradient norm = 0.013426412143677832\n",
      "Iteration 319 : x = [2.11849631 4.56988295] f(x) = 0.03382939557042129 gradient norm = 0.013426141422125767\n",
      "Iteration 320 : x = [2.11852585 4.56854066] f(x) = 0.03381136962197357 gradient norm = 0.013425876436155415\n",
      "Iteration 321 : x = [2.11855472 4.56719838] f(x) = 0.03379334438127205 gradient norm = 0.013425617068247556\n",
      "Iteration 322 : x = [2.11858292 4.56585611] f(x) = 0.03377531983329561 gradient norm = 0.013425363202884368\n",
      "Iteration 323 : x = [2.11861045 4.56451386] f(x) = 0.03375729596333282 gradient norm = 0.013425114726515775\n",
      "Iteration 324 : x = [2.11863733 4.56317162] f(x) = 0.03373927275697668 gradient norm = 0.013424871527526198\n",
      "Iteration 325 : x = [2.11866355 4.56182939] f(x) = 0.033721250200119374 gradient norm = 0.013424633496201937\n",
      "Iteration 326 : x = [2.11868913 4.56048717] f(x) = 0.03370322827894715 gradient norm = 0.01342440052469907\n",
      "Iteration 327 : x = [2.11871407 4.55914496] f(x) = 0.03368520697993532 gradient norm = 0.01342417250701185\n",
      "Iteration 328 : x = [2.11873838 4.55780276] f(x) = 0.033667186289843276 gradient norm = 0.013423949338941631\n",
      "Iteration 329 : x = [2.11876205 4.55646058] f(x) = 0.03364916619570962 gradient norm = 0.013423730918066317\n",
      "Iteration 330 : x = [2.11878511 4.5551184 ] f(x) = 0.03363114668484741 gradient norm = 0.013423517143710293\n",
      "Iteration 331 : x = [2.11880754 4.55377624] f(x) = 0.03361312774483943 gradient norm = 0.013423307916914847\n",
      "Iteration 332 : x = [2.11882936 4.55243408] f(x) = 0.0335951093635336 gradient norm = 0.0134231031404091\n",
      "Iteration 333 : x = [2.11885058 4.55109194] f(x) = 0.033577091529038414 gradient norm = 0.013422902718581379\n",
      "Iteration 334 : x = [2.1188712  4.54974981] f(x) = 0.03355907422971847 gradient norm = 0.013422706557451085\n",
      "Iteration 335 : x = [2.11889121 4.54840769] f(x) = 0.03354105745419012 gradient norm = 0.013422514564641025\n",
      "Iteration 336 : x = [2.11891064 4.54706558] f(x) = 0.03352304119131715 gradient norm = 0.013422326649350162\n",
      "Iteration 337 : x = [2.11892949 4.54572348] f(x) = 0.03350502543020647 gradient norm = 0.013422142722326877\n",
      "Iteration 338 : x = [2.11894775 4.54438139] f(x) = 0.03348701016020406 gradient norm = 0.013421962695842603\n",
      "Iteration 339 : x = [2.11896544 4.54303931] f(x) = 0.03346899537089082 gradient norm = 0.013421786483665949\n",
      "Iteration 340 : x = [2.11898256 4.54169724] f(x) = 0.03345098105207851 gradient norm = 0.013421614001037202\n",
      "Iteration 341 : x = [2.11899911 4.54035518] f(x) = 0.03343296719380589 gradient norm = 0.013421445164643296\n",
      "Iteration 342 : x = [2.11901511 4.53901313] f(x) = 0.033414953786334724 gradient norm = 0.01342127989259318\n",
      "Iteration 343 : x = [2.11903055 4.53767109] f(x) = 0.033396940820146055 gradient norm = 0.013421118104393545\n",
      "Iteration 344 : x = [2.11904544 4.53632906] f(x) = 0.03337892828593639 gradient norm = 0.01342095972092505\n",
      "Iteration 345 : x = [2.11905978 4.53498704] f(x) = 0.03336091617461404 gradient norm = 0.013420804664418837\n",
      "Iteration 346 : x = [2.11907359 4.53364503] f(x) = 0.0333429044772955 gradient norm = 0.013420652858433512\n",
      "Iteration 347 : x = [2.11908686 4.53230303] f(x) = 0.03332489318530184 gradient norm = 0.013420504227832468\n",
      "Iteration 348 : x = [2.1190996  4.53096104] f(x) = 0.03330688229015525 gradient norm = 0.013420358698761592\n",
      "Iteration 349 : x = [2.11911181 4.52961906] f(x) = 0.03328887178357557 gradient norm = 0.01342021619862736\n",
      "Iteration 350 : x = [2.11912351 4.52827709] f(x) = 0.03327086165747692 gradient norm = 0.013420076656075258\n",
      "Iteration 351 : x = [2.11913469 4.52693513] f(x) = 0.03325285190396439 gradient norm = 0.013419940000968598\n",
      "Iteration 352 : x = [2.11914535 4.52559318] f(x) = 0.0332348425153307 gradient norm = 0.013419806164367675\n",
      "Iteration 353 : x = [2.11915551 4.52425124] f(x) = 0.03321683348405312 gradient norm = 0.013419675078509262\n",
      "Iteration 354 : x = [2.11916517 4.5229093 ] f(x) = 0.03319882480279017 gradient norm = 0.013419546676786447\n",
      "Iteration 355 : x = [2.11917433 4.52156738] f(x) = 0.03318081646437864 gradient norm = 0.013419420893728828\n",
      "Iteration 356 : x = [2.11918299 4.52022547] f(x) = 0.03316280846183042 gradient norm = 0.013419297664983001\n",
      "Iteration 357 : x = [2.11919117 4.51888356] f(x) = 0.03314480078832963 gradient norm = 0.013419176927293415\n",
      "Iteration 358 : x = [2.11919886 4.51754166] f(x) = 0.0331267934372296 gradient norm = 0.013419058618483515\n",
      "Iteration 359 : x = [2.11920607 4.51619978] f(x) = 0.033108786402049964 gradient norm = 0.013418942677437205\n",
      "Iteration 360 : x = [2.11921281 4.5148579 ] f(x) = 0.033090779676473885 gradient norm = 0.013418829044080635\n",
      "Iteration 361 : x = [2.11921907 4.51351603] f(x) = 0.033072773254345204 gradient norm = 0.013418717659364289\n",
      "Iteration 362 : x = [2.11922487 4.51217417] f(x) = 0.033054767129665714 gradient norm = 0.013418608465245356\n",
      "Iteration 363 : x = [2.1192302  4.51083232] f(x) = 0.03303676129659248 gradient norm = 0.013418501404670408\n",
      "Iteration 364 : x = [2.11923508 4.50949048] f(x) = 0.03301875574943511 gradient norm = 0.013418396421558386\n",
      "Iteration 365 : x = [2.1192395  4.50814865] f(x) = 0.03300075048265329 gradient norm = 0.013418293460783822\n",
      "Iteration 366 : x = [2.11924347 4.50680683] f(x) = 0.03298274549085407 gradient norm = 0.01341819246816041\n",
      "Iteration 367 : x = [2.11924699 4.50546501] f(x) = 0.032964740768789455 gradient norm = 0.013418093390424792\n",
      "Iteration 368 : x = [2.11925007 4.50412321] f(x) = 0.03294673631135388 gradient norm = 0.013417996175220643\n",
      "Iteration 369 : x = [2.11925271 4.50278141] f(x) = 0.0329287321135818 gradient norm = 0.013417900771083027\n",
      "Iteration 370 : x = [2.11925491 4.50143962] f(x) = 0.032910728170645304 gradient norm = 0.013417807127423007\n",
      "Iteration 371 : x = [2.11925669 4.50009784] f(x) = 0.03289272447785173 gradient norm = 0.013417715194512523\n",
      "Iteration 372 : x = [2.11925804 4.49875607] f(x) = 0.03287472103064146 gradient norm = 0.013417624923469505\n",
      "Iteration 373 : x = [2.11925896 4.49741431] f(x) = 0.03285671782458549 gradient norm = 0.01341753626624326\n",
      "Iteration 374 : x = [2.11925946 4.49607255] f(x) = 0.03283871485538339 gradient norm = 0.013417449175600104\n",
      "Iteration 375 : x = [2.11925955 4.49473081] f(x) = 0.032820712118860944 gradient norm = 0.013417363605109188\n",
      "Iteration 376 : x = [2.11925923 4.49338907] f(x) = 0.03280270961096816 gradient norm = 0.013417279509128655\n",
      "Iteration 377 : x = [2.1192585  4.49204735] f(x) = 0.032784707327777 gradient norm = 0.013417196842791941\n",
      "Iteration 378 : x = [2.11925737 4.49070563] f(x) = 0.032766705265479465 gradient norm = 0.013417115561994363\n",
      "Iteration 379 : x = [2.11925583 4.48936392] f(x) = 0.032748703420385404 gradient norm = 0.013417035623379888\n",
      "Iteration 380 : x = [2.1192539  4.48802221] f(x) = 0.0327307017889206 gradient norm = 0.013416956984328196\n",
      "Iteration 381 : x = [2.11925157 4.48668052] f(x) = 0.0327127003676248 gradient norm = 0.013416879602941875\n",
      "Iteration 382 : x = [2.11924886 4.48533883] f(x) = 0.03269469915314973 gradient norm = 0.013416803438033895\n",
      "Iteration 383 : x = [2.11924575 4.48399716] f(x) = 0.03267669814225724 gradient norm = 0.013416728449115267\n",
      "Iteration 384 : x = [2.11924227 4.48265549] f(x) = 0.032658697331817414 gradient norm = 0.01341665459638294\n",
      "Iteration 385 : x = [2.1192384  4.48131383] f(x) = 0.03264069671880675 gradient norm = 0.013416581840707837\n",
      "Iteration 386 : x = [2.11923416 4.47997218] f(x) = 0.0326226963003063 gradient norm = 0.013416510143623194\n",
      "Iteration 387 : x = [2.11922955 4.47863053] f(x) = 0.03260469607350001 gradient norm = 0.01341643946731298\n",
      "Iteration 388 : x = [2.11922456 4.4772889 ] f(x) = 0.032586696035672866 gradient norm = 0.013416369774600635\n",
      "Iteration 389 : x = [2.11921922 4.47594727] f(x) = 0.03256869618420925 gradient norm = 0.013416301028937885\n",
      "Iteration 390 : x = [2.1192135  4.47460566] f(x) = 0.032550696516591204 gradient norm = 0.013416233194393832\n",
      "Iteration 391 : x = [2.11920743 4.47326405] f(x) = 0.03253269703039686 gradient norm = 0.01341616623564419\n",
      "Iteration 392 : x = [2.11920101 4.47192245] f(x) = 0.032514697723298736 gradient norm = 0.013416100117960707\n",
      "Iteration 393 : x = [2.11919423 4.47058085] f(x) = 0.03249669859306216 gradient norm = 0.013416034807200768\n",
      "Iteration 394 : x = [2.1191871  4.46923927] f(x) = 0.032478699637543754 gradient norm = 0.013415970269797201\n",
      "Iteration 395 : x = [2.11917962 4.46789769] f(x) = 0.03246070085468984 gradient norm = 0.01341590647274819\n",
      "Iteration 396 : x = [2.1191718  4.46655612] f(x) = 0.032442702242534954 gradient norm = 0.013415843383607445\n",
      "Iteration 397 : x = [2.11916365 4.46521456] f(x) = 0.032424703799200316 gradient norm = 0.013415780970474488\n",
      "Iteration 398 : x = [2.11915515 4.46387301] f(x) = 0.03240670552289246 gradient norm = 0.01341571920198509\n",
      "Iteration 399 : x = [2.11914632 4.46253147] f(x) = 0.03238870741190169 gradient norm = 0.013415658047301928\n",
      "Iteration 400 : x = [2.11913716 4.46118994] f(x) = 0.032370709464600765 gradient norm = 0.01341559747610533\n",
      "Iteration 401 : x = [2.11912767 4.45984841] f(x) = 0.03235271167944347 gradient norm = 0.013415537458584276\n",
      "Iteration 402 : x = [2.11911786 4.45850689] f(x) = 0.03233471405496323 gradient norm = 0.013415477965427422\n",
      "Iteration 403 : x = [2.11910772 4.45716538] f(x) = 0.03231671658977184 gradient norm = 0.013415418967814396\n",
      "Iteration 404 : x = [2.11909726 4.45582388] f(x) = 0.03229871928255809 gradient norm = 0.013415360437407188\n",
      "Iteration 405 : x = [2.11908649 4.45448239] f(x) = 0.03228072213208652 gradient norm = 0.013415302346341666\n",
      "Iteration 406 : x = [2.11907541 4.4531409 ] f(x) = 0.03226272513719612 gradient norm = 0.0134152446672193\n",
      "Iteration 407 : x = [2.11906401 4.45179943] f(x) = 0.032244728296799106 gradient norm = 0.013415187373098993\n",
      "Iteration 408 : x = [2.11905231 4.45045796] f(x) = 0.032226731609879676 gradient norm = 0.013415130437489002\n",
      "Iteration 409 : x = [2.11904031 4.4491165 ] f(x) = 0.03220873507549286 gradient norm = 0.01341507383433911\n",
      "Iteration 410 : x = [2.119028   4.44777505] f(x) = 0.03219073869276323 gradient norm = 0.013415017538032835\n",
      "Iteration 411 : x = [2.11901539 4.44643361] f(x) = 0.032172742460883884 gradient norm = 0.01341496152337979\n",
      "Iteration 412 : x = [2.11900248 4.44509217] f(x) = 0.0321547463791152 gradient norm = 0.013414905765608253\n",
      "Iteration 413 : x = [2.11898928 4.44375075] f(x) = 0.032136750446783754 gradient norm = 0.013414850240357724\n",
      "Iteration 414 : x = [2.1189758  4.44240933] f(x) = 0.0321187546632812 gradient norm = 0.01341479492367173\n",
      "Iteration 415 : x = [2.11896202 4.44106792] f(x) = 0.03210075902806324 gradient norm = 0.013414739791990723\n",
      "Iteration 416 : x = [2.11894795 4.43972652] f(x) = 0.0320827635406485 gradient norm = 0.013414684822145043\n",
      "Iteration 417 : x = [2.11893361 4.43838513] f(x) = 0.03206476820061753 gradient norm = 0.013414629991348088\n",
      "Iteration 418 : x = [2.11891898 4.43704375] f(x) = 0.03204677300761179 gradient norm = 0.013414575277189544\n",
      "Iteration 419 : x = [2.11890407 4.43570237] f(x) = 0.03202877796133256 gradient norm = 0.013414520657628735\n",
      "Iteration 420 : x = [2.11888889 4.43436101] f(x) = 0.03201078306154004 gradient norm = 0.013414466110988125\n",
      "Iteration 421 : x = [2.11887344 4.43301965] f(x) = 0.0319927883080524 gradient norm = 0.013414411615946881\n",
      "Iteration 422 : x = [2.11885771 4.4316783 ] f(x) = 0.03197479370074469 gradient norm = 0.013414357151534587\n",
      "Iteration 423 : x = [2.11884172 4.43033696] f(x) = 0.03195679923954808 gradient norm = 0.013414302697125046\n",
      "Iteration 424 : x = [2.11882546 4.42899563] f(x) = 0.031938804924448755 gradient norm = 0.013414248232430204\n",
      "Iteration 425 : x = [2.11880894 4.4276543 ] f(x) = 0.031920810755487194 gradient norm = 0.013414193737494145\n",
      "Iteration 426 : x = [2.11879216 4.42631299] f(x) = 0.031902816732757154 gradient norm = 0.013414139192687233\n",
      "Iteration 427 : x = [2.11877512 4.42497168] f(x) = 0.03188482285640481 gradient norm = 0.013414084578700334\n",
      "Iteration 428 : x = [2.11875783 4.42363039] f(x) = 0.031866829126627985 gradient norm = 0.013414029876539122\n",
      "Iteration 429 : x = [2.11874028 4.4222891 ] f(x) = 0.03184883554367522 gradient norm = 0.013413975067518529\n",
      "Iteration 430 : x = [2.11872248 4.42094782] f(x) = 0.03183084210784497 gradient norm = 0.013413920133257233\n",
      "Iteration 431 : x = [2.11870443 4.41960655] f(x) = 0.0318128488194848 gradient norm = 0.013413865055672268\n",
      "Iteration 432 : x = [2.11868613 4.41826529] f(x) = 0.03179485567899061 gradient norm = 0.013413809816973767\n",
      "Iteration 433 : x = [2.11866759 4.41692403] f(x) = 0.03177686268680579 gradient norm = 0.013413754399659713\n",
      "Iteration 434 : x = [2.11864881 4.41558279] f(x) = 0.0317588698434205 gradient norm = 0.013413698786510853\n",
      "Iteration 435 : x = [2.11862979 4.41424155] f(x) = 0.03174087714937093 gradient norm = 0.013413642960585661\n",
      "Iteration 436 : x = [2.11861053 4.41290033] f(x) = 0.03172288460523849 gradient norm = 0.01341358690521539\n",
      "Iteration 437 : x = [2.11859104 4.41155911] f(x) = 0.03170489221164914 gradient norm = 0.013413530603999252\n",
      "Iteration 438 : x = [2.11857131 4.4102179 ] f(x) = 0.031686899969272646 gradient norm = 0.013413474040799601\n",
      "Iteration 439 : x = [2.11855135 4.4088767 ] f(x) = 0.03166890787882191 gradient norm = 0.013413417199737298\n",
      "Iteration 440 : x = [2.11853116 4.40753552] f(x) = 0.03165091594105219 gradient norm = 0.013413360065187053\n",
      "Iteration 441 : x = [2.11851074 4.40619433] f(x) = 0.03163292415676054 gradient norm = 0.013413302621772942\n",
      "Iteration 442 : x = [2.1184901  4.40485316] f(x) = 0.031614932526785086 gradient norm = 0.013413244854363938\n",
      "Iteration 443 : x = [2.11846924 4.403512  ] f(x) = 0.031596941052004335 gradient norm = 0.013413186748069546\n",
      "Iteration 444 : x = [2.11844816 4.40217085] f(x) = 0.031578949733336616 gradient norm = 0.013413128288235501\n",
      "Iteration 445 : x = [2.11842686 4.4008297 ] f(x) = 0.03156095857173935 gradient norm = 0.013413069460439563\n",
      "Iteration 446 : x = [2.11840534 4.39948857] f(x) = 0.03154296756820852 gradient norm = 0.013413010250487353\n",
      "Iteration 447 : x = [2.11838361 4.39814744] f(x) = 0.03152497672377801 gradient norm = 0.01341295064440829\n",
      "Iteration 448 : x = [2.11836166 4.39680633] f(x) = 0.03150698603951903 gradient norm = 0.013412890628451583\n",
      "Iteration 449 : x = [2.11833951 4.39546522] f(x) = 0.0314889955165395 gradient norm = 0.013412830189082304\n",
      "Iteration 450 : x = [2.11831714 4.39412413] f(x) = 0.031471005155983486 gradient norm = 0.013412769312977503\n",
      "Iteration 451 : x = [2.11829457 4.39278304] f(x) = 0.031453014959030676 gradient norm = 0.013412707987022413\n",
      "Iteration 452 : x = [2.11827179 4.39144196] f(x) = 0.03143502492689575 gradient norm = 0.013412646198306753\n",
      "Iteration 453 : x = [2.11824882 4.39010089] f(x) = 0.03141703506082786 gradient norm = 0.013412583934120998\n",
      "Iteration 454 : x = [2.11822564 4.38875984] f(x) = 0.03139904536211013 gradient norm = 0.013412521181952823\n",
      "Iteration 455 : x = [2.11820226 4.38741879] f(x) = 0.0313810558320591 gradient norm = 0.013412457929483548\n",
      "Iteration 456 : x = [2.11817868 4.38607775] f(x) = 0.03136306647202419 gradient norm = 0.013412394164584653\n",
      "Iteration 457 : x = [2.11815491 4.38473672] f(x) = 0.0313450772833872 gradient norm = 0.01341232987531435\n",
      "Iteration 458 : x = [2.11813094 4.3833957 ] f(x) = 0.031327088267561864 gradient norm = 0.013412265049914253\n",
      "Iteration 459 : x = [2.11810679 4.38205469] f(x) = 0.03130909942599328 gradient norm = 0.013412199676806047\n",
      "Iteration 460 : x = [2.11808244 4.38071369] f(x) = 0.03129111076015747 gradient norm = 0.013412133744588262\n",
      "Iteration 461 : x = [2.1180579  4.37937271] f(x) = 0.031273122271560885 gradient norm = 0.013412067242033065\n",
      "Iteration 462 : x = [2.11803318 4.37803173] f(x) = 0.03125513396174001 gradient norm = 0.013412000158083161\n",
      "Iteration 463 : x = [2.11800828 4.37669076] f(x) = 0.031237145832260782 gradient norm = 0.013411932481848686\n",
      "Iteration 464 : x = [2.11798319 4.3753498 ] f(x) = 0.031219157884718265 gradient norm = 0.013411864202604195\n",
      "Iteration 465 : x = [2.11795791 4.37400885] f(x) = 0.031201170120736164 gradient norm = 0.013411795309785696\n",
      "Iteration 466 : x = [2.11793246 4.37266791] f(x) = 0.031183182541966337 gradient norm = 0.013411725792987727\n",
      "Iteration 467 : x = [2.11790684 4.37132698] f(x) = 0.031165195150088493 gradient norm = 0.013411655641960485\n",
      "Iteration 468 : x = [2.11788103 4.36998607] f(x) = 0.031147207946809648 gradient norm = 0.013411584846607016\n",
      "Iteration 469 : x = [2.11785505 4.36864516] f(x) = 0.031129220933863787 gradient norm = 0.013411513396980433\n",
      "Iteration 470 : x = [2.1178289  4.36730426] f(x) = 0.031111234113011487 gradient norm = 0.013411441283281207\n",
      "Iteration 471 : x = [2.11780257 4.36596338] f(x) = 0.031093247486039415 gradient norm = 0.013411368495854512\n",
      "Iteration 472 : x = [2.11777608 4.3646225 ] f(x) = 0.031075261054760075 gradient norm = 0.013411295025187557\n",
      "Iteration 473 : x = [2.11774942 4.36328164] f(x) = 0.031057274821011317 gradient norm = 0.013411220861907033\n",
      "Iteration 474 : x = [2.11772259 4.36194079] f(x) = 0.031039288786656054 gradient norm = 0.013411145996776582\n",
      "Iteration 475 : x = [2.11769559 4.36059994] f(x) = 0.031021302953581787 gradient norm = 0.013411070420694301\n",
      "Iteration 476 : x = [2.11766844 4.35925911] f(x) = 0.031003317323700395 gradient norm = 0.013410994124690287\n",
      "Iteration 477 : x = [2.11764112 4.35791829] f(x) = 0.030985331898947612 gradient norm = 0.01341091709992423\n",
      "Iteration 478 : x = [2.11761364 4.35657748] f(x) = 0.03096734668128282 gradient norm = 0.013410839337683098\n",
      "Iteration 479 : x = [2.117586   4.35523668] f(x) = 0.03094936167268863 gradient norm = 0.01341076082937874\n",
      "Iteration 480 : x = [2.1175582  4.35389589] f(x) = 0.030931376875170585 gradient norm = 0.013410681566545663\n",
      "Iteration 481 : x = [2.11753025 4.35255512] f(x) = 0.03091339229075681 gradient norm = 0.013410601540838781\n",
      "Iteration 482 : x = [2.11750214 4.35121435] f(x) = 0.03089540792149768 gradient norm = 0.013410520744031205\n",
      "Iteration 483 : x = [2.11747388 4.3498736 ] f(x) = 0.030877423769465548 gradient norm = 0.01341043916801208\n",
      "Iteration 484 : x = [2.11744547 4.34853285] f(x) = 0.030859439836754408 gradient norm = 0.013410356804784484\n",
      "Iteration 485 : x = [2.11741691 4.34719212] f(x) = 0.03084145612547954 gradient norm = 0.0134102736464633\n",
      "Iteration 486 : x = [2.1173882 4.3458514] f(x) = 0.030823472637777304 gradient norm = 0.013410189685273213\n",
      "Iteration 487 : x = [2.11735934 4.34451069] f(x) = 0.030805489375804816 gradient norm = 0.013410104913546666\n",
      "Iteration 488 : x = [2.11733033 4.34317   ] f(x) = 0.0307875063417396 gradient norm = 0.013410019323721892\n",
      "Iteration 489 : x = [2.11730118 4.34182931] f(x) = 0.030769523537779377 gradient norm = 0.013409932908340963\n",
      "Iteration 490 : x = [2.11727189 4.34048864] f(x) = 0.03075154096614174 gradient norm = 0.013409845660047893\n",
      "Iteration 491 : x = [2.11724246 4.33914798] f(x) = 0.030733558629063917 gradient norm = 0.013409757571586738\n",
      "Iteration 492 : x = [2.11721288 4.33780733] f(x) = 0.030715576528802472 gradient norm = 0.01340966863579979\n",
      "Iteration 493 : x = [2.11718317 4.33646669] f(x) = 0.03069759466763309 gradient norm = 0.013409578845625747\n",
      "Iteration 494 : x = [2.11715332 4.33512606] f(x) = 0.03067961304785024 gradient norm = 0.01340948819409791\n",
      "Iteration 495 : x = [2.11712333 4.33378545] f(x) = 0.030661631671766977 gradient norm = 0.013409396674342482\n",
      "Iteration 496 : x = [2.1170932  4.33244485] f(x) = 0.0306436505417147 gradient norm = 0.013409304279576819\n",
      "Iteration 497 : x = [2.11706295 4.33110426] f(x) = 0.03062566966004288 gradient norm = 0.013409211003107754\n",
      "Iteration 498 : x = [2.11703255 4.32976368] f(x) = 0.03060768902911883 gradient norm = 0.013409116838329944\n",
      "Iteration 499 : x = [2.11700203 4.32842312] f(x) = 0.030589708651327478 gradient norm = 0.013409021778724233\n",
      "Iteration 500 : x = [2.11697138 4.32708257] f(x) = 0.030571728529071113 gradient norm = 0.01340892581785606\n",
      "Iteration 501 : x = [2.1169406  4.32574203] f(x) = 0.030553748664769176 gradient norm = 0.013408828949373881\n",
      "Iteration 502 : x = [2.11690969 4.3244015 ] f(x) = 0.03053576906085805 gradient norm = 0.013408731167007656\n",
      "Iteration 503 : x = [2.11687865 4.32306099] f(x) = 0.0305177897197908 gradient norm = 0.013408632464567279\n",
      "Iteration 504 : x = [2.11684749 4.32172049] f(x) = 0.030499810644036986 gradient norm = 0.013408532835941143\n",
      "Iteration 505 : x = [2.1168162 4.32038  ] f(x) = 0.0304818318360825 gradient norm = 0.013408432275094636\n",
      "Iteration 506 : x = [2.11678479 4.31903952] f(x) = 0.030463853298429253 gradient norm = 0.013408330776068733\n",
      "Iteration 507 : x = [2.11675326 4.31769906] f(x) = 0.030445875033595048 gradient norm = 0.013408228332978576\n",
      "Iteration 508 : x = [2.11672161 4.31635861] f(x) = 0.03042789704411336 gradient norm = 0.013408124940012077\n",
      "Iteration 509 : x = [2.11668984 4.31501818] f(x) = 0.030409919332533168 gradient norm = 0.013408020591428574\n",
      "Iteration 510 : x = [2.11665795 4.31367775] f(x) = 0.0303919419014187 gradient norm = 0.013407915281557475\n",
      "Iteration 511 : x = [2.11662594 4.31233734] f(x) = 0.03037396475334933 gradient norm = 0.013407809004796954\n",
      "Iteration 512 : x = [2.11659382 4.31099695] f(x) = 0.030355987890919287 gradient norm = 0.013407701755612659\n",
      "Iteration 513 : x = [2.11656158 4.30965656] f(x) = 0.03033801131673758 gradient norm = 0.013407593528536448\n",
      "Iteration 514 : x = [2.11652923 4.3083162 ] f(x) = 0.03032003503342777 gradient norm = 0.01340748431816513\n",
      "Iteration 515 : x = [2.11649676 4.30697584] f(x) = 0.03030205904362778 gradient norm = 0.013407374119159259\n",
      "Iteration 516 : x = [2.11646418 4.3056355 ] f(x) = 0.030284083349989763 gradient norm = 0.01340726292624191\n",
      "Iteration 517 : x = [2.1164315  4.30429517] f(x) = 0.03026610795517989 gradient norm = 0.013407150734197527\n",
      "Iteration 518 : x = [2.1163987  4.30295486] f(x) = 0.030248132861878246 gradient norm = 0.013407037537870743\n",
      "Iteration 519 : x = [2.11636579 4.30161456] f(x) = 0.030230158072778616 gradient norm = 0.013406923332165217\n",
      "Iteration 520 : x = [2.11633278 4.30027427] f(x) = 0.03021218359058832 gradient norm = 0.013406808112042581\n",
      "Iteration 521 : x = [2.11629966 4.298934  ] f(x) = 0.03019420941802811 gradient norm = 0.013406691872521283\n",
      "Iteration 522 : x = [2.11626643 4.29759374] f(x) = 0.030176235557831985 gradient norm = 0.013406574608675528\n",
      "Iteration 523 : x = [2.1162331 4.2962535] f(x) = 0.030158262012747048 gradient norm = 0.013406456315634223\n",
      "Iteration 524 : x = [2.11619967 4.29491327] f(x) = 0.0301402887855333 gradient norm = 0.013406336988579915\n",
      "Iteration 525 : x = [2.11616613 4.29357306] f(x) = 0.030122315878963635 gradient norm = 0.01340621662274779\n",
      "Iteration 526 : x = [2.11613249 4.29223286] f(x) = 0.03010434329582354 gradient norm = 0.013406095213424648\n",
      "Iteration 527 : x = [2.11609875 4.29089267] f(x) = 0.03008637103891108 gradient norm = 0.013405972755947944\n",
      "Iteration 528 : x = [2.11606492 4.2895525 ] f(x) = 0.03006839911103668 gradient norm = 0.013405849245704777\n",
      "Iteration 529 : x = [2.11603098 4.28821235] f(x) = 0.030050427515023036 gradient norm = 0.013405724678130978\n",
      "Iteration 530 : x = [2.11599694 4.28687221] f(x) = 0.03003245625370498 gradient norm = 0.01340559904871014\n",
      "Iteration 531 : x = [2.11596281 4.28553208] f(x) = 0.030014485329929327 gradient norm = 0.01340547235297274\n",
      "Iteration 532 : x = [2.11592858 4.28419197] f(x) = 0.029996514746554768 gradient norm = 0.013405344586495178\n",
      "Iteration 533 : x = [2.11589426 4.28285188] f(x) = 0.029978544506451734 gradient norm = 0.01340521574489896\n",
      "Iteration 534 : x = [2.11585985 4.2815118 ] f(x) = 0.029960574612502296 gradient norm = 0.013405085823849755\n",
      "Iteration 535 : x = [2.11582534 4.28017173] f(x) = 0.02994260506760004 gradient norm = 0.013404954819056604\n",
      "Iteration 536 : x = [2.11579073 4.27883168] f(x) = 0.02992463587464992 gradient norm = 0.013404822726271031\n",
      "Iteration 537 : x = [2.11575604 4.27749165] f(x) = 0.029906667036568187 gradient norm = 0.013404689541286242\n",
      "Iteration 538 : x = [2.11572126 4.27615163] f(x) = 0.029888698556282234 gradient norm = 0.013404555259936328\n",
      "Iteration 539 : x = [2.11568638 4.27481163] f(x) = 0.02987073043673053 gradient norm = 0.01340441987809542\n",
      "Iteration 540 : x = [2.11565142 4.27347164] f(x) = 0.029852762680862482 gradient norm = 0.013404283391676952\n",
      "Iteration 541 : x = [2.11561637 4.27213167] f(x) = 0.029834795291638322 gradient norm = 0.013404145796632893\n",
      "Iteration 542 : x = [2.11558124 4.27079172] f(x) = 0.029816828272029063 gradient norm = 0.013404007088952953\n",
      "Iteration 543 : x = [2.11554601 4.26945178] f(x) = 0.02979886162501628 gradient norm = 0.01340386726466387\n",
      "Iteration 544 : x = [2.11551071 4.26811186] f(x) = 0.029780895353592157 gradient norm = 0.013403726319828693\n",
      "Iteration 545 : x = [2.11547531 4.26677196] f(x) = 0.029762929460759275 gradient norm = 0.013403584250546045\n",
      "Iteration 546 : x = [2.11543984 4.26543207] f(x) = 0.02974496394953054 gradient norm = 0.013403441052949423\n",
      "Iteration 547 : x = [2.11540428 4.26409219] f(x) = 0.02972699882292914 gradient norm = 0.013403296723206523\n",
      "Iteration 548 : x = [2.11536864 4.26275234] f(x) = 0.029709034083988378 gradient norm = 0.013403151257518545\n",
      "Iteration 549 : x = [2.11533292 4.2614125 ] f(x) = 0.029691069735751675 gradient norm = 0.013403004652119552\n",
      "Iteration 550 : x = [2.11529711 4.26007268] f(x) = 0.029673105781272354 gradient norm = 0.013402856903275771\n",
      "Iteration 551 : x = [2.11526123 4.25873287] f(x) = 0.029655142223613686 gradient norm = 0.013402708007285017\n",
      "Iteration 552 : x = [2.11522527 4.25739308] f(x) = 0.029637179065848732 gradient norm = 0.013402557960475998\n",
      "Iteration 553 : x = [2.11518923 4.25605331] f(x) = 0.02961921631106024 gradient norm = 0.013402406759207739\n",
      "Iteration 554 : x = [2.11515311 4.25471356] f(x) = 0.029601253962340607 gradient norm = 0.013402254399868948\n",
      "Iteration 555 : x = [2.11511692 4.25337382] f(x) = 0.029583292022791818 gradient norm = 0.013402100878877454\n",
      "Iteration 556 : x = [2.11508065 4.2520341 ] f(x) = 0.02956533049552529 gradient norm = 0.013401946192679568\n",
      "Iteration 557 : x = [2.11504431 4.2506944 ] f(x) = 0.029547369383661842 gradient norm = 0.013401790337749549\n",
      "Iteration 558 : x = [2.11500789 4.24935472] f(x) = 0.029529408690331663 gradient norm = 0.013401633310589028\n",
      "Iteration 559 : x = [2.1149714  4.24801505] f(x) = 0.02951144841867413 gradient norm = 0.013401475107726445\n",
      "Iteration 560 : x = [2.11493483 4.2466754 ] f(x) = 0.02949348857183785 gradient norm = 0.01340131572571651\n",
      "Iteration 561 : x = [2.11489819 4.24533577] f(x) = 0.02947552915298049 gradient norm = 0.013401155161139659\n",
      "Iteration 562 : x = [2.11486148 4.24399616] f(x) = 0.029457570165268777 gradient norm = 0.013400993410601534\n",
      "Iteration 563 : x = [2.1148247  4.24265656] f(x) = 0.029439611611878413 gradient norm = 0.01340083047073247\n",
      "Iteration 564 : x = [2.11478786 4.24131699] f(x) = 0.029421653495993953 gradient norm = 0.013400666338186977\n",
      "Iteration 565 : x = [2.11475094 4.23997743] f(x) = 0.029403695820808866 gradient norm = 0.013400501009643255\n",
      "Iteration 566 : x = [2.11471395 4.23863789] f(x) = 0.02938573858952533 gradient norm = 0.013400334481802686\n",
      "Iteration 567 : x = [2.11467689 4.23729837] f(x) = 0.02936778180535423 gradient norm = 0.013400166751389369\n",
      "Iteration 568 : x = [2.11463977 4.23595887] f(x) = 0.02934982547151511 gradient norm = 0.013399997815149629\n",
      "Iteration 569 : x = [2.11460258 4.23461938] f(x) = 0.02933186959123609 gradient norm = 0.013399827669851582\n",
      "Iteration 570 : x = [2.11456532 4.23327992] f(x) = 0.02931391416775385 gradient norm = 0.01339965631228466\n",
      "Iteration 571 : x = [2.114528   4.23194047] f(x) = 0.029295959204313476 gradient norm = 0.013399483739259158\n",
      "Iteration 572 : x = [2.11449062 4.23060105] f(x) = 0.029278004704168508 gradient norm = 0.013399309947605798\n",
      "Iteration 573 : x = [2.11445317 4.22926164] f(x) = 0.02926005067058083 gradient norm = 0.013399134934175322\n",
      "Iteration 574 : x = [2.11441565 4.22792225] f(x) = 0.029242097106820616 gradient norm = 0.013398958695838023\n",
      "Iteration 575 : x = [2.11437807 4.22658288] f(x) = 0.029224144016166284 gradient norm = 0.013398781229483382\n",
      "Iteration 576 : x = [2.11434044 4.22524353] f(x) = 0.029206191401904457 gradient norm = 0.013398602532019608\n",
      "Iteration 577 : x = [2.11430274 4.2239042 ] f(x) = 0.029188239267329903 gradient norm = 0.013398422600373262\n",
      "Iteration 578 : x = [2.11426497 4.22256489] f(x) = 0.02917028761574545 gradient norm = 0.013398241431488872\n",
      "Iteration 579 : x = [2.11422715 4.2212256 ] f(x) = 0.029152336450462016 gradient norm = 0.013398059022328521\n",
      "Iteration 580 : x = [2.11418927 4.21988633] f(x) = 0.029134385774798474 gradient norm = 0.01339787536987149\n",
      "Iteration 581 : x = [2.11415133 4.21854708] f(x) = 0.029116435592081654 gradient norm = 0.013397690471113858\n",
      "Iteration 582 : x = [2.11411333 4.21720785] f(x) = 0.029098485905646298 gradient norm = 0.013397504323068167\n",
      "Iteration 583 : x = [2.11407527 4.21586864] f(x) = 0.02908053671883498 gradient norm = 0.013397316922763036\n",
      "Iteration 584 : x = [2.11403716 4.21452945] f(x) = 0.029062588034998133 gradient norm = 0.013397128267242831\n",
      "Iteration 585 : x = [2.11399899 4.21319028] f(x) = 0.0290446398574939 gradient norm = 0.013396938353567275\n",
      "Iteration 586 : x = [2.11396076 4.21185113] f(x) = 0.02902669218968818 gradient norm = 0.013396747178811164\n",
      "Iteration 587 : x = [2.11392247 4.21051201] f(x) = 0.029008745034954573 gradient norm = 0.01339655474006399\n",
      "Iteration 588 : x = [2.11388413 4.2091729 ] f(x) = 0.028990798396674258 gradient norm = 0.013396361034429616\n",
      "Iteration 589 : x = [2.11384574 4.20783381] f(x) = 0.028972852278236094 gradient norm = 0.013396166059025981\n",
      "Iteration 590 : x = [2.11380729 4.20649475] f(x) = 0.028954906683036446 gradient norm = 0.01339596981098475\n",
      "Iteration 591 : x = [2.11376879 4.20515571] f(x) = 0.028936961614479256 gradient norm = 0.013395772287451008\n",
      "Iteration 592 : x = [2.11373024 4.20381668] f(x) = 0.028919017075975908 gradient norm = 0.013395573485582984\n",
      "Iteration 593 : x = [2.11369163 4.20247768] f(x) = 0.028901073070945284 gradient norm = 0.01339537340255171\n",
      "Iteration 594 : x = [2.11365297 4.2011387 ] f(x) = 0.02888312960281365 gradient norm = 0.013395172035540748\n",
      "Iteration 595 : x = [2.11361426 4.19979975] f(x) = 0.02886518667501469 gradient norm = 0.01339496938174589\n",
      "Iteration 596 : x = [2.1135755  4.19846081] f(x) = 0.028847244290989362 gradient norm = 0.013394765438374886\n",
      "Iteration 597 : x = [2.11353669 4.1971219 ] f(x) = 0.028829302454186048 gradient norm = 0.01339456020264716\n",
      "Iteration 598 : x = [2.11349783 4.195783  ] f(x) = 0.028811361168060313 gradient norm = 0.01339435367179352\n",
      "Iteration 599 : x = [2.11345892 4.19444413] f(x) = 0.02879342043607504 gradient norm = 0.0133941458430559\n",
      "Iteration 600 : x = [2.11341996 4.19310529] f(x) = 0.028775480261700303 gradient norm = 0.01339393671368712\n",
      "Iteration 601 : x = [2.11338095 4.19176646] f(x) = 0.028757540648413387 gradient norm = 0.01339372628095057\n",
      "Iteration 602 : x = [2.11334189 4.19042766] f(x) = 0.028739601599698687 gradient norm = 0.013393514542120004\n",
      "Iteration 603 : x = [2.11330279 4.18908888] f(x) = 0.028721663119047808 gradient norm = 0.013393301494479261\n",
      "Iteration 604 : x = [2.11326364 4.18775012] f(x) = 0.028703725209959386 gradient norm = 0.013393087135322038\n",
      "Iteration 605 : x = [2.11322444 4.18641138] f(x) = 0.028685787875939166 gradient norm = 0.013392871461951636\n",
      "Iteration 606 : x = [2.1131852  4.18507267] f(x) = 0.028667851120499927 gradient norm = 0.013392654471680726\n",
      "Iteration 607 : x = [2.11314591 4.18373398] f(x) = 0.028649914947161483 gradient norm = 0.013392436161831112\n",
      "Iteration 608 : x = [2.11310658 4.18239532] f(x) = 0.02863197935945065 gradient norm = 0.013392216529733495\n",
      "Iteration 609 : x = [2.1130672  4.18105667] f(x) = 0.028614044360901182 gradient norm = 0.01339199557272729\n",
      "Iteration 610 : x = [2.11302778 4.17971806] f(x) = 0.028596109955053794 gradient norm = 0.013391773288160342\n",
      "Iteration 611 : x = [2.11298831 4.17837946] f(x) = 0.02857817614545616 gradient norm = 0.013391549673388733\n",
      "Iteration 612 : x = [2.11294881 4.17704089] f(x) = 0.0285602429356628 gradient norm = 0.013391324725776612\n",
      "Iteration 613 : x = [2.11290925 4.17570234] f(x) = 0.028542310329235134 gradient norm = 0.013391098442695922\n",
      "Iteration 614 : x = [2.11286966 4.17436381] f(x) = 0.028524378329741414 gradient norm = 0.013390870821526226\n",
      "Iteration 615 : x = [2.11283002 4.17302531] f(x) = 0.02850644694075678 gradient norm = 0.013390641859654514\n",
      "Iteration 616 : x = [2.11279035 4.17168684] f(x) = 0.028488516165863103 gradient norm = 0.01339041155447496\n",
      "Iteration 617 : x = [2.11275063 4.17034839] f(x) = 0.028470586008649105 gradient norm = 0.013390179903388803\n",
      "Iteration 618 : x = [2.11271087 4.16900996] f(x) = 0.02845265647271024 gradient norm = 0.013389946903804073\n",
      "Iteration 619 : x = [2.11267107 4.16767156] f(x) = 0.028434727561648727 gradient norm = 0.01338971255313546\n",
      "Iteration 620 : x = [2.11263123 4.16633318] f(x) = 0.028416799279073538 gradient norm = 0.01338947684880411\n",
      "Iteration 621 : x = [2.11259135 4.16499482] f(x) = 0.028398871628600296 gradient norm = 0.013389239788237445\n",
      "Iteration 622 : x = [2.11255144 4.16365649] f(x) = 0.028380944613851378 gradient norm = 0.013389001368868994\n",
      "Iteration 623 : x = [2.11251148 4.16231819] f(x) = 0.028363018238455787 gradient norm = 0.01338876158813818\n",
      "Iteration 624 : x = [2.11247149 4.16097991] f(x) = 0.028345092506049236 gradient norm = 0.013388520443490223\n",
      "Iteration 625 : x = [2.11243145 4.15964166] f(x) = 0.02832716742027404 gradient norm = 0.013388277932375884\n",
      "Iteration 626 : x = [2.11239138 4.15830343] f(x) = 0.028309242984779135 gradient norm = 0.013388034052251377\n",
      "Iteration 627 : x = [2.11235128 4.15696523] f(x) = 0.028291319203220106 gradient norm = 0.013387788800578155\n",
      "Iteration 628 : x = [2.11231113 4.15562705] f(x) = 0.028273396079259085 gradient norm = 0.013387542174822766\n",
      "Iteration 629 : x = [2.11227095 4.1542889 ] f(x) = 0.028255473616564806 gradient norm = 0.01338729417245671\n",
      "Iteration 630 : x = [2.11223074 4.15295077] f(x) = 0.028237551818812573 gradient norm = 0.013387044790956256\n",
      "Iteration 631 : x = [2.11219049 4.15161268] f(x) = 0.02821963068968422 gradient norm = 0.013386794027802323\n",
      "Iteration 632 : x = [2.1121502 4.1502746] f(x) = 0.028201710232868122 gradient norm = 0.013386541880480317\n",
      "Iteration 633 : x = [2.11210988 4.14893656] f(x) = 0.02818379045205918 gradient norm = 0.01338628834647998\n",
      "Iteration 634 : x = [2.11206953 4.14759854] f(x) = 0.028165871350958795 gradient norm = 0.013386033423295241\n",
      "Iteration 635 : x = [2.11202914 4.14626054] f(x) = 0.02814795293327487 gradient norm = 0.013385777108424111\n",
      "Iteration 636 : x = [2.11198872 4.14492257] f(x) = 0.02813003520272178 gradient norm = 0.0133855193993685\n",
      "Iteration 637 : x = [2.11194826 4.14358463] f(x) = 0.028112118163020398 gradient norm = 0.013385260293634104\n",
      "Iteration 638 : x = [2.11190777 4.14224672] f(x) = 0.028094201817898026 gradient norm = 0.013384999788730288\n",
      "Iteration 639 : x = [2.11186725 4.14090883] f(x) = 0.028076286171088417 gradient norm = 0.01338473788216991\n",
      "Iteration 640 : x = [2.1118267  4.13957097] f(x) = 0.02805837122633178 gradient norm = 0.013384474571469244\n",
      "Iteration 641 : x = [2.11178611 4.13823314] f(x) = 0.028040456987374708 gradient norm = 0.013384209854147814\n",
      "Iteration 642 : x = [2.11174549 4.13689534] f(x) = 0.028022543457970284 gradient norm = 0.01338394372772829\n",
      "Iteration 643 : x = [2.11170484 4.13555756] f(x) = 0.028004630641877932 gradient norm = 0.013383676189736363\n",
      "Iteration 644 : x = [2.11166416 4.13421981] f(x) = 0.027986718542863477 gradient norm = 0.01338340723770062\n",
      "Iteration 645 : x = [2.11162345 4.13288209] f(x) = 0.027968807164699166 gradient norm = 0.013383136869152438\n",
      "Iteration 646 : x = [2.11158271 4.1315444 ] f(x) = 0.027950896511163587 gradient norm = 0.013382865081625863\n",
      "Iteration 647 : x = [2.11154194 4.13020673] f(x) = 0.027932986586041722 gradient norm = 0.013382591872657482\n",
      "Iteration 648 : x = [2.11150114 4.12886909] f(x) = 0.027915077393124887 gradient norm = 0.013382317239786352\n",
      "Iteration 649 : x = [2.11146031 4.12753149] f(x) = 0.02789716893621078 gradient norm = 0.013382041180553838\n",
      "Iteration 650 : x = [2.11141946 4.12619391] f(x) = 0.02787926121910341 gradient norm = 0.01338176369250354\n",
      "Iteration 651 : x = [2.11137857 4.12485635] f(x) = 0.027861354245613153 gradient norm = 0.013381484773181193\n",
      "Iteration 652 : x = [2.11133765 4.12351883] f(x) = 0.027843448019556703 gradient norm = 0.013381204420134534\n",
      "Iteration 653 : x = [2.11129671 4.12218134] f(x) = 0.027825542544757057 gradient norm = 0.013380922630913226\n",
      "Iteration 654 : x = [2.11125574 4.12084387] f(x) = 0.027807637825043554 gradient norm = 0.013380639403068747\n",
      "Iteration 655 : x = [2.11121474 4.11950644] f(x) = 0.027789733864251827 gradient norm = 0.013380354734154295\n",
      "Iteration 656 : x = [2.11117371 4.11816903] f(x) = 0.027771830666223806 gradient norm = 0.013380068621724696\n",
      "Iteration 657 : x = [2.11113266 4.11683165] f(x) = 0.027753928234807726 gradient norm = 0.013379781063336295\n",
      "Iteration 658 : x = [2.11109158 4.11549431] f(x) = 0.027736026573858114 gradient norm = 0.013379492056546885\n",
      "Iteration 659 : x = [2.11105047 4.11415699] f(x) = 0.02771812568723578 gradient norm = 0.013379201598915591\n",
      "Iteration 660 : x = [2.11100934 4.1128197 ] f(x) = 0.0277002255788078 gradient norm = 0.013378909688002809\n",
      "Iteration 661 : x = [2.11096819 4.11148244] f(x) = 0.027682326252447553 gradient norm = 0.013378616321370081\n",
      "Iteration 662 : x = [2.110927   4.11014522] f(x) = 0.02766442771203463 gradient norm = 0.013378321496580046\n",
      "Iteration 663 : x = [2.11088579 4.10880802] f(x) = 0.027646529961454967 gradient norm = 0.013378025211196343\n",
      "Iteration 664 : x = [2.11084456 4.10747085] f(x) = 0.027628633004600684 gradient norm = 0.013377727462783512\n",
      "Iteration 665 : x = [2.1108033  4.10613371] f(x) = 0.027610736845370205 gradient norm = 0.013377428248906933\n",
      "Iteration 666 : x = [2.11076202 4.10479661] f(x) = 0.027592841487668187 gradient norm = 0.013377127567132725\n",
      "Iteration 667 : x = [2.11072071 4.10345953] f(x) = 0.027574946935405516 gradient norm = 0.013376825415027691\n",
      "Iteration 668 : x = [2.11067938 4.10212249] f(x) = 0.027557053192499372 gradient norm = 0.013376521790159223\n",
      "Iteration 669 : x = [2.11063803 4.10078548] f(x) = 0.02753916026287314 gradient norm = 0.01337621669009523\n",
      "Iteration 670 : x = [2.11059665 4.0994485 ] f(x) = 0.027521268150456444 gradient norm = 0.01337591011240407\n",
      "Iteration 671 : x = [2.11055525 4.09811155] f(x) = 0.027503376859185136 gradient norm = 0.013375602054654464\n",
      "Iteration 672 : x = [2.11051383 4.09677463] f(x) = 0.027485486393001326 gradient norm = 0.013375292514415427\n",
      "Iteration 673 : x = [2.11047238 4.09543774] f(x) = 0.02746759675585334 gradient norm = 0.013374981489256216\n",
      "Iteration 674 : x = [2.11043092 4.09410088] f(x) = 0.027449707951695716 gradient norm = 0.013374668976746235\n",
      "Iteration 675 : x = [2.11038943 4.09276406] f(x) = 0.027431819984489236 gradient norm = 0.013374354974454978\n",
      "Iteration 676 : x = [2.11034792 4.09142727] f(x) = 0.02741393285820089 gradient norm = 0.013374039479951952\n",
      "Iteration 677 : x = [2.11030638 4.09009051] f(x) = 0.02739604657680388 gradient norm = 0.013373722490806633\n",
      "Iteration 678 : x = [2.11026483 4.08875379] f(x) = 0.027378161144277664 gradient norm = 0.013373404004588384\n",
      "Iteration 679 : x = [2.11022325 4.08741709] f(x) = 0.02736027656460788 gradient norm = 0.013373084018866386\n",
      "Iteration 680 : x = [2.11018166 4.08608043] f(x) = 0.02734239284178641 gradient norm = 0.013372762531209597\n",
      "Iteration 681 : x = [2.11014004 4.0847438 ] f(x) = 0.027324509979811326 gradient norm = 0.013372439539186664\n",
      "Iteration 682 : x = [2.1100984  4.08340721] f(x) = 0.02730662798268689 gradient norm = 0.013372115040365893\n",
      "Iteration 683 : x = [2.11005674 4.08207064] f(x) = 0.027288746854423642 gradient norm = 0.01337178903231515\n",
      "Iteration 684 : x = [2.11001506 4.08073411] f(x) = 0.027270866599038275 gradient norm = 0.013371461512601861\n",
      "Iteration 685 : x = [2.10997337 4.07939762] f(x) = 0.02725298722055372 gradient norm = 0.013371132478792876\n",
      "Iteration 686 : x = [2.10993165 4.07806116] f(x) = 0.02723510872299913 gradient norm = 0.013370801928454489\n",
      "Iteration 687 : x = [2.10988991 4.07672473] f(x) = 0.0272172311104098 gradient norm = 0.013370469859152335\n",
      "Iteration 688 : x = [2.10984816 4.07538833] f(x) = 0.02719935438682733 gradient norm = 0.013370136268451358\n",
      "Iteration 689 : x = [2.10980639 4.07405197] f(x) = 0.027181478556299453 gradient norm = 0.013369801153915747\n",
      "Iteration 690 : x = [2.10976459 4.07271564] f(x) = 0.027163603622880155 gradient norm = 0.013369464513108883\n",
      "Iteration 691 : x = [2.10972278 4.07137935] f(x) = 0.0271457295906296 gradient norm = 0.0133691263435933\n",
      "Iteration 692 : x = [2.10968095 4.07004309] f(x) = 0.027127856463614177 gradient norm = 0.013368786642930622\n",
      "Iteration 693 : x = [2.10963911 4.06870687] f(x) = 0.02710998424590649 gradient norm = 0.01336844540868151\n",
      "Iteration 694 : x = [2.10959724 4.06737068] f(x) = 0.02709211294158534 gradient norm = 0.013368102638405632\n",
      "Iteration 695 : x = [2.10955536 4.06603453] f(x) = 0.027074242554735752 gradient norm = 0.013367758329661595\n",
      "Iteration 696 : x = [2.10951346 4.06469841] f(x) = 0.027056373089448953 gradient norm = 0.013367412480006915\n",
      "Iteration 697 : x = [2.10947154 4.06336232] f(x) = 0.027038504549822383 gradient norm = 0.013367065086997953\n",
      "Iteration 698 : x = [2.10942961 4.06202628] f(x) = 0.027020636939959687 gradient norm = 0.013366716148189878\n",
      "Iteration 699 : x = [2.10938766 4.06069026] f(x) = 0.02700277026397075 gradient norm = 0.013366365661136633\n",
      "Iteration 700 : x = [2.10934569 4.05935429] f(x) = 0.02698490452597165 gradient norm = 0.013366013623390875\n",
      "Iteration 701 : x = [2.1093037  4.05801834] f(x) = 0.026967039730084692 gradient norm = 0.01336566003250393\n",
      "Iteration 702 : x = [2.1092617  4.05668244] f(x) = 0.026949175880438388 gradient norm = 0.013365304886025766\n",
      "Iteration 703 : x = [2.10921969 4.05534657] f(x) = 0.02693131298116749 gradient norm = 0.013364948181504951\n",
      "Iteration 704 : x = [2.10917766 4.05401073] f(x) = 0.026913451036412947 gradient norm = 0.013364589916488591\n",
      "Iteration 705 : x = [2.10913561 4.05267494] f(x) = 0.02689559005032198 gradient norm = 0.013364230088522304\n",
      "Iteration 706 : x = [2.10909355 4.05133918] f(x) = 0.026877730027047957 gradient norm = 0.013363868695150197\n",
      "Iteration 707 : x = [2.10905147 4.05000345] f(x) = 0.02685987097075053 gradient norm = 0.013363505733914786\n",
      "Iteration 708 : x = [2.10900938 4.04866776] f(x) = 0.02684201288559556 gradient norm = 0.01336314120235699\n",
      "Iteration 709 : x = [2.10896727 4.04733211] f(x) = 0.02682415577575516 gradient norm = 0.0133627750980161\n",
      "Iteration 710 : x = [2.10892514 4.0459965 ] f(x) = 0.026806299645407657 gradient norm = 0.013362407418429713\n",
      "Iteration 711 : x = [2.10888301 4.04466092] f(x) = 0.02678844449873761 gradient norm = 0.013362038161133708\n",
      "Iteration 712 : x = [2.10884086 4.04332539] f(x) = 0.02677059033993584 gradient norm = 0.01336166732366222\n",
      "Iteration 713 : x = [2.10879869 4.04198988] f(x) = 0.026752737173199374 gradient norm = 0.013361294903547592\n",
      "Iteration 714 : x = [2.10875651 4.04065442] f(x) = 0.026734885002731527 gradient norm = 0.013360920898320354\n",
      "Iteration 715 : x = [2.10871432 4.03931899] f(x) = 0.026717033832741807 gradient norm = 0.013360545305509166\n",
      "Iteration 716 : x = [2.10867211 4.03798361] f(x) = 0.026699183667446023 gradient norm = 0.01336016812264082\n",
      "Iteration 717 : x = [2.10862989 4.03664826] f(x) = 0.026681334511066194 gradient norm = 0.01335978934724017\n",
      "Iteration 718 : x = [2.10858765 4.03531295] f(x) = 0.026663486367830613 gradient norm = 0.013359408976830125\n",
      "Iteration 719 : x = [2.10854541 4.03397767] f(x) = 0.02664563924197383 gradient norm = 0.013359027008931606\n",
      "Iteration 720 : x = [2.10850315 4.03264244] f(x) = 0.026627793137736652 gradient norm = 0.013358643441063526\n",
      "Iteration 721 : x = [2.10846087 4.03130724] f(x) = 0.026609948059366142 gradient norm = 0.013358258270742746\n",
      "Iteration 722 : x = [2.10841859 4.02997209] f(x) = 0.02659210401111567 gradient norm = 0.013357871495484052\n",
      "Iteration 723 : x = [2.10837629 4.02863697] f(x) = 0.026574260997244813 gradient norm = 0.013357483112800115\n",
      "Iteration 724 : x = [2.10833398 4.02730189] f(x) = 0.02655641902201945 gradient norm = 0.013357093120201497\n",
      "Iteration 725 : x = [2.10829165 4.02596685] f(x) = 0.026538578089711766 gradient norm = 0.013356701515196573\n",
      "Iteration 726 : x = [2.10824932 4.02463185] f(x) = 0.026520738204600176 gradient norm = 0.01335630829529153\n",
      "Iteration 727 : x = [2.10820697 4.0232969 ] f(x) = 0.026502899370969415 gradient norm = 0.013355913457990353\n",
      "Iteration 728 : x = [2.10816461 4.02196198] f(x) = 0.026485061593110475 gradient norm = 0.01335551700079476\n",
      "Iteration 729 : x = [2.10812224 4.0206271 ] f(x) = 0.02646722487532068 gradient norm = 0.013355118921204211\n",
      "Iteration 730 : x = [2.10807986 4.01929226] f(x) = 0.0264493892219036 gradient norm = 0.013354719216715862\n",
      "Iteration 731 : x = [2.10803747 4.01795746] f(x) = 0.02643155463716914 gradient norm = 0.013354317884824551\n",
      "Iteration 732 : x = [2.10799506 4.0166227 ] f(x) = 0.026413721125433495 gradient norm = 0.013353914923022764\n",
      "Iteration 733 : x = [2.10795264 4.01528798] f(x) = 0.026395888691019158 gradient norm = 0.013353510328800604\n",
      "Iteration 734 : x = [2.10791022 4.01395331] f(x) = 0.026378057338254962 gradient norm = 0.013353104099645782\n",
      "Iteration 735 : x = [2.10786778 4.01261867] f(x) = 0.026360227071476016 gradient norm = 0.013352696233043599\n",
      "Iteration 736 : x = [2.10782533 4.01128408] f(x) = 0.026342397895023757 gradient norm = 0.01335228672647688\n",
      "Iteration 737 : x = [2.10778287 4.00994952] f(x) = 0.026324569813245963 gradient norm = 0.013351875577426016\n",
      "Iteration 738 : x = [2.1077404  4.00861501] f(x) = 0.026306742830496724 gradient norm = 0.013351462783368875\n",
      "Iteration 739 : x = [2.10769792 4.00728054] f(x) = 0.02628891695113647 gradient norm = 0.013351048341780834\n",
      "Iteration 740 : x = [2.10765544 4.00594611] f(x) = 0.026271092179531944 gradient norm = 0.01335063225013471\n",
      "Iteration 741 : x = [2.10761294 4.00461172] f(x) = 0.026253268520056237 gradient norm = 0.013350214505900777\n",
      "Iteration 742 : x = [2.10757043 4.00327738] f(x) = 0.02623544597708882 gradient norm = 0.013349795106546733\n",
      "Iteration 743 : x = [2.10752791 4.00194308] f(x) = 0.02621762455501545 gradient norm = 0.01334937404953765\n",
      "Iteration 744 : x = [2.10748538 4.00060882] f(x) = 0.026199804258228286 gradient norm = 0.013348951332336016\n",
      "Iteration 745 : x = [2.10744284 3.9992746 ] f(x) = 0.026181985091125827 gradient norm = 0.013348526952401638\n",
      "Iteration 746 : x = [2.10740029 3.99794043] f(x) = 0.026164167058112926 gradient norm = 0.013348100907191686\n",
      "Iteration 747 : x = [2.10735774 3.99660629] f(x) = 0.026146350163600816 gradient norm = 0.013347673194160642\n",
      "Iteration 748 : x = [2.10731517 3.99527221] f(x) = 0.026128534412007076 gradient norm = 0.013347243810760275\n",
      "Iteration 749 : x = [2.1072726  3.99393816] f(x) = 0.02611071980775571 gradient norm = 0.01334681275443966\n",
      "Iteration 750 : x = [2.10723001 3.99260416] f(x) = 0.02609290635527705 gradient norm = 0.0133463800226451\n",
      "Iteration 751 : x = [2.10718742 3.9912702 ] f(x) = 0.02607509405900783 gradient norm = 0.013345945612820176\n",
      "Iteration 752 : x = [2.10714482 3.98993629] f(x) = 0.026057282923391187 gradient norm = 0.013345509522405652\n",
      "Iteration 753 : x = [2.10710221 3.98860242] f(x) = 0.026039472952876647 gradient norm = 0.013345071748839536\n",
      "Iteration 754 : x = [2.1070596  3.98726859] f(x) = 0.026021664151920133 gradient norm = 0.013344632289557005\n",
      "Iteration 755 : x = [2.10701697 3.98593481] f(x) = 0.02600385652498395 gradient norm = 0.013344191141990418\n",
      "Iteration 756 : x = [2.10697434 3.98460107] f(x) = 0.02598605007653685 gradient norm = 0.013343748303569278\n",
      "Iteration 757 : x = [2.10693169 3.98326738] f(x) = 0.025968244811053986 gradient norm = 0.013343303771720234\n",
      "Iteration 758 : x = [2.10688904 3.98193373] f(x) = 0.025950440733016916 gradient norm = 0.013342857543867048\n",
      "Iteration 759 : x = [2.10684639 3.98060012] f(x) = 0.02593263784691365 gradient norm = 0.013342409617430601\n",
      "Iteration 760 : x = [2.10680372 3.97926656] f(x) = 0.025914836157238594 gradient norm = 0.013341959989828853\n",
      "Iteration 761 : x = [2.10676105 3.97793305] f(x) = 0.025897035668492618 gradient norm = 0.013341508658476837\n",
      "Iteration 762 : x = [2.10671837 3.97659958] f(x) = 0.02587923638518301 gradient norm = 0.01334105562078665\n",
      "Iteration 763 : x = [2.10667568 3.97526616] f(x) = 0.02586143831182352 gradient norm = 0.013340600874167425\n",
      "Iteration 764 : x = [2.10663299 3.97393278] f(x) = 0.02584364145293434 gradient norm = 0.013340144416025334\n",
      "Iteration 765 : x = [2.10659028 3.97259945] f(x) = 0.02582584581304212 gradient norm = 0.013339686243763556\n",
      "Iteration 766 : x = [2.10654757 3.97126617] f(x) = 0.02580805139667998 gradient norm = 0.013339226354782262\n",
      "Iteration 767 : x = [2.10650486 3.96993293] f(x) = 0.025790258208387463 gradient norm = 0.013338764746478616\n",
      "Iteration 768 : x = [2.10646214 3.96859974] f(x) = 0.02577246625271064 gradient norm = 0.013338301416246758\n",
      "Iteration 769 : x = [2.10641941 3.96726659] f(x) = 0.025754675534202038 gradient norm = 0.013337836361477774\n",
      "Iteration 770 : x = [2.10637667 3.96593349] f(x) = 0.02573688605742064 gradient norm = 0.013337369579559692\n",
      "Iteration 771 : x = [2.10633393 3.96460044] f(x) = 0.02571909782693196 gradient norm = 0.013336901067877483\n",
      "Iteration 772 : x = [2.10629118 3.96326744] f(x) = 0.02570131084730799 gradient norm = 0.013336430823813025\n",
      "Iteration 773 : x = [2.10624842 3.96193448] f(x) = 0.025683525123127184 gradient norm = 0.013335958844745095\n",
      "Iteration 774 : x = [2.10620566 3.96060157] f(x) = 0.02566574065897457 gradient norm = 0.013335485128049376\n",
      "Iteration 775 : x = [2.10616289 3.95926871] f(x) = 0.02564795745944161 gradient norm = 0.013335009671098417\n",
      "Iteration 776 : x = [2.10612012 3.95793589] f(x) = 0.025630175529126335 gradient norm = 0.013334532471261635\n",
      "Iteration 777 : x = [2.10607734 3.95660313] f(x) = 0.025612394872633257 gradient norm = 0.013334053525905302\n",
      "Iteration 778 : x = [2.10603455 3.95527041] f(x) = 0.025594615494573467 gradient norm = 0.013333572832392534\n",
      "Iteration 779 : x = [2.10599176 3.95393774] f(x) = 0.02557683739956453 gradient norm = 0.013333090388083283\n",
      "Iteration 780 : x = [2.10594896 3.95260511] f(x) = 0.025559060592230592 gradient norm = 0.013332606190334294\n",
      "Iteration 781 : x = [2.10590616 3.95127254] f(x) = 0.025541285077202318 gradient norm = 0.013332120236499153\n",
      "Iteration 782 : x = [2.10586335 3.94994002] f(x) = 0.02552351085911692 gradient norm = 0.013331632523928215\n",
      "Iteration 783 : x = [2.10582054 3.94860754] f(x) = 0.025505737942618182 gradient norm = 0.013331143049968634\n",
      "Iteration 784 : x = [2.10577772 3.94727511] f(x) = 0.02548796633235642 gradient norm = 0.013330651811964333\n",
      "Iteration 785 : x = [2.1057349  3.94594274] f(x) = 0.025470196032988557 gradient norm = 0.013330158807255996\n",
      "Iteration 786 : x = [2.10569207 3.94461041] f(x) = 0.025452427049178043 gradient norm = 0.013329664033181057\n",
      "Iteration 787 : x = [2.10564923 3.94327813] f(x) = 0.025434659385594926 gradient norm = 0.013329167487073702\n",
      "Iteration 788 : x = [2.10560639 3.9419459 ] f(x) = 0.02541689304691586 gradient norm = 0.013328669166264838\n",
      "Iteration 789 : x = [2.10556355 3.94061372] f(x) = 0.02539912803782404 gradient norm = 0.0133281690680821\n",
      "Iteration 790 : x = [2.1055207 3.9392816] f(x) = 0.025381364363009275 gradient norm = 0.013327667189849826\n",
      "Iteration 791 : x = [2.10547784 3.93794952] f(x) = 0.025363602027167996 gradient norm = 0.013327163528889066\n",
      "Iteration 792 : x = [2.10543498 3.93661749] f(x) = 0.025345841035003213 gradient norm = 0.013326658082517543\n",
      "Iteration 793 : x = [2.10539212 3.93528552] f(x) = 0.02532808139122456 gradient norm = 0.013326150848049686\n",
      "Iteration 794 : x = [2.10534925 3.93395359] f(x) = 0.025310323100548295 gradient norm = 0.013325641822796589\n",
      "Iteration 795 : x = [2.10530638 3.93262172] f(x) = 0.02529256616769727 gradient norm = 0.013325131004065998\n",
      "Iteration 796 : x = [2.1052635  3.93128989] f(x) = 0.02527481059740099 gradient norm = 0.013324618389162319\n",
      "Iteration 797 : x = [2.10522062 3.92995812] f(x) = 0.025257056394395613 gradient norm = 0.013324103975386609\n",
      "Iteration 798 : x = [2.10517774 3.9286264 ] f(x) = 0.0252393035634239 gradient norm = 0.013323587760036552\n",
      "Iteration 799 : x = [2.10513485 3.92729473] f(x) = 0.02522155210923528 gradient norm = 0.013323069740406469\n",
      "Iteration 800 : x = [2.10509196 3.92596312] f(x) = 0.025203802036585822 gradient norm = 0.01332254991378729\n",
      "Iteration 801 : x = [2.10504906 3.92463155] f(x) = 0.025186053350238272 gradient norm = 0.013322028277466565\n",
      "Iteration 802 : x = [2.10500616 3.92330004] f(x) = 0.02516830605496204 gradient norm = 0.013321504828728436\n",
      "Iteration 803 : x = [2.10496325 3.92196858] f(x) = 0.025150560155533196 gradient norm = 0.013320979564853654\n",
      "Iteration 804 : x = [2.10492034 3.92063717] f(x) = 0.025132815656734496 gradient norm = 0.013320452483119529\n",
      "Iteration 805 : x = [2.10487743 3.91930582] f(x) = 0.025115072563355354 gradient norm = 0.01331992358079998\n",
      "Iteration 806 : x = [2.10483452 3.91797452] f(x) = 0.025097330880191903 gradient norm = 0.013319392855165474\n",
      "Iteration 807 : x = [2.1047916  3.91664327] f(x) = 0.02507959061204696 gradient norm = 0.013318860303483044\n",
      "Iteration 808 : x = [2.10474867 3.91531208] f(x) = 0.02506185176373005 gradient norm = 0.013318325923016277\n",
      "Iteration 809 : x = [2.10470575 3.91398094] f(x) = 0.025044114340057388 gradient norm = 0.013317789711025315\n",
      "Iteration 810 : x = [2.10466282 3.91264985] f(x) = 0.02502637834585191 gradient norm = 0.013317251664766822\n",
      "Iteration 811 : x = [2.10461988 3.91131882] f(x) = 0.025008643785943294 gradient norm = 0.013316711781494019\n",
      "Iteration 812 : x = [2.10457695 3.90998784] f(x) = 0.024990910665167895 gradient norm = 0.01331617005845662\n",
      "Iteration 813 : x = [2.10453401 3.90865691] f(x) = 0.024973178988368833 gradient norm = 0.013315626492900877\n",
      "Iteration 814 : x = [2.10449107 3.90732604] f(x) = 0.02495544876039597 gradient norm = 0.01331508108206955\n",
      "Iteration 815 : x = [2.10444812 3.90599523] f(x) = 0.024937719986105892 gradient norm = 0.013314533823201895\n",
      "Iteration 816 : x = [2.10440517 3.90466447] f(x) = 0.024919992670361938 gradient norm = 0.013313984713533676\n",
      "Iteration 817 : x = [2.10436222 3.90333376] f(x) = 0.0249022668180342 gradient norm = 0.01331343375029712\n",
      "Iteration 818 : x = [2.10431927 3.90200311] f(x) = 0.024884542433999558 gradient norm = 0.013312880930720979\n",
      "Iteration 819 : x = [2.10427631 3.90067252] f(x) = 0.024866819523141608 gradient norm = 0.01331232625203044\n",
      "Iteration 820 : x = [2.10423335 3.89934198] f(x) = 0.0248490980903508 gradient norm = 0.013311769711447178\n",
      "Iteration 821 : x = [2.10419039 3.8980115 ] f(x) = 0.024831378140524267 gradient norm = 0.013311211306189336\n",
      "Iteration 822 : x = [2.10414742 3.89668107] f(x) = 0.024813659678565986 gradient norm = 0.013310651033471505\n",
      "Iteration 823 : x = [2.10410446 3.8953507 ] f(x) = 0.024795942709386724 gradient norm = 0.013310088890504728\n",
      "Iteration 824 : x = [2.10406149 3.89402038] f(x) = 0.024778227237904033 gradient norm = 0.013309524874496494\n",
      "Iteration 825 : x = [2.10401851 3.89269012] f(x) = 0.02476051326904227 gradient norm = 0.013308958982650733\n",
      "Iteration 826 : x = [2.10397554 3.89135992] f(x) = 0.024742800807732605 gradient norm = 0.0133083912121678\n",
      "Iteration 827 : x = [2.10393256 3.89002978] f(x) = 0.02472508985891303 gradient norm = 0.013307821560244477\n",
      "Iteration 828 : x = [2.10388958 3.88869969] f(x) = 0.024707380427528347 gradient norm = 0.013307250024073979\n",
      "Iteration 829 : x = [2.1038466  3.88736966] f(x) = 0.024689672518530194 gradient norm = 0.013306676600845922\n",
      "Iteration 830 : x = [2.10380362 3.88603968] f(x) = 0.02467196613687705 gradient norm = 0.013306101287746331\n",
      "Iteration 831 : x = [2.10376063 3.88470977] f(x) = 0.024654261287534215 gradient norm = 0.013305524081957655\n",
      "Iteration 832 : x = [2.10371765 3.88337991] f(x) = 0.024636557975473865 gradient norm = 0.013304944980658703\n",
      "Iteration 833 : x = [2.10367466 3.88205011] f(x) = 0.02461885620567502 gradient norm = 0.01330436398102472\n",
      "Iteration 834 : x = [2.10363167 3.88072037] f(x) = 0.024601155983123516 gradient norm = 0.013303781080227305\n",
      "Iteration 835 : x = [2.10358867 3.87939069] f(x) = 0.02458345731281212 gradient norm = 0.013303196275434453\n",
      "Iteration 836 : x = [2.10354568 3.87806106] f(x) = 0.02456576019974045 gradient norm = 0.013302609563810535\n",
      "Iteration 837 : x = [2.10350268 3.8767315 ] f(x) = 0.024548064648914965 gradient norm = 0.013302020942516288\n",
      "Iteration 838 : x = [2.10345968 3.87540199] f(x) = 0.024530370665349056 gradient norm = 0.013301430408708834\n",
      "Iteration 839 : x = [2.10341668 3.87407254] f(x) = 0.024512678254062975 gradient norm = 0.01330083795954162\n",
      "Iteration 840 : x = [2.10337368 3.87274315] f(x) = 0.024494987420083884 gradient norm = 0.013300243592164479\n",
      "Iteration 841 : x = [2.10333068 3.87141382] f(x) = 0.02447729816844584 gradient norm = 0.013299647303723594\n",
      "Iteration 842 : x = [2.10328768 3.87008455] f(x) = 0.02445961050418981 gradient norm = 0.013299049091361483\n",
      "Iteration 843 : x = [2.10324467 3.86875534] f(x) = 0.024441924432363676 gradient norm = 0.013298448952217006\n",
      "Iteration 844 : x = [2.10320166 3.86742619] f(x) = 0.024424239958022256 gradient norm = 0.013297846883425368\n",
      "Iteration 845 : x = [2.10315865 3.86609711] f(x) = 0.024406557086227253 gradient norm = 0.01329724288211811\n",
      "Iteration 846 : x = [2.10311564 3.86476808] f(x) = 0.024388875822047358 gradient norm = 0.013296636945423082\n",
      "Iteration 847 : x = [2.10307263 3.86343911] f(x) = 0.024371196170558156 gradient norm = 0.013296029070464477\n",
      "Iteration 848 : x = [2.10302962 3.8621102 ] f(x) = 0.024353518136842202 gradient norm = 0.013295419254362792\n",
      "Iteration 849 : x = [2.10298661 3.86078136] f(x) = 0.024335841725988985 gradient norm = 0.013294807494234855\n",
      "Iteration 850 : x = [2.10294359 3.85945257] f(x) = 0.024318166943094965 gradient norm = 0.013294193787193782\n",
      "Iteration 851 : x = [2.10290058 3.85812385] f(x) = 0.024300493793263583 gradient norm = 0.013293578130349013\n",
      "Iteration 852 : x = [2.10285756 3.85679519] f(x) = 0.02428282228160521 gradient norm = 0.013292960520806288\n",
      "Iteration 853 : x = [2.10281454 3.85546659] f(x) = 0.02426515241323719 gradient norm = 0.013292340955667633\n",
      "Iteration 854 : x = [2.10277152 3.85413805] f(x) = 0.024247484193283927 gradient norm = 0.013291719432031375\n",
      "Iteration 855 : x = [2.10272851 3.85280957] f(x) = 0.024229817626876714 gradient norm = 0.013291095946992123\n",
      "Iteration 856 : x = [2.10268548 3.85148116] f(x) = 0.024212152719153876 gradient norm = 0.013290470497640794\n",
      "Iteration 857 : x = [2.10264246 3.85015281] f(x) = 0.02419448947526078 gradient norm = 0.013289843081064548\n",
      "Iteration 858 : x = [2.10259944 3.84882452] f(x) = 0.024176827900349737 gradient norm = 0.013289213694346859\n",
      "Iteration 859 : x = [2.10255642 3.8474963 ] f(x) = 0.024159167999580126 gradient norm = 0.013288582334567447\n",
      "Iteration 860 : x = [2.1025134  3.84616814] f(x) = 0.024141509778118266 gradient norm = 0.013287948998802318\n",
      "Iteration 861 : x = [2.10247037 3.84484004] f(x) = 0.0241238532411376 gradient norm = 0.013287313684123735\n",
      "Iteration 862 : x = [2.10242735 3.843512  ] f(x) = 0.024106198393818522 gradient norm = 0.013286676387600237\n",
      "Iteration 863 : x = [2.10238432 3.84218403] f(x) = 0.024088545241348513 gradient norm = 0.013286037106296592\n",
      "Iteration 864 : x = [2.1023413  3.84085613] f(x) = 0.024070893788922076 gradient norm = 0.013285395837273856\n",
      "Iteration 865 : x = [2.10229827 3.83952828] f(x) = 0.024053244041740758 gradient norm = 0.013284752577589307\n",
      "Iteration 866 : x = [2.10225525 3.8382005 ] f(x) = 0.024035596005013173 gradient norm = 0.013284107324296496\n",
      "Iteration 867 : x = [2.10221222 3.83687279] f(x) = 0.024017949683954987 gradient norm = 0.013283460074445204\n",
      "Iteration 868 : x = [2.10216919 3.83554514] f(x) = 0.02400030508378896 gradient norm = 0.013282810825081454\n",
      "Iteration 869 : x = [2.10212616 3.83421756] f(x) = 0.02398266220974487 gradient norm = 0.013282159573247502\n",
      "Iteration 870 : x = [2.10208314 3.83289004] f(x) = 0.023965021067059628 gradient norm = 0.013281506315981849\n",
      "Iteration 871 : x = [2.10204011 3.83156259] f(x) = 0.023947381660977218 gradient norm = 0.013280851050319212\n",
      "Iteration 872 : x = [2.10199708 3.8302352 ] f(x) = 0.023929743996748708 gradient norm = 0.013280193773290552\n",
      "Iteration 873 : x = [2.10195405 3.82890788] f(x) = 0.02391210807963224 gradient norm = 0.013279534481923039\n",
      "Iteration 874 : x = [2.10191102 3.82758062] f(x) = 0.02389447391489311 gradient norm = 0.013278873173240079\n",
      "Iteration 875 : x = [2.10186799 3.82625343] f(x) = 0.023876841507803694 gradient norm = 0.013278209844261273\n",
      "Iteration 876 : x = [2.10182497 3.82492631] f(x) = 0.023859210863643492 gradient norm = 0.013277544492002458\n",
      "Iteration 877 : x = [2.10178194 3.82359925] f(x) = 0.023841581987699114 gradient norm = 0.013276877113475671\n",
      "Iteration 878 : x = [2.10173891 3.82227226] f(x) = 0.02382395488526433 gradient norm = 0.013276207705689168\n",
      "Iteration 879 : x = [2.10169588 3.82094533] f(x) = 0.02380632956163999 gradient norm = 0.013275536265647396\n",
      "Iteration 880 : x = [2.10165285 3.81961848] f(x) = 0.023788706022134135 gradient norm = 0.013274862790351012\n",
      "Iteration 881 : x = [2.10160982 3.81829169] f(x) = 0.023771084272061913 gradient norm = 0.01327418727679687\n",
      "Iteration 882 : x = [2.10156679 3.81696497] f(x) = 0.02375346431674566 gradient norm = 0.01327350972197804\n",
      "Iteration 883 : x = [2.10152377 3.81563832] f(x) = 0.023735846161514848 gradient norm = 0.013272830122883753\n",
      "Iteration 884 : x = [2.10148074 3.81431173] f(x) = 0.02371822981170611 gradient norm = 0.01327214847649945\n",
      "Iteration 885 : x = [2.10143771 3.81298521] f(x) = 0.02370061527266327 gradient norm = 0.013271464779806758\n",
      "Iteration 886 : x = [2.10139468 3.81165876] f(x) = 0.023683002549737313 gradient norm = 0.013270779029783493\n",
      "Iteration 887 : x = [2.10135166 3.81033238] f(x) = 0.023665391648286387 gradient norm = 0.013270091223403653\n",
      "Iteration 888 : x = [2.10130863 3.80900607] f(x) = 0.02364778257367586 gradient norm = 0.013269401357637394\n",
      "Iteration 889 : x = [2.1012656  3.80767983] f(x) = 0.023630175331278282 gradient norm = 0.013268709429451095\n",
      "Iteration 890 : x = [2.10122258 3.80635366] f(x) = 0.023612569926473412 gradient norm = 0.013268015435807275\n",
      "Iteration 891 : x = [2.10117955 3.80502755] f(x) = 0.023594966364648192 gradient norm = 0.013267319373664628\n",
      "Iteration 892 : x = [2.10113653 3.80370152] f(x) = 0.023577364651196784 gradient norm = 0.013266621239978037\n",
      "Iteration 893 : x = [2.1010935  3.80237555] f(x) = 0.02355976479152058 gradient norm = 0.013265921031698541\n",
      "Iteration 894 : x = [2.10105048 3.80104966] f(x) = 0.02354216679102818 gradient norm = 0.013265218745773336\n",
      "Iteration 895 : x = [2.10100745 3.79972384] f(x) = 0.023524570655135423 gradient norm = 0.0132645143791458\n",
      "Iteration 896 : x = [2.10096443 3.79839808] f(x) = 0.023506976389265386 gradient norm = 0.013263807928755457\n",
      "Iteration 897 : x = [2.10092141 3.7970724 ] f(x) = 0.023489383998848368 gradient norm = 0.013263099391537993\n",
      "Iteration 898 : x = [2.10087838 3.79574679] f(x) = 0.02347179348932193 gradient norm = 0.01326238876442525\n",
      "Iteration 899 : x = [2.10083536 3.79442125] f(x) = 0.02345420486613089 gradient norm = 0.013261676044345236\n",
      "Iteration 900 : x = [2.10079234 3.79309578] f(x) = 0.0234366181347273 gradient norm = 0.013260961228222082\n",
      "Iteration 901 : x = [2.10074932 3.79177038] f(x) = 0.023419033300570505 gradient norm = 0.013260244312976092\n",
      "Iteration 902 : x = [2.1007063  3.79044505] f(x) = 0.02340145036912711 gradient norm = 0.01325952529552372\n",
      "Iteration 903 : x = [2.10066329 3.7891198 ] f(x) = 0.023383869345871004 gradient norm = 0.013258804172777548\n",
      "Iteration 904 : x = [2.10062027 3.78779462] f(x) = 0.02336629023628331 gradient norm = 0.013258080941646308\n",
      "Iteration 905 : x = [2.10057725 3.78646951] f(x) = 0.02334871304585251 gradient norm = 0.013257355599034881\n",
      "Iteration 906 : x = [2.10053424 3.78514447] f(x) = 0.023331137780074326 gradient norm = 0.01325662814184427\n",
      "Iteration 907 : x = [2.10049122 3.7838195 ] f(x) = 0.023313564444451807 gradient norm = 0.01325589856697164\n",
      "Iteration 908 : x = [2.10044821 3.78249461] f(x) = 0.023295993044495297 gradient norm = 0.01325516687131026\n",
      "Iteration 909 : x = [2.10040519 3.78116979] f(x) = 0.02327842358572245 gradient norm = 0.01325443305174956\n",
      "Iteration 910 : x = [2.10036218 3.77984505] f(x) = 0.023260856073658236 gradient norm = 0.013253697105175086\n",
      "Iteration 911 : x = [2.10031917 3.77852038] f(x) = 0.023243290513834936 gradient norm = 0.013252959028468519\n",
      "Iteration 912 : x = [2.10027616 3.77719578] f(x) = 0.023225726911792192 gradient norm = 0.01325221881850766\n",
      "Iteration 913 : x = [2.10023315 3.77587126] f(x) = 0.023208165273076956 gradient norm = 0.013251476472166443\n",
      "Iteration 914 : x = [2.10019014 3.77454681] f(x) = 0.02319060560324351 gradient norm = 0.013250731986314932\n",
      "Iteration 915 : x = [2.10014713 3.77322243] f(x) = 0.023173047907853492 gradient norm = 0.013249985357819299\n",
      "Iteration 916 : x = [2.10010413 3.77189813] f(x) = 0.023155492192475893 gradient norm = 0.01324923658354185\n",
      "Iteration 917 : x = [2.10006112 3.7705739 ] f(x) = 0.023137938462687052 gradient norm = 0.013248485660340991\n",
      "Iteration 918 : x = [2.10001812 3.76924975] f(x) = 0.023120386724070695 gradient norm = 0.013247732585071266\n",
      "Iteration 919 : x = [2.09997512 3.76792568] f(x) = 0.023102836982217868 gradient norm = 0.01324697735458333\n",
      "Iteration 920 : x = [2.09993211 3.76660168] f(x) = 0.023085289242727017 gradient norm = 0.01324621996572394\n",
      "Iteration 921 : x = [2.09988911 3.76527776] f(x) = 0.023067743511203994 gradient norm = 0.013245460415335975\n",
      "Iteration 922 : x = [2.09984611 3.76395391] f(x) = 0.023050199793261977 gradient norm = 0.013244698700258436\n",
      "Iteration 923 : x = [2.09980312 3.76263014] f(x) = 0.02303265809452158 gradient norm = 0.0132439348173264\n",
      "Iteration 924 : x = [2.09976012 3.76130644] f(x) = 0.023015118420610783 gradient norm = 0.013243168763371086\n",
      "Iteration 925 : x = [2.09971712 3.75998282] f(x) = 0.022997580777165003 gradient norm = 0.013242400535219809\n",
      "Iteration 926 : x = [2.09967413 3.75865928] f(x) = 0.022980045169827015 gradient norm = 0.01324163012969598\n",
      "Iteration 927 : x = [2.09963114 3.75733581] f(x) = 0.022962511604247032 gradient norm = 0.013240857543619125\n",
      "Iteration 928 : x = [2.09958815 3.75601243] f(x) = 0.02294498008608271 gradient norm = 0.013240082773804868\n",
      "Iteration 929 : x = [2.09954516 3.75468912] f(x) = 0.022927450620999074 gradient norm = 0.013239305817064938\n",
      "Iteration 930 : x = [2.09950217 3.75336588] f(x) = 0.022909923214668608 gradient norm = 0.013238526670207154\n",
      "Iteration 931 : x = [2.09945918 3.75204273] f(x) = 0.022892397872771246 gradient norm = 0.013237745330035447\n",
      "Iteration 932 : x = [2.09941619 3.75071965] f(x) = 0.022874874600994317 gradient norm = 0.013236961793349824\n",
      "Iteration 933 : x = [2.09937321 3.74939666] f(x) = 0.022857353405032636 gradient norm = 0.013236176056946429\n",
      "Iteration 934 : x = [2.09933023 3.74807374] f(x) = 0.022839834290588445 gradient norm = 0.013235388117617443\n",
      "Iteration 935 : x = [2.09928725 3.7467509 ] f(x) = 0.02282231726337145 gradient norm = 0.013234597972151199\n",
      "Iteration 936 : x = [2.09924427 3.74542813] f(x) = 0.022804802329098803 gradient norm = 0.013233805617332076\n",
      "Iteration 937 : x = [2.09920129 3.74410545] f(x) = 0.02278728949349516 gradient norm = 0.013233011049940577\n",
      "Iteration 938 : x = [2.09915831 3.74278285] f(x) = 0.022769778762292605 gradient norm = 0.01323221426675328\n",
      "Iteration 939 : x = [2.09911533 3.74146032] f(x) = 0.022752270141230716 gradient norm = 0.01323141526454286\n",
      "Iteration 940 : x = [2.09907236 3.74013788] f(x) = 0.022734763636056567 gradient norm = 0.013230614040078068\n",
      "Iteration 941 : x = [2.09902939 3.73881552] f(x) = 0.022717259252524706 gradient norm = 0.013229810590123759\n",
      "Iteration 942 : x = [2.09898642 3.73749323] f(x) = 0.02269975699639718 gradient norm = 0.013229004911440863\n",
      "Iteration 943 : x = [2.09894345 3.73617103] f(x) = 0.022682256873443524 gradient norm = 0.0132281970007864\n",
      "Iteration 944 : x = [2.09890048 3.73484891] f(x) = 0.022664758889440778 gradient norm = 0.01322738685491347\n",
      "Iteration 945 : x = [2.09885752 3.73352687] f(x) = 0.022647263050173515 gradient norm = 0.013226574470571273\n",
      "Iteration 946 : x = [2.09881455 3.73220491] f(x) = 0.02262976936143378 gradient norm = 0.013225759844505061\n",
      "Iteration 947 : x = [2.09877159 3.73088303] f(x) = 0.022612277829021178 gradient norm = 0.01322494297345621\n",
      "Iteration 948 : x = [2.09872863 3.72956124] f(x) = 0.02259478845874282 gradient norm = 0.01322412385416214\n",
      "Iteration 949 : x = [2.09868567 3.72823952] f(x) = 0.022577301256413357 gradient norm = 0.013223302483356373\n",
      "Iteration 950 : x = [2.09864271 3.72691789] f(x) = 0.022559816227854947 gradient norm = 0.0132224788577685\n",
      "Iteration 951 : x = [2.09859976 3.72559634] f(x) = 0.02254233337889732 gradient norm = 0.013221652974124205\n",
      "Iteration 952 : x = [2.0985568  3.72427487] f(x) = 0.022524852715377738 gradient norm = 0.013220824829145232\n",
      "Iteration 953 : x = [2.09851385 3.72295349] f(x) = 0.02250737424314101 gradient norm = 0.013219994419549417\n",
      "Iteration 954 : x = [2.0984709  3.72163219] f(x) = 0.022489897968039515 gradient norm = 0.01321916174205067\n",
      "Iteration 955 : x = [2.09842795 3.72031097] f(x) = 0.022472423895933184 gradient norm = 0.01321832679335898\n",
      "Iteration 956 : x = [2.09838501 3.71898983] f(x) = 0.022454952032689508 gradient norm = 0.013217489570180404\n",
      "Iteration 957 : x = [2.09834206 3.71766878] f(x) = 0.02243748238418355 gradient norm = 0.013216650069217085\n",
      "Iteration 958 : x = [2.09829912 3.71634781] f(x) = 0.022420014956297966 gradient norm = 0.013215808287167237\n",
      "Iteration 959 : x = [2.09825618 3.71502693] f(x) = 0.022402549754922965 gradient norm = 0.013214964220725144\n",
      "Iteration 960 : x = [2.09821324 3.71370613] f(x) = 0.022385086785956382 gradient norm = 0.013214117866581169\n",
      "Iteration 961 : x = [2.0981703  3.71238542] f(x) = 0.02236762605530359 gradient norm = 0.013213269221421754\n",
      "Iteration 962 : x = [2.09812737 3.71106479] f(x) = 0.022350167568877595 gradient norm = 0.013212418281929405\n",
      "Iteration 963 : x = [2.09808444 3.70974425] f(x) = 0.022332711332599012 gradient norm = 0.013211565044782703\n",
      "Iteration 964 : x = [2.09804151 3.70842379] f(x) = 0.022315257352396034 gradient norm = 0.01321070950665631\n",
      "Iteration 965 : x = [2.09799858 3.70710341] f(x) = 0.022297805634204488 gradient norm = 0.013209851664220961\n",
      "Iteration 966 : x = [2.09795565 3.70578313] f(x) = 0.022280356183967794 gradient norm = 0.013208991514143441\n",
      "Iteration 967 : x = [2.09791272 3.70446292] f(x) = 0.022262909007637006 gradient norm = 0.013208129053086628\n",
      "Iteration 968 : x = [2.0978698  3.70314281] f(x) = 0.022245464111170805 gradient norm = 0.013207264277709475\n",
      "Iteration 969 : x = [2.09782688 3.70182278] f(x) = 0.022228021500535506 gradient norm = 0.013206397184666992\n",
      "Iteration 970 : x = [2.09778396 3.70050284] f(x) = 0.022210581181705047 gradient norm = 0.013205527770610263\n",
      "Iteration 971 : x = [2.09774104 3.69918298] f(x) = 0.022193143160661004 gradient norm = 0.013204656032186459\n",
      "Iteration 972 : x = [2.09769813 3.69786321] f(x) = 0.02217570744339263 gradient norm = 0.013203781966038799\n",
      "Iteration 973 : x = [2.09765522 3.69654353] f(x) = 0.022158274035896795 gradient norm = 0.013202905568806593\n",
      "Iteration 974 : x = [2.0976123  3.69522394] f(x) = 0.02214084294417803 gradient norm = 0.01320202683712521\n",
      "Iteration 975 : x = [2.0975694  3.69390444] f(x) = 0.02212341417424852 gradient norm = 0.013201145767626087\n",
      "Iteration 976 : x = [2.09752649 3.69258502] f(x) = 0.02210598773212813 gradient norm = 0.013200262356936747\n",
      "Iteration 977 : x = [2.09748358 3.69126569] f(x) = 0.022088563623844405 gradient norm = 0.013199376601680773\n",
      "Iteration 978 : x = [2.09744068 3.68994645] f(x) = 0.022071141855432526 gradient norm = 0.013198488498477825\n",
      "Iteration 979 : x = [2.09739778 3.6886273 ] f(x) = 0.022053722432935376 gradient norm = 0.013197598043943626\n",
      "Iteration 980 : x = [2.09735488 3.68730824] f(x) = 0.022036305362403523 gradient norm = 0.01319670523468997\n",
      "Iteration 981 : x = [2.09731199 3.68598926] f(x) = 0.022018890649895203 gradient norm = 0.013195810067324745\n",
      "Iteration 982 : x = [2.09726909 3.68467038] f(x) = 0.022001478301476363 gradient norm = 0.01319491253845188\n",
      "Iteration 983 : x = [2.0972262  3.68335159] f(x) = 0.02198406832322065 gradient norm = 0.013194012644671387\n",
      "Iteration 984 : x = [2.09718331 3.68203288] f(x) = 0.02196666072120939 gradient norm = 0.013193110382579363\n",
      "Iteration 985 : x = [2.09714043 3.68071427] f(x) = 0.02194925550153163 gradient norm = 0.013192205748767954\n",
      "Iteration 986 : x = [2.09709754 3.67939574] f(x) = 0.021931852670284132 gradient norm = 0.0131912987398254\n",
      "Iteration 987 : x = [2.09705466 3.67807731] f(x) = 0.021914452233571368 gradient norm = 0.013190389352336004\n",
      "Iteration 988 : x = [2.09701178 3.67675897] f(x) = 0.021897054197505525 gradient norm = 0.013189477582880143\n",
      "Iteration 989 : x = [2.0969689  3.67544072] f(x) = 0.021879658568206506 gradient norm = 0.013188563428034268\n",
      "Iteration 990 : x = [2.09692602 3.67412256] f(x) = 0.021862265351801972 gradient norm = 0.013187646884370895\n",
      "Iteration 991 : x = [2.09688315 3.67280449] f(x) = 0.02184487455442729 gradient norm = 0.013186727948458635\n",
      "Iteration 992 : x = [2.09684028 3.67148652] f(x) = 0.02182748618222556 gradient norm = 0.013185806616862158\n",
      "Iteration 993 : x = [2.09679741 3.67016863] f(x) = 0.02181010024134765 gradient norm = 0.013184882886142219\n",
      "Iteration 994 : x = [2.09675454 3.66885084] f(x) = 0.02179271673795216 gradient norm = 0.013183956752855636\n",
      "Iteration 995 : x = [2.09671168 3.66753314] f(x) = 0.021775335678205453 gradient norm = 0.013183028213555317\n",
      "Iteration 996 : x = [2.09666882 3.66621554] f(x) = 0.021757957068281587 gradient norm = 0.013182097264790235\n",
      "Iteration 997 : x = [2.09662596 3.66489802] f(x) = 0.02174058091436248 gradient norm = 0.01318116390310545\n",
      "Iteration 998 : x = [2.0965831  3.66358061] f(x) = 0.02172320722263773 gradient norm = 0.013180228125042104\n",
      "Iteration 999 : x = [2.09654024 3.66226328] f(x) = 0.02170583599930474 gradient norm = 0.013179289927137402\n",
      "\n",
      "\tStep size: 1\n",
      "Iteration 0 : x = [2. 5.] f(x) = 0.04037643540736778 gradient norm = 0.017863549100416345\n",
      "Iteration 1 : x = [2.01158942 4.98640619] f(x) = 0.04006309913390959 gradient norm = 0.01723261186881376\n",
      "Iteration 2 : x = [2.02219061 4.97282025] f(x) = 0.03977102293968484 gradient norm = 0.016679799162598628\n",
      "Iteration 3 : x = [2.03187963 4.95924311] f(x) = 0.03949693976448002 gradient norm = 0.016197739077489226\n",
      "Iteration 4 : x = [2.04072742 4.94567538] f(x) = 0.0392380629356495 gradient norm = 0.015779298058660757\n",
      "Iteration 5 : x = [2.0488     4.93211737] f(x) = 0.03899202008335923 gradient norm = 0.015417663834878814\n",
      "Iteration 6 : x = [2.05615874 4.91856918] f(x) = 0.038756795077792845 gradient norm = 0.015106413931172773\n",
      "Iteration 7 : x = [2.06286055 4.90503074] f(x) = 0.03853067728596525 gradient norm = 0.01483956747443785\n",
      "Iteration 8 : x = [2.06895822 4.89150184] f(x) = 0.038312217430111116 gradient norm = 0.01461161938800308\n",
      "Iteration 9 : x = [2.07450057 4.87798216] f(x) = 0.03810018934347399 gradient norm = 0.014417557454639568\n",
      "Iteration 10 : x = [2.07953279 4.86447132] f(x) = 0.03789355695270152 gradient norm = 0.014252863879552581\n",
      "Iteration 11 : x = [2.08409661 4.85096889] f(x) = 0.037691445861420265 gradient norm = 0.014113503774129952\n",
      "Iteration 12 : x = [2.08823053 4.83747438] f(x) = 0.037493118961382334 gradient norm = 0.013995903377601697\n",
      "Iteration 13 : x = [2.09197009 4.82398732] f(x) = 0.03729795555188683 gradient norm = 0.013896920883428015\n",
      "Iteration 14 : x = [2.09534804 4.81050719] f(x) = 0.03710543350224288 gradient norm = 0.013813812527948055\n",
      "Iteration 15 : x = [2.09839454 4.7970335 ] f(x) = 0.03691511404403798 gradient norm = 0.013744196228997797\n",
      "Iteration 16 : x = [2.10113735 4.78356576] f(x) = 0.03672662882877245 gradient norm = 0.013686014619683343\n",
      "Iteration 17 : x = [2.10360202 4.77010351] f(x) = 0.036539668931382996 gradient norm = 0.013637498874061986\n",
      "Iteration 18 : x = [2.10581203 4.75664627] f(x) = 0.036353975521020675 gradient norm = 0.01359713431072103\n",
      "Iteration 19 : x = [2.10778896 4.74319362] f(x) = 0.036169331957134954 gradient norm = 0.013563628410442846\n",
      "Iteration 20 : x = [2.10955264 4.72974514] f(x) = 0.03598555710156826 gradient norm = 0.013535881603340315\n",
      "Iteration 21 : x = [2.11112128 4.71630046] f(x) = 0.035802499666209554 gradient norm = 0.01351296096704958\n",
      "Iteration 22 : x = [2.11251158 4.70285921] f(x) = 0.03562003344107776 gradient norm = 0.013494076823154462\n",
      "Iteration 23 : x = [2.11373887 4.68942106] f(x) = 0.03543805326981659 gradient norm = 0.013478562113943856\n",
      "Iteration 24 : x = [2.11481722 4.67598571] f(x) = 0.035256471658802566 gradient norm = 0.013465854375493209\n",
      "Iteration 25 : x = [2.11575951 4.66255286] f(x) = 0.0350752159227109 gradient norm = 0.013455480086395034\n",
      "Iteration 26 : x = [2.11657755 4.64912227] f(x) = 0.0348942257837454 gradient norm = 0.013447041156132484\n",
      "Iteration 27 : x = [2.11728215 4.6356937 ] f(x) = 0.03471345135409516 gradient norm = 0.013440203316545933\n",
      "Iteration 28 : x = [2.11788323 4.62226695] f(x) = 0.03453285144178459 gradient norm = 0.01343468618901216\n",
      "Iteration 29 : x = [2.11838986 4.60884182] f(x) = 0.034352392129161906 gradient norm = 0.013430254815048441\n",
      "Iteration 30 : x = [2.11881033 4.59541815] f(x) = 0.03417204558102696 gradient norm = 0.013426712456332123\n",
      "Iteration 31 : x = [2.11915225 4.58199579] f(x) = 0.0339917890460144 gradient norm = 0.013423894489678576\n",
      "Iteration 32 : x = [2.11942257 4.56857462] f(x) = 0.03381160402047846 gradient norm = 0.01342166324206705\n",
      "Iteration 33 : x = [2.11962762 4.55515452] f(x) = 0.03363147554891256 gradient norm = 0.013419903629528145\n",
      "Iteration 34 : x = [2.11977323 4.5417354 ] f(x) = 0.033451391638999614 gradient norm = 0.013418519481127683\n",
      "Iteration 35 : x = [2.1198647 4.5283172] f(x) = 0.03327134277283318 gradient norm = 0.013417430445152121\n",
      "Iteration 36 : x = [2.11990687 4.51489983] f(x) = 0.033091321498765584 gradient norm = 0.013416569388831862\n",
      "Iteration 37 : x = [2.11990418 4.50148326] f(x) = 0.032911322090805786 gradient norm = 0.013415880215544494\n",
      "Iteration 38 : x = [2.11986067 4.48806745] f(x) = 0.03273134026457321 gradient norm = 0.013415316034500618\n",
      "Iteration 39 : x = [2.11978003 4.47465238] f(x) = 0.03255137294057275 gradient norm = 0.013414837627543906\n",
      "Iteration 40 : x = [2.11966562 4.46123803] f(x) = 0.0323714180470391 gradient norm = 0.013414412166028674\n",
      "Iteration 41 : x = [2.11952053 4.4478244 ] f(x) = 0.032191474355848154 gradient norm = 0.013414012137909728\n",
      "Iteration 42 : x = [2.11934755 4.43441151] f(x) = 0.032011541346045 gradient norm = 0.013413614451326153\n",
      "Iteration 43 : x = [2.11914924 4.42099936] f(x) = 0.03183161909042284 gradient norm = 0.013413199686210476\n",
      "Iteration 44 : x = [2.11892794 4.40758798] f(x) = 0.0316517081613308 gradient norm = 0.013412751469924825\n",
      "Iteration 45 : x = [2.11868576 4.39417742] f(x) = 0.03147180955251295 gradient norm = 0.013412255956722137\n",
      "Iteration 46 : x = [2.11842464 4.38076771] f(x) = 0.03129192461430534 gradient norm = 0.013411701394047437\n",
      "Iteration 47 : x = [2.11814635 4.36735889] f(x) = 0.031112054999957055 gradient norm = 0.0134110777614154\n",
      "Iteration 48 : x = [2.11785249 4.35395103] f(x) = 0.03093220262120996 gradient norm = 0.013410376469897508\n",
      "Iteration 49 : x = [2.11754451 4.34054419] f(x) = 0.03075236961158054 gradient norm = 0.013409590112189201\n",
      "Iteration 50 : x = [2.11722377 4.32713844] f(x) = 0.030572558296044997 gradient norm = 0.013408712254858238\n",
      "Iteration 51 : x = [2.11689145 4.31373385] f(x) = 0.03039277116604553 gradient norm = 0.013407737265746638\n",
      "Iteration 52 : x = [2.11654868 4.30033049] f(x) = 0.03021301085891572 gradient norm = 0.013406660170651055\n",
      "Iteration 53 : x = [2.11619644 4.28692846] f(x) = 0.030033280140974294 gradient norm = 0.013405476534372775\n",
      "Iteration 54 : x = [2.11583565 4.27352784] f(x) = 0.029853581893662235 gradient norm = 0.01340418236203948\n",
      "Iteration 55 : x = [2.11546714 4.26012872] f(x) = 0.029673919102203686 gradient norm = 0.013402774017279821\n",
      "Iteration 56 : x = [2.11509166 4.24673121] f(x) = 0.029494294846358335 gradient norm = 0.013401248154400256\n",
      "Iteration 57 : x = [2.1147099 4.2333354] f(x) = 0.02931471229290658 gradient norm = 0.013399601662189056\n",
      "Iteration 58 : x = [2.11432248 4.2199414 ] f(x) = 0.02913517468956916 gradient norm = 0.013397831617369757\n",
      "Iteration 59 : x = [2.11392995 4.20654932] f(x) = 0.02895568536011397 gradient norm = 0.01339593524605811\n",
      "Iteration 60 : x = [2.11353285 4.19315927] f(x) = 0.028776247700444967 gradient norm = 0.013393909891853838\n",
      "Iteration 61 : x = [2.11313162 4.17977137] f(x) = 0.02859686517550268 gradient norm = 0.013391752989429219\n",
      "Iteration 62 : x = [2.11272669 4.16638574] f(x) = 0.028417541316835646 gradient norm = 0.013389462042669572\n",
      "Iteration 63 : x = [2.11231846 4.15300251] f(x) = 0.028238279720725862 gradient norm = 0.013387034606580766\n",
      "Iteration 64 : x = [2.11190725 4.13962179] f(x) = 0.028059084046771484 gradient norm = 0.013384468272312844\n",
      "Iteration 65 : x = [2.11149339 4.12624372] f(x) = 0.027879958016846857 gradient norm = 0.013381760654759775\n",
      "Iteration 66 : x = [2.11107717 4.11286843] f(x) = 0.027700905414373707 gradient norm = 0.013378909382288019\n",
      "Iteration 67 : x = [2.11065885 4.09949607] f(x) = 0.027521930083848508 gradient norm = 0.013375912088223236\n",
      "Iteration 68 : x = [2.11023865 4.08612676] f(x) = 0.027343035930581135 gradient norm = 0.013372766403788513\n",
      "Iteration 69 : x = [2.10981679 4.07276065] f(x) = 0.027164226920606962 gradient norm = 0.013369469952240276\n",
      "Iteration 70 : x = [2.10939347 4.05939788] f(x) = 0.02698550708074195 gradient norm = 0.013366020343992263\n",
      "Iteration 71 : x = [2.10896886 4.0460386 ] f(x) = 0.026806880498754685 gradient norm = 0.013362415172554157\n",
      "Iteration 72 : x = [2.10854311 4.03268297] f(x) = 0.02662835132363471 gradient norm = 0.013358652011141926\n",
      "Iteration 73 : x = [2.10811638 4.01933114] f(x) = 0.02644992376593916 gradient norm = 0.013354728409841816\n",
      "Iteration 74 : x = [2.10768878 4.00598326] f(x) = 0.0262716020982038 gradient norm = 0.01335064189323074\n",
      "Iteration 75 : x = [2.10726044 3.99263949] f(x) = 0.02609339065540603 gradient norm = 0.013346389958372918\n",
      "Iteration 76 : x = [2.10683146 3.9793    ] f(x) = 0.025915293835470154 gradient norm = 0.013341970073126902\n",
      "Iteration 77 : x = [2.10640195 3.96596494] f(x) = 0.025737316099806604 gradient norm = 0.013337379674708761\n",
      "Iteration 78 : x = [2.10597197 3.95263449] f(x) = 0.0255594619738782 gradient norm = 0.013332616168466883\n",
      "Iteration 79 : x = [2.10554162 3.93930882] f(x) = 0.02538173604778784 gradient norm = 0.01332767692683201\n",
      "Iteration 80 : x = [2.10511097 3.92598811] f(x) = 0.025204142976882556 gradient norm = 0.013322559288412495\n",
      "Iteration 81 : x = [2.10468007 3.91267252] f(x) = 0.0250266874823701 gradient norm = 0.013317260557210445\n",
      "Iteration 82 : x = [2.10424899 3.89936224] f(x) = 0.0248493743519445 gradient norm = 0.013311778001938794\n",
      "Iteration 83 : x = [2.10381777 3.88605745] f(x) = 0.02467220844041759 gradient norm = 0.013306108855423023\n",
      "Iteration 84 : x = [2.10338647 3.87275833] f(x) = 0.024495194670354187 gradient norm = 0.013300250314074443\n",
      "Iteration 85 : x = [2.10295513 3.85946507] f(x) = 0.024318338032708293 gradient norm = 0.01329419953742436\n",
      "Iteration 86 : x = [2.10252378 3.84617787] f(x) = 0.02414164358745888 gradient norm = 0.013287953647710495\n",
      "Iteration 87 : x = [2.10209246 3.83289692] f(x) = 0.023965116464243073 gradient norm = 0.01328150972950893\n",
      "Iteration 88 : x = [2.10166119 3.81962242] f(x) = 0.023788761862985393 gradient norm = 0.013274864829405946\n",
      "Iteration 89 : x = [2.10123002 3.80635456] f(x) = 0.023612585054521542 gradient norm = 0.013268015955705644\n",
      "Iteration 90 : x = [2.10079896 3.79309354] f(x) = 0.02343659138121538 gradient norm = 0.013260960078169896\n",
      "Iteration 91 : x = [2.10036803 3.77983959] f(x) = 0.02326078625756781 gradient norm = 0.013253694127788086\n",
      "Iteration 92 : x = [2.09993726 3.7665929 ] f(x) = 0.02308517517081648 gradient norm = 0.013246214996574862\n",
      "Iteration 93 : x = [2.09950666 3.75335368] f(x) = 0.022909763681524795 gradient norm = 0.013238519537394414\n",
      "Iteration 94 : x = [2.09907626 3.74012216] f(x) = 0.02273455742415957 gradient norm = 0.013230604563810424\n",
      "Iteration 95 : x = [2.09864605 3.72689855] f(x) = 0.022559562107655712 gradient norm = 0.013222466849961232\n",
      "Iteration 96 : x = [2.09821606 3.71368308] f(x) = 0.02238478351596713 gradient norm = 0.01321410313045985\n",
      "Iteration 97 : x = [2.0977863  3.70047597] f(x) = 0.02221022750860253 gradient norm = 0.013205510100318984\n",
      "Iteration 98 : x = [2.09735677 3.68727744] f(x) = 0.02203590002114515 gradient norm = 0.013196684414901285\n",
      "Iteration 99 : x = [2.09692749 3.67408774] f(x) = 0.02186180706575497 gradient norm = 0.013187622689895213\n",
      "Iteration 100 : x = [2.09649846 3.6609071 ] f(x) = 0.021687954731652602 gradient norm = 0.013178321501317163\n",
      "Iteration 101 : x = [2.0960697  3.64773576] f(x) = 0.021514349185583294 gradient norm = 0.013168777385540568\n",
      "Iteration 102 : x = [2.0956412  3.63457395] f(x) = 0.021340996672260068 gradient norm = 0.013158986839352802\n",
      "Iteration 103 : x = [2.09521297 3.62142193] f(x) = 0.021167903514784644 gradient norm = 0.0131489463200408\n",
      "Iteration 104 : x = [2.09478501 3.60827995] f(x) = 0.020995076115044788 gradient norm = 0.013138652245506447\n",
      "Iteration 105 : x = [2.09435734 3.59514826] f(x) = 0.0208225209540869 gradient norm = 0.013128100994412884\n",
      "Iteration 106 : x = [2.09392994 3.58202712] f(x) = 0.02065024459246247 gradient norm = 0.013117288906362719\n",
      "Iteration 107 : x = [2.09350283 3.56891679] f(x) = 0.02047825367054685 gradient norm = 0.013106212282109626\n",
      "Iteration 108 : x = [2.09307601 3.55581753] f(x) = 0.020306554908829096 gradient norm = 0.01309486738380437\n",
      "Iteration 109 : x = [2.09264947 3.54272961] f(x) = 0.020135155108171432 gradient norm = 0.013083250435276774\n",
      "Iteration 110 : x = [2.09222322 3.52965331] f(x) = 0.019964061150036603 gradient norm = 0.013071357622354932\n",
      "Iteration 111 : x = [2.09179725 3.51658889] f(x) = 0.01979327999668188 gradient norm = 0.013059185093223045\n",
      "Iteration 112 : x = [2.09137158 3.50353664] f(x) = 0.01962281869131795 gradient norm = 0.013046728958819505\n",
      "Iteration 113 : x = [2.09094619 3.49049685] f(x) = 0.01945268435823113 gradient norm = 0.013033985293276516\n",
      "Iteration 114 : x = [2.09052108 3.4774698 ] f(x) = 0.01928288420286727 gradient norm = 0.01302095013440301\n",
      "Iteration 115 : x = [2.09009626 3.46445578] f(x) = 0.019113425511875632 gradient norm = 0.013007619484212292\n",
      "Iteration 116 : x = [2.08967172 3.45145509] f(x) = 0.018944315653111065 gradient norm = 0.012993989309496072\n",
      "Iteration 117 : x = [2.08924747 3.43846803] f(x) = 0.01877556207559263 gradient norm = 0.012980055542446522\n",
      "Iteration 118 : x = [2.08882349 3.4254949 ] f(x) = 0.018607172309416966 gradient norm = 0.012965814081328042\n",
      "Iteration 119 : x = [2.08839979 3.41253601] f(x) = 0.018439153965624507 gradient norm = 0.012951260791200419\n",
      "Iteration 120 : x = [2.08797635 3.39959168] f(x) = 0.018271514736016726 gradient norm = 0.01293639150469508\n",
      "Iteration 121 : x = [2.08755319 3.38666221] f(x) = 0.018104262392922354 gradient norm = 0.012921202022846237\n",
      "Iteration 122 : x = [2.0871303  3.37374793] f(x) = 0.017937404788910923 gradient norm = 0.012905688115978668\n",
      "Iteration 123 : x = [2.08670767 3.36084916] f(x) = 0.017770949856451303 gradient norm = 0.012889845524653894\n",
      "Iteration 124 : x = [2.08628529 3.34796624] f(x) = 0.017604905607513568 gradient norm = 0.012873669960676605\n",
      "Iteration 125 : x = [2.08586318 3.33509949] f(x) = 0.01743928013311185 gradient norm = 0.01285715710816314\n",
      "Iteration 126 : x = [2.08544131 3.32224926] f(x) = 0.017274081602786394 gradient norm = 0.012840302624673821\n",
      "Iteration 127 : x = [2.08501968 3.30941588] f(x) = 0.01710931826402254 gradient norm = 0.012823102142411074\n",
      "Iteration 128 : x = [2.0845983 3.2965997] f(x) = 0.016944998441604568 gradient norm = 0.012805551269485033\n",
      "Iteration 129 : x = [2.08417716 3.28380108] f(x) = 0.016781130536902302 gradient norm = 0.012787645591248691\n",
      "Iteration 130 : x = [2.08375624 3.27102036] f(x) = 0.016617723027088322 gradient norm = 0.012769380671704236\n",
      "Iteration 131 : x = [2.08333555 3.25825791] f(x) = 0.016454784464283535 gradient norm = 0.012750752054982594\n",
      "Iteration 132 : x = [2.08291508 3.24551409] f(x) = 0.016292323474628993 gradient norm = 0.012731755266897911\n",
      "Iteration 133 : x = [2.08249482 3.23278928] f(x) = 0.016130348757281726 gradient norm = 0.012712385816578879\n",
      "Iteration 134 : x = [2.08207477 3.22008383] f(x) = 0.01596886908333242 gradient norm = 0.012692639198178705\n",
      "Iteration 135 : x = [2.08165493 3.20739814] f(x) = 0.015807893294642626 gradient norm = 0.012672510892665492\n",
      "Iteration 136 : x = [2.08123527 3.19473258] f(x) = 0.015647430302599408 gradient norm = 0.012651996369694867\n",
      "Iteration 137 : x = [2.08081581 3.18208754] f(x) = 0.015487489086785147 gradient norm = 0.012631091089566546\n",
      "Iteration 138 : x = [2.08039653 3.16946341] f(x) = 0.015328078693560239 gradient norm = 0.012609790505266541\n",
      "Iteration 139 : x = [2.07997742 3.15686058] f(x) = 0.015169208234556635 gradient norm = 0.01258809006459686\n",
      "Iteration 140 : x = [2.07955848 3.14427947] f(x) = 0.015010886885079917 gradient norm = 0.012565985212393974\n",
      "Iteration 141 : x = [2.0791397  3.13172046] f(x) = 0.014853123882417716 gradient norm = 0.012543471392838013\n",
      "Iteration 142 : x = [2.07872107 3.11918398] f(x) = 0.0146959285240525 gradient norm = 0.012520544051853918\n",
      "Iteration 143 : x = [2.07830259 3.10667043] f(x) = 0.014539310165776401 gradient norm = 0.012497198639606223\n",
      "Iteration 144 : x = [2.07788425 3.09418023] f(x) = 0.014383278219706171 gradient norm = 0.01247343061308861\n",
      "Iteration 145 : x = [2.07746604 3.08171382] f(x) = 0.014227842152196189 gradient norm = 0.012449235438809832\n",
      "Iteration 146 : x = [2.07704795 3.0692716 ] f(x) = 0.014073011481647387 gradient norm = 0.012424608595576926\n",
      "Iteration 147 : x = [2.07662997 3.05685403] f(x) = 0.013918795776210415 gradient norm = 0.012399545577377075\n",
      "Iteration 148 : x = [2.0762121  3.04446153] f(x) = 0.013765204651380957 gradient norm = 0.01237404189635899\n",
      "Iteration 149 : x = [2.07579433 3.03209454] f(x) = 0.013612247767485442 gradient norm = 0.012348093085914823\n",
      "Iteration 150 : x = [2.07537665 3.01975351] f(x) = 0.013459934827055433 gradient norm = 0.012321694703863352\n",
      "Iteration 151 : x = [2.07495904 3.0074389 ] f(x) = 0.01330827557208904 gradient norm = 0.012294842335735074\n",
      "Iteration 152 : x = [2.07454151 2.99515114] f(x) = 0.013157279781197764 gradient norm = 0.012267531598159888\n",
      "Iteration 153 : x = [2.07412404 2.98289072] f(x) = 0.013006957266637238 gradient norm = 0.012239758142357495\n",
      "Iteration 154 : x = [2.07370663 2.97065808] f(x) = 0.012857317871220667 gradient norm = 0.012211517657731093\n",
      "Iteration 155 : x = [2.07328927 2.9584537 ] f(x) = 0.012708371465113465 gradient norm = 0.012182805875564048\n",
      "Iteration 156 : x = [2.07287194 2.94627804] f(x) = 0.012560127942508189 gradient norm = 0.012153618572819776\n",
      "Iteration 157 : x = [2.07245464 2.93413159] f(x) = 0.012412597218178592 gradient norm = 0.012123951576044355\n",
      "Iteration 158 : x = [2.07203735 2.92201482] f(x) = 0.01226578922391197 gradient norm = 0.012093800765371393\n",
      "Iteration 159 : x = [2.07162008 2.90992822] f(x) = 0.012119713904819118 gradient norm = 0.012063162078628597\n",
      "Iteration 160 : x = [2.07120281 2.89787228] f(x) = 0.011974381215521294 gradient norm = 0.01203203151554497\n",
      "Iteration 161 : x = [2.07078554 2.88584748] f(x) = 0.011829801116213763 gradient norm = 0.012000405142057663\n",
      "Iteration 162 : x = [2.07036824 2.87385434] f(x) = 0.011685983568605738 gradient norm = 0.011968279094717024\n",
      "Iteration 163 : x = [2.06995092 2.86189333] f(x) = 0.011542938531736616 gradient norm = 0.011935649585188324\n",
      "Iteration 164 : x = [2.06953357 2.84996498] f(x) = 0.011400675957668742 gradient norm = 0.011902512904848225\n",
      "Iteration 165 : x = [2.06911618 2.83806979] f(x) = 0.011259205787056966 gradient norm = 0.011868865429473978\n",
      "Iteration 166 : x = [2.06869873 2.82620827] f(x) = 0.011118537944595577 gradient norm = 0.011834703624022854\n",
      "Iteration 167 : x = [2.06828123 2.81438093] f(x) = 0.010978682334343485 gradient norm = 0.011800024047499238\n",
      "Iteration 168 : x = [2.06786365 2.8025883 ] f(x) = 0.010839648834928491 gradient norm = 0.011764823357906335\n",
      "Iteration 169 : x = [2.067446   2.79083089] f(x) = 0.010701447294632098 gradient norm = 0.011729098317279314\n",
      "Iteration 170 : x = [2.06702826 2.77910923] f(x) = 0.01056408752635625 gradient norm = 0.011692845796796228\n",
      "Iteration 171 : x = [2.06661043 2.76742386] f(x) = 0.010427579302473775 gradient norm = 0.011656062781962942\n",
      "Iteration 172 : x = [2.0661925  2.75577529] f(x) = 0.010291932349564645 gradient norm = 0.011618746377867695\n",
      "Iteration 173 : x = [2.06577447 2.74416407] f(x) = 0.010157156343040204 gradient norm = 0.01158089381450096\n",
      "Iteration 174 : x = [2.06535631 2.73259072] f(x) = 0.010023260901658188 gradient norm = 0.011542502452135514\n",
      "Iteration 175 : x = [2.06493803 2.7210558 ] f(x) = 0.009890255581931181 gradient norm = 0.01150356978676169\n",
      "Iteration 176 : x = [2.06451962 2.70955984] f(x) = 0.009758149872431872 gradient norm = 0.01146409345557205\n",
      "Iteration 177 : x = [2.06410108 2.69810339] f(x) = 0.009626953187998489 gradient norm = 0.011424071242489736\n",
      "Iteration 178 : x = [2.06368239 2.686687  ] f(x) = 0.009496674863844269 gradient norm = 0.01138350108373413\n",
      "Iteration 179 : x = [2.06326355 2.6753112 ] f(x) = 0.009367324149575095 gradient norm = 0.011342381073417172\n",
      "Iteration 180 : x = [2.06284455 2.66397656] f(x) = 0.009238910203119696 gradient norm = 0.011300709469163412\n",
      "Iteration 181 : x = [2.0624254  2.65268363] f(x) = 0.009111442084577173 gradient norm = 0.011258484697746417\n",
      "Iteration 182 : x = [2.06200607 2.64143296] f(x) = 0.008984928749987029 gradient norm = 0.01121570536073377\n",
      "Iteration 183 : x = [2.06158658 2.6302251 ] f(x) = 0.008859379045027085 gradient norm = 0.01117237024013272\n",
      "Iteration 184 : x = [2.06116691 2.61906062] f(x) = 0.008734801698644991 gradient norm = 0.011128478304027948\n",
      "Iteration 185 : x = [2.06074706 2.60794006] f(x) = 0.008611205316629561 gradient norm = 0.011084028712202742\n",
      "Iteration 186 : x = [2.06032702 2.59686399] f(x) = 0.008488598375128303 gradient norm = 0.011039020821734531\n",
      "Iteration 187 : x = [2.0599068  2.58583297] f(x) = 0.008366989214117888 gradient norm = 0.010993454192555156\n",
      "Iteration 188 : x = [2.05948639 2.57484756] f(x) = 0.008246386030834772 gradient norm = 0.010947328592966451\n",
      "Iteration 189 : x = [2.05906579 2.56390831] f(x) = 0.008126796873173293 gradient norm = 0.01090064400510064\n",
      "Iteration 190 : x = [2.05864499 2.5530158 ] f(x) = 0.008008229633059109 gradient norm = 0.010853400630315597\n",
      "Iteration 191 : x = [2.058224   2.54217056] f(x) = 0.007890692039805993 gradient norm = 0.010805598894513992\n",
      "Iteration 192 : x = [2.05780282 2.53137318] f(x) = 0.007774191653464421 gradient norm = 0.010757239453375566\n",
      "Iteration 193 : x = [2.05738144 2.52062419] f(x) = 0.007658735858170653 gradient norm = 0.01070832319749134\n",
      "Iteration 194 : x = [2.05695987 2.50992417] f(x) = 0.007544331855505303 gradient norm = 0.010658851257388276\n",
      "Iteration 195 : x = [2.05653811 2.49927367] f(x) = 0.007430986657870668 gradient norm = 0.010608825008432828\n",
      "Iteration 196 : x = [2.05611615 2.48867324] f(x) = 0.007318707081896378 gradient norm = 0.010558246075601555\n",
      "Iteration 197 : x = [2.05569401 2.47812343] f(x) = 0.007207499741883222 gradient norm = 0.010507116338106819\n",
      "Iteration 198 : x = [2.05527168 2.46762481] f(x) = 0.007097371043295133 gradient norm = 0.010455437933865427\n",
      "Iteration 199 : x = [2.05484917 2.45717791] f(x) = 0.006988327176309669 gradient norm = 0.010403213263798044\n",
      "Iteration 200 : x = [2.05442649 2.44678329] f(x) = 0.0068803741094374685 gradient norm = 0.010350444995947007\n",
      "Iteration 201 : x = [2.05400363 2.43644148] f(x) = 0.006773517583221366 gradient norm = 0.010297136069400258\n",
      "Iteration 202 : x = [2.05358062 2.42615304] f(x) = 0.006667763104025971 gradient norm = 0.01024328969800894\n",
      "Iteration 203 : x = [2.05315744 2.4159185 ] f(x) = 0.006563115937928794 gradient norm = 0.010188909373886395\n",
      "Iteration 204 : x = [2.05273411 2.40573838] f(x) = 0.006459581104723932 gradient norm = 0.010133998870676193\n",
      "Iteration 205 : x = [2.05231065 2.39561324] f(x) = 0.006357163372049595 gradient norm = 0.010078562246577012\n",
      "Iteration 206 : x = [2.05188705 2.38554358] f(x) = 0.006255867249650736 gradient norm = 0.010022603847112344\n",
      "Iteration 207 : x = [2.05146333 2.37552994] f(x) = 0.006155696983788102 gradient norm = 0.00996612830763301\n",
      "Iteration 208 : x = [2.0510395  2.36557282] f(x) = 0.00605665655180504 gradient norm = 0.00990914055554092\n",
      "Iteration 209 : x = [2.05061558 2.35567276] f(x) = 0.005958749656863393 gradient norm = 0.00985164581222254\n",
      "Iteration 210 : x = [2.05019157 2.34583024] f(x) = 0.005861979722859766 gradient norm = 0.009793649594680971\n",
      "Iteration 211 : x = [2.04976748 2.33604578] f(x) = 0.005766349889533347 gradient norm = 0.009735157716855817\n",
      "Iteration 212 : x = [2.04934335 2.32631986] f(x) = 0.0056718630077763465 gradient norm = 0.009676176290620429\n",
      "Iteration 213 : x = [2.04891916 2.31665299] f(x) = 0.0055785216351580715 gradient norm = 0.009616711726446498\n",
      "Iteration 214 : x = [2.04849496 2.30704564] f(x) = 0.0054863280316733 gradient norm = 0.009556770733726504\n",
      "Iteration 215 : x = [2.04807075 2.29749829] f(x) = 0.0053952841557255785 gradient norm = 0.009496360320744945\n",
      "Iteration 216 : x = [2.04764655 2.2880114 ] f(x) = 0.005305391660355726 gradient norm = 0.009435487794289973\n",
      "Iteration 217 : x = [2.04722238 2.27858546] f(x) = 0.005216651889725548 gradient norm = 0.009374160758897422\n",
      "Iteration 218 : x = [2.04679826 2.26922089] f(x) = 0.0051290658758664735 gradient norm = 0.009312387115720182\n",
      "Iteration 219 : x = [2.04637421 2.25991817] f(x) = 0.005042634335702497 gradient norm = 0.00925017506101623\n",
      "Iteration 220 : x = [2.04595026 2.25067771] f(x) = 0.004957357668356344 gradient norm = 0.009187533084249506\n",
      "Iteration 221 : x = [2.04552643 2.24149996] f(x) = 0.004873235952747409 gradient norm = 0.009124469965798646\n",
      "Iteration 222 : x = [2.04510273 2.23238533] f(x) = 0.004790268945489599 gradient norm = 0.009060994774269191\n",
      "Iteration 223 : x = [2.04467921 2.22333424] f(x) = 0.00470845607909666 gradient norm = 0.008997116863405872\n",
      "Iteration 224 : x = [2.04425587 2.21434709] f(x) = 0.0046277964605020375 gradient norm = 0.008932845868602381\n",
      "Iteration 225 : x = [2.04383276 2.20542427] f(x) = 0.004548288869899835 gradient norm = 0.00886819170300686\n",
      "Iteration 226 : x = [2.04340989 2.19656617] f(x) = 0.004469931759912859 gradient norm = 0.008803164553222423\n",
      "Iteration 227 : x = [2.0429873  2.18777315] f(x) = 0.004392723255093014 gradient norm = 0.008737774874602759\n",
      "Iteration 228 : x = [2.04256501 2.17904559] f(x) = 0.004316661151758817 gradient norm = 0.008672033386143987\n",
      "Iteration 229 : x = [2.04214306 2.17038382] f(x) = 0.00424174291817407 gradient norm = 0.008605951064974854\n",
      "Iteration 230 : x = [2.04172147 2.16178821] f(x) = 0.004167965695071048 gradient norm = 0.008539539140448313\n",
      "Iteration 231 : x = [2.04130029 2.15325906] f(x) = 0.004095326296520887 gradient norm = 0.008472809087838649\n",
      "Iteration 232 : x = [2.04087953 2.1447967 ] f(x) = 0.004023821211153067 gradient norm = 0.008405772621649179\n",
      "Iteration 233 : x = [2.04045925 2.13640144] f(x) = 0.003953446603725271 gradient norm = 0.008338441688536717\n",
      "Iteration 234 : x = [2.04003946 2.12807358] f(x) = 0.0038841983170439997 gradient norm = 0.008270828459859898\n",
      "Iteration 235 : x = [2.03962022 2.11981338] f(x) = 0.003816071874235648 gradient norm = 0.00820294532385952\n",
      "Iteration 236 : x = [2.03920154 2.11162113] f(x) = 0.003749062481366985 gradient norm = 0.008134804877480098\n",
      "Iteration 237 : x = [2.03878348 2.10349707] f(x) = 0.0036831650304131203 gradient norm = 0.0080664199178427\n",
      "Iteration 238 : x = [2.03836606 2.09544146] f(x) = 0.003618374102570357 gradient norm = 0.007997803433380307\n",
      "Iteration 239 : x = [2.03794933 2.08745452] f(x) = 0.003554683971910449 gradient norm = 0.007928968594647685\n",
      "Iteration 240 : x = [2.03753333 2.07953647] f(x) = 0.0034920886093720853 gradient norm = 0.007859928744818792\n",
      "Iteration 241 : x = [2.0371181  2.07168752] f(x) = 0.003430581687084589 gradient norm = 0.007790697389885724\n",
      "Iteration 242 : x = [2.03670366 2.06390785] f(x) = 0.003370156583018078 gradient norm = 0.007721288188573861\n",
      "Iteration 243 : x = [2.03629008 2.05619765] f(x) = 0.003310806385953581 gradient norm = 0.0076517149419889725\n",
      "Iteration 244 : x = [2.03587739 2.04855707] f(x) = 0.0032525239007658337 gradient norm = 0.007581991583012613\n",
      "Iteration 245 : x = [2.03546562 2.04098627] f(x) = 0.003195301654010774 gradient norm = 0.007512132165462967\n",
      "Iteration 246 : x = [2.03505484 2.03348538] f(x) = 0.003139131899809089 gradient norm = 0.007442150853039151\n",
      "Iteration 247 : x = [2.03464506 2.02605452] f(x) = 0.0030840066260163475 gradient norm = 0.007372061908067317\n",
      "Iteration 248 : x = [2.03423635 2.01869379] f(x) = 0.0030299175606698144 gradient norm = 0.007301879680067857\n",
      "Iteration 249 : x = [2.03382874 2.0114033 ] f(x) = 0.002976856178701172 gradient norm = 0.0072316185941633014\n",
      "Iteration 250 : x = [2.03342229 2.00418311] f(x) = 0.002924813708903955 gradient norm = 0.007161293139347091\n",
      "Iteration 251 : x = [2.03301702 1.99703329] f(x) = 0.0028737811411438624 gradient norm = 0.007090917856633815\n",
      "Iteration 252 : x = [2.03261299 1.9899539 ] f(x) = 0.002823749233799564 gradient norm = 0.0070205073271119335\n",
      "Iteration 253 : x = [2.03221024 1.98294495] f(x) = 0.002774708521421174 gradient norm = 0.006950076159920131\n",
      "Iteration 254 : x = [2.03180883 1.97600648] f(x) = 0.00272664932259305 gradient norm = 0.0068796389801689005\n",
      "Iteration 255 : x = [2.03140878 1.96913848] f(x) = 0.002679561747987229 gradient norm = 0.006809210416828944\n",
      "Iteration 256 : x = [2.03101015 1.96234095] f(x) = 0.00263343570859335 gradient norm = 0.006738805090608196\n",
      "Iteration 257 : x = [2.03061299 1.95561386] f(x) = 0.0025882609241106662 gradient norm = 0.006668437601839249\n",
      "Iteration 258 : x = [2.03021734 1.94895717] f(x) = 0.002544026931487392 gradient norm = 0.006598122518398914\n",
      "Iteration 259 : x = [2.02982324 1.94237082] f(x) = 0.0025007230935924453 gradient norm = 0.006527874363681601\n",
      "Iteration 260 : x = [2.02943074 1.93585476] f(x) = 0.0024583386080043994 gradient norm = 0.0064577076046479776\n",
      "Iteration 261 : x = [2.02903989 1.92940889] f(x) = 0.0024168625159023504 gradient norm = 0.006387636639970177\n",
      "Iteration 262 : x = [2.02865072 1.92303312] f(x) = 0.0023762837110432554 gradient norm = 0.006317675788294433\n",
      "Iteration 263 : x = [2.02826329 1.91672734] f(x) = 0.002336590948810295 gradient norm = 0.006247839276641809\n",
      "Iteration 264 : x = [2.02787764 1.91049141] f(x) = 0.002297772855316742 gradient norm = 0.006178141228967078\n",
      "Iteration 265 : x = [2.02749382 1.9043252 ] f(x) = 0.0022598179365499087 gradient norm = 0.006108595654895483\n",
      "Iteration 266 : x = [2.02711186 1.89822856] f(x) = 0.002222714587539772 gradient norm = 0.00603921643865642\n",
      "Iteration 267 : x = [2.02673181 1.89220131] f(x) = 0.002186451101537044 gradient norm = 0.005970017328232635\n",
      "Iteration 268 : x = [2.02635372 1.88624328] f(x) = 0.0021510156791855906 gradient norm = 0.005901011924742714\n",
      "Iteration 269 : x = [2.02597762 1.88035427] f(x) = 0.0021163964376743286 gradient norm = 0.0058322136720741\n",
      "Iteration 270 : x = [2.02560357 1.87453406] f(x) = 0.0020825814198539645 gradient norm = 0.005763635846782978\n",
      "Iteration 271 : x = [2.02523159 1.86878244] f(x) = 0.002049558603304259 gradient norm = 0.005695291548276704\n",
      "Iteration 272 : x = [2.02486173 1.86309917] f(x) = 0.0020173159093377813 gradient norm = 0.005627193689293549\n",
      "Iteration 273 : x = [2.02449404 1.857484  ] f(x) = 0.001985841211926516 gradient norm = 0.005559354986693682\n",
      "Iteration 274 : x = [2.02412855 1.85193668] f(x) = 0.0019551223465380753 gradient norm = 0.005491787952574438\n",
      "Iteration 275 : x = [2.0237653  1.84645691] f(x) = 0.0019251471188686873 gradient norm = 0.005424504885721999\n",
      "Iteration 276 : x = [2.02340432 1.84104443] f(x) = 0.001895903313460584 gradient norm = 0.005357517863410606\n",
      "Iteration 277 : x = [2.02304567 1.83569893] f(x) = 0.0018673787021919281 gradient norm = 0.005290838733559598\n",
      "Iteration 278 : x = [2.02268936 1.83042011] f(x) = 0.0018395610526278745 gradient norm = 0.005224479107257366\n",
      "Iteration 279 : x = [2.02233545 1.82520763] f(x) = 0.0018124381362219625 gradient norm = 0.005158450351660628\n",
      "Iteration 280 : x = [2.02198396 1.82006117] f(x) = 0.001785997736357504 gradient norm = 0.0050927635832760795\n",
      "Iteration 281 : x = [2.02163493 1.81498038] f(x) = 0.0017602276562192942 gradient norm = 0.005027429661630781\n",
      "Iteration 282 : x = [2.02128839 1.80996491] f(x) = 0.0017351157264864742 gradient norm = 0.004962459183336466\n",
      "Iteration 283 : x = [2.02094437 1.80501439] f(x) = 0.0017106498128380166 gradient norm = 0.00489786247655197\n",
      "Iteration 284 : x = [2.02060291 1.80012844] f(x) = 0.0016868178232629116 gradient norm = 0.004833649595847077\n",
      "Iteration 285 : x = [2.02026403 1.79530668] f(x) = 0.0016636077151677214 gradient norm = 0.004769830317469998\n",
      "Iteration 286 : x = [2.01992777 1.79054872] f(x) = 0.0016410075022748145 gradient norm = 0.004706414135019792\n",
      "Iteration 287 : x = [2.01959415 1.78585415] f(x) = 0.0016190052613051992 gradient norm = 0.004643410255524063\n",
      "Iteration 288 : x = [2.0192632  1.78122255] f(x) = 0.0015975891384405166 gradient norm = 0.004580827595921399\n",
      "Iteration 289 : x = [2.01893495 1.77665349] f(x) = 0.0015767473555593368 gradient norm = 0.004518674779946979\n",
      "Iteration 290 : x = [2.01860942 1.77214656] f(x) = 0.0015564682162435798 gradient norm = 0.004456960135419094\n",
      "Iteration 291 : x = [2.01828664 1.7677013 ] f(x) = 0.0015367401115514256 gradient norm = 0.004395691691923274\n",
      "Iteration 292 : x = [2.01796662 1.76331728] f(x) = 0.0015175515255537344 gradient norm = 0.004334877178890051\n",
      "Iteration 293 : x = [2.0176494  1.75899402] f(x) = 0.0014988910406315717 gradient norm = 0.004274524024061545\n",
      "Iteration 294 : x = [2.01733499 1.75473108] f(x) = 0.001480747342533002 gradient norm = 0.004214639352341263\n",
      "Iteration 295 : x = [2.0170234  1.75052797] f(x) = 0.001463109225187909 gradient norm = 0.004155229985020894\n",
      "Iteration 296 : x = [2.01671467 1.74638423] f(x) = 0.0014459655952801373 gradient norm = 0.004096302439377093\n",
      "Iteration 297 : x = [2.01640881 1.74229936] f(x) = 0.0014293054765767874 gradient norm = 0.004037862928630713\n",
      "Iteration 298 : x = [2.01610582 1.73827288] f(x) = 0.0014131180140150288 gradient norm = 0.003979917362260276\n",
      "Iteration 299 : x = [2.01580574 1.73430429] f(x) = 0.0013973924775472798 gradient norm = 0.003922471346660913\n",
      "Iteration 300 : x = [2.01550857 1.73039309] f(x) = 0.0013821182657460995 gradient norm = 0.003865530186139573\n",
      "Iteration 301 : x = [2.01521432 1.72653878] f(x) = 0.001367284909170593 gradient norm = 0.0038090988842367445\n",
      "Iteration 302 : x = [2.01492301 1.72274083] f(x) = 0.0013528820734965575 gradient norm = 0.0037531821453645107\n",
      "Iteration 303 : x = [2.01463464 1.71899875] f(x) = 0.0013388995624130438 gradient norm = 0.0036977843767504117\n",
      "Iteration 304 : x = [2.01434923 1.71531199] f(x) = 0.0013253273202883664 gradient norm = 0.0036429096906762303\n",
      "Iteration 305 : x = [2.01406679 1.71168005] f(x) = 0.0013121554346089996 gradient norm = 0.0035885619070004466\n",
      "Iteration 306 : x = [2.01378731 1.70810239] f(x) = 0.0012993741381951193 gradient norm = 0.0035347445559529684\n",
      "Iteration 307 : x = [2.01351081 1.70457847] f(x) = 0.0012869738111968923 gradient norm = 0.0034814608811903625\n",
      "Iteration 308 : x = [2.0132373  1.70110777] f(x) = 0.0012749449828759075 gradient norm = 0.0034287138430997926\n",
      "Iteration 309 : x = [2.01296677 1.69768975] f(x) = 0.0012632783331764216 gradient norm = 0.0033765061223395496\n",
      "Iteration 310 : x = [2.01269922 1.69432386] f(x) = 0.0012519646940913473 gradient norm = 0.0033248401236041416\n",
      "Iteration 311 : x = [2.01243467 1.69100956] f(x) = 0.0012409950508281379 gradient norm = 0.0032737179796016383\n",
      "Iteration 312 : x = [2.01217311 1.68774631] f(x) = 0.001230360542779938 gradient norm = 0.003223141555231095\n",
      "Iteration 313 : x = [2.01191454 1.68453356] f(x) = 0.0012200524643075459 gradient norm = 0.0031731124519477653\n",
      "Iteration 314 : x = [2.01165895 1.68137075] f(x) = 0.0012100622653378934 gradient norm = 0.0031236320123039112\n",
      "Iteration 315 : x = [2.01140635 1.67825735] f(x) = 0.0012003815517849024 gradient norm = 0.0030747013246530115\n",
      "Iteration 316 : x = [2.01115674 1.6751928 ] f(x) = 0.0011910020857986861 gradient norm = 0.0030263212280053488\n",
      "Iteration 317 : x = [2.0109101  1.67217654] f(x) = 0.0011819157858491524 gradient norm = 0.0029784923170229527\n",
      "Iteration 318 : x = [2.01066643 1.66920804] f(x) = 0.0011731147266501717 gradient norm = 0.0029312149471421352\n",
      "Iteration 319 : x = [2.01042574 1.66628672] f(x) = 0.0011645911389305064 gradient norm = 0.0028844892398119447\n",
      "Iteration 320 : x = [2.01018799 1.66341205] f(x) = 0.0011563374090577444 gradient norm = 0.0028383150878370836\n",
      "Iteration 321 : x = [2.0099532  1.66058346] f(x) = 0.0011483460785215163 gradient norm = 0.0027926921608140455\n",
      "Iteration 322 : x = [2.00972135 1.65780041] f(x) = 0.0011406098432822655 gradient norm = 0.002747619910649463\n",
      "Iteration 323 : x = [2.00949244 1.65506234] f(x) = 0.001133121552991835 gradient norm = 0.002703097577149872\n",
      "Iteration 324 : x = [2.00926644 1.65236871] f(x) = 0.001125874210092116 gradient norm = 0.0026591241936724315\n",
      "Iteration 325 : x = [2.00904335 1.64971896] f(x) = 0.0011188609687979574 gradient norm = 0.002615698592826329\n",
      "Iteration 326 : x = [2.00882316 1.64711254] f(x) = 0.0011120751339704798 gradient norm = 0.0025728194122149814\n",
      "Iteration 327 : x = [2.00860586 1.64454892] f(x) = 0.0011055101598868866 gradient norm = 0.002530485100209403\n",
      "Iteration 328 : x = [2.00839142 1.64202753] f(x) = 0.0010991596489127644 gradient norm = 0.002488693921743413\n",
      "Iteration 329 : x = [2.00817984 1.63954785] f(x) = 0.0010930173500827965 gradient norm = 0.002447443964121694\n",
      "Iteration 330 : x = [2.00797111 1.63710932] f(x) = 0.0010870771575957078 gradient norm = 0.002406733142832105\n",
      "Iteration 331 : x = [2.00776519 1.63471141] f(x) = 0.0010813331092291514 gradient norm = 0.0023665592073538514\n",
      "Iteration 332 : x = [2.00756209 1.63235359] f(x) = 0.001075779384680128 gradient norm = 0.002326919746953615\n",
      "Iteration 333 : x = [2.00736177 1.63003531] f(x) = 0.001070410303836413 gradient norm = 0.0022878121964619545\n",
      "Iteration 334 : x = [2.00716423 1.62775604] f(x) = 0.0010652203249843356 gradient norm = 0.002249233842022749\n",
      "Iteration 335 : x = [2.00696944 1.62551525] f(x) = 0.0010602040429581077 gradient norm = 0.002211181826808723\n",
      "Iteration 336 : x = [2.00677739 1.62331243] f(x) = 0.0010553561872357696 gradient norm = 0.002173653156696457\n",
      "Iteration 337 : x = [2.00658806 1.62114704] f(x) = 0.0010506716199866757 gradient norm = 0.002136644705894709\n",
      "Iteration 338 : x = [2.00640143 1.61901856] f(x) = 0.0010461453340752768 gradient norm = 0.002100153222520097\n",
      "Iteration 339 : x = [2.00621747 1.61692648] f(x) = 0.0010417724510258233 gradient norm = 0.0020641753341146137\n",
      "Iteration 340 : x = [2.00603617 1.61487028] f(x) = 0.0010375482189524448 gradient norm = 0.002028707553099813\n",
      "Iteration 341 : x = [2.0058575  1.61284945] f(x) = 0.0010334680104589036 gradient norm = 0.0019937462821627097\n",
      "Iteration 342 : x = [2.00568144 1.6108635 ] f(x) = 0.001029527320512172 gradient norm = 0.001959287819568942\n",
      "Iteration 343 : x = [2.00550798 1.6089119 ] f(x) = 0.0010257217642938093 gradient norm = 0.0019253283643989273\n",
      "Iteration 344 : x = [2.00533709 1.60699417] f(x) = 0.0010220470750329652 gradient norm = 0.0018918640217031333\n",
      "Iteration 345 : x = [2.00516874 1.60510982] f(x) = 0.0010184991018246667 gradient norm = 0.0018588908075728586\n",
      "Iteration 346 : x = [2.00500291 1.60325834] f(x) = 0.001015073807436894 gradient norm = 0.0018264046541232467\n",
      "Iteration 347 : x = [2.00483959 1.60143925] f(x) = 0.0010117672661097905 gradient norm = 0.001794401414385581\n",
      "Iteration 348 : x = [2.00467874 1.59965207] f(x) = 0.0010085756613501854 gradient norm = 0.0017628768671060738\n",
      "Iteration 349 : x = [2.00452034 1.59789632] f(x) = 0.0010054952837244703 gradient norm = 0.0017318267214488133\n",
      "Iteration 350 : x = [2.00436437 1.59617153] f(x) = 0.0010025225286527004 gradient norm = 0.001701246621600677\n",
      "Iteration 351 : x = [2.00421081 1.59447723] f(x) = 0.0009996538942066435 gradient norm = 0.0016711321512763058\n",
      "Iteration 352 : x = [2.00405962 1.59281295] f(x) = 0.0009968859789143644 gradient norm = 0.0016414788381215349\n",
      "Iteration 353 : x = [2.00391079 1.59117824] f(x) = 0.000994215479573761 gradient norm = 0.0016122821580138553\n",
      "Iteration 354 : x = [2.00376429 1.58957262] f(x) = 0.0009916391890773583 gradient norm = 0.0015835375392587502\n",
      "Iteration 355 : x = [2.00362009 1.58799567] f(x) = 0.000989153994250495 gradient norm = 0.0015552403666809734\n",
      "Iteration 356 : x = [2.00347817 1.58644691] f(x) = 0.0009867568737049232 gradient norm = 0.001527385985610024\n",
      "Iteration 357 : x = [2.00333851 1.58492593] f(x) = 0.0009844448957096986 gradient norm = 0.0014999697057593215\n",
      "Iteration 358 : x = [2.00320107 1.58343227] f(x) = 0.00098221521608112 gradient norm = 0.0014729868049987267\n",
      "Iteration 359 : x = [2.00306584 1.5819655 ] f(x) = 0.0009800650760933348 gradient norm = 0.0014464325330202728\n",
      "Iteration 360 : x = [2.00293278 1.5805252 ] f(x) = 0.000977991800411123 gradient norm = 0.0014203021148971508\n",
      "Iteration 361 : x = [2.00280188 1.57911094] f(x) = 0.0009759927950462508 gradient norm = 0.0013945907545361428\n",
      "Iteration 362 : x = [2.0026731  1.57772231] f(x) = 0.0009740655453386621 gradient norm = 0.0013692936380238477\n",
      "Iteration 363 : x = [2.00254643 1.57635889] f(x) = 0.0009722076139636826 gradient norm = 0.0013444059368672226\n",
      "Iteration 364 : x = [2.00242183 1.57502027] f(x) = 0.0009704166389662912 gradient norm = 0.0013199228111290804\n",
      "Iteration 365 : x = [2.00229928 1.57370605] f(x) = 0.0009686903318234261 gradient norm = 0.0012958394124593013\n",
      "Iteration 366 : x = [2.00217875 1.57241583] f(x) = 0.0009670264755351855 gradient norm = 0.0012721508870226833\n",
      "Iteration 367 : x = [2.00206022 1.57114921] f(x) = 0.0009654229227456942 gradient norm = 0.0012488523783244282\n",
      "Iteration 368 : x = [2.00194367 1.56990581] f(x) = 0.0009638775938943219 gradient norm = 0.0012259390299343691\n",
      "Iteration 369 : x = [2.00182906 1.56868524] f(x) = 0.0009623884753978469 gradient norm = 0.0012034059881111847\n",
      "Iteration 370 : x = [2.00171637 1.56748712] f(x) = 0.0009609536178640848 gradient norm = 0.0011812484043278828\n",
      "Iteration 371 : x = [2.00160558 1.56631108] f(x) = 0.0009595711343374213 gradient norm = 0.001159461437699942\n",
      "Iteration 372 : x = [2.00149666 1.56515674] f(x) = 0.0009582391985766131 gradient norm = 0.0011380402573176027\n",
      "Iteration 373 : x = [2.00138959 1.56402375] f(x) = 0.0009569560433651604 gradient norm = 0.0011169800444837947\n",
      "Iteration 374 : x = [2.00128433 1.56291174] f(x) = 0.0009557199588544735 gradient norm = 0.0010962759948593527\n",
      "Iteration 375 : x = [2.00118088 1.56182036] f(x) = 0.0009545292909400094 gradient norm = 0.0010759233205171255\n",
      "Iteration 376 : x = [2.00107919 1.56074925] f(x) = 0.000953382439670487 gradient norm = 0.0010559172519066995\n",
      "Iteration 377 : x = [2.00097925 1.55969807] f(x) = 0.0009522778576902335 gradient norm = 0.0010362530397315063\n",
      "Iteration 378 : x = [2.00088103 1.55866649] f(x) = 0.0009512140487146658 gradient norm = 0.0010169259567400606\n",
      "Iteration 379 : x = [2.00078451 1.55765415] f(x) = 0.0009501895660388631 gradient norm = 0.000997931299433157\n",
      "Iteration 380 : x = [2.00068967 1.55666074] f(x) = 0.0009492030110791343 gradient norm = 0.0009792643896888904\n",
      "Iteration 381 : x = [2.00059647 1.55568592] f(x) = 0.0009482530319474512 gradient norm = 0.0009609205763073716\n",
      "Iteration 382 : x = [2.00050489 1.55472937] f(x) = 0.0009473383220585646 gradient norm = 0.0009428952364769695\n",
      "Iteration 383 : x = [2.00041492 1.55379078] f(x) = 0.0009464576187696016 gradient norm = 0.000925183777164085\n",
      "Iteration 384 : x = [2.00032653 1.55286983] f(x) = 0.0009456097020518899 gradient norm = 0.0009077816364282559\n",
      "Iteration 385 : x = [2.00023969 1.55196621] f(x) = 0.0009447933931947328 gradient norm = 0.0008906842846645923\n",
      "Iteration 386 : x = [2.00015438 1.55107962] f(x) = 0.000944007553540835 gradient norm = 0.0008738872257754468\n",
      "Iteration 387 : x = [2.00007058 1.55020976] f(x) = 0.0009432510832530293 gradient norm = 0.0008573859982732102\n",
      "Iteration 388 : x = [1.99998826 1.54935633] f(x) = 0.0009425229201119636 gradient norm = 0.0008411761763161857\n",
      "Iteration 389 : x = [1.99990741 1.54851905] f(x) = 0.0009418220383443531 gradient norm = 0.0008252533706794348\n",
      "Iteration 390 : x = [1.999828   1.54769763] f(x) = 0.0009411474474814008 gradient norm = 0.000809613229662484\n",
      "Iteration 391 : x = [1.99975    1.54689178] f(x) = 0.0009404981912469699 gradient norm = 0.0007942514399358128\n",
      "Iteration 392 : x = [1.9996734  1.54610123] f(x) = 0.0009398733464750621 gradient norm = 0.0007791637273279628\n",
      "Iteration 393 : x = [1.99959818 1.54532571] f(x) = 0.0009392720220561614 gradient norm = 0.0007643458575551255\n",
      "Iteration 394 : x = [1.9995243  1.54456494] f(x) = 0.0009386933579119701 gradient norm = 0.0007497936368950928\n",
      "Iteration 395 : x = [1.99945176 1.54381866] f(x) = 0.0009381365239980655 gradient norm = 0.0007355029128072859\n",
      "Iteration 396 : x = [1.99938053 1.54308662] f(x) = 0.0009376007193339908 gradient norm = 0.0007214695745007679\n",
      "Iteration 397 : x = [1.99931059 1.54236855] f(x) = 0.0009370851710602861 gradient norm = 0.0007076895534519212\n",
      "Iteration 398 : x = [1.99924192 1.5416642 ] f(x) = 0.0009365891335219615 gradient norm = 0.0006941588238735965\n",
      "Iteration 399 : x = [1.99917449 1.54097332] f(x) = 0.0009361118873778975 gradient norm = 0.000680873403137367\n",
      "Iteration 400 : x = [1.9991083  1.54029567] f(x) = 0.0009356527387356699 gradient norm = 0.0006678293521506653\n",
      "Iteration 401 : x = [1.99904331 1.53963101] f(x) = 0.0009352110183112838 gradient norm = 0.0006550227756903931\n",
      "Iteration 402 : x = [1.99897951 1.53897911] f(x) = 0.0009347860806132899 gradient norm = 0.0006424498226946373\n",
      "Iteration 403 : x = [1.99891688 1.53833972] f(x) = 0.0009343773031507802 gradient norm = 0.0006301066865141374\n",
      "Iteration 404 : x = [1.9988554  1.53771262] f(x) = 0.0009339840856647324 gradient norm = 0.0006179896051249867\n",
      "Iteration 405 : x = [1.99879505 1.53709758] f(x) = 0.0009336058493821882 gradient norm = 0.0006060948613041552\n",
      "Iteration 406 : x = [1.99873581 1.53649439] f(x) = 0.0009332420362927544 gradient norm = 0.0005944187827693369\n",
      "Iteration 407 : x = [1.99867766 1.53590282] f(x) = 0.0009328921084469009 gradient norm = 0.0005829577422845213\n",
      "Iteration 408 : x = [1.99862059 1.53532266] f(x) = 0.0009325555472755552 gradient norm = 0.000571708157732789\n",
      "Iteration 409 : x = [1.99856458 1.5347537 ] f(x) = 0.0009322318529304768 gradient norm = 0.0005606664921576734\n",
      "Iteration 410 : x = [1.9985096  1.53419574] f(x) = 0.0009319205436449092 gradient norm = 0.0005498292537745023\n",
      "Iteration 411 : x = [1.99845565 1.53364856] f(x) = 0.0009316211551140149 gradient norm = 0.0005391929959530105\n",
      "Iteration 412 : x = [1.9984027  1.53311198] f(x) = 0.0009313332398945858 gradient norm = 0.0005287543171724964\n",
      "Iteration 413 : x = [1.99835074 1.53258578] f(x) = 0.000931056366823554 gradient norm = 0.0005185098609508508\n",
      "Iteration 414 : x = [1.99829975 1.53206979] f(x) = 0.0009307901204548084 gradient norm = 0.0005084563157486186\n",
      "Iteration 415 : x = [1.99824971 1.5315638 ] f(x) = 0.000930534100513846 gradient norm = 0.0004985904148493048\n",
      "Iteration 416 : x = [1.99820061 1.53106763] f(x) = 0.0009302879213697857 gradient norm = 0.00048890893621711\n",
      "Iteration 417 : x = [1.99815243 1.5305811 ] f(x) = 0.0009300512115242765 gradient norm = 0.0004794087023331678\n",
      "Iteration 418 : x = [1.99810515 1.53010403] f(x) = 0.0009298236131168508 gradient norm = 0.0004700865800114115\n",
      "Iteration 419 : x = [1.99805876 1.52963624] f(x) = 0.0009296047814462699 gradient norm = 0.0004609394801951214\n",
      "Iteration 420 : x = [1.99801325 1.52917755] f(x) = 0.0009293943845074155 gradient norm = 0.00045196435773518404\n",
      "Iteration 421 : x = [1.99796859 1.5287278 ] f(x) = 0.0009291921025433048 gradient norm = 0.00044315821115103993\n",
      "Iteration 422 : x = [1.99792478 1.52828681] f(x) = 0.0009289976276117886 gradient norm = 0.0004345180823752852\n",
      "Iteration 423 : x = [1.99788179 1.52785442] f(x) = 0.0009288106631665283 gradient norm = 0.0004260410564828759\n",
      "Iteration 424 : x = [1.99783962 1.52743047] f(x) = 0.0009286309236518314 gradient norm = 0.00041772426140584056\n",
      "Iteration 425 : x = [1.99779825 1.5270148 ] f(x) = 0.0009284581341109525 gradient norm = 0.00040956486763430724\n",
      "Iteration 426 : x = [1.99775766 1.52660726] f(x) = 0.0009282920298074581 gradient norm = 0.00040156008790480477\n",
      "Iteration 427 : x = [1.99771785 1.52620767] f(x) = 0.0009281323558592777 gradient norm = 0.000393707176876513\n",
      "Iteration 428 : x = [1.99767879 1.52581591] f(x) = 0.0009279788668850607 gradient norm = 0.00038600343079634917\n",
      "Iteration 429 : x = [1.99764047 1.52543181] f(x) = 0.0009278313266624708 gradient norm = 0.00037844618715363683\n",
      "Iteration 430 : x = [1.99760289 1.52505524] f(x) = 0.0009276895077980618 gradient norm = 0.00037103282432498927\n",
      "Iteration 431 : x = [1.99756602 1.52468604] f(x) = 0.0009275531914083763 gradient norm = 0.0003637607612102421\n",
      "Iteration 432 : x = [1.99752986 1.52432408] f(x) = 0.0009274221668119321 gradient norm = 0.00035662745686002874\n",
      "Iteration 433 : x = [1.99749438 1.52396922] f(x) = 0.0009272962312317559 gradient norm = 0.00034963041009566356\n",
      "Iteration 434 : x = [1.99745959 1.52362133] f(x) = 0.0009271751895081373 gradient norm = 0.00034276715912196957\n",
      "Iteration 435 : x = [1.99742546 1.52328026] f(x) = 0.0009270588538212905 gradient norm = 0.0003360352811336406\n",
      "Iteration 436 : x = [1.99739199 1.5229459 ] f(x) = 0.0009269470434236041 gradient norm = 0.0003294323919157443\n",
      "Iteration 437 : x = [1.99735916 1.52261811] f(x) = 0.0009268395843811824 gradient norm = 0.0003229561454388516\n",
      "Iteration 438 : x = [1.99732697 1.52229676] f(x) = 0.0009267363093243851 gradient norm = 0.0003166042334494217\n",
      "Iteration 439 : x = [1.99729539 1.52198173] f(x) = 0.0009266370572070674 gradient norm = 0.0003103743850558503\n",
      "Iteration 440 : x = [1.99726442 1.52167291] f(x) = 0.000926541673074258 gradient norm = 0.0003042643663107623\n",
      "Iteration 441 : x = [1.99723404 1.52137017] f(x) = 0.0009264500078379855 gradient norm = 0.0002982719797899567\n",
      "Iteration 442 : x = [1.99720425 1.52107338] f(x) = 0.0009263619180610019 gradient norm = 0.00029239506416847206\n",
      "Iteration 443 : x = [1.99717504 1.52078245] f(x) = 0.0009262772657481393 gradient norm = 0.00028663149379416737\n",
      "Iteration 444 : x = [1.99714639 1.52049726] f(x) = 0.0009261959181450517 gradient norm = 0.0002809791782593292\n",
      "Iteration 445 : x = [1.99711829 1.52021769] f(x) = 0.0009261177475440986 gradient norm = 0.0002754360619705462\n",
      "Iteration 446 : x = [1.99709074 1.51994363] f(x) = 0.0009260426310971337 gradient norm = 0.00027000012371736443\n",
      "Iteration 447 : x = [1.99706373 1.51967499] f(x) = 0.0009259704506349734 gradient norm = 0.00026466937623997617\n",
      "Iteration 448 : x = [1.99703723 1.51941165] f(x) = 0.0009259010924933149 gradient norm = 0.00025944186579634836\n",
      "Iteration 449 : x = [1.99701125 1.51915351] f(x) = 0.0009258344473448946 gradient norm = 0.00025431567172907397\n",
      "Iteration 450 : x = [1.99698577 1.51890047] f(x) = 0.0009257704100376753 gradient norm = 0.0002492889060322739\n",
      "Iteration 451 : x = [1.99696079 1.51865244] f(x) = 0.0009257088794388568 gradient norm = 0.0002443597129188313\n",
      "Iteration 452 : x = [1.9969363  1.51840931] f(x) = 0.0009256497582845145 gradient norm = 0.00023952626838825004\n",
      "Iteration 453 : x = [1.99691228 1.51817099] f(x) = 0.0009255929530346725 gradient norm = 0.0002347867797953671\n",
      "Iteration 454 : x = [1.99688873 1.51793739] f(x) = 0.0009255383737336312 gradient norm = 0.00023013948542021864\n",
      "Iteration 455 : x = [1.99686563 1.51770841] f(x) = 0.0009254859338753585 gradient norm = 0.00022558265403923707\n",
      "Iteration 456 : x = [1.99684299 1.51748397] f(x) = 0.0009254355502737869 gradient norm = 0.00022111458449806525\n",
      "Iteration 457 : x = [1.99682079 1.51726397] f(x) = 0.0009253871429378266 gradient norm = 0.00021673360528615555\n",
      "Iteration 458 : x = [1.99679902 1.51704833] f(x) = 0.0009253406349509521 gradient norm = 0.00021243807411333766\n",
      "Iteration 459 : x = [1.99677768 1.51683697] f(x) = 0.0009252959523551897 gradient norm = 0.00020822637748862212\n",
      "Iteration 460 : x = [1.99675675 1.5166298 ] f(x) = 0.0009252530240393543 gradient norm = 0.0002040969303013176\n",
      "Iteration 461 : x = [1.99673623 1.51642673] f(x) = 0.0009252117816313972 gradient norm = 0.00020004817540470257\n",
      "Iteration 462 : x = [1.99671612 1.5162277 ] f(x) = 0.0009251721593947052 gradient norm = 0.00019607858320237054\n",
      "Iteration 463 : x = [1.9966964  1.51603261] f(x) = 0.0009251340941282265 gradient norm = 0.00019218665123740141\n",
      "Iteration 464 : x = [1.99667706 1.5158414 ] f(x) = 0.0009250975250702762 gradient norm = 0.0001883709037845021\n",
      "Iteration 465 : x = [1.9966581  1.51565399] f(x) = 0.0009250623938059045 gradient norm = 0.000184629891445244\n",
      "Iteration 466 : x = [1.99663952 1.5154703 ] f(x) = 0.0009250286441776898 gradient norm = 0.0001809621907465044\n",
      "Iteration 467 : x = [1.9966213  1.51529025] f(x) = 0.0009249962221998378 gradient norm = 0.00017736640374223735\n",
      "Iteration 468 : x = [1.99660344 1.51511379] f(x) = 0.0009249650759754772 gradient norm = 0.00017384115761867342\n",
      "Iteration 469 : x = [1.99658592 1.51494083] f(x) = 0.0009249351556170267 gradient norm = 0.0001703851043030251\n",
      "Iteration 470 : x = [1.99656876 1.51477131] f(x) = 0.0009249064131695258 gradient norm = 0.000166996920075824\n",
      "Iteration 471 : x = [1.99655193 1.51460517] f(x) = 0.0009248788025368317 gradient norm = 0.00016367530518692375\n",
      "Iteration 472 : x = [1.99653543 1.51444233] f(x) = 0.0009248522794105685 gradient norm = 0.00016041898347528\n",
      "Iteration 473 : x = [1.99651925 1.51428272] f(x) = 0.0009248268012017339 gradient norm = 0.00015722670199255225\n",
      "Iteration 474 : x = [1.9965034 1.5141263] f(x) = 0.0009248023269748692 gradient norm = 0.00015409723063059997\n",
      "Iteration 475 : x = [1.99648785 1.51397299] f(x) = 0.0009247788173846949 gradient norm = 0.0001510293617529278\n",
      "Iteration 476 : x = [1.99647261 1.51382273] f(x) = 0.0009247562346151297 gradient norm = 0.0001480219098301174\n",
      "Iteration 477 : x = [1.99645768 1.51367546] f(x) = 0.0009247345423205996 gradient norm = 0.0001450737110793085\n",
      "Iteration 478 : x = [1.99644303 1.51353113] f(x) = 0.0009247137055695532 gradient norm = 0.00014218362310773378\n",
      "Iteration 479 : x = [1.99642868 1.51338967] f(x) = 0.0009246936907901138 gradient norm = 0.00013935052456041773\n",
      "Iteration 480 : x = [1.99641461 1.51325103] f(x) = 0.0009246744657177721 gradient norm = 0.0001365733147719551\n",
      "Iteration 481 : x = [1.99640081 1.51311516] f(x) = 0.0009246559993450638 gradient norm = 0.000133850913422496\n",
      "Iteration 482 : x = [1.99638729 1.51298199] f(x) = 0.0009246382618731426 gradient norm = 0.00013118226019789506\n",
      "Iteration 483 : x = [1.99637404 1.51285148] f(x) = 0.0009246212246651914 gradient norm = 0.00012856631445408995\n",
      "Iteration 484 : x = [1.99636105 1.51272357] f(x) = 0.0009246048602015978 gradient norm = 0.00012600205488566278\n",
      "Iteration 485 : x = [1.99634831 1.51259822] f(x) = 0.0009245891420368277 gradient norm = 0.00012348847919864853\n",
      "Iteration 486 : x = [1.99633583 1.51247536] f(x) = 0.0009245740447579414 gradient norm = 0.00012102460378756535\n",
      "Iteration 487 : x = [1.99632359 1.51235496] f(x) = 0.0009245595439446812 gradient norm = 0.00011860946341667956\n",
      "Iteration 488 : x = [1.9963116  1.51223696] f(x) = 0.0009245456161310809 gradient norm = 0.00011624211090548277\n",
      "Iteration 489 : x = [1.99629984 1.51212131] f(x) = 0.000924532238768539 gradient norm = 0.0001139216168184338\n",
      "Iteration 490 : x = [1.99628832 1.51200797] f(x) = 0.0009245193901902942 gradient norm = 0.00011164706915889017\n",
      "Iteration 491 : x = [1.99627702 1.5118969 ] f(x) = 0.0009245070495772618 gradient norm = 0.00010941757306723889\n",
      "Iteration 492 : x = [1.99626595 1.51178804] f(x) = 0.0009244951969251733 gradient norm = 0.00010723225052327936\n",
      "Iteration 493 : x = [1.9962551  1.51168136] f(x) = 0.0009244838130129693 gradient norm = 0.00010509024005272214\n",
      "Iteration 494 : x = [1.99624446 1.51157681] f(x) = 0.0009244728793724057 gradient norm = 0.00010299069643789897\n",
      "Iteration 495 : x = [1.99623404 1.51147435] f(x) = 0.000924462378258822 gradient norm = 0.00010093279043262443\n",
      "Iteration 496 : x = [1.99622382 1.51137393] f(x) = 0.0009244522926230281 gradient norm = 9.891570848113914e-05\n",
      "Iteration 497 : x = [1.9962138  1.51127553] f(x) = 0.0009244426060842734 gradient norm = 9.693865244122436e-05\n",
      "Iteration 498 : x = [1.99620399 1.51117909] f(x) = 0.0009244333029042495 gradient norm = 9.5000839311333e-05\n",
      "Iteration 499 : x = [1.99619437 1.51108457] f(x) = 0.0009244243679620927 gradient norm = 9.31015009618214e-05\n",
      "Iteration 500 : x = [1.99618493 1.51099195] f(x) = 0.0009244157867303489 gradient norm = 9.123988387018975e-05\n",
      "Iteration 501 : x = [1.99617569 1.51090118] f(x) = 0.0009244075452518621 gradient norm = 8.941524886031923e-05\n",
      "Iteration 502 : x = [1.99616663 1.51081223] f(x) = 0.0009243996301175517 gradient norm = 8.762687084568687e-05\n",
      "Iteration 503 : x = [1.99615775 1.51072505] f(x) = 0.0009243920284450469 gradient norm = 8.58740385765076e-05\n",
      "Iteration 504 : x = [1.99614905 1.51063962] f(x) = 0.0009243847278581465 gradient norm = 8.41560543907883e-05\n",
      "Iteration 505 : x = [1.99614052 1.5105559 ] f(x) = 0.0009243777164670673 gradient norm = 8.24722339692457e-05\n",
      "Iteration 506 : x = [1.99613216 1.51047385] f(x) = 0.0009243709828494586 gradient norm = 8.082190609406775e-05\n",
      "Iteration 507 : x = [1.99612396 1.51039344] f(x) = 0.0009243645160321481 gradient norm = 7.920441241147691e-05\n",
      "Iteration 508 : x = [1.99611593 1.51031465] f(x) = 0.0009243583054735938 gradient norm = 7.761910719802744e-05\n",
      "Iteration 509 : x = [1.99610806 1.51023743] f(x) = 0.0009243523410470157 gradient norm = 7.606535713068508e-05\n",
      "Iteration 510 : x = [1.99610035 1.51016175] f(x) = 0.0009243466130241779 gradient norm = 7.454254106054297e-05\n",
      "Iteration 511 : x = [1.99609279 1.5100876 ] f(x) = 0.0009243411120598016 gradient norm = 7.305004979021713e-05\n",
      "Iteration 512 : x = [1.99608538 1.51001492] f(x) = 0.00092433582917658 gradient norm = 7.158728585485596e-05\n",
      "Iteration 513 : x = [1.99607811 1.5099437 ] f(x) = 0.0009243307557507767 gradient norm = 7.015366330668892e-05\n",
      "Iteration 514 : x = [1.996071   1.50987391] f(x) = 0.0009243258834983781 gradient norm = 6.874860750314707e-05\n",
      "Iteration 515 : x = [1.99606402 1.50980552] f(x) = 0.0009243212044617884 gradient norm = 6.737155489846281e-05\n",
      "Iteration 516 : x = [1.99605718 1.5097385 ] f(x) = 0.0009243167109970392 gradient norm = 6.602195283869988e-05\n",
      "Iteration 517 : x = [1.99605048 1.50967281] f(x) = 0.0009243123957614944 gradient norm = 6.469925936022648e-05\n",
      "Iteration 518 : x = [1.99604392 1.50960845] f(x) = 0.0009243082517020362 gradient norm = 6.340294299153525e-05\n",
      "Iteration 519 : x = [1.99603748 1.50954537] f(x) = 0.0009243042720437092 gradient norm = 6.213248255839889e-05\n",
      "Iteration 520 : x = [1.99603117 1.50948356] f(x) = 0.0009243004502788043 gradient norm = 6.0887366992300964e-05\n",
      "Iteration 521 : x = [1.99602499 1.50942299] f(x) = 0.0009242967801563725 gradient norm = 5.966709514214031e-05\n",
      "Iteration 522 : x = [1.99601893 1.50936363] f(x) = 0.0009242932556721422 gradient norm = 5.847117558908774e-05\n",
      "Iteration 523 : x = [1.996013   1.50930546] f(x) = 0.0009242898710588318 gradient norm = 5.7299126464663436e-05\n",
      "Iteration 524 : x = [1.99600718 1.50924846] f(x) = 0.000924286620776841 gradient norm = 5.6150475271888105e-05\n",
      "Iteration 525 : x = [1.99600148 1.5091926 ] f(x) = 0.0009242834995053023 gradient norm = 5.502475870952242e-05\n",
      "Iteration 526 : x = [1.99599589 1.50913786] f(x) = 0.0009242805021334836 gradient norm = 5.392152249935931e-05\n",
      "Iteration 527 : x = [1.99599041 1.50908422] f(x) = 0.0009242776237525279 gradient norm = 5.284032121648522e-05\n",
      "Iteration 528 : x = [1.99598504 1.50903165] f(x) = 0.0009242748596475106 gradient norm = 5.178071812250486e-05\n",
      "Iteration 529 : x = [1.99597978 1.50898014] f(x) = 0.0009242722052898138 gradient norm = 5.074228500167832e-05\n",
      "Iteration 530 : x = [1.99597463 1.50892966] f(x) = 0.0009242696563297928 gradient norm = 4.972460199992702e-05\n",
      "Iteration 531 : x = [1.99596958 1.50888019] f(x) = 0.0009242672085897332 gradient norm = 4.872725746666306e-05\n",
      "Iteration 532 : x = [1.99596462 1.50883171] f(x) = 0.0009242648580570808 gradient norm = 4.7749847799410285e-05\n",
      "Iteration 533 : x = [1.99595977 1.50878421] f(x) = 0.0009242626008779395 gradient norm = 4.679197729116292e-05\n",
      "Iteration 534 : x = [1.99595502 1.50873766] f(x) = 0.0009242604333508206 gradient norm = 4.58532579804636e-05\n",
      "Iteration 535 : x = [1.99595036 1.50869205] f(x) = 0.0009242583519206387 gradient norm = 4.493330950413756e-05\n",
      "Iteration 536 : x = [1.99594579 1.50864734] f(x) = 0.0009242563531729421 gradient norm = 4.40317589526574e-05\n",
      "Iteration 537 : x = [1.99594132 1.50860354] f(x) = 0.0009242544338283712 gradient norm = 4.3148240728085145e-05\n",
      "Iteration 538 : x = [1.99593693 1.50856062] f(x) = 0.0009242525907373296 gradient norm = 4.2282396404587655e-05\n",
      "Iteration 539 : x = [1.99593263 1.50851855] f(x) = 0.0009242508208748695 gradient norm = 4.143387459139639e-05\n",
      "Iteration 540 : x = [1.99592842 1.50847733] f(x) = 0.0009242491213357757 gradient norm = 4.060233079833333e-05\n",
      "Iteration 541 : x = [1.99592429 1.50843694] f(x) = 0.0009242474893298386 gradient norm = 3.9787427303666324e-05\n",
      "Iteration 542 : x = [1.99592025 1.50839736] f(x) = 0.0009242459221773216 gradient norm = 3.898883302442159e-05\n",
      "Iteration 543 : x = [1.99591628 1.50835857] f(x) = 0.0009242444173045965 gradient norm = 3.8206223389045956e-05\n",
      "Iteration 544 : x = [1.9959124  1.50832057] f(x) = 0.000924242972239958 gradient norm = 3.7439280212337544e-05\n",
      "Iteration 545 : x = [1.99590859 1.50828332] f(x) = 0.0009242415846095978 gradient norm = 3.6687691572719226e-05\n",
      "Iteration 546 : x = [1.99590486 1.50824682] f(x) = 0.0009242402521337401 gradient norm = 3.595115169170668e-05\n",
      "Iteration 547 : x = [1.9959012  1.50821106] f(x) = 0.0009242389726229266 gradient norm = 3.5229360815622305e-05\n",
      "Iteration 548 : x = [1.99589762 1.50817601] f(x) = 0.0009242377439744503 gradient norm = 3.452202509944734e-05\n",
      "Iteration 549 : x = [1.99589411 1.50814167] f(x) = 0.0009242365641689261 gradient norm = 3.382885649282829e-05\n",
      "Iteration 550 : x = [1.99589067 1.50810801] f(x) = 0.0009242354312669997 gradient norm = 3.314957262817601e-05\n",
      "Iteration 551 : x = [1.9958873  1.50807504] f(x) = 0.0009242343434061827 gradient norm = 3.24838967108419e-05\n",
      "Iteration 552 : x = [1.99588399 1.50804272] f(x) = 0.0009242332987978155 gradient norm = 3.1831557411305665e-05\n",
      "Iteration 553 : x = [1.99588075 1.50801106] f(x) = 0.0009242322957241494 gradient norm = 3.1192288759385125e-05\n",
      "Iteration 554 : x = [1.99587758 1.50798002] f(x) = 0.0009242313325355388 gradient norm = 3.056583004038077e-05\n",
      "Iteration 555 : x = [1.99587447 1.50794962] f(x) = 0.0009242304076477518 gradient norm = 2.9951925693191312e-05\n",
      "Iteration 556 : x = [1.99587142 1.50791982] f(x) = 0.0009242295195393809 gradient norm = 2.935032521028151e-05\n",
      "Iteration 557 : x = [1.99586844 1.50789062] f(x) = 0.0009242286667493571 gradient norm = 2.8760783039551693e-05\n",
      "Iteration 558 : x = [1.99586551 1.50786201] f(x) = 0.0009242278478745642 gradient norm = 2.8183058488034756e-05\n",
      "Iteration 559 : x = [1.99586264 1.50783397] f(x) = 0.000924227061567543 gradient norm = 2.7616915627371945e-05\n",
      "Iteration 560 : x = [1.99585983 1.5078065 ] f(x) = 0.0009242263065342915 gradient norm = 2.7062123201106417e-05\n",
      "Iteration 561 : x = [1.99585708 1.50777958] f(x) = 0.0009242255815321457 gradient norm = 2.651845453366067e-05\n",
      "Iteration 562 : x = [1.99585438 1.5077532 ] f(x) = 0.00092422488536775 gradient norm = 2.5985687441082526e-05\n",
      "Iteration 563 : x = [1.99585174 1.50772735] f(x) = 0.0009242242168951026 gradient norm = 2.5463604143432252e-05\n",
      "Iteration 564 : x = [1.99584915 1.50770202] f(x) = 0.0009242235750136817 gradient norm = 2.495199117884742e-05\n",
      "Iteration 565 : x = [1.99584661 1.50767719] f(x) = 0.0009242229586666443 gradient norm = 2.445063931920115e-05\n",
      "Iteration 566 : x = [1.99584412 1.50765287] f(x) = 0.0009242223668390946 gradient norm = 2.3959343487396104e-05\n",
      "Iteration 567 : x = [1.99584168 1.50762904] f(x) = 0.0009242217985564237 gradient norm = 2.3477902676183576e-05\n",
      "Iteration 568 : x = [1.99583929 1.50760568] f(x) = 0.000924221252882714 gradient norm = 2.3006119868563622e-05\n",
      "Iteration 569 : x = [1.99583695 1.50758279] f(x) = 0.000924220728919204 gradient norm = 2.2543801959652685e-05\n",
      "Iteration 570 : x = [1.99583465 1.50756037] f(x) = 0.0009242202258028172 gradient norm = 2.2090759680064237e-05\n",
      "Iteration 571 : x = [1.9958324  1.50753839] f(x) = 0.000924219742704748 gradient norm = 2.1646807520758058e-05\n",
      "Iteration 572 : x = [1.9958302  1.50751686] f(x) = 0.0009242192788291035 gradient norm = 2.121176365928737e-05\n",
      "Iteration 573 : x = [1.99582804 1.50749575] f(x) = 0.000924218833411596 gradient norm = 2.0785449887478604e-05\n",
      "Iteration 574 : x = [1.99582593 1.50747508] f(x) = 0.0009242184057182952 gradient norm = 2.036769154049248e-05\n",
      "Iteration 575 : x = [1.99582385 1.50745482] f(x) = 0.0009242179950444188 gradient norm = 1.99583174272212e-05\n",
      "Iteration 576 : x = [1.99582182 1.50743496] f(x) = 0.0009242176007131814 gradient norm = 1.955715976204225e-05\n",
      "Iteration 577 : x = [1.99581983 1.5074155 ] f(x) = 0.00092421722207468 gradient norm = 1.9164054097867284e-05\n",
      "Iteration 578 : x = [1.99581788 1.50739644] f(x) = 0.0009242168585048328 gradient norm = 1.8778839260478654e-05\n",
      "Iteration 579 : x = [1.99581597 1.50737776] f(x) = 0.0009242165094043497 gradient norm = 1.8401357284120613e-05\n",
      "Iteration 580 : x = [1.99581409 1.50735945] f(x) = 0.000924216174197752 gradient norm = 1.8031453348346592e-05\n",
      "Iteration 581 : x = [1.99581226 1.50734152] f(x) = 0.0009242158523324273 gradient norm = 1.7668975716056095e-05\n",
      "Iteration 582 : x = [1.99581046 1.50732394] f(x) = 0.0009242155432777216 gradient norm = 1.7313775672747863e-05\n",
      "Iteration 583 : x = [1.99580869 1.50730671] f(x) = 0.0009242152465240686 gradient norm = 1.696570746692107e-05\n",
      "Iteration 584 : x = [1.99580697 1.50728984] f(x) = 0.000924214961582152 gradient norm = 1.66246282516564e-05\n",
      "Iteration 585 : x = [1.99580527 1.5072733 ] f(x) = 0.000924214687982103 gradient norm = 1.629039802730291e-05\n",
      "Iteration 586 : x = [1.99580361 1.50725709] f(x) = 0.0009242144252727273 gradient norm = 1.5962879585266277e-05\n",
      "Iteration 587 : x = [1.99580199 1.50724121] f(x) = 0.0009242141730207654 gradient norm = 1.5641938452913325e-05\n",
      "Iteration 588 : x = [1.9958004  1.50722565] f(x) = 0.0009242139308101781 gradient norm = 1.5327442839523868e-05\n",
      "Iteration 589 : x = [1.99579884 1.50721041] f(x) = 0.0009242136982414656 gradient norm = 1.5019263583274615e-05\n",
      "Iteration 590 : x = [1.99579731 1.50719546] f(x) = 0.0009242134749310084 gradient norm = 1.4717274099298155e-05\n",
      "Iteration 591 : x = [1.99579581 1.50718082] f(x) = 0.0009242132605104396 gradient norm = 1.4421350328699725e-05\n",
      "Iteration 592 : x = [1.99579434 1.50716648] f(x) = 0.000924213054626036 gradient norm = 1.4131370688584414e-05\n",
      "Iteration 593 : x = [1.9957929  1.50715242] f(x) = 0.000924212856938139 gradient norm = 1.3847216023073993e-05\n",
      "Iteration 594 : x = [1.99579149 1.50713864] f(x) = 0.0009242126671205953 gradient norm = 1.3568769555246355e-05\n",
      "Iteration 595 : x = [1.99579011 1.50712515] f(x) = 0.00092421248486022 gradient norm = 1.3295916840018728e-05\n",
      "Iteration 596 : x = [1.99578875 1.50711192] f(x) = 0.0009242123098562816 gradient norm = 1.3028545717970485e-05\n",
      "Iteration 597 : x = [1.99578742 1.50709896] f(x) = 0.0009242121418200086 gradient norm = 1.2766546270037003e-05\n",
      "Iteration 598 : x = [1.99578612 1.50708626] f(x) = 0.0009242119804741131 gradient norm = 1.2509810773096867e-05\n",
      "Iteration 599 : x = [1.99578485 1.50707381] f(x) = 0.0009242118255523336 gradient norm = 1.2258233656432856e-05\n",
      "Iteration 600 : x = [1.9957836  1.50706162] f(x) = 0.0009242116767990001 gradient norm = 1.2011711459031795e-05\n",
      "Iteration 601 : x = [1.99578238 1.50704967] f(x) = 0.0009242115339686101 gradient norm = 1.1770142787742883e-05\n",
      "Iteration 602 : x = [1.99578118 1.50703796] f(x) = 0.0009242113968254272 gradient norm = 1.1533428276219711e-05\n",
      "Iteration 603 : x = [1.99578    1.50702649] f(x) = 0.0009242112651430895 gradient norm = 1.1301470544686903e-05\n",
      "Iteration 604 : x = [1.99577885 1.50701524] f(x) = 0.0009242111387042411 gradient norm = 1.1074174160489176e-05\n",
      "Iteration 605 : x = [1.99577772 1.50700423] f(x) = 0.0009242110173001719 gradient norm = 1.0851445599425702e-05\n",
      "Iteration 606 : x = [1.99577662 1.50699343] f(x) = 0.0009242109007304744 gradient norm = 1.063319320780643e-05\n",
      "Iteration 607 : x = [1.99577554 1.50698285] f(x) = 0.0009242107888027132 gradient norm = 1.0419327165308052e-05\n",
      "Iteration 608 : x = [1.99577447 1.50697249] f(x) = 0.000924210681332109 gradient norm = 1.0209759448504265e-05\n",
      "Iteration 609 : x = [1.99577343 1.50696233] f(x) = 0.0009242105781412344 gradient norm = 1.0004403795142564e-05\n",
      "Iteration 610 : x = [1.99577242 1.50695238] f(x) = 0.0009242104790597205 gradient norm = 9.80317566911804e-06\n",
      "Iteration 611 : x = [1.99577142 1.50694263] f(x) = 0.000924210383923977 gradient norm = 9.605992226128538e-06\n",
      "Iteration 612 : x = [1.99577044 1.50693307] f(x) = 0.0009242102925769227 gradient norm = 9.412772280018046e-06\n",
      "Iteration 613 : x = [1.99576948 1.50692371] f(x) = 0.000924210204867727 gradient norm = 9.223436269763387e-06\n",
      "Iteration 614 : x = [1.99576854 1.50691453] f(x) = 0.0009242101206515609 gradient norm = 9.037906227118215e-06\n",
      "Iteration 615 : x = [1.99576762 1.50690554] f(x) = 0.0009242100397893581 gradient norm = 8.856105744916383e-06\n",
      "Iteration 616 : x = [1.99576672 1.50689673] f(x) = 0.0009242099621475865 gradient norm = 8.677959945954723e-06\n",
      "Iteration 617 : x = [1.99576583 1.5068881 ] f(x) = 0.0009242098875980279 gradient norm = 8.503395452532753e-06\n",
      "Iteration 618 : x = [1.99576497 1.50687964] f(x) = 0.0009242098160175667 gradient norm = 8.332340356570204e-06\n",
      "Iteration 619 : x = [1.99576412 1.50687135] f(x) = 0.0009242097472879865 gradient norm = 8.164724190316022e-06\n",
      "Iteration 620 : x = [1.99576328 1.50686323] f(x) = 0.0009242096812957774 gradient norm = 8.00047789763355e-06\n",
      "Iteration 621 : x = [1.99576247 1.50685527] f(x) = 0.0009242096179319445 gradient norm = 7.83953380586552e-06\n",
      "Iteration 622 : x = [1.99576167 1.50684747] f(x) = 0.000924209557091832 gradient norm = 7.681825598237197e-06\n",
      "Iteration 623 : x = [1.99576089 1.50683983] f(x) = 0.0009242094986749509 gradient norm = 7.527288286815208e-06\n",
      "Iteration 624 : x = [1.99576012 1.50683234] f(x) = 0.0009242094425848101 gradient norm = 7.375858186009499e-06\n",
      "Iteration 625 : x = [1.99575937 1.506825  ] f(x) = 0.0009242093887287593 gradient norm = 7.227472886573627e-06\n",
      "Iteration 626 : x = [1.99575863 1.50681781] f(x) = 0.0009242093370178377 gradient norm = 7.082071230138809e-06\n",
      "Iteration 627 : x = [1.99575791 1.50681077] f(x) = 0.0009242092873666234 gradient norm = 6.939593284258023e-06\n",
      "Iteration 628 : x = [1.9957572  1.50680387] f(x) = 0.000924209239693096 gradient norm = 6.799980317905416e-06\n",
      "Iteration 629 : x = [1.99575651 1.5067971 ] f(x) = 0.0009242091939185005 gradient norm = 6.6631747775248295e-06\n",
      "Iteration 630 : x = [1.99575583 1.50679047] f(x) = 0.0009242091499672159 gradient norm = 6.5291202634900325e-06\n",
      "Iteration 631 : x = [1.99575517 1.50678398] f(x) = 0.0009242091077666323 gradient norm = 6.397761507068215e-06\n",
      "Iteration 632 : x = [1.99575451 1.50677761] f(x) = 0.0009242090672470305 gradient norm = 6.269044347820911e-06\n",
      "Iteration 633 : x = [1.99575388 1.50677138] f(x) = 0.0009242090283414657 gradient norm = 6.142915711472945e-06\n",
      "Iteration 634 : x = [1.99575325 1.50676527] f(x) = 0.0009242089909856597 gradient norm = 6.019323588210405e-06\n",
      "Iteration 635 : x = [1.99575264 1.50675928] f(x) = 0.0009242089551178926 gradient norm = 5.898217011382902e-06\n",
      "Iteration 636 : x = [1.99575204 1.50675341] f(x) = 0.0009242089206789018 gradient norm = 5.779546036691127e-06\n",
      "Iteration 637 : x = [1.99575145 1.50674766] f(x) = 0.0009242088876117839 gradient norm = 5.663261721712561e-06\n",
      "Iteration 638 : x = [1.99575087 1.50674203] f(x) = 0.000924208855861902 gradient norm = 5.549316105903449e-06\n",
      "Iteration 639 : x = [1.9957503  1.50673651] f(x) = 0.0009242088253767943 gradient norm = 5.437662190938202e-06\n",
      "Iteration 640 : x = [1.99574975 1.5067311 ] f(x) = 0.0009242087961060864 gradient norm = 5.328253921477997e-06\n",
      "Iteration 641 : x = [1.99574921 1.5067258 ] f(x) = 0.0009242087680014112 gradient norm = 5.221046166311464e-06\n",
      "Iteration 642 : x = [1.99574867 1.5067206 ] f(x) = 0.000924208741016327 gradient norm = 5.115994699874343e-06\n",
      "Iteration 643 : x = [1.99574815 1.50671551] f(x) = 0.0009242087151062414 gradient norm = 5.013056184095545e-06\n",
      "Iteration 644 : x = [1.99574764 1.50671053] f(x) = 0.0009242086902283373 gradient norm = 4.912188150700311e-06\n",
      "Iteration 645 : x = [1.99574714 1.50670564] f(x) = 0.0009242086663415031 gradient norm = 4.8133489837499906e-06\n",
      "Iteration 646 : x = [1.99574665 1.50670085] f(x) = 0.0009242086434062631 gradient norm = 4.716497902605747e-06\n",
      "Iteration 647 : x = [1.99574617 1.50669616] f(x) = 0.0009242086213847151 gradient norm = 4.621594945215223e-06\n",
      "Iteration 648 : x = [1.9957457  1.50669156] f(x) = 0.0009242086002404656 gradient norm = 4.528600951711852e-06\n",
      "Iteration 649 : x = [1.99574524 1.50668706] f(x) = 0.0009242085799385695 gradient norm = 4.437477548367042e-06\n",
      "Iteration 650 : x = [1.99574479 1.50668264] f(x) = 0.0009242085604454744 gradient norm = 4.348187131835776e-06\n",
      "Iteration 651 : x = [1.99574434 1.50667832] f(x) = 0.0009242085417289634 gradient norm = 4.260692853745408e-06\n",
      "Iteration 652 : x = [1.99574391 1.50667408] f(x) = 0.0009242085237581032 gradient norm = 4.174958605561811e-06\n",
      "Iteration 653 : x = [1.99574348 1.50666993] f(x) = 0.0009242085065031923 gradient norm = 4.0909490037895025e-06\n",
      "Iteration 654 : x = [1.99574307 1.50666586] f(x) = 0.0009242084899357107 gradient norm = 4.008629375426629e-06\n",
      "Iteration 655 : x = [1.99574266 1.50666187] f(x) = 0.0009242084740282765 gradient norm = 3.927965743746066e-06\n",
      "Iteration 656 : x = [1.99574226 1.50665796] f(x) = 0.0009242084587545966 gradient norm = 3.848924814336231e-06\n",
      "Iteration 657 : x = [1.99574186 1.50665413] f(x) = 0.0009242084440894253 gradient norm = 3.7714739614444938e-06\n",
      "Iteration 658 : x = [1.99574148 1.50665038] f(x) = 0.0009242084300085234 gradient norm = 3.695581214563773e-06\n",
      "Iteration 659 : x = [1.9957411 1.5066467] f(x) = 0.0009242084164886154 gradient norm = 3.6212152453112235e-06\n",
      "Iteration 660 : x = [1.99574073 1.5066431 ] f(x) = 0.0009242084035073543 gradient norm = 3.5483453545486867e-06\n",
      "Iteration 661 : x = [1.99574037 1.50663957] f(x) = 0.0009242083910432823 gradient norm = 3.4769414597713013e-06\n",
      "Iteration 662 : x = [1.99574002 1.50663611] f(x) = 0.0009242083790757963 gradient norm = 3.4069740827678e-06\n",
      "Iteration 663 : x = [1.99573967 1.50663272] f(x) = 0.0009242083675851145 gradient norm = 3.3384143374733414e-06\n",
      "Iteration 664 : x = [1.99573933 1.5066294 ] f(x) = 0.0009242083565522423 gradient norm = 3.2712339181299536e-06\n",
      "Iteration 665 : x = [1.995739   1.50662615] f(x) = 0.0009242083459589413 gradient norm = 3.20540508760789e-06\n",
      "Iteration 666 : x = [1.99573867 1.50662296] f(x) = 0.0009242083357877011 gradient norm = 3.140900666062969e-06\n",
      "Iteration 667 : x = [1.99573835 1.50661983] f(x) = 0.000924208326021707 gradient norm = 3.0776940197069153e-06\n",
      "Iteration 668 : x = [1.99573804 1.50661677] f(x) = 0.0009242083166448147 gradient norm = 3.015759049884681e-06\n",
      "Iteration 669 : x = [1.99573773 1.50661377] f(x) = 0.0009242083076415236 gradient norm = 2.9550701823388127e-06\n",
      "Iteration 670 : x = [1.99573743 1.50661083] f(x) = 0.0009242082989969495 gradient norm = 2.8956023566772494e-06\n",
      "Iteration 671 : x = [1.99573713 1.50660795] f(x) = 0.0009242082906968015 gradient norm = 2.8373310160883296e-06\n",
      "Iteration 672 : x = [1.99573684 1.50660513] f(x) = 0.0009242082827273587 gradient norm = 2.7802320972153127e-06\n",
      "Iteration 673 : x = [1.99573656 1.50660236] f(x) = 0.0009242082750754453 gradient norm = 2.7242820202705405e-06\n",
      "Iteration 674 : x = [1.99573628 1.50659965] f(x) = 0.0009242082677284112 gradient norm = 2.6694576793338414e-06\n",
      "Iteration 675 : x = [1.99573601 1.506597  ] f(x) = 0.0009242082606741099 gradient norm = 2.6157364328347343e-06\n",
      "Iteration 676 : x = [1.99573574 1.5065944 ] f(x) = 0.0009242082539008796 gradient norm = 2.5630960942443047e-06\n",
      "Iteration 677 : x = [1.99573548 1.50659185] f(x) = 0.0009242082473975217 gradient norm = 2.511514922941495e-06\n",
      "Iteration 678 : x = [1.99573523 1.50658935] f(x) = 0.0009242082411532849 gradient norm = 2.460971615255764e-06\n",
      "Iteration 679 : x = [1.99573498 1.5065869 ] f(x) = 0.0009242082351578448 gradient norm = 2.4114452957123653e-06\n",
      "Iteration 680 : x = [1.99573473 1.5065845 ] f(x) = 0.0009242082294012897 gradient norm = 2.3629155084270585e-06\n",
      "Iteration 681 : x = [1.99573449 1.50658215] f(x) = 0.0009242082238741023 gradient norm = 2.315362208690778e-06\n",
      "Iteration 682 : x = [1.99573425 1.50657985] f(x) = 0.0009242082185671438 gradient norm = 2.2687657547083824e-06\n",
      "Iteration 683 : x = [1.99573402 1.50657759] f(x) = 0.0009242082134716405 gradient norm = 2.2231068995165453e-06\n",
      "Iteration 684 : x = [1.9957338  1.50657538] f(x) = 0.0009242082085791671 gradient norm = 2.1783667830579935e-06\n",
      "Iteration 685 : x = [1.99573357 1.50657321] f(x) = 0.000924208203881635 gradient norm = 2.134526924407132e-06\n",
      "Iteration 686 : x = [1.99573336 1.50657109] f(x) = 0.0009242081993712767 gradient norm = 2.091569214168437e-06\n",
      "Iteration 687 : x = [1.99573314 1.50656901] f(x) = 0.0009242081950406357 gradient norm = 2.0494759070109627e-06\n",
      "Iteration 688 : x = [1.99573293 1.50656697] f(x) = 0.0009242081908825504 gradient norm = 2.008229614346684e-06\n",
      "Iteration 689 : x = [1.99573273 1.50656497] f(x) = 0.0009242081868901471 gradient norm = 1.967813297186582e-06\n",
      "Iteration 690 : x = [1.99573253 1.50656301] f(x) = 0.0009242081830568235 gradient norm = 1.928210259117893e-06\n",
      "Iteration 691 : x = [1.99573233 1.5065611 ] f(x) = 0.0009242081793762418 gradient norm = 1.8894041394061073e-06\n",
      "Iteration 692 : x = [1.99573214 1.50655922] f(x) = 0.0009242081758423162 gradient norm = 1.85137890627626e-06\n",
      "Iteration 693 : x = [1.99573195 1.50655737] f(x) = 0.0009242081724492036 gradient norm = 1.814118850286144e-06\n",
      "Iteration 694 : x = [1.99573177 1.50655557] f(x) = 0.0009242081691912937 gradient norm = 1.77760857786488e-06\n",
      "Iteration 695 : x = [1.99573158 1.5065538 ] f(x) = 0.0009242081660631989 gradient norm = 1.7418330049698293e-06\n",
      "Iteration 696 : x = [1.99573141 1.50655207] f(x) = 0.0009242081630597471 gradient norm = 1.7067773508615199e-06\n",
      "Iteration 697 : x = [1.99573123 1.50655037] f(x) = 0.0009242081601759725 gradient norm = 1.672427132003825e-06\n",
      "Iteration 698 : x = [1.99573106 1.50654871] f(x) = 0.0009242081574071059 gradient norm = 1.6387681561172685e-06\n",
      "Iteration 699 : x = [1.9957309  1.50654708] f(x) = 0.0009242081547485694 gradient norm = 1.605786516307778e-06\n",
      "Iteration 700 : x = [1.99573073 1.50654548] f(x) = 0.0009242081521959672 gradient norm = 1.5734685853423757e-06\n",
      "Iteration 701 : x = [1.99573057 1.50654391] f(x) = 0.0009242081497450775 gradient norm = 1.5418010100266255e-06\n",
      "Iteration 702 : x = [1.99573041 1.50654238] f(x) = 0.0009242081473918484 gradient norm = 1.5107707056966108e-06\n",
      "Iteration 703 : x = [1.99573026 1.50654088] f(x) = 0.0009242081451323886 gradient norm = 1.4803648508294837e-06\n",
      "Iteration 704 : x = [1.99573011 1.50653941] f(x) = 0.0009242081429629613 gradient norm = 1.4505708817534092e-06\n",
      "Iteration 705 : x = [1.99572996 1.50653796] f(x) = 0.0009242081408799797 gradient norm = 1.421376487469052e-06\n",
      "Iteration 706 : x = [1.99572982 1.50653655] f(x) = 0.0009242081388799993 gradient norm = 1.3927696045697498e-06\n",
      "Iteration 707 : x = [1.99572967 1.50653516] f(x) = 0.0009242081369597126 gradient norm = 1.3647384122598348e-06\n",
      "Iteration 708 : x = [1.99572954 1.5065338 ] f(x) = 0.0009242081351159441 gradient norm = 1.3372713274876065e-06\n",
      "Iteration 709 : x = [1.9957294  1.50653247] f(x) = 0.0009242081333456454 gradient norm = 1.310357000173065e-06\n",
      "Iteration 710 : x = [1.99572927 1.50653117] f(x) = 0.0009242081316458888 gradient norm = 1.2839843085076412e-06\n",
      "Iteration 711 : x = [1.99572913 1.50652989] f(x) = 0.0009242081300138633 gradient norm = 1.2581423543818117e-06\n",
      "Iteration 712 : x = [1.99572901 1.50652864] f(x) = 0.0009242081284468706 gradient norm = 1.2328204588868028e-06\n",
      "Iteration 713 : x = [1.99572888 1.50652742] f(x) = 0.0009242081269423189 gradient norm = 1.2080081578992557e-06\n",
      "Iteration 714 : x = [1.99572876 1.50652621] f(x) = 0.0009242081254977202 gradient norm = 1.1836951977805771e-06\n",
      "Iteration 715 : x = [1.99572864 1.50652504] f(x) = 0.0009242081241106857 gradient norm = 1.1598715311290826e-06\n",
      "Iteration 716 : x = [1.99572852 1.50652388] f(x) = 0.0009242081227789218 gradient norm = 1.1365273126444741e-06\n",
      "Iteration 717 : x = [1.9957284  1.50652275] f(x) = 0.0009242081215002264 gradient norm = 1.113652895064345e-06\n",
      "Iteration 718 : x = [1.99572829 1.50652164] f(x) = 0.0009242081202724845 gradient norm = 1.0912388251864569e-06\n",
      "Iteration 719 : x = [1.99572818 1.50652056] f(x) = 0.0009242081190936656 gradient norm = 1.0692758399518713e-06\n",
      "Iteration 720 : x = [1.99572807 1.50651949] f(x) = 0.000924208117961821 gradient norm = 1.0477548626432962e-06\n",
      "Iteration 721 : x = [1.99572796 1.50651845] f(x) = 0.0009242081168750781 gradient norm = 1.0266669991282017e-06\n",
      "Iteration 722 : x = [1.99572786 1.50651743] f(x) = 0.0009242081158316401 gradient norm = 1.006003534193525e-06\n",
      "Iteration 723 : x = [1.99572776 1.50651643] f(x) = 0.0009242081148297814 gradient norm = 9.857559279292378e-07\n",
      "Completed in 723 iterations\n",
      "\n",
      "\tStep size: 10\n",
      "Iteration 0 : x = [2. 5.] f(x) = 0.04037643540736778 gradient norm = 0.017863549100416345\n",
      "Iteration 1 : x = [2.11589422 4.86406189] f(x) = 0.03778025365492496 gradient norm = 0.013484651133016348\n",
      "Iteration 2 : x = [2.1295057  4.72990411] f(x) = 0.035974411188198406 gradient norm = 0.013390034812189406\n",
      "Iteration 3 : x = [2.12711873 4.59602504] f(x) = 0.034180542744469876 gradient norm = 0.013404051639364395\n",
      "Iteration 4 : x = [2.12283437 4.46205302] f(x) = 0.03238328013058849 gradient norm = 0.01341113673741785\n",
      "Iteration 5 : x = [2.11838895 4.32801535] f(x) = 0.03058476320117384 gradient norm = 0.013408329778640362\n",
      "Iteration 6 : x = [2.11395495 4.19400538] f(x) = 0.028787752546028642 gradient norm = 0.01339398908223033\n",
      "Iteration 7 : x = [2.10954704 4.06013804] f(x) = 0.0269954612619708 gradient norm = 0.01336621086345381\n",
      "Iteration 8 : x = [2.10516761 3.9265477 ] f(x) = 0.025211618803550558 gradient norm = 0.013322777987618273\n",
      "Iteration 9 : x = [2.10081794 3.79339094] f(x) = 0.023440541290063267 gradient norm = 0.013261120792177282\n",
      "Iteration 10 : x = [2.09649852 3.6608501 ] f(x) = 0.021687203974305423 gradient norm = 0.01317828077810248\n",
      "Iteration 11 : x = [2.09220873 3.52913713] f(x) = 0.019957311582038666 gradient norm = 0.013070882283782363\n",
      "Iteration 12 : x = [2.08794651 3.39849782] f(x) = 0.018257359805439046 gradient norm = 0.012935119726259364\n",
      "Iteration 13 : x = [2.08370809 3.26921608] f(x) = 0.016594678086484092 gradient norm = 0.012766771150569465\n",
      "Iteration 14 : x = [2.07948774 3.14161814] f(x) = 0.014977440005315985 gradient norm = 0.012561252498315753\n",
      "Iteration 15 : x = [2.07527776 3.01607619] f(x) = 0.013414623393165301 gradient norm = 0.012313730695693926\n",
      "Iteration 16 : x = [2.07106874 2.89301084] f(x) = 0.011915898439144586 gradient norm = 0.012019316328460443\n",
      "Iteration 17 : x = [2.0668501  2.77289173] f(x) = 0.010491419886718431 gradient norm = 0.011673356515271118\n",
      "Iteration 18 : x = [2.06261119 2.65623516] f(x) = 0.009151500985744979 gradient norm = 0.011271842976295477\n",
      "Iteration 19 : x = [2.05834294 2.54359757] f(x) = 0.007906154858652946 gradient norm = 0.010811936080389228\n",
      "Iteration 20 : x = [2.05403988 2.43556387] f(x) = 0.006764506014218475 gradient norm = 0.010292580275528271\n",
      "Iteration 21 : x = [2.04970268 2.33272949] f(x) = 0.00573410216094259 gradient norm = 0.00971514985134839\n",
      "Iteration 22 : x = [2.0453406  2.23567597] f(x) = 0.004820192031018409 gradient norm = 0.00908402196983132\n",
      "Iteration 23 : x = [2.04097358 2.14494078] f(x) = 0.004025070964817625 gradient norm = 0.008406939365829282\n",
      "Iteration 24 : x = [2.03663316 2.06098351] f(x) = 0.003347619159795749 gradient norm = 0.0076950174063402646\n",
      "Iteration 25 : x = [2.03236188 1.98415197] f(x) = 0.002783152172639853 gradient norm = 0.006962287965849761\n",
      "Iteration 26 : x = [2.02821069 1.91465295] f(x) = 0.0023236593994590327 gradient norm = 0.006224761611676067\n",
      "Iteration 27 : x = [2.02423458 1.85253245] f(x) = 0.001958428152702755 gradient norm = 0.00549911175983376\n",
      "Iteration 28 : x = [2.02048708 1.79766918] f(x) = 0.0016749608318166634 gradient norm = 0.004801197980578772\n",
      "Iteration 29 : x = [2.01701462 1.74978293] f(x) = 0.0014600233823584522 gradient norm = 0.0041447023915493495\n",
      "Iteration 30 : x = [2.01385202 1.70845675] f(x) = 0.0013006418412930892 gradient norm = 0.003540125396748673\n",
      "Iteration 31 : x = [2.01101976 1.67316897] f(x) = 0.0011848964798662034 gradient norm = 0.0029942853595907727\n",
      "Iteration 32 : x = [2.00852351 1.64333035] f(x) = 0.0011024323801005727 gradient norm = 0.0025103341464450925\n",
      "Iteration 33 : x = [2.00635555 1.6183208 ] f(x) = 0.0010446813315305884 gradient norm = 0.002088187518242478\n",
      "Iteration 34 : x = [2.00449747 1.59752175] f(x) = 0.001004846916392588 gradient norm = 0.0017252087362102837\n",
      "Iteration 35 : x = [2.00292347 1.58034162] f(x) = 0.0009777312609106717 gradient norm = 0.0014169798140328434\n",
      "Iteration 36 : x = [2.00160352 1.56623343] f(x) = 0.0009594813395450331 gradient norm = 0.0011580305072039217\n",
      "Iteration 37 : x = [2.00050615 1.55470524] f(x) = 0.0009473157921713486 gradient norm = 0.0009424463945080609\n",
      "Iteration 38 : x = [1.99960044 1.5453244 ] f(x) = 0.0009392711924544625 gradient norm = 0.0007643250958399417\n",
      "Iteration 39 : x = [1.99885745 1.53771735] f(x) = 0.0009339871186326907 gradient norm = 0.000618083959449126\n",
      "Iteration 40 : x = [1.998251   1.53156633] f(x) = 0.0009305354203272289 gradient norm = 0.0004986417624966464\n",
      "Iteration 41 : x = [1.99775806 1.52660434] f(x) = 0.0009282908792867428 gradient norm = 0.00040150405288197875\n",
      "Iteration 42 : x = [1.99735872 1.5226092 ] f(x) = 0.0009268367100498178 gradient norm = 0.00032278108192019736\n",
      "Iteration 43 : x = [1.9970361  1.51939756] f(x) = 0.0009258974283493642 gradient norm = 0.00025916270676661\n",
      "Iteration 44 : x = [1.99677605 1.51681901] f(x) = 0.000925292201218354 gradient norm = 0.00020786885792664931\n",
      "Iteration 45 : x = [1.99656681 1.51475088] f(x) = 0.0009249029895196658 gradient norm = 0.00016658868680209952\n",
      "Iteration 46 : x = [1.99639869 1.5130935 ] f(x) = 0.0009246530907177728 gradient norm = 0.00013341699541713614\n",
      "Iteration 47 : x = [1.99626378 1.51176617] f(x) = 0.0009244928444523454 gradient norm = 0.00010679315487405734\n",
      "Iteration 48 : x = [1.99615561 1.51070373] f(x) = 0.0009243901927596868 gradient norm = 8.54453330630191e-05\n",
      "Iteration 49 : x = [1.99606895 1.50985368] f(x) = 0.0009243244895233129 gradient norm = 6.834127301167806e-05\n",
      "Iteration 50 : x = [1.99599957 1.5091738 ] f(x) = 0.0009242824632631732 gradient norm = 5.464588019116163e-05\n",
      "Iteration 51 : x = [1.99594404 1.50863017] f(x) = 0.0009242555958986849 gradient norm = 4.3685309231147436e-05\n",
      "Iteration 52 : x = [1.99589963 1.50819558] f(x) = 0.0009242384268784953 gradient norm = 3.4916947760694255e-05\n",
      "Iteration 53 : x = [1.9958641  1.50784822] f(x) = 0.0009242274590966507 gradient norm = 2.790457599601869e-05\n",
      "Iteration 54 : x = [1.9958357  1.50757062] f(x) = 0.0009242204546411538 gradient norm = 2.229796528195317e-05\n",
      "Iteration 55 : x = [1.995813  1.5073488] f(x) = 0.0009242159822907871 gradient norm = 1.78162208057013e-05\n",
      "Iteration 56 : x = [1.99579486 1.50717157] f(x) = 0.000924213127186385 gradient norm = 1.4234243745563351e-05\n",
      "Iteration 57 : x = [1.99578036 1.50702996] f(x) = 0.0009242113047683454 gradient norm = 1.1371768299903515e-05\n",
      "Iteration 58 : x = [1.99576878 1.50691684] f(x) = 0.0009242101416445668 gradient norm = 9.084509047275955e-06\n",
      "Iteration 59 : x = [1.99575952 1.50682647] f(x) = 0.0009242093993685329 gradient norm = 7.25702843250418e-06\n",
      "Iteration 60 : x = [1.99575212 1.50675427] f(x) = 0.0009242089257003204 gradient norm = 5.797000349315526e-06\n",
      "Iteration 61 : x = [1.99574622 1.50669661] f(x) = 0.0009242086234557477 gradient norm = 4.630603049685978e-06\n",
      "Iteration 62 : x = [1.9957415  1.50665054] f(x) = 0.0009242084306041754 gradient norm = 3.6988231899026858e-06\n",
      "Iteration 63 : x = [1.99573773 1.50661374] f(x) = 0.0009242083075568436 gradient norm = 2.954493457857698e-06\n",
      "Iteration 64 : x = [1.99573472 1.50658435] f(x) = 0.0009242082290497845 gradient norm = 2.35991986074135e-06\n",
      "Iteration 65 : x = [1.99573231 1.50656088] f(x) = 0.0009242081789616072 gradient norm = 1.8849823735230863e-06\n",
      "Iteration 66 : x = [1.99573039 1.50654213] f(x) = 0.0009242081470055078 gradient norm = 1.5056151956235727e-06\n",
      "Iteration 67 : x = [1.99572885 1.50652715] f(x) = 0.0009242081266179162 gradient norm = 1.2025911825468315e-06\n",
      "Iteration 68 : x = [1.99572763 1.50651518] f(x) = 0.0009242081136110404 gradient norm = 9.605498503264685e-07\n",
      "Completed in 68 iterations\n",
      "\n",
      "\tStep size: 100\n",
      "Iteration 0 : x = [2. 5.] f(x) = 0.04037643540736778 gradient norm = 0.017863549100416345\n",
      "Iteration 1 : x = [3.15894217 3.64061892] f(x) = 0.08135271459030034 gradient norm = 0.10034952868227055\n",
      "Iteration 2 : x = [-6.87453609  3.81264555] f(x) = 0.20302412766704322 gradient norm = 0.06780012483752593\n",
      "Iteration 3 : x = [-13.50780891   2.40969829] f(x) = 0.15953847830394888 gradient norm = 1.0753304800711694e-13\n",
      "Completed in 3 iterations\n",
      "\n",
      "--------------- Starting point: [1, 0.5] ---------------\n",
      "\n",
      "\tStep size: 0.1\n",
      "Iteration 0 : x = [1.  0.5] f(x) = 0.11204289613814822 gradient norm = 0.16286411890444852\n",
      "Iteration 1 : x = [1.01522255 0.50578975] f(x) = 0.10937718996761575 gradient norm = 0.1644533484728546\n",
      "Iteration 2 : x = [1.03061067 0.51159103] f(x) = 0.10666102761006391 gradient norm = 0.16583536633992418\n",
      "Iteration 3 : x = [1.04614519 0.51739555] f(x) = 0.10390093146096882 gradient norm = 0.1669976219483643\n",
      "Iteration 4 : x = [1.06180567 0.52319479] f(x) = 0.1011039992544921 gradient norm = 0.16792905030357935\n",
      "Iteration 5 : x = [1.07757057 0.52898009] f(x) = 0.0982778338523362 gradient norm = 0.16862035007138054\n",
      "Iteration 6 : x = [1.09341734 0.53474274] f(x) = 0.09543045731887866 gradient norm = 0.16906423351289818\n",
      "Iteration 7 : x = [1.10932264 0.5404741 ] f(x) = 0.09257021110675143 gradient norm = 0.16925563602540564\n",
      "Iteration 8 : x = [1.12526254 0.54616571] f(x) = 0.08970564497491293 gradient norm = 0.16919187446867434\n",
      "Iteration 9 : x = [1.1412127  0.55180941] f(x) = 0.08684539794926024 gradient norm = 0.16887274572609196\n",
      "Iteration 10 : x = [1.15714862 0.55739746] f(x) = 0.08399807515068963 gradient norm = 0.16830055991375417\n",
      "Iteration 11 : x = [1.1730459 0.5629226] f(x) = 0.08117212460785511 gradient norm = 0.16748010606569388\n",
      "Iteration 12 : x = [1.18888043 0.56837821] f(x) = 0.07837571821271436 gradient norm = 0.1664185516964825\n",
      "Iteration 13 : x = [1.20462864 0.57375829] f(x) = 0.07561664076155963 gradient norm = 0.16512528106796714\n",
      "Iteration 14 : x = [1.22026772 0.5790576 ] f(x) = 0.07290219057263359 gradient norm = 0.16361167998388568\n",
      "Iteration 15 : x = [1.23577582 0.58427167] f(x) = 0.07023909452549129 gradient norm = 0.1618908772804136\n",
      "Iteration 16 : x = [1.25113224 0.5893968 ] f(x) = 0.06763343958500877 gradient norm = 0.15997745472734373\n",
      "Iteration 17 : x = [1.26631756 0.59443009] f(x) = 0.06509062202103792 gradient norm = 0.15788713774737093\n",
      "Iteration 18 : x = [1.28131379 0.5993694 ] f(x) = 0.06261531468055244 gradient norm = 0.1556364792293918\n",
      "Iteration 19 : x = [1.29610443 0.60421335] f(x) = 0.060211451873567946 gradient norm = 0.15324254785744956\n",
      "Iteration 20 : x = [1.31067461 0.60896126] f(x) = 0.057882230745923045 gradient norm = 0.15072263095288307\n",
      "Iteration 21 : x = [1.32501105 0.6136131 ] f(x) = 0.05563012746454777 gradient norm = 0.1480939600137794\n",
      "Iteration 22 : x = [1.33910211 0.61816944] f(x) = 0.05345692615111955 gradient norm = 0.14537346511792046\n",
      "Iteration 23 : x = [1.35293778 0.62263137] f(x) = 0.05136375826970244 gradient norm = 0.14257756230331597\n",
      "Iteration 24 : x = [1.36650961 0.62700046] f(x) = 0.04935115009204899 gradient norm = 0.13972197609605097\n",
      "Iteration 25 : x = [1.37981071 0.63127867] f(x) = 0.047419075910415595 gradient norm = 0.13682159762453813\n",
      "Iteration 26 : x = [1.39283563 0.63546828] f(x) = 0.04556701481613371 gradient norm = 0.13389037731039574\n",
      "Iteration 27 : x = [1.40558032 0.63957186] f(x) = 0.043794009084809134 gradient norm = 0.13094124999164797\n",
      "Iteration 28 : x = [1.41804198 0.64359219] f(x) = 0.04209872247862557 gradient norm = 0.1279860895163367\n",
      "Iteration 29 : x = [1.43021904 0.64753219] f(x) = 0.04047949706834474 gradient norm = 0.1250356893235981\n",
      "Iteration 30 : x = [1.442111   0.65139491] f(x) = 0.038934407471834735 gradient norm = 0.12209976526893228\n",
      "Iteration 31 : x = [1.45371834 0.65518345] f(x) = 0.037461311686569805 gradient norm = 0.11918697690626529\n",
      "Iteration 32 : x = [1.46504246 0.65890095] f(x) = 0.03605789794941833 gradient norm = 0.11630496356403563\n",
      "Iteration 33 : x = [1.47608551 0.66255054] f(x) = 0.03472172728128411 gradient norm = 0.11346039179991779\n",
      "Iteration 34 : x = [1.48685036 0.6661353 ] f(x) = 0.03345027156349213 gradient norm = 0.11065901114731065\n",
      "Iteration 35 : x = [1.49734049 0.66965828] f(x) = 0.03224094714674221 gradient norm = 0.10790571544085195\n",
      "Iteration 36 : x = [1.50755988 0.67312244] f(x) = 0.031091144113599898 gradient norm = 0.10520460739927619\n",
      "Iteration 37 : x = [1.51751298 0.67653066] f(x) = 0.029998251404846434 gradient norm = 0.10255906452997472\n",
      "Iteration 38 : x = [1.52720459 0.6798857 ] f(x) = 0.0289596780823662 gradient norm = 0.09997180478492691\n",
      "Iteration 39 : x = [1.53663983 0.68319023] f(x) = 0.02797287104074983 gradient norm = 0.09744495073191567\n",
      "Iteration 40 : x = [1.54582405 0.68644679] f(x) = 0.027035329500569385 gradient norm = 0.09498009130219849\n",
      "Iteration 41 : x = [1.55476282 0.68965782] f(x) = 0.026144616622236657 gradient norm = 0.09257834043361544\n",
      "Iteration 42 : x = [1.56346182 0.69282561] f(x) = 0.025298368574000682 gradient norm = 0.09024039214658133\n",
      "Iteration 43 : x = [1.57192684 0.69595236] f(x) = 0.024494301374025383 gradient norm = 0.0879665717714199\n",
      "Iteration 44 : x = [1.58016376 0.69904014] f(x) = 0.023730215807184273 gradient norm = 0.08575688319209156\n",
      "Iteration 45 : x = [1.58817846 0.70209089] f(x) = 0.02300400069431419 gradient norm = 0.08361105208723559\n",
      "Iteration 46 : x = [1.59597682 0.70510645] f(x) = 0.02231363476684789 gradient norm = 0.08152856523853241\n",
      "Iteration 47 : x = [1.60356472 0.70808855] f(x) = 0.021657187374279192 gradient norm = 0.07950870604263545\n",
      "Iteration 48 : x = [1.61094796 0.71103881] f(x) = 0.021032818226756143 gradient norm = 0.07755058641006686\n",
      "Iteration 49 : x = [1.61813231 0.71395874] f(x) = 0.02043877635092464 gradient norm = 0.07565317526594839\n",
      "Iteration 50 : x = [1.62512345 0.71684978] f(x) = 0.01987339841441496 gradient norm = 0.07381532388631158\n",
      "Iteration 51 : x = [1.63192694 0.71971326] f(x) = 0.019335106553356504 gradient norm = 0.07203578831266659\n",
      "Iteration 52 : x = [1.63854828 0.7225504 ] f(x) = 0.01882240581816665 gradient norm = 0.07031324908878628\n",
      "Iteration 53 : x = [1.64499283 0.72536239] f(x) = 0.0183338813356333 gradient norm = 0.06864632855919174\n",
      "Iteration 54 : x = [1.65126585 0.7281503 ] f(x) = 0.01786819526996629 gradient norm = 0.06703360596018486\n",
      "Iteration 55 : x = [1.65737246 0.73091514] f(x) = 0.017424083651952412 gradient norm = 0.06547363052274237\n",
      "Iteration 56 : x = [1.66331766 0.73365786] f(x) = 0.01700035313349782 gradient norm = 0.06396493279318445\n",
      "Iteration 57 : x = [1.66910633 0.73637934] f(x) = 0.016595877714548096 gradient norm = 0.06250603436306208\n",
      "Iteration 58 : x = [1.67474321 0.73908039] f(x) = 0.016209595480499016 gradient norm = 0.06109545618478632\n",
      "Iteration 59 : x = [1.6802329  0.74176178] f(x) = 0.0158405053806056 gradient norm = 0.059731725634615145\n",
      "Iteration 60 : x = [1.68557989 0.74442421] f(x) = 0.015487664071423725 gradient norm = 0.058413382470057396\n",
      "Iteration 61 : x = [1.69078851 0.74706835] f(x) = 0.015150182843844536 gradient norm = 0.05713898381479132\n",
      "Iteration 62 : x = [1.69586298 0.74969482] f(x) = 0.01482722464768146 gradient norm = 0.05590710829098518\n",
      "Iteration 63 : x = [1.7008074  0.75230419] f(x) = 0.014518001223931012 gradient norm = 0.05471635940655086\n",
      "Iteration 64 : x = [1.70562572 0.75489699] f(x) = 0.014221770351646644 gradient norm = 0.05356536829340999\n",
      "Iteration 65 : x = [1.71032177 0.75747372] f(x) = 0.01393783321374848 gradient norm = 0.05245279588231885\n",
      "Iteration 66 : x = [1.71489928 0.76003484] f(x) = 0.013665531883958627 gradient norm = 0.0513773345901796\n",
      "Iteration 67 : x = [1.71936184 0.76258079] f(x) = 0.013404246935329073 gradient norm = 0.05033770958702376\n",
      "Iteration 68 : x = [1.72371294 0.76511197] f(x) = 0.013153395169454796 gradient norm = 0.04933267970195646\n",
      "Iteration 69 : x = [1.72795592 0.76762875] f(x) = 0.012912427464382625 gradient norm = 0.04836103802024026\n",
      "Iteration 70 : x = [1.73209407 0.77013148] f(x) = 0.01268082673838969 gradient norm = 0.04742161221732433\n",
      "Iteration 71 : x = [1.73613051 0.77262049] f(x) = 0.012458106026173145 gradient norm = 0.04651326466993141\n",
      "Iteration 72 : x = [1.74006831 0.77509609] f(x) = 0.012243806663529618 gradient norm = 0.04563489237924347\n",
      "Iteration 73 : x = [1.74391041 0.77755856] f(x) = 0.012037496576279375 gradient norm = 0.04478542673672338\n",
      "Iteration 74 : x = [1.74765965 0.78000816] f(x) = 0.011838768668980626 gradient norm = 0.043963833159120155\n",
      "Iteration 75 : x = [1.75131879 0.78244514] f(x) = 0.011647239308862314 gradient norm = 0.04316911061567985\n",
      "Iteration 76 : x = [1.75489049 0.78486974] f(x) = 0.011462546900361375 gradient norm = 0.04240029106747515\n",
      "Iteration 77 : x = [1.75837733 0.78728217] f(x) = 0.01128435054566705 gradient norm = 0.041656438836032275\n",
      "Iteration 78 : x = [1.76178178 0.78968264] f(x) = 0.011112328786738415 gradient norm = 0.04093664991603231\n",
      "Iteration 79 : x = [1.76510627 0.79207133] f(x) = 0.010946178424360513 gradient norm = 0.04024005124475969\n",
      "Iteration 80 : x = [1.76835312 0.79444844] f(x) = 0.010785613409931229 gradient norm = 0.03956579993913052\n",
      "Iteration 81 : x = [1.77152456 0.79681412] f(x) = 0.010630363805817842 gradient norm = 0.038913082509527894\n",
      "Iteration 82 : x = [1.77462279 0.79916853] f(x) = 0.01048017481028291 gradient norm = 0.03828111405827109\n",
      "Iteration 83 : x = [1.7776499  0.80151183] f(x) = 0.010334805843149544 gradient norm = 0.03766913746933075\n",
      "Iteration 84 : x = [1.78060793 0.80384415] f(x) = 0.010194029688551579 gradient norm = 0.037076422594845615\n",
      "Iteration 85 : x = [1.78349884 0.80616563] f(x) = 0.0100576316912922 gradient norm = 0.0365022654430837\n",
      "Iteration 86 : x = [1.78632453 0.80847639] f(x) = 0.0099254090035122 gradient norm = 0.03594598737170162\n",
      "Iteration 87 : x = [1.78908685 0.81077655] f(x) = 0.00979716987854478 gradient norm = 0.035406934289475875\n",
      "Iteration 88 : x = [1.79178757 0.81306622] f(x) = 0.009672733009005513 gradient norm = 0.03488447586909495\n",
      "Iteration 89 : x = [1.79442843 0.8153455 ] f(x) = 0.00955192690633347 gradient norm = 0.03437800477310103\n",
      "Iteration 90 : x = [1.79701108 0.81761451] f(x) = 0.009434589319160898 gradient norm = 0.03388693589464132\n",
      "Iteration 91 : x = [1.79953714 0.81987333] f(x) = 0.009320566688044084 gradient norm = 0.03341070561432398\n",
      "Iteration 92 : x = [1.80200817 0.82212205] f(x) = 0.009209713634236892 gradient norm = 0.03294877107416463\n",
      "Iteration 93 : x = [1.80442569 0.82436077] f(x) = 0.009101892480330047 gradient norm = 0.03250060946934668\n",
      "Iteration 94 : x = [1.80679114 0.82658956] f(x) = 0.008996972800714285 gradient norm = 0.032065717358298336\n",
      "Iteration 95 : x = [1.80910597 0.8288085 ] f(x) = 0.008894830999953283 gradient norm = 0.031643609991404226\n",
      "Iteration 96 : x = [1.81137152 0.83101767] f(x) = 0.008795349917273302 gradient norm = 0.031233820658515474\n",
      "Iteration 97 : x = [1.81358914 0.83321714] f(x) = 0.008698418455490894 gradient norm = 0.030835900055294047\n",
      "Iteration 98 : x = [1.81576011 0.83540699] f(x) = 0.008603931232807473 gradient norm = 0.030449415668321978\n",
      "Iteration 99 : x = [1.81788568 0.83758727] f(x) = 0.008511788256001197 gradient norm = 0.030073951178821\n",
      "Iteration 100 : x = [1.81996705 0.83975806] f(x) = 0.008421894613641798 gradient norm = 0.029709105884757996\n",
      "Iteration 101 : x = [1.82200539 0.84191941] f(x) = 0.008334160188043416 gradient norm = 0.029354494141056908\n",
      "Iteration 102 : x = [1.82400185 0.84407139] f(x) = 0.008248499384754476 gradient norm = 0.029009744817594246\n",
      "Iteration 103 : x = [1.82595752 0.84621406] f(x) = 0.008164830878462282 gradient norm = 0.028674500774621563\n",
      "Iteration 104 : x = [1.82787346 0.84834747] f(x) = 0.008083077374263536 gradient norm = 0.02834841835523365\n",
      "Iteration 105 : x = [1.82975072 0.85047167] f(x) = 0.008003165383321013 gradient norm = 0.028031166894482467\n",
      "Iteration 106 : x = [1.83159028 0.85258673] f(x) = 0.00792502501199092 gradient norm = 0.027722428244724803\n",
      "Iteration 107 : x = [1.83339313 0.85469269] f(x) = 0.007848589763565724 gradient norm = 0.027421896316783777\n",
      "Iteration 108 : x = [1.8351602  0.85678961] f(x) = 0.007773796351833618 gradient norm = 0.027129276636500745\n",
      "Iteration 109 : x = [1.83689242 0.85887752] f(x) = 0.007700584525708058 gradient norm = 0.026844285916253256\n",
      "Iteration 110 : x = [1.83859066 0.8609565 ] f(x) = 0.007628896904230211 gradient norm = 0.026566651641016934\n",
      "Iteration 111 : x = [1.84025579 0.86302657] f(x) = 0.007558678821292633 gradient norm = 0.026296111668552627\n",
      "Iteration 112 : x = [1.84188865 0.86508779] f(x) = 0.007489878179475472 gradient norm = 0.026032413843306252\n",
      "Iteration 113 : x = [1.84349004 0.86714021] f(x) = 0.0074224453124262305 gradient norm = 0.02577531562361455\n",
      "Iteration 114 : x = [1.84506075 0.86918387] f(x) = 0.007356332855251381 gradient norm = 0.025524583721818563\n",
      "Iteration 115 : x = [1.84660155 0.87121881] f(x) = 0.007291495622422844 gradient norm = 0.02527999375689388\n",
      "Iteration 116 : x = [1.84811317 0.87324508] f(x) = 0.007227890492734687 gradient norm = 0.02504132991921596\n",
      "Iteration 117 : x = [1.84959635 0.87526272] f(x) = 0.007165476300875664 gradient norm = 0.02480838464708756\n",
      "Iteration 118 : x = [1.85105177 0.87727178] f(x) = 0.0071042137352113136 gradient norm = 0.024580958314664482\n",
      "Iteration 119 : x = [1.85248012 0.87927229] f(x) = 0.0070440652413956955 gradient norm = 0.024358858930924793\n",
      "Iteration 120 : x = [1.85388206 0.8812643 ] f(x) = 0.006984994931457279 gradient norm = 0.024141901849336084\n",
      "Iteration 121 : x = [1.85525822 0.88324785] f(x) = 0.006926968498026541 gradient norm = 0.02392990948788426\n",
      "Iteration 122 : x = [1.85660924 0.88522299] f(x) = 0.006869953133393886 gradient norm = 0.02372271105913601\n",
      "Iteration 123 : x = [1.85793571 0.88718975] f(x) = 0.0068139174531067406 gradient norm = 0.023520142310016368\n",
      "Iteration 124 : x = [1.85923824 0.88914817] f(x) = 0.006758831423833035 gradient norm = 0.02332204527099088\n",
      "Iteration 125 : x = [1.86051738 0.89109829] f(x) = 0.006704666295235721 gradient norm = 0.02312826801435053\n",
      "Iteration 126 : x = [1.86177369 0.89304015] f(x) = 0.006651394535619129 gradient norm = 0.022938664421305578\n",
      "Iteration 127 : x = [1.86300772 0.8949738 ] f(x) = 0.006598989771123166 gradient norm = 0.022753093957602655\n",
      "Iteration 128 : x = [1.86421999 0.89689927] f(x) = 0.00654742672825534 gradient norm = 0.02257142145738692\n",
      "Iteration 129 : x = [1.86541102 0.8988166 ] f(x) = 0.006496681179563895 gradient norm = 0.022393516915039022\n",
      "Iteration 130 : x = [1.86658129 0.90072583] f(x) = 0.006446729892267594 gradient norm = 0.022219255284723568\n",
      "Iteration 131 : x = [1.86773129 0.902627  ] f(x) = 0.006397550579669206 gradient norm = 0.022048516287393446\n",
      "Iteration 132 : x = [1.8688615  0.90452014] f(x) = 0.006349121855190504 gradient norm = 0.021881184225000794\n",
      "Iteration 133 : x = [1.86997237 0.9064053 ] f(x) = 0.0063014231888766 gradient norm = 0.021717147801673074\n",
      "Iteration 134 : x = [1.87106435 0.90828252] f(x) = 0.006254434866226898 gradient norm = 0.021556299951618393\n",
      "Iteration 135 : x = [1.87213787 0.91015182] f(x) = 0.006208137949218633 gradient norm = 0.02139853767353161\n",
      "Iteration 136 : x = [1.87319335 0.91201326] f(x) = 0.006162514239397252 gradient norm = 0.021243761871278685\n",
      "Iteration 137 : x = [1.8742312  0.91386686] f(x) = 0.006117546242915517 gradient norm = 0.021091877200643063\n",
      "Iteration 138 : x = [1.87525182 0.91571266] f(x) = 0.006073217137410465 gradient norm = 0.02094279192192419\n",
      "Iteration 139 : x = [1.87625561 0.91755071] f(x) = 0.0060295107406139695 gradient norm = 0.0207964177581839\n",
      "Iteration 140 : x = [1.87724293 0.91938104] f(x) = 0.005986411480599061 gradient norm = 0.02065266975894258\n",
      "Iteration 141 : x = [1.87821416 0.92120369] f(x) = 0.005943904367569965 gradient norm = 0.020511466169132686\n",
      "Iteration 142 : x = [1.87916966 0.92301869] f(x) = 0.005901974967109388 gradient norm = 0.020372728303122763\n",
      "Iteration 143 : x = [1.88010978 0.92482608] f(x) = 0.005860609374801718 gradient norm = 0.02023638042363064\n",
      "Iteration 144 : x = [1.88103485 0.9266259 ] f(x) = 0.0058197941921556366 gradient norm = 0.020102349625349982\n",
      "Iteration 145 : x = [1.88194522 0.92841818] f(x) = 0.00577951650375422 gradient norm = 0.019970565723119553\n",
      "Iteration 146 : x = [1.88284119 0.93020297] f(x) = 0.005739763855564794 gradient norm = 0.01984096114446992\n",
      "Iteration 147 : x = [1.8837231  0.93198029] f(x) = 0.005700524234344857 gradient norm = 0.019713470826387126\n",
      "Iteration 148 : x = [1.88459123 0.93375019] f(x) = 0.00566178604808407 gradient norm = 0.01958803211613828\n",
      "Iteration 149 : x = [1.8854459 0.9355127] f(x) = 0.005623538107425821 gradient norm = 0.019464584676008402\n",
      "Iteration 150 : x = [1.8862874  0.93726786] f(x) = 0.005585769608015203 gradient norm = 0.019343070391803042\n",
      "Iteration 151 : x = [1.887116   0.93901571] f(x) = 0.00554847011372328 gradient norm = 0.019223433284975715\n",
      "Iteration 152 : x = [1.88793199 0.94075627] f(x) = 0.005511629540700429 gradient norm = 0.019105619428243677\n",
      "Iteration 153 : x = [1.88873563 0.94248959] f(x) = 0.005475238142214249 gradient norm = 0.01898957686456022\n",
      "Iteration 154 : x = [1.88952719 0.94421571] f(x) = 0.00543928649423012 gradient norm = 0.01887525552931591\n",
      "Iteration 155 : x = [1.89030693 0.94593465] f(x) = 0.005403765481694856 gradient norm = 0.01876260717564552\n",
      "Iteration 156 : x = [1.89107509 0.94764646] f(x) = 0.005368666285486117 gradient norm = 0.01865158530272158\n",
      "Iteration 157 : x = [1.89183191 0.94935117] f(x) = 0.00533398036999246 gradient norm = 0.018542145086919388\n",
      "Iteration 158 : x = [1.89257765 0.95104881] f(x) = 0.005299699471290772 gradient norm = 0.018434243315742525\n",
      "Iteration 159 : x = [1.89331251 0.95273943] f(x) = 0.005265815585889825 gradient norm = 0.018327838324401657\n",
      "Iteration 160 : x = [1.89403675 0.95442305] f(x) = 0.005232320960010314 gradient norm = 0.018222889934943053\n",
      "Iteration 161 : x = [1.89475056 0.95609972] f(x) = 0.005199208079373515 gradient norm = 0.018119359397827137\n",
      "Iteration 162 : x = [1.89545418 0.95776946] f(x) = 0.0051664696594721825 gradient norm = 0.018017209335860734\n",
      "Iteration 163 : x = [1.8961478  0.95943231] f(x) = 0.005134098636298773 gradient norm = 0.017916403690390298\n",
      "Iteration 164 : x = [1.89683164 0.96108831] f(x) = 0.005102088157507516 gradient norm = 0.017816907669666763\n",
      "Iteration 165 : x = [1.89750589 0.9627375 ] f(x) = 0.00507043157398803 gradient norm = 0.017718687699295587\n",
      "Iteration 166 : x = [1.89817075 0.9643799 ] f(x) = 0.005039122431829579 gradient norm = 0.01762171137468938\n",
      "Iteration 167 : x = [1.8988264  0.96601555] f(x) = 0.005008154464656001 gradient norm = 0.017525947415442913\n",
      "Iteration 168 : x = [1.89947305 0.96764449] f(x) = 0.004977521586312614 gradient norm = 0.017431365621553677\n",
      "Iteration 169 : x = [1.90011085 0.96926675] f(x) = 0.004947217883887317 gradient norm = 0.017337936831414005\n",
      "Iteration 170 : x = [1.90074    0.97088237] f(x) = 0.004917237611049079 gradient norm = 0.017245632881503353\n",
      "Iteration 171 : x = [1.90136067 0.97249137] f(x) = 0.004887575181687917 gradient norm = 0.017154426567712298\n",
      "Iteration 172 : x = [1.90197301 0.9740938 ] f(x) = 0.004858225163841383 gradient norm = 0.017064291608232425\n",
      "Iteration 173 : x = [1.90257721 0.97568968] f(x) = 0.004829182273893247 gradient norm = 0.016975202607948436\n",
      "Iteration 174 : x = [1.90317341 0.97727906] f(x) = 0.004800441371030977 gradient norm = 0.016887135024271804\n",
      "Iteration 175 : x = [1.90376178 0.97886196] f(x) = 0.004771997451949189 gradient norm = 0.01680006513435724\n",
      "Iteration 176 : x = [1.90434247 0.98043842] f(x) = 0.004743845645787075 gradient norm = 0.0167139700036458\n",
      "Iteration 177 : x = [1.90491563 0.98200847] f(x) = 0.004715981209288255 gradient norm = 0.01662882745568039\n",
      "Iteration 178 : x = [1.9054814  0.98357214] f(x) = 0.004688399522172321 gradient norm = 0.016544616043141898\n",
      "Iteration 179 : x = [1.90603993 0.98512948] f(x) = 0.004661096082707714 gradient norm = 0.016461315020055874\n",
      "Iteration 180 : x = [1.90659136 0.9866805 ] f(x) = 0.0046340665034762555 gradient norm = 0.01637890431512195\n",
      "Iteration 181 : x = [1.90713582 0.98822525] f(x) = 0.004607306507320067 gradient norm = 0.016297364506120012\n",
      "Iteration 182 : x = [1.90767345 0.98976375] f(x) = 0.004580811923462142 gradient norm = 0.01621667679534882\n",
      "Iteration 183 : x = [1.90820437 0.99129605] f(x) = 0.004554578683792285 gradient norm = 0.01613682298605483\n",
      "Iteration 184 : x = [1.90872872 0.99282217] f(x) = 0.004528602819310502 gradient norm = 0.016057785459810393\n",
      "Iteration 185 : x = [1.90924661 0.99434214] f(x) = 0.004502880456720441 gradient norm = 0.015979547154802414\n",
      "Iteration 186 : x = [1.90975817 0.99585599] f(x) = 0.00447740781516573 gradient norm = 0.0159020915449939\n",
      "Iteration 187 : x = [1.91026352 0.99736377] f(x) = 0.004452181203102534 gradient norm = 0.015825402620122518\n",
      "Iteration 188 : x = [1.91076278 0.99886549] f(x) = 0.004427197015301932 gradient norm = 0.015749464866501642\n",
      "Iteration 189 : x = [1.91125604 1.0003612 ] f(x) = 0.00440245172997607 gradient norm = 0.015674263248590854\n",
      "Iteration 190 : x = [1.91174344 1.00185092] f(x) = 0.004377941906022296 gradient norm = 0.015599783191304189\n",
      "Iteration 191 : x = [1.91222507 1.00333469] f(x) = 0.004353664180379864 gradient norm = 0.01552601056302561\n",
      "Iteration 192 : x = [1.91270104 1.00481253] f(x) = 0.00432961526549399 gradient norm = 0.015452931659302721\n",
      "Iteration 193 : x = [1.91317146 1.00628449] f(x) = 0.004305791946882328 gradient norm = 0.015380533187190574\n",
      "Iteration 194 : x = [1.91363642 1.00775057] f(x) = 0.004282191080799194 gradient norm = 0.015308802250218894\n",
      "Iteration 195 : x = [1.91409603 1.00921083] f(x) = 0.004258809591993062 gradient norm = 0.015237726333956916\n",
      "Iteration 196 : x = [1.91455038 1.01066529] f(x) = 0.004235644471553134 gradient norm = 0.015167293292151302\n",
      "Iteration 197 : x = [1.91499956 1.01211398] f(x) = 0.00421269277484092 gradient norm = 0.015097491333413383\n",
      "Iteration 198 : x = [1.91544367 1.01355693] f(x) = 0.004189951619503031 gradient norm = 0.015028309008433249\n",
      "Iteration 199 : x = [1.9158828  1.01499418] f(x) = 0.0041674181835615436 gradient norm = 0.01495973519769885\n",
      "Iteration 200 : x = [1.91631703 1.01642574] f(x) = 0.004145089703578444 gradient norm = 0.014891759099699375\n",
      "Iteration 201 : x = [1.91674646 1.01785166] f(x) = 0.004122963472890901 gradient norm = 0.014824370219592984\n",
      "Iteration 202 : x = [1.91717117 1.01927195] f(x) = 0.004101036839914205 gradient norm = 0.014757558358319836\n",
      "Iteration 203 : x = [1.91759123 1.02068666] f(x) = 0.004079307206509398 gradient norm = 0.01469131360214194\n",
      "Iteration 204 : x = [1.91800674 1.02209581] f(x) = 0.00405777202641275 gradient norm = 0.014625626312592536\n",
      "Iteration 205 : x = [1.91841777 1.02349943] f(x) = 0.004036428803724397 gradient norm = 0.014560487116818009\n",
      "Iteration 206 : x = [1.9188244  1.02489755] f(x) = 0.004015275091453544 gradient norm = 0.014495886898296324\n",
      "Iteration 207 : x = [1.9192267  1.02629019] f(x) = 0.003994308490117792 gradient norm = 0.014431816787916522\n",
      "Iteration 208 : x = [1.91962475 1.02767739] f(x) = 0.003973526646394261 gradient norm = 0.014368268155404491\n",
      "Iteration 209 : x = [1.92001862 1.02905918] f(x) = 0.003952927251820258 gradient norm = 0.014305232601080874\n",
      "Iteration 210 : x = [1.92040838 1.03043558] f(x) = 0.003932508041541416 gradient norm = 0.014242701947937525\n",
      "Iteration 211 : x = [1.92079411 1.03180663] f(x) = 0.003912266793105236 gradient norm = 0.014180668234019499\n",
      "Iteration 212 : x = [1.92117586 1.03317234] f(x) = 0.0038922013252981305 gradient norm = 0.014119123705100078\n",
      "Iteration 213 : x = [1.92155371 1.03453276] f(x) = 0.0038723094970241406 gradient norm = 0.014058060807637036\n",
      "Iteration 214 : x = [1.92192772 1.0358879 ] f(x) = 0.0038525892062235387 gradient norm = 0.013997472181998509\n",
      "Iteration 215 : x = [1.92229796 1.03723779] f(x) = 0.0038330383888297128 gradient norm = 0.013937350655947634\n",
      "Iteration 216 : x = [1.92266448 1.03858247] f(x) = 0.0038136550177626646 gradient norm = 0.01387768923837549\n",
      "Iteration 217 : x = [1.92302736 1.03992196] f(x) = 0.0037944371019576566 gradient norm = 0.013818481113272097\n",
      "Iteration 218 : x = [1.92338664 1.04125628] f(x) = 0.0037753826854275358 gradient norm = 0.013759719633926054\n",
      "Iteration 219 : x = [1.92374239 1.04258547] f(x) = 0.003756489846357358 gradient norm = 0.013701398317343409\n",
      "Iteration 220 : x = [1.92409467 1.04390955] f(x) = 0.003737756696229997 gradient norm = 0.013643510838877012\n",
      "Iteration 221 : x = [1.92444352 1.04522854] f(x) = 0.003719181378981445 gradient norm = 0.01358605102705776\n",
      "Iteration 222 : x = [1.92478902 1.04654249] f(x) = 0.0037007620701846673 gradient norm = 0.01352901285861977\n",
      "Iteration 223 : x = [1.9251312 1.0478514] f(x) = 0.003682496976260783 gradient norm = 0.013472390453711496\n",
      "Iteration 224 : x = [1.92547013 1.04915531] f(x) = 0.0036643843337165437 gradient norm = 0.013416178071285478\n",
      "Iteration 225 : x = [1.92580586 1.05045424] f(x) = 0.0036464224084070173 gradient norm = 0.013360370104659498\n",
      "Iteration 226 : x = [1.92613843 1.05174822] f(x) = 0.003628609494822484 gradient norm = 0.013304961077242258\n",
      "Iteration 227 : x = [1.92646789 1.05303728] f(x) = 0.0036109439153986086 gradient norm = 0.013249945638417143\n",
      "Iteration 228 : x = [1.9267943  1.05432144] f(x) = 0.00359342401984894 gradient norm = 0.01319531855957757\n",
      "Iteration 229 : x = [1.9271177  1.05560073] f(x) = 0.003576048184518895 gradient norm = 0.013141074730308063\n",
      "Iteration 230 : x = [1.92743815 1.05687517] f(x) = 0.00355881481176037 gradient norm = 0.013087209154705187\n",
      "Iteration 231 : x = [1.92775567 1.05814479] f(x) = 0.003541722329326192 gradient norm = 0.013033716947832804\n",
      "Iteration 232 : x = [1.92807033 1.05940961] f(x) = 0.0035247691897836216 gradient norm = 0.012980593332306322\n",
      "Iteration 233 : x = [1.92838216 1.06066965] f(x) = 0.0035079538699462295 gradient norm = 0.012927833635000892\n",
      "Iteration 234 : x = [1.9286912  1.06192495] f(x) = 0.003491274870323377 gradient norm = 0.012875433283878593\n",
      "Iteration 235 : x = [1.92899751 1.06317553] f(x) = 0.003474730714586679 gradient norm = 0.012823387804930001\n",
      "Iteration 236 : x = [1.92930112 1.06442141] f(x) = 0.003458319949052808 gradient norm = 0.012771692819225595\n",
      "Iteration 237 : x = [1.92960206 1.06566262] f(x) = 0.003442041142181977 gradient norm = 0.012720344040072678\n",
      "Iteration 238 : x = [1.92990039 1.06689917] f(x) = 0.0034258928840915897 gradient norm = 0.01266933727027377\n",
      "Iteration 239 : x = [1.93019614 1.0681311 ] f(x) = 0.003409873786084433 gradient norm = 0.012618668399482431\n",
      "Iteration 240 : x = [1.93048935 1.06935843] f(x) = 0.0033939824801908942 gradient norm = 0.012568333401652755\n",
      "Iteration 241 : x = [1.93078005 1.07058119] f(x) = 0.003378217618724696 gradient norm = 0.012518328332578887\n",
      "Iteration 242 : x = [1.93106828 1.07179938] f(x) = 0.0033625778738516536 gradient norm = 0.012468649327521068\n",
      "Iteration 243 : x = [1.93135408 1.07301305] f(x) = 0.003347061937170947 gradient norm = 0.012419292598914843\n",
      "Iteration 244 : x = [1.93163749 1.07422221] f(x) = 0.0033316685193085106 gradient norm = 0.012370254434160314\n",
      "Iteration 245 : x = [1.93191854 1.07542689] f(x) = 0.0033163963495220663 gradient norm = 0.012321531193488179\n",
      "Iteration 246 : x = [1.93219725 1.0766271 ] f(x) = 0.0033012441753173844 gradient norm = 0.012273119307899781\n",
      "Iteration 247 : x = [1.93247368 1.07782288] f(x) = 0.0032862107620753936 gradient norm = 0.012225015277178227\n",
      "Iteration 248 : x = [1.93274784 1.07901425] f(x) = 0.003271294892689731 gradient norm = 0.012177215667967884\n",
      "Iteration 249 : x = [1.93301977 1.08020122] f(x) = 0.003256495367214382 gradient norm = 0.012129717111919631\n",
      "Iteration 250 : x = [1.93328951 1.08138382] f(x) = 0.0032418110025210695 gradient norm = 0.012082516303899438\n",
      "Iteration 251 : x = [1.93355708 1.08256207] f(x) = 0.00322724063196599 gradient norm = 0.012035610000257706\n",
      "Iteration 252 : x = [1.93382251 1.083736  ] f(x) = 0.0032127831050656774 gradient norm = 0.011988995017157231\n",
      "Iteration 253 : x = [1.93408583 1.08490562] f(x) = 0.0031984372871815703 gradient norm = 0.011942668228957513\n",
      "Iteration 254 : x = [1.93434708 1.08607096] f(x) = 0.0031842020592130773 gradient norm = 0.01189662656665322\n",
      "Iteration 255 : x = [1.93460628 1.08723204] f(x) = 0.0031700763172987775 gradient norm = 0.011850867016364895\n",
      "Iteration 256 : x = [1.93486345 1.08838889] f(x) = 0.003156058972525539 gradient norm = 0.01180538661787985\n",
      "Iteration 257 : x = [1.93511864 1.08954152] f(x) = 0.0031421489506452596 gradient norm = 0.01176018246324143\n",
      "Iteration 258 : x = [1.93537185 1.09068995] f(x) = 0.003128345191798964 gradient norm = 0.01171525169538475\n",
      "Iteration 259 : x = [1.93562313 1.09183421] f(x) = 0.003114646650248056 gradient norm = 0.011670591506817313\n",
      "Iteration 260 : x = [1.93587249 1.09297432] f(x) = 0.0031010522941124392 gradient norm = 0.011626199138342744\n",
      "Iteration 261 : x = [1.93611997 1.0941103 ] f(x) = 0.0030875611051153257 gradient norm = 0.011582071877826046\n",
      "Iteration 262 : x = [1.93636558 1.09524216] f(x) = 0.0030741720783344813 gradient norm = 0.01153820705899892\n",
      "Iteration 263 : x = [1.93660935 1.09636994] f(x) = 0.00306088422195971 gradient norm = 0.011494602060303557\n",
      "Iteration 264 : x = [1.93685131 1.09749364] f(x) = 0.0030476965570563836 gradient norm = 0.011451254303773627\n",
      "Iteration 265 : x = [1.93709148 1.0986133 ] f(x) = 0.0030346081173348157 gradient norm = 0.011408161253950982\n",
      "Iteration 266 : x = [1.93732988 1.09972893] f(x) = 0.0030216179489253 gradient norm = 0.01136532041683685\n",
      "Iteration 267 : x = [1.93756654 1.10084055] f(x) = 0.0030087251101586178 gradient norm = 0.011322729338876217\n",
      "Iteration 268 : x = [1.93780147 1.10194818] f(x) = 0.002995928671351867 gradient norm = 0.011280385605974245\n",
      "Iteration 269 : x = [1.93803471 1.10305184] f(x) = 0.0029832277145994224 gradient norm = 0.011238286842543483\n",
      "Iteration 270 : x = [1.93826627 1.10415156] f(x) = 0.002970621333568892 gradient norm = 0.011196430710580883\n",
      "Iteration 271 : x = [1.93849617 1.10524734] f(x) = 0.002958108633301891 gradient norm = 0.011154814908773389\n",
      "Iteration 272 : x = [1.93872443 1.10633922] f(x) = 0.002945688730019503 gradient norm = 0.011113437171631265\n",
      "Iteration 273 : x = [1.93895108 1.10742721] f(x) = 0.0029333607509322746 gradient norm = 0.011072295268647971\n",
      "Iteration 274 : x = [1.93917613 1.10851132] f(x) = 0.0029211238340546243 gradient norm = 0.011031387003485849\n",
      "Iteration 275 : x = [1.93939961 1.10959159] f(x) = 0.0029089771280235033 gradient norm = 0.01099071021318649\n",
      "Iteration 276 : x = [1.93962153 1.11066802] f(x) = 0.0028969197919212074 gradient norm = 0.01095026276740506\n",
      "Iteration 277 : x = [1.93984192 1.11174064] f(x) = 0.0028849509951022114 gradient norm = 0.010910042567667767\n",
      "Iteration 278 : x = [1.94006079 1.11280946] f(x) = 0.0028730699170238885 gradient norm = 0.010870047546651405\n",
      "Iteration 279 : x = [1.94027816 1.11387451] f(x) = 0.002861275747081025 gradient norm = 0.010830275667484566\n",
      "Iteration 280 : x = [1.94049405 1.11493581] f(x) = 0.002849567684444019 gradient norm = 0.01079072492306946\n",
      "Iteration 281 : x = [1.94070847 1.11599336] f(x) = 0.0028379449379006176 gradient norm = 0.01075139333542376\n",
      "Iteration 282 : x = [1.94092145 1.11704719] f(x) = 0.0028264067257011594 gradient norm = 0.010712278955041805\n",
      "Iteration 283 : x = [1.941133   1.11809732] f(x) = 0.002814952275407157 gradient norm = 0.010673379860274425\n",
      "Iteration 284 : x = [1.94134314 1.11914377] f(x) = 0.0028035808237431483 gradient norm = 0.010634694156726682\n",
      "Iteration 285 : x = [1.94155188 1.12018655] f(x) = 0.002792291616451757 gradient norm = 0.010596219976673172\n",
      "Iteration 286 : x = [1.94175924 1.12122569] f(x) = 0.0027810839081517966 gradient norm = 0.010557955478489933\n",
      "Iteration 287 : x = [1.94196525 1.12226119] f(x) = 0.0027699569621994226 gradient norm = 0.010519898846102672\n",
      "Iteration 288 : x = [1.9421699  1.12329308] f(x) = 0.0027589100505521834 gradient norm = 0.010482048288450672\n",
      "Iteration 289 : x = [1.94237323 1.12432138] f(x) = 0.0027479424536359064 gradient norm = 0.010444402038965747\n",
      "Iteration 290 : x = [1.94257523 1.1253461 ] f(x) = 0.0027370534602143603 gradient norm = 0.010406958355065919\n",
      "Iteration 291 : x = [1.94277594 1.12636725] f(x) = 0.002726242367261594 gradient norm = 0.010369715517663127\n",
      "Iteration 292 : x = [1.94297536 1.12738487] f(x) = 0.002715508479836905 gradient norm = 0.01033267183068472\n",
      "Iteration 293 : x = [1.94317351 1.12839896] f(x) = 0.002704851110962337 gradient norm = 0.01029582562060804\n",
      "Iteration 294 : x = [1.94337041 1.12940954] f(x) = 0.002694269581502658 gradient norm = 0.010259175236007867\n",
      "Iteration 295 : x = [1.94356606 1.13041663] f(x) = 0.002683763220047761 gradient norm = 0.010222719047116108\n",
      "Iteration 296 : x = [1.94376048 1.13142024] f(x) = 0.0026733313627974003 gradient norm = 0.01018645544539353\n",
      "Iteration 297 : x = [1.94395368 1.1324204 ] f(x) = 0.0026629733534482237 gradient norm = 0.01015038284311298\n",
      "Iteration 298 : x = [1.94414569 1.13341711] f(x) = 0.002652688543083019 gradient norm = 0.01011449967295376\n",
      "Iteration 299 : x = [1.9443365 1.1344104] f(x) = 0.002642476290062156 gradient norm = 0.010078804387606864\n",
      "Iteration 300 : x = [1.94452614 1.13540028] f(x) = 0.002632335959917115 gradient norm = 0.010043295459390611\n",
      "Iteration 301 : x = [1.94471461 1.13638676] f(x) = 0.0026222669252460875 gradient norm = 0.010007971379876445\n",
      "Iteration 302 : x = [1.94490194 1.13736987] f(x) = 0.0026122685656115967 gradient norm = 0.00997283065952448\n",
      "Iteration 303 : x = [1.94508812 1.13834962] f(x) = 0.00260234026744005 gradient norm = 0.009937871827328543\n",
      "Iteration 304 : x = [1.94527318 1.13932603] f(x) = 0.0025924814239232296 gradient norm = 0.009903093430470423\n",
      "Iteration 305 : x = [1.94545712 1.1402991 ] f(x) = 0.0025826914349216267 gradient norm = 0.00986849403398296\n",
      "Iteration 306 : x = [1.94563997 1.14126887] f(x) = 0.002572969706869598 gradient norm = 0.00983407222042175\n",
      "Iteration 307 : x = [1.94582172 1.14223533] f(x) = 0.002563315652682285 gradient norm = 0.009799826589545178\n",
      "Iteration 308 : x = [1.94600239 1.14319852] f(x) = 0.0025537286916642726 gradient norm = 0.009765755758002552\n",
      "Iteration 309 : x = [1.94618199 1.14415843] f(x) = 0.0025442082494199383 gradient norm = 0.009731858359030003\n",
      "Iteration 310 : x = [1.94636054 1.1451151 ] f(x) = 0.002534753757765424 gradient norm = 0.00969813304215403\n",
      "Iteration 311 : x = [1.94653804 1.14606853] f(x) = 0.002525364654642241 gradient norm = 0.009664578472902292\n",
      "Iteration 312 : x = [1.9467145  1.14701874] f(x) = 0.0025160403840324246 gradient norm = 0.009631193332521623\n",
      "Iteration 313 : x = [1.94688994 1.14796575] f(x) = 0.002506780395875229 gradient norm = 0.009597976317702846\n",
      "Iteration 314 : x = [1.94706436 1.14890957] f(x) = 0.0024975841459853178 gradient norm = 0.00956492614031235\n",
      "Iteration 315 : x = [1.94723778 1.14985021] f(x) = 0.002488451095972412 gradient norm = 0.009532041527130093\n",
      "Iteration 316 : x = [1.94741021 1.15078769] f(x) = 0.0024793807131623592 gradient norm = 0.009499321219593907\n",
      "Iteration 317 : x = [1.94758165 1.15172202] f(x) = 0.002470372470519614 gradient norm = 0.009466763973549954\n",
      "Iteration 318 : x = [1.94775211 1.15265322] f(x) = 0.0024614258465710625 gradient norm = 0.009434368559008989\n",
      "Iteration 319 : x = [1.94792161 1.15358131] f(x) = 0.0024525403253311795 gradient norm = 0.009402133759908449\n",
      "Iteration 320 : x = [1.94809015 1.15450629] f(x) = 0.002443715396228505 gradient norm = 0.009370058373880096\n",
      "Iteration 321 : x = [1.94825775 1.15542819] f(x) = 0.0024349505540333643 gradient norm = 0.009338141212023013\n",
      "Iteration 322 : x = [1.94842441 1.15634701] f(x) = 0.002426245298786855 gradient norm = 0.009306381098681898\n",
      "Iteration 323 : x = [1.94859015 1.15726277] f(x) = 0.002417599135731036 gradient norm = 0.009274776871230433\n",
      "Iteration 324 : x = [1.94875496 1.15817549] f(x) = 0.0024090115752403137 gradient norm = 0.00924332737985958\n",
      "Iteration 325 : x = [1.94891886 1.15908517] f(x) = 0.002400482132753978 gradient norm = 0.009212031487370681\n",
      "Iteration 326 : x = [1.94908186 1.15999184] f(x) = 0.002392010328709892 gradient norm = 0.009180888068973228\n",
      "Iteration 327 : x = [1.94924397 1.1608955 ] f(x) = 0.0023835956884792836 gradient norm = 0.009149896012087157\n",
      "Iteration 328 : x = [1.94940519 1.16179618] f(x) = 0.0023752377423026235 gradient norm = 0.00911905421614952\n",
      "Iteration 329 : x = [1.94956554 1.16269387] f(x) = 0.002366936025226581 gradient norm = 0.009088361592425445\n",
      "Iteration 330 : x = [1.94972502 1.16358861] f(x) = 0.0023586900770420065 gradient norm = 0.009057817063823267\n",
      "Iteration 331 : x = [1.94988364 1.16448039] f(x) = 0.002350499442222947 gradient norm = 0.009027419564713634\n",
      "Iteration 332 : x = [1.9500414  1.16536924] f(x) = 0.002342363669866652 gradient norm = 0.008997168040752594\n",
      "Iteration 333 : x = [1.95019832 1.16625517] f(x) = 0.002334282313634566 gradient norm = 0.00896706144870847\n",
      "Iteration 334 : x = [1.95035441 1.16713819] f(x) = 0.002326254931694261 gradient norm = 0.008937098756292408\n",
      "Iteration 335 : x = [1.95050966 1.16801831] f(x) = 0.002318281086662336 gradient norm = 0.008907278941992619\n",
      "Iteration 336 : x = [1.9506641  1.16889555] f(x) = 0.0023103603455482007 gradient norm = 0.008877600994911998\n",
      "Iteration 337 : x = [1.95081772 1.16976991] f(x) = 0.0023024922796987843 gradient norm = 0.008848063914609265\n",
      "Iteration 338 : x = [1.95097053 1.17064142] f(x) = 0.0022946764647441133 gradient norm = 0.00881866671094336\n",
      "Iteration 339 : x = [1.95112254 1.17151009] f(x) = 0.002286912480543759 gradient norm = 0.008789408403921114\n",
      "Iteration 340 : x = [1.95127376 1.17237592] f(x) = 0.002279199911134125 gradient norm = 0.008760288023547972\n",
      "Iteration 341 : x = [1.9514242  1.17323894] f(x) = 0.0022715383446765586 gradient norm = 0.008731304609681871\n",
      "Iteration 342 : x = [1.95157385 1.17409915] f(x) = 0.0022639273734062944 gradient norm = 0.008702457211890027\n",
      "Iteration 343 : x = [1.95172273 1.17495657] f(x) = 0.0022563665935821744 gradient norm = 0.008673744889308676\n",
      "Iteration 344 : x = [1.95187085 1.1758112 ] f(x) = 0.002248855605437152 gradient norm = 0.008645166710505543\n",
      "Iteration 345 : x = [1.95201821 1.17666306] f(x) = 0.002241394013129572 gradient norm = 0.008616721753345163\n",
      "Iteration 346 : x = [1.95216482 1.17751217] f(x) = 0.0022339814246951856 gradient norm = 0.008588409104856795\n",
      "Iteration 347 : x = [1.95231068 1.17835854] f(x) = 0.002226617451999911 gradient norm = 0.00856022786110499\n",
      "Iteration 348 : x = [1.9524558  1.17920217] f(x) = 0.0022193017106933153 gradient norm = 0.00853217712706267\n",
      "Iteration 349 : x = [1.95260019 1.18004308] f(x) = 0.002212033820162797 gradient norm = 0.008504256016486694\n",
      "Iteration 350 : x = [1.95274385 1.18088128] f(x) = 0.002204813403488464 gradient norm = 0.008476463651795814\n",
      "Iteration 351 : x = [1.95288679 1.18171679] f(x) = 0.0021976400873987 gradient norm = 0.008448799163951023\n",
      "Iteration 352 : x = [1.95302902 1.18254961] f(x) = 0.002190513502226392 gradient norm = 0.00842126169233814\n",
      "Iteration 353 : x = [1.95317054 1.18337976] f(x) = 0.0021834332818658066 gradient norm = 0.008393850384652651\n",
      "Iteration 354 : x = [1.95331135 1.18420725] f(x) = 0.0021763990637301265 gradient norm = 0.008366564396786748\n",
      "Iteration 355 : x = [1.95345147 1.18503209] f(x) = 0.0021694104887095954 gradient norm = 0.008339402892718426\n",
      "Iteration 356 : x = [1.9535909 1.1858543] f(x) = 0.0021624672011303064 gradient norm = 0.00831236504440276\n",
      "Iteration 357 : x = [1.95372964 1.18667387] f(x) = 0.0021555688487135778 gradient norm = 0.008285450031665064\n",
      "Iteration 358 : x = [1.9538677  1.18749083] f(x) = 0.002148715082535927 gradient norm = 0.00825865704209612\n",
      "Iteration 359 : x = [1.95400509 1.18830519] f(x) = 0.002141905556989653 gradient norm = 0.008231985270949331\n",
      "Iteration 360 : x = [1.9541418  1.18911696] f(x) = 0.002135139929743954 gradient norm = 0.008205433921039642\n",
      "Iteration 361 : x = [1.95427785 1.18992614] f(x) = 0.0021284178617066536 gradient norm = 0.008179002202644458\n",
      "Iteration 362 : x = [1.95441325 1.19073276] f(x) = 0.0021217390169864367 gradient norm = 0.00815268933340618\n",
      "Iteration 363 : x = [1.95454799 1.19153682] f(x) = 0.0021151030628556674 gradient norm = 0.008126494538236606\n",
      "Iteration 364 : x = [1.95468208 1.19233833] f(x) = 0.0021085096697137204 gradient norm = 0.008100417049223003\n",
      "Iteration 365 : x = [1.95481553 1.1931373 ] f(x) = 0.0021019585110508376 gradient norm = 0.008074456105535793\n",
      "Iteration 366 : x = [1.95494834 1.19393375] f(x) = 0.002095449263412513 gradient norm = 0.008048610953337951\n",
      "Iteration 367 : x = [1.95508052 1.19472768] f(x) = 0.0020889816063643656 gradient norm = 0.00802288084569591\n",
      "Iteration 368 : x = [1.95521207 1.19551911] f(x) = 0.002082555222457529 gradient norm = 0.007997265042492067\n",
      "Iteration 369 : x = [1.955343   1.19630805] f(x) = 0.002076169797194507 gradient norm = 0.007971762810338763\n",
      "Iteration 370 : x = [1.95547331 1.1970945 ] f(x) = 0.0020698250189955408 gradient norm = 0.007946373422493809\n",
      "Iteration 371 : x = [1.955603   1.19787848] f(x) = 0.0020635205791654124 gradient norm = 0.007921096158777376\n",
      "Iteration 372 : x = [1.95573209 1.19866   ] f(x) = 0.0020572561718607395 gradient norm = 0.007895930305490363\n",
      "Iteration 373 : x = [1.95586057 1.19943907] f(x) = 0.0020510314940577093 gradient norm = 0.007870875155334111\n",
      "Iteration 374 : x = [1.95598845 1.2002157 ] f(x) = 0.0020448462455202694 gradient norm = 0.00784593000733148\n",
      "Iteration 375 : x = [1.95611574 1.2009899 ] f(x) = 0.0020387001287687535 gradient norm = 0.007821094166749268\n",
      "Iteration 376 : x = [1.95624243 1.20176168] f(x) = 0.0020325928490489446 gradient norm = 0.007796366945021874\n",
      "Iteration 377 : x = [1.95636854 1.20253105] f(x) = 0.0020265241143015565 gradient norm = 0.007771747659676266\n",
      "Iteration 378 : x = [1.95649407 1.20329802] f(x) = 0.0020204936351321417 gradient norm = 0.007747235634258182\n",
      "Iteration 379 : x = [1.95661901 1.2040626 ] f(x) = 0.0020145011247814006 gradient norm = 0.007722830198259505\n",
      "Iteration 380 : x = [1.95674339 1.20482481] f(x) = 0.0020085462990959094 gradient norm = 0.007698530687046877\n",
      "Iteration 381 : x = [1.95686719 1.20558464] f(x) = 0.002002628876499227 gradient norm = 0.007674336441791416\n",
      "Iteration 382 : x = [1.95699044 1.20634211] f(x) = 0.0019967485779634093 gradient norm = 0.007650246809399609\n",
      "Iteration 383 : x = [1.95711311 1.20709724] f(x) = 0.001990905126980895 gradient norm = 0.00762626114244526\n",
      "Iteration 384 : x = [1.95723524 1.20785002] f(x) = 0.001985098249536781 gradient norm = 0.007602378799102619\n",
      "Iteration 385 : x = [1.95735681 1.20860048] f(x) = 0.0019793276740814594 gradient norm = 0.007578599143080451\n",
      "Iteration 386 : x = [1.95747783 1.20934861] f(x) = 0.0019735931315036275 gradient norm = 0.007554921543557253\n",
      "Iteration 387 : x = [1.9575983  1.21009443] f(x) = 0.00196789435510365 gradient norm = 0.007531345375117412\n",
      "Iteration 388 : x = [1.95771823 1.21083796] f(x) = 0.001962231080567288 gradient norm = 0.007507870017688421\n",
      "Iteration 389 : x = [1.95783763 1.21157919] f(x) = 0.0019566030459397623 gradient norm = 0.007484494856479028\n",
      "Iteration 390 : x = [1.95795649 1.21231814] f(x) = 0.0019510099916001619 gradient norm = 0.007461219281918369\n",
      "Iteration 391 : x = [1.95807483 1.21305482] f(x) = 0.0019454516602361988 gradient norm = 0.007438042689596008\n",
      "Iteration 392 : x = [1.95819263 1.21378924] f(x) = 0.0019399277968192847 gradient norm = 0.007414964480202947\n",
      "Iteration 393 : x = [1.95830992 1.2145214 ] f(x) = 0.0019344381485799393 gradient norm = 0.007391984059473487\n",
      "Iteration 394 : x = [1.95842668 1.21525132] f(x) = 0.0019289824649835162 gradient norm = 0.007369100838127996\n",
      "Iteration 395 : x = [1.95854293 1.215979  ] f(x) = 0.0019235604977062507 gradient norm = 0.007346314231816536\n",
      "Iteration 396 : x = [1.95865867 1.21670446] f(x) = 0.0019181720006116057 gradient norm = 0.007323623661063336\n",
      "Iteration 397 : x = [1.9587739 1.2174277] f(x) = 0.0019128167297269452 gradient norm = 0.007301028551212106\n",
      "Iteration 398 : x = [1.95888863 1.21814873] f(x) = 0.0019074944432204823 gradient norm = 0.007278528332372126\n",
      "Iteration 399 : x = [1.95900285 1.21886756] f(x) = 0.0019022049013785517 gradient norm = 0.0072561224393652216\n",
      "Iteration 400 : x = [1.95911658 1.21958421] f(x) = 0.0018969478665831524 gradient norm = 0.00723381031167341\n",
      "Iteration 401 : x = [1.95922981 1.22029867] f(x) = 0.001891723103289789 gradient norm = 0.007211591393387407\n",
      "Iteration 402 : x = [1.95934255 1.22101096] f(x) = 0.0018865303780055953 gradient norm = 0.0071894651331558404\n",
      "Iteration 403 : x = [1.95945481 1.22172109] f(x) = 0.001881369459267729 gradient norm = 0.007167430984135194\n",
      "Iteration 404 : x = [1.95956657 1.22242907] f(x) = 0.0018762401176220533 gradient norm = 0.007145488403940534\n",
      "Iteration 405 : x = [1.95967786 1.2231349 ] f(x) = 0.0018711421256020755 gradient norm = 0.007123636854596871\n",
      "Iteration 406 : x = [1.95978867 1.22383859] f(x) = 0.0018660752577081658 gradient norm = 0.007101875802491286\n",
      "Iteration 407 : x = [1.959899   1.22454015] f(x) = 0.0018610392903870214 gradient norm = 0.007080204718325686\n",
      "Iteration 408 : x = [1.96000887 1.2252396 ] f(x) = 0.0018560340020114055 gradient norm = 0.007058623077070281\n",
      "Iteration 409 : x = [1.96011826 1.22593693] f(x) = 0.001851059172860128 gradient norm = 0.007037130357917685\n",
      "Iteration 410 : x = [1.96022719 1.22663216] f(x) = 0.0018461145850982817 gradient norm = 0.00701572604423768\n",
      "Iteration 411 : x = [1.96033565 1.2273253 ] f(x) = 0.001841200022757729 gradient norm = 0.006994409623532615\n",
      "Iteration 412 : x = [1.96044366 1.22801635] f(x) = 0.0018363152717178182 gradient norm = 0.0069731805873934185\n",
      "Iteration 413 : x = [1.96055121 1.22870533] f(x) = 0.001831460119686358 gradient norm = 0.006952038431456244\n",
      "Iteration 414 : x = [1.9606583  1.22939223] f(x) = 0.0018266343561808135 gradient norm = 0.006930982655359702\n",
      "Iteration 415 : x = [1.96076494 1.23007708] f(x) = 0.0018218377725097313 gradient norm = 0.00691001276270267\n",
      "Iteration 416 : x = [1.96087114 1.23075987] f(x) = 0.0018170701617544124 gradient norm = 0.006889128261002725\n",
      "Iteration 417 : x = [1.96097689 1.23144062] f(x) = 0.0018123313187507922 gradient norm = 0.006868328661655105\n",
      "Iteration 418 : x = [1.9610822  1.23211933] f(x) = 0.0018076210400715502 gradient norm = 0.006847613479892243\n",
      "Iteration 419 : x = [1.96118707 1.23279601] f(x) = 0.001802939124008437 gradient norm = 0.0068269822347438594\n",
      "Iteration 420 : x = [1.9612915  1.23347068] f(x) = 0.0017982853705548144 gradient norm = 0.0068064344489975745\n",
      "Iteration 421 : x = [1.9613955  1.23414333] f(x) = 0.0017936595813884163 gradient norm = 0.006785969649160093\n",
      "Iteration 422 : x = [1.96149907 1.23481398] f(x) = 0.00178906155985431 gradient norm = 0.006765587365418853\n",
      "Iteration 423 : x = [1.96160221 1.23548263] f(x) = 0.0017844911109480654 gradient norm = 0.006745287131604234\n",
      "Iteration 424 : x = [1.96170492 1.23614929] f(x) = 0.001779948041299137 gradient norm = 0.006725068485152247\n",
      "Iteration 425 : x = [1.96180721 1.23681397] f(x) = 0.0017754321591544257 gradient norm = 0.006704930967067724\n",
      "Iteration 426 : x = [1.96190908 1.23747668] f(x) = 0.0017709432743620664 gradient norm = 0.006684874121888004\n",
      "Iteration 427 : x = [1.96201053 1.23813743] f(x) = 0.0017664811983553806 gradient norm = 0.006664897497647065\n",
      "Iteration 428 : x = [1.96211156 1.23879621] f(x) = 0.0017620457441370463 gradient norm = 0.006645000645840179\n",
      "Iteration 429 : x = [1.96221219 1.23945305] f(x) = 0.001757636726263441 gradient norm = 0.00662518312138898\n",
      "Iteration 430 : x = [1.9623124  1.24010795] f(x) = 0.001753253960829175 gradient norm = 0.006605444482607012\n",
      "Iteration 431 : x = [1.9624122  1.24076091] f(x) = 0.0017488972654518137 gradient norm = 0.0065857842911657095\n",
      "Iteration 432 : x = [1.9625116  1.24141194] f(x) = 0.0017445664592567762 gradient norm = 0.0065662021120608555\n",
      "Iteration 433 : x = [1.9626106  1.24206106] f(x) = 0.0017402613628624123 gradient norm = 0.0065466975135794105\n",
      "Iteration 434 : x = [1.96270919 1.24270826] f(x) = 0.0017359817983652569 gradient norm = 0.006527270067266821\n",
      "Iteration 435 : x = [1.96280739 1.24335356] f(x) = 0.0017317275893254627 gradient norm = 0.006507919347894712\n",
      "Iteration 436 : x = [1.96290519 1.24399696] f(x) = 0.0017274985607523934 gradient norm = 0.006488644933429006\n",
      "Iteration 437 : x = [1.9630026  1.24463847] f(x) = 0.0017232945390903962 gradient norm = 0.006469446404998461\n",
      "Iteration 438 : x = [1.96309962 1.2452781 ] f(x) = 0.0017191153522047348 gradient norm = 0.006450323346863557\n",
      "Iteration 439 : x = [1.96319624 1.24591585] f(x) = 0.0017149608293676912 gradient norm = 0.006431275346385836\n",
      "Iteration 440 : x = [1.96329249 1.24655174] f(x) = 0.001710830801244827 gradient norm = 0.0064123019939976034\n",
      "Iteration 441 : x = [1.96338834 1.24718576] f(x) = 0.001706725099881398 gradient norm = 0.006393402883171965\n",
      "Iteration 442 : x = [1.96348382 1.24781793] f(x) = 0.0017026435586889447 gradient norm = 0.006374577610393335\n",
      "Iteration 443 : x = [1.96357891 1.24844826] f(x) = 0.001698586012432011 gradient norm = 0.006355825775128198\n",
      "Iteration 444 : x = [1.96367363 1.24907674] f(x) = 0.0016945522972150462 gradient norm = 0.006337146979796325\n",
      "Iteration 445 : x = [1.96376798 1.2497034 ] f(x) = 0.0016905422504694323 gradient norm = 0.00631854082974229\n",
      "Iteration 446 : x = [1.96386195 1.25032822] f(x) = 0.0016865557109406772 gradient norm = 0.006300006933207364\n",
      "Iteration 447 : x = [1.96395554 1.25095123] f(x) = 0.001682592518675746 gradient norm = 0.006281544901301744\n",
      "Iteration 448 : x = [1.96404877 1.25157243] f(x) = 0.0016786525150105417 gradient norm = 0.006263154347977119\n",
      "Iteration 449 : x = [1.96414164 1.25219182] f(x) = 0.0016747355425575292 gradient norm = 0.006244834889999575\n",
      "Iteration 450 : x = [1.96423414 1.25280942] f(x) = 0.0016708414451934944 gradient norm = 0.006226586146922838\n",
      "Iteration 451 : x = [1.96432627 1.25342522] f(x) = 0.0016669700680474533 gradient norm = 0.006208407741061811\n",
      "Iteration 452 : x = [1.96441805 1.25403924] f(x) = 0.0016631212574886867 gradient norm = 0.006190299297466481\n",
      "Iteration 453 : x = [1.96450947 1.25465148] f(x) = 0.0016592948611149202 gradient norm = 0.006172260443896082\n",
      "Iteration 454 : x = [1.96460053 1.25526196] f(x) = 0.0016554907277406307 gradient norm = 0.006154290810793608\n",
      "Iteration 455 : x = [1.96469124 1.25587066] f(x) = 0.001651708707385489 gradient norm = 0.006136390031260617\n",
      "Iteration 456 : x = [1.96478159 1.25647761] f(x) = 0.001647948651262933 gradient norm = 0.006118557741032346\n",
      "Iteration 457 : x = [1.96487159 1.25708281] f(x) = 0.0016442104117688663 gradient norm = 0.006100793578453092\n",
      "Iteration 458 : x = [1.96496125 1.25768627] f(x) = 0.0016404938424704866 gradient norm = 0.006083097184451925\n",
      "Iteration 459 : x = [1.96505056 1.25828799] f(x) = 0.001636798798095234 gradient norm = 0.006065468202518662\n",
      "Iteration 460 : x = [1.96513952 1.25888797] f(x) = 0.0016331251345198707 gradient norm = 0.006047906278680116\n",
      "Iteration 461 : x = [1.96522815 1.25948624] f(x) = 0.0016294727087596778 gradient norm = 0.006030411061476666\n",
      "Iteration 462 : x = [1.96531643 1.26008278] f(x) = 0.0016258413789577717 gradient norm = 0.006012982201939048\n",
      "Iteration 463 : x = [1.96540437 1.26067761] f(x) = 0.0016222310043745372 gradient norm = 0.005995619353565453\n",
      "Iteration 464 : x = [1.96549198 1.26127074] f(x) = 0.0016186414453771903 gradient norm = 0.005978322172298885\n",
      "Iteration 465 : x = [1.96557925 1.26186217] f(x) = 0.0016150725634294354 gradient norm = 0.0059610903165047595\n",
      "Iteration 466 : x = [1.96566619 1.2624519 ] f(x) = 0.0016115242210812566 gradient norm = 0.0059439234469487985\n",
      "Iteration 467 : x = [1.96575279 1.26303995] f(x) = 0.001607996281958808 gradient norm = 0.005926821226775138\n",
      "Iteration 468 : x = [1.96583907 1.26362632] f(x) = 0.0016044886107544254 gradient norm = 0.005909783321484743\n",
      "Iteration 469 : x = [1.96592502 1.26421102] f(x) = 0.0016010010732167396 gradient norm = 0.00589280939891401\n",
      "Iteration 470 : x = [1.96601064 1.26479404] f(x) = 0.0015975335361408988 gradient norm = 0.005875899129213634\n",
      "Iteration 471 : x = [1.96609594 1.26537541] f(x) = 0.001594085867358905 gradient norm = 0.005859052184827754\n",
      "Iteration 472 : x = [1.96618091 1.26595512] f(x) = 0.0015906579357300489 gradient norm = 0.005842268240473277\n",
      "Iteration 473 : x = [1.96626557 1.26653318] f(x) = 0.0015872496111314495 gradient norm = 0.00582554697311948\n",
      "Iteration 474 : x = [1.96634991 1.2671096 ] f(x) = 0.0015838607644487 gradient norm = 0.005808888061967818\n",
      "Iteration 475 : x = [1.96643392 1.26768438] f(x) = 0.0015804912675666122 gradient norm = 0.005792291188431971\n",
      "Iteration 476 : x = [1.96651763 1.26825753] f(x) = 0.0015771409933600655 gradient norm = 0.0057757560361181145\n",
      "Iteration 477 : x = [1.96660102 1.26882905] f(x) = 0.0015738098156849471 gradient norm = 0.005759282290805413\n",
      "Iteration 478 : x = [1.96668409 1.26939896] f(x) = 0.0015704976093691989 gradient norm = 0.005742869640426727\n",
      "Iteration 479 : x = [1.96676686 1.26996725] f(x) = 0.0015672042502039483 gradient norm = 0.005726517775049506\n",
      "Iteration 480 : x = [1.96684932 1.27053393] f(x) = 0.0015639296149347545 gradient norm = 0.005710226386856983\n",
      "Iteration 481 : x = [1.96693146 1.27109902] f(x) = 0.0015606735812529282 gradient norm = 0.005693995170129466\n",
      "Iteration 482 : x = [1.96701331 1.2716625 ] f(x) = 0.0015574360277869552 gradient norm = 0.005677823821225918\n",
      "Iteration 483 : x = [1.96709485 1.2722244 ] f(x) = 0.0015542168340940072 gradient norm = 0.005661712038565702\n",
      "Iteration 484 : x = [1.96717609 1.27278471] f(x) = 0.0015510158806515506 gradient norm = 0.00564565952261053\n",
      "Iteration 485 : x = [1.96725702 1.27334345] f(x) = 0.001547833048849031 gradient norm = 0.005629665975846626\n",
      "Iteration 486 : x = [1.96733766 1.27390061] f(x) = 0.0015446682209796652 gradient norm = 0.0056137311027670824\n",
      "Iteration 487 : x = [1.967418  1.2744562] f(x) = 0.0015415212802322967 gradient norm = 0.005597854609854365\n",
      "Iteration 488 : x = [1.96749804 1.27501024] f(x) = 0.001538392110683362 gradient norm = 0.0055820362055630885\n",
      "Iteration 489 : x = [1.96757779 1.27556271] f(x) = 0.0015352805972889225 gradient norm = 0.005566275600302913\n",
      "Iteration 490 : x = [1.96765724 1.27611364] f(x) = 0.0015321866258767927 gradient norm = 0.005550572506421652\n",
      "Iteration 491 : x = [1.9677364  1.27666302] f(x) = 0.0015291100831387459 gradient norm = 0.0055349266381885505\n",
      "Iteration 492 : x = [1.96781528 1.27721087] f(x) = 0.001526050856622796 gradient norm = 0.00551933771177776\n",
      "Iteration 493 : x = [1.96789386 1.27775718] f(x) = 0.0015230088347255785 gradient norm = 0.005503805445251985\n",
      "Iteration 494 : x = [1.96797216 1.27830196] f(x) = 0.001519983906684792 gradient norm = 0.005488329558546297\n",
      "Iteration 495 : x = [1.96805017 1.27884522] f(x) = 0.00151697596257173 gradient norm = 0.005472909773452129\n",
      "Iteration 496 : x = [1.96812789 1.27938697] f(x) = 0.0015139848932838856 gradient norm = 0.005457545813601445\n",
      "Iteration 497 : x = [1.96820534 1.2799272 ] f(x) = 0.0015110105905376354 gradient norm = 0.005442237404451053\n",
      "Iteration 498 : x = [1.9682825  1.28046592] f(x) = 0.001508052946861001 gradient norm = 0.005426984273267137\n",
      "Iteration 499 : x = [1.96835938 1.28100315] f(x) = 0.0015051118555864803 gradient norm = 0.005411786149109878\n",
      "Iteration 500 : x = [1.96843598 1.28153888] f(x) = 0.0015021872108439624 gradient norm = 0.005396642762818318\n",
      "Iteration 501 : x = [1.96851231 1.28207312] f(x) = 0.0014992789075537031 gradient norm = 0.005381553846995315\n",
      "Iteration 502 : x = [1.96858836 1.28260587] f(x) = 0.0014963868414193868 gradient norm = 0.005366519135992711\n",
      "Iteration 503 : x = [1.96866413 1.28313715] f(x) = 0.0014935109089212453 gradient norm = 0.005351538365896594\n",
      "Iteration 504 : x = [1.96873964 1.28366695] f(x) = 0.001490651007309268 gradient norm = 0.005336611274512801\n",
      "Iteration 505 : x = [1.96881487 1.28419528] f(x) = 0.0014878070345964545 gradient norm = 0.005321737601352478\n",
      "Iteration 506 : x = [1.96888983 1.28472215] f(x) = 0.0014849788895521625 gradient norm = 0.005306917087617859\n",
      "Iteration 507 : x = [1.96896452 1.28524756] f(x) = 0.001482166471695505 gradient norm = 0.0052921494761881465\n",
      "Iteration 508 : x = [1.96903894 1.28577151] f(x) = 0.00147936968128883 gradient norm = 0.005277434511605589\n",
      "Iteration 509 : x = [1.9691131  1.28629402] f(x) = 0.0014765884193312523 gradient norm = 0.005262771940061658\n",
      "Iteration 510 : x = [1.96918699 1.28681508] f(x) = 0.0014738225875522636 gradient norm = 0.005248161509383372\n",
      "Iteration 511 : x = [1.96926062 1.28733471] f(x) = 0.0014710720884053997 gradient norm = 0.005233602969019792\n",
      "Iteration 512 : x = [1.96933399 1.2878529 ] f(x) = 0.0014683368250619738 gradient norm = 0.005219096070028619\n",
      "Iteration 513 : x = [1.96940709 1.28836967] f(x) = 0.0014656167014048785 gradient norm = 0.005204640565062971\n",
      "Iteration 514 : x = [1.96947994 1.28888501] f(x) = 0.0014629116220224415 gradient norm = 0.005190236208358237\n",
      "Iteration 515 : x = [1.96955252 1.28939893] f(x) = 0.0014602214922023527 gradient norm = 0.005175882755719132\n",
      "Iteration 516 : x = [1.96962485 1.28991144] f(x) = 0.0014575462179256425 gradient norm = 0.005161579964506818\n",
      "Iteration 517 : x = [1.96969693 1.29042254] f(x) = 0.001454885705860732 gradient norm = 0.0051473275936262134\n",
      "Iteration 518 : x = [1.96976875 1.29093224] f(x) = 0.0014522398633575343 gradient norm = 0.00513312540351339\n",
      "Iteration 519 : x = [1.96984031 1.29144054] f(x) = 0.0014496085984416183 gradient norm = 0.005118973156123124\n",
      "Iteration 520 : x = [1.96991162 1.29194745] f(x) = 0.001446991819808434 gradient norm = 0.005104870614916556\n",
      "Iteration 521 : x = [1.96998268 1.29245296] f(x) = 0.0014443894368175864 gradient norm = 0.005090817544848975\n",
      "Iteration 522 : x = [1.9700535  1.29295709] f(x) = 0.0014418013594871774 gradient norm = 0.0050768137123577365\n",
      "Iteration 523 : x = [1.97012406 1.29345985] f(x) = 0.0014392274984882003 gradient norm = 0.005062858885350305\n",
      "Iteration 524 : x = [1.97019437 1.29396123] f(x) = 0.0014366677651389845 gradient norm = 0.005048952833192392\n",
      "Iteration 525 : x = [1.97026444 1.29446124] f(x) = 0.0014341220713997042 gradient norm = 0.005035095326696233\n",
      "Iteration 526 : x = [1.97033427 1.29495988] f(x) = 0.0014315903298669364 gradient norm = 0.005021286138108988\n",
      "Iteration 527 : x = [1.97040384 1.29545717] f(x) = 0.0014290724537682703 gradient norm = 0.005007525041101206\n",
      "Iteration 528 : x = [1.97047318 1.2959531 ] f(x) = 0.0014265683569569842 gradient norm = 0.004993811810755503\n",
      "Iteration 529 : x = [1.97054228 1.29644767] f(x) = 0.0014240779539067526 gradient norm = 0.004980146223555239\n",
      "Iteration 530 : x = [1.97061113 1.29694091] f(x) = 0.0014216011597064212 gradient norm = 0.0049665280573733825\n",
      "Iteration 531 : x = [1.97067975 1.2974328 ] f(x) = 0.0014191378900548365 gradient norm = 0.004952957091461461\n",
      "Iteration 532 : x = [1.97074812 1.29792335] f(x) = 0.0014166880612557099 gradient norm = 0.004939433106438621\n",
      "Iteration 533 : x = [1.97081626 1.29841257] f(x) = 0.001414251590212545 gradient norm = 0.004925955884280787\n",
      "Iteration 534 : x = [1.97088417 1.29890046] f(x) = 0.0014118283944236144 gradient norm = 0.004912525208309941\n",
      "Iteration 535 : x = [1.97095184 1.29938703] f(x) = 0.0014094183919769788 gradient norm = 0.004899140863183508\n",
      "Iteration 536 : x = [1.97101927 1.29987228] f(x) = 0.0014070215015455606 gradient norm = 0.004885802634883823\n",
      "Iteration 537 : x = [1.97108647 1.30035622] f(x) = 0.0014046376423822613 gradient norm = 0.004872510310707718\n",
      "Iteration 538 : x = [1.97115344 1.30083885] f(x) = 0.0014022667343151329 gradient norm = 0.0048592636792562285\n",
      "Iteration 539 : x = [1.97122018 1.30132017] f(x) = 0.001399908697742585 gradient norm = 0.004846062530424338\n",
      "Iteration 540 : x = [1.97128669 1.30180019] f(x) = 0.0013975634536286517 gradient norm = 0.004832906655390898\n",
      "Iteration 541 : x = [1.97135298 1.30227891] f(x) = 0.0013952309234982975 gradient norm = 0.004819795846608592\n",
      "Iteration 542 : x = [1.97141903 1.30275634] f(x) = 0.0013929110294327635 gradient norm = 0.004806729897794012\n",
      "Iteration 543 : x = [1.97148486 1.30323249] f(x) = 0.001390603694064973 gradient norm = 0.004793708603917846\n",
      "Iteration 544 : x = [1.97155046 1.30370735] f(x) = 0.0013883088405749668 gradient norm = 0.004780731761195139\n",
      "Iteration 545 : x = [1.97161584 1.30418093] f(x) = 0.0013860263926853875 gradient norm = 0.004767799167075629\n",
      "Iteration 546 : x = [1.971681   1.30465324] f(x) = 0.0013837562746570138 gradient norm = 0.0047549106202342435\n",
      "Iteration 547 : x = [1.97174593 1.30512427] f(x) = 0.001381498411284328 gradient norm = 0.0047420659205616115\n",
      "Iteration 548 : x = [1.97181065 1.30559404] f(x) = 0.00137925272789113 gradient norm = 0.004729264869154708\n",
      "Iteration 549 : x = [1.97187514 1.30606255] f(x) = 0.0013770191503261952 gradient norm = 0.004716507268307568\n",
      "Iteration 550 : x = [1.97193941 1.3065298 ] f(x) = 0.0013747976049589719 gradient norm = 0.004703792921502115\n",
      "Iteration 551 : x = [1.97200347 1.3069958 ] f(x) = 0.001372588018675318 gradient norm = 0.004691121633399041\n",
      "Iteration 552 : x = [1.97206731 1.30746055] f(x) = 0.0013703903188732813 gradient norm = 0.004678493209828793\n",
      "Iteration 553 : x = [1.97213093 1.30792405] f(x) = 0.001368204433458922 gradient norm = 0.00466590745778265\n",
      "Iteration 554 : x = [1.97219434 1.30838631] f(x) = 0.001366030290842166 gradient norm = 0.00465336418540386\n",
      "Iteration 555 : x = [1.97225753 1.30884734] f(x) = 0.0013638678199327093 gradient norm = 0.004640863201978895\n",
      "Iteration 556 : x = [1.97232051 1.30930713] f(x) = 0.0013617169501359508 gradient norm = 0.004628404317928744\n",
      "Iteration 557 : x = [1.97238328 1.3097657 ] f(x) = 0.0013595776113489708 gradient norm = 0.004615987344800336\n",
      "Iteration 558 : x = [1.97244583 1.31022304] f(x) = 0.001357449733956544 gradient norm = 0.004603612095257998\n",
      "Iteration 559 : x = [1.97250818 1.31067916] f(x) = 0.001355333248827192 gradient norm = 0.004591278383075033\n",
      "Iteration 560 : x = [1.97257032 1.31113406] f(x) = 0.0013532280873092687 gradient norm = 0.004578986023125334\n",
      "Iteration 561 : x = [1.97263224 1.31158775] f(x) = 0.0013511341812270908 gradient norm = 0.004566734831375124\n",
      "Iteration 562 : x = [1.97269397 1.31204024] f(x) = 0.0013490514628770938 gradient norm = 0.0045545246248747135\n",
      "Iteration 563 : x = [1.97275548 1.31249151] f(x) = 0.0013469798650240362 gradient norm = 0.004542355221750405\n",
      "Iteration 564 : x = [1.97281679 1.31294159] f(x) = 0.0013449193208972244 gradient norm = 0.004530226441196392\n",
      "Iteration 565 : x = [1.97287789 1.31339048] f(x) = 0.0013428697641867915 gradient norm = 0.004518138103466828\n",
      "Iteration 566 : x = [1.97293879 1.31383817] f(x) = 0.0013408311290399925 gradient norm = 0.004506090029867857\n",
      "Iteration 567 : x = [1.97299949 1.31428467] f(x) = 0.0013388033500575482 gradient norm = 0.004494082042749833\n",
      "Iteration 568 : x = [1.97305999 1.31472999] f(x) = 0.0013367863622900107 gradient norm = 0.004482113965499495\n",
      "Iteration 569 : x = [1.97312028 1.31517412] f(x) = 0.0013347801012341728 gradient norm = 0.004470185622532314\n",
      "Iteration 570 : x = [1.97318038 1.31561709] f(x) = 0.0013327845028295125 gradient norm = 0.0044582968392848634\n",
      "Iteration 571 : x = [1.97324027 1.31605887] f(x) = 0.0013307995034546533 gradient norm = 0.004446447442207237\n",
      "Iteration 572 : x = [1.97329997 1.31649949] f(x) = 0.0013288250399238776 gradient norm = 0.0044346372587555916\n",
      "Iteration 573 : x = [1.97335947 1.31693895] f(x) = 0.0013268610494836636 gradient norm = 0.004422866117384706\n",
      "Iteration 574 : x = [1.97341877 1.31737724] f(x) = 0.0013249074698092498 gradient norm = 0.004411133847540647\n",
      "Iteration 575 : x = [1.97347787 1.31781438] f(x) = 0.0013229642390012372 gradient norm = 0.004399440279653456\n",
      "Iteration 576 : x = [1.97353679 1.31825036] f(x) = 0.0013210312955822259 gradient norm = 0.0043877852451299736\n",
      "Iteration 577 : x = [1.9735955  1.31868519] f(x) = 0.0013191085784934704 gradient norm = 0.004376168576346633\n",
      "Iteration 578 : x = [1.97365403 1.31911887] f(x) = 0.0013171960270915788 gradient norm = 0.0043645901066424065\n",
      "Iteration 579 : x = [1.97371236 1.31955142] f(x) = 0.0013152935811452339 gradient norm = 0.00435304967031176\n",
      "Iteration 580 : x = [1.9737705  1.31998282] f(x) = 0.0013134011808319487 gradient norm = 0.004341547102597704\n",
      "Iteration 581 : x = [1.97382845 1.32041309] f(x) = 0.0013115187667348495 gradient norm = 0.0043300822396848725\n",
      "Iteration 582 : x = [1.97388621 1.32084223] f(x) = 0.0013096462798394854 gradient norm = 0.004318654918692696\n",
      "Iteration 583 : x = [1.97394378 1.32127024] f(x) = 0.0013077836615306752 gradient norm = 0.00430726497766862\n",
      "Iteration 584 : x = [1.97400116 1.32169713] f(x) = 0.0013059308535893755 gradient norm = 0.004295912255581377\n",
      "Iteration 585 : x = [1.97405836 1.3221229 ] f(x) = 0.00130408779818958 gradient norm = 0.004284596592314348\n",
      "Iteration 586 : x = [1.97411537 1.32254755] f(x) = 0.001302254437895245 gradient norm = 0.004273317828658928\n",
      "Iteration 587 : x = [1.97417219 1.32297108] f(x) = 0.0013004307156572479 gradient norm = 0.004262075806308026\n",
      "Iteration 588 : x = [1.97422883 1.32339351] f(x) = 0.001298616574810368 gradient norm = 0.004250870367849547\n",
      "Iteration 589 : x = [1.97428528 1.32381483] f(x) = 0.0012968119590702919 gradient norm = 0.004239701356759968\n",
      "Iteration 590 : x = [1.97434155 1.32423505] f(x) = 0.0012950168125306608 gradient norm = 0.0042285686173979915\n",
      "Iteration 591 : x = [1.97439764 1.32465417] f(x) = 0.0012932310796601252 gradient norm = 0.004217471994998211\n",
      "Iteration 592 : x = [1.97445354 1.3250722 ] f(x) = 0.0012914547052994352 gradient norm = 0.004206411335664845\n",
      "Iteration 593 : x = [1.97450926 1.32548913] f(x) = 0.0012896876346585615 gradient norm = 0.004195386486365553\n",
      "Iteration 594 : x = [1.97456481 1.32590498] f(x) = 0.001287929813313834 gradient norm = 0.004184397294925271\n",
      "Iteration 595 : x = [1.97462017 1.32631974] f(x) = 0.0012861811872051107 gradient norm = 0.004173443610020126\n",
      "Iteration 596 : x = [1.97467536 1.32673342] f(x) = 0.001284441702632969 gradient norm = 0.004162525281171376\n",
      "Iteration 597 : x = [1.97473037 1.32714602] f(x) = 0.0012827113062559242 gradient norm = 0.004151642158739423\n",
      "Iteration 598 : x = [1.9747852  1.32755755] f(x) = 0.0012809899450876752 gradient norm = 0.0041407940939178975\n",
      "Iteration 599 : x = [1.97483985 1.32796801] f(x) = 0.0012792775664943684 gradient norm = 0.004129980938727741\n",
      "Iteration 600 : x = [1.97489433 1.32837739] f(x) = 0.0012775741181918915 gradient norm = 0.00411920254601138\n",
      "Iteration 601 : x = [1.97494863 1.32878572] f(x) = 0.0012758795482431845 gradient norm = 0.004108458769426936\n",
      "Iteration 602 : x = [1.97500276 1.32919298] f(x) = 0.0012741938050555904 gradient norm = 0.004097749463442506\n",
      "Iteration 603 : x = [1.97505671 1.32959919] f(x) = 0.001272516837378206 gradient norm = 0.004087074483330449\n",
      "Iteration 604 : x = [1.9751105  1.33000434] f(x) = 0.001270848594299277 gradient norm = 0.00407643368516177\n",
      "Iteration 605 : x = [1.97516411 1.33040845] f(x) = 0.0012691890252436015 gradient norm = 0.004065826925800512\n",
      "Iteration 606 : x = [1.97521754 1.3308115 ] f(x) = 0.0012675380799699694 gradient norm = 0.004055254062898238\n",
      "Iteration 607 : x = [1.97527081 1.33121351] f(x) = 0.0012658957085686113 gradient norm = 0.004044714954888504\n",
      "Iteration 608 : x = [1.97532391 1.33161449] f(x) = 0.0012642618614586815 gradient norm = 0.004034209460981441\n",
      "Iteration 609 : x = [1.97537684 1.33201442] f(x) = 0.0012626364893857523 gradient norm = 0.004023737441158338\n",
      "Iteration 610 : x = [1.9754296  1.33241332] f(x) = 0.0012610195434193403 gradient norm = 0.004013298756166288\n",
      "Iteration 611 : x = [1.97548219 1.33281119] f(x) = 0.0012594109749504475 gradient norm = 0.00400289326751288\n",
      "Iteration 612 : x = [1.97553462 1.33320803] f(x) = 0.001257810735689128 gradient norm = 0.003992520837460931\n",
      "Iteration 613 : x = [1.97558688 1.33360385] f(x) = 0.001256218777662071 gradient norm = 0.003982181329023265\n",
      "Iteration 614 : x = [1.97563897 1.33399864] f(x) = 0.001254635053210214 gradient norm = 0.0039718746059575595\n",
      "Iteration 615 : x = [1.9756909  1.33439242] f(x) = 0.001253059514986366 gradient norm = 0.003961600532761162\n",
      "Iteration 616 : x = [1.97574266 1.33478518] f(x) = 0.0012514921159528574 gradient norm = 0.003951358974666062\n",
      "Iteration 617 : x = [1.97579426 1.33517694] f(x) = 0.0012499328093792128 gradient norm = 0.003941149797633791\n",
      "Iteration 618 : x = [1.9758457  1.33556768] f(x) = 0.001248381548839834 gradient norm = 0.003930972868350448\n",
      "Iteration 619 : x = [1.97589697 1.33595742] f(x) = 0.0012468382882117178 gradient norm = 0.003920828054221732\n",
      "Iteration 620 : x = [1.97594809 1.33634616] f(x) = 0.0012453029816721804 gradient norm = 0.003910715223368026\n",
      "Iteration 621 : x = [1.97599904 1.3367339 ] f(x) = 0.0012437755836966068 gradient norm = 0.003900634244619493\n",
      "Iteration 622 : x = [1.97604983 1.33712064] f(x) = 0.0012422560490562232 gradient norm = 0.003890584987511269\n",
      "Iteration 623 : x = [1.97610046 1.33750639] f(x) = 0.0012407443328158786 gradient norm = 0.0038805673222786384\n",
      "Iteration 624 : x = [1.97615094 1.33789115] f(x) = 0.00123924039033186 gradient norm = 0.0038705811198522953\n",
      "Iteration 625 : x = [1.97620125 1.33827492] f(x) = 0.0012377441772497102 gradient norm = 0.0038606262518536116\n",
      "Iteration 626 : x = [1.97625141 1.33865771] f(x) = 0.0012362556495020788 gradient norm = 0.003850702590589951\n",
      "Iteration 627 : x = [1.97630141 1.33903952] f(x) = 0.0012347747633065823 gradient norm = 0.0038408100090500516\n",
      "Iteration 628 : x = [1.97635125 1.33942036] f(x) = 0.001233301475163686 gradient norm = 0.003830948380899393\n",
      "Iteration 629 : x = [1.97640094 1.33980021] f(x) = 0.001231835741854604 gradient norm = 0.003821117580475658\n",
      "Iteration 630 : x = [1.97645047 1.3401791 ] f(x) = 0.0012303775204392155 gradient norm = 0.0038113174827841805\n",
      "Iteration 631 : x = [1.97649985 1.34055702] f(x) = 0.0012289267682540047 gradient norm = 0.003801547963493474\n",
      "Iteration 632 : x = [1.97654907 1.34093398] f(x) = 0.0012274834429100074 gradient norm = 0.0037918088989307673\n",
      "Iteration 633 : x = [1.97659814 1.34130997] f(x) = 0.001226047502290785 gradient norm = 0.0037821001660775875\n",
      "Iteration 634 : x = [1.97664706 1.341685  ] f(x) = 0.0012246189045504142 gradient norm = 0.00377242164256539\n",
      "Iteration 635 : x = [1.97669583 1.34205908] f(x) = 0.0012231976081114866 gradient norm = 0.00376277320667119\n",
      "Iteration 636 : x = [1.97674444 1.3424322 ] f(x) = 0.0012217835716631363 gradient norm = 0.003753154737313287\n",
      "Iteration 637 : x = [1.9767929  1.34280438] f(x) = 0.0012203767541590768 gradient norm = 0.003743566114046965\n",
      "Iteration 638 : x = [1.97684122 1.3431756 ] f(x) = 0.0012189771148156513 gradient norm = 0.0037340072170602445\n",
      "Iteration 639 : x = [1.97688938 1.34354588] f(x) = 0.0012175846131099123 gradient norm = 0.003724477927169709\n",
      "Iteration 640 : x = [1.9769374  1.34391522] f(x) = 0.0012161992087777042 gradient norm = 0.003714978125816307\n",
      "Iteration 641 : x = [1.97698526 1.34428362] f(x) = 0.0012148208618117699 gradient norm = 0.003705507695061227\n",
      "Iteration 642 : x = [1.97703298 1.34465109] f(x) = 0.0012134495324598706 gradient norm = 0.003696066517581789\n",
      "Iteration 643 : x = [1.97708055 1.34501762] f(x) = 0.0012120851812229183 gradient norm = 0.003686654476667357\n",
      "Iteration 644 : x = [1.97712797 1.34538322] f(x) = 0.0012107277688531341 gradient norm = 0.0036772714562153417\n",
      "Iteration 645 : x = [1.97717525 1.3457479 ] f(x) = 0.00120937725635221 gradient norm = 0.003667917340727156\n",
      "Iteration 646 : x = [1.97722239 1.34611165] f(x) = 0.001208033604969495 gradient norm = 0.0036585920153042657\n",
      "Iteration 647 : x = [1.97726937 1.34647448] f(x) = 0.0012066967762001872 gradient norm = 0.0036492953656442214\n",
      "Iteration 648 : x = [1.97731622 1.34683639] f(x) = 0.0012053667317835548 gradient norm = 0.003640027278036775\n",
      "Iteration 649 : x = [1.97736292 1.34719739] f(x) = 0.0012040434337011567 gradient norm = 0.0036307876393599863\n",
      "Iteration 650 : x = [1.97740947 1.34755747] f(x) = 0.0012027268441750902 gradient norm = 0.0036215763370763846\n",
      "Iteration 651 : x = [1.97745589 1.34791664] f(x) = 0.001201416925666244 gradient norm = 0.0036123932592291384\n",
      "Iteration 652 : x = [1.97750216 1.3482749 ] f(x) = 0.0012001136408725745 gradient norm = 0.0036032382944382797\n",
      "Iteration 653 : x = [1.97754829 1.34863226] f(x) = 0.001198816952727388 gradient norm = 0.0035941113318969427\n",
      "Iteration 654 : x = [1.97759428 1.34898872] f(x) = 0.0011975268243976424 gradient norm = 0.003585012261367636\n",
      "Iteration 655 : x = [1.97764013 1.34934427] f(x) = 0.0011962432192822617 gradient norm = 0.0035759409731785353\n",
      "Iteration 656 : x = [1.97768584 1.34969893] f(x) = 0.0011949661010104658 gradient norm = 0.0035668973582198434\n",
      "Iteration 657 : x = [1.97773141 1.3500527 ] f(x) = 0.0011936954334401115 gradient norm = 0.003557881307940131\n",
      "Iteration 658 : x = [1.97777684 1.35040558] f(x) = 0.001192431180656047 gradient norm = 0.003548892714342711\n",
      "Iteration 659 : x = [1.97782213 1.35075756] f(x) = 0.0011911733069684843 gradient norm = 0.0035399314699820867\n",
      "Iteration 660 : x = [1.97786728 1.35110867] f(x) = 0.0011899217769113823 gradient norm = 0.0035309974679603963\n",
      "Iteration 661 : x = [1.9779123  1.35145888] f(x) = 0.0011886765552408386 gradient norm = 0.0035220906019238453\n",
      "Iteration 662 : x = [1.97795718 1.35180822] f(x) = 0.0011874376069335047 gradient norm = 0.003513210766059264\n",
      "Iteration 663 : x = [1.97800193 1.35215668] f(x) = 0.0011862048971850048 gradient norm = 0.0035043578550905926\n",
      "Iteration 664 : x = [1.97804654 1.35250427] f(x) = 0.0011849783914083744 gradient norm = 0.003495531764275471\n",
      "Iteration 665 : x = [1.97809101 1.35285098] f(x) = 0.001183758055232506 gradient norm = 0.0034867323894018\n",
      "Iteration 666 : x = [1.97813535 1.35319682] f(x) = 0.0011825438545006112 gradient norm = 0.0034779596267843537\n",
      "Iteration 667 : x = [1.97817956 1.3535418 ] f(x) = 0.0011813357552686932 gradient norm = 0.0034692133732614123\n",
      "Iteration 668 : x = [1.97822363 1.35388591] f(x) = 0.001180133723804038 gradient norm = 0.003460493526191451\n",
      "Iteration 669 : x = [1.97826757 1.35422916] f(x) = 0.0011789377265837037 gradient norm = 0.003451799983449781\n",
      "Iteration 670 : x = [1.97831138 1.35457154] f(x) = 0.001177747730293041 gradient norm = 0.0034431326434253146\n",
      "Iteration 671 : x = [1.97835506 1.35491308] f(x) = 0.0011765637018242088 gradient norm = 0.0034344914050172593\n",
      "Iteration 672 : x = [1.9783986  1.35525375] f(x) = 0.001175385608274714 gradient norm = 0.003425876167631918\n",
      "Iteration 673 : x = [1.97844201 1.35559358] f(x) = 0.0011742134169459544 gradient norm = 0.0034172868311794537\n",
      "Iteration 674 : x = [1.9784853  1.35593256] f(x) = 0.001173047095341781 gradient norm = 0.003408723296070717\n",
      "Iteration 675 : x = [1.97852845 1.35627069] f(x) = 0.0011718866111670645 gradient norm = 0.0034001854632140713\n",
      "Iteration 676 : x = [1.97857147 1.35660797] f(x) = 0.0011707319323262801 gradient norm = 0.00339167323401228\n",
      "Iteration 677 : x = [1.97861437 1.35694442] f(x) = 0.0011695830269220985 gradient norm = 0.00338318651035936\n",
      "Iteration 678 : x = [1.97865713 1.35728002] f(x) = 0.0011684398632539935 gradient norm = 0.0033747251946375247\n",
      "Iteration 679 : x = [1.97869977 1.35761479] f(x) = 0.0011673024098168548 gradient norm = 0.0033662891897140975\n",
      "Iteration 680 : x = [1.97874228 1.35794872] f(x) = 0.0011661706352996159 gradient norm = 0.003357878398938477\n",
      "Iteration 681 : x = [1.97878467 1.35828182] f(x) = 0.0011650445085838938 gradient norm = 0.003349492726139118\n",
      "Iteration 682 : x = [1.97882692 1.3586141 ] f(x) = 0.0011639239987426364 gradient norm = 0.003341132075620534\n",
      "Iteration 683 : x = [1.97886906 1.35894554] f(x) = 0.001162809075038783 gradient norm = 0.003332796352160324\n",
      "Iteration 684 : x = [1.97891106 1.35927617] f(x) = 0.0011616997069239339 gradient norm = 0.00332448546100622\n",
      "Iteration 685 : x = [1.97895294 1.35960597] f(x) = 0.0011605958640370346 gradient norm = 0.0033161993078731715\n",
      "Iteration 686 : x = [1.9789947  1.35993495] f(x) = 0.0011594975162030642 gradient norm = 0.0033079377989404224\n",
      "Iteration 687 : x = [1.97903633 1.36026311] f(x) = 0.001158404633431739 gradient norm = 0.00329970084084863\n",
      "Iteration 688 : x = [1.97907784 1.36059046] f(x) = 0.001157317185916226 gradient norm = 0.0032914883406970122\n",
      "Iteration 689 : x = [1.97911923 1.36091699] f(x) = 0.001156235144031865 gradient norm = 0.003283300206040497\n",
      "Iteration 690 : x = [1.97916049 1.36124272] f(x) = 0.0011551584783349026 gradient norm = 0.003275136344886916\n",
      "Iteration 691 : x = [1.97920163 1.36156764] f(x) = 0.0011540871595612325 gradient norm = 0.0032669966656941885\n",
      "Iteration 692 : x = [1.97924265 1.36189176] f(x) = 0.0011530211586251535 gradient norm = 0.0032588810773675576\n",
      "Iteration 693 : x = [1.97928355 1.36221507] f(x) = 0.001151960446618128 gradient norm = 0.003250789489256829\n",
      "Iteration 694 : x = [1.97932432 1.36253758] f(x) = 0.0011509049948075563 gradient norm = 0.0032427218111536326\n",
      "Iteration 695 : x = [1.97936498 1.36285929] f(x) = 0.0011498547746355628 gradient norm = 0.003234677953288725\n",
      "Iteration 696 : x = [1.97940552 1.36318021] f(x) = 0.0011488097577177813 gradient norm = 0.003226657826329266\n",
      "Iteration 697 : x = [1.97944593 1.36350033] f(x) = 0.0011477699158421626 gradient norm = 0.0032186613413761633\n",
      "Iteration 698 : x = [1.97948623 1.36381967] f(x) = 0.0011467352209677828 gradient norm = 0.0032106884099614135\n",
      "Iteration 699 : x = [1.97952641 1.36413821] f(x) = 0.0011457056452236656 gradient norm = 0.003202738944045469\n",
      "Iteration 700 : x = [1.97956647 1.36445597] f(x) = 0.0011446811609076113 gradient norm = 0.0031948128560146225\n",
      "Iteration 701 : x = [1.97960642 1.36477295] f(x) = 0.0011436617404850346 gradient norm = 0.003186910058678401\n",
      "Iteration 702 : x = [1.97964624 1.36508914] f(x) = 0.0011426473565878162 gradient norm = 0.003179030465267\n",
      "Iteration 703 : x = [1.97968595 1.36540455] f(x) = 0.0011416379820131557 gradient norm = 0.0031711739894287184\n",
      "Iteration 704 : x = [1.97972555 1.36571919] f(x) = 0.0011406335897224422 gradient norm = 0.00316334054522743\n",
      "Iteration 705 : x = [1.97976502 1.36603305] f(x) = 0.0011396341528401262 gradient norm = 0.003155530047140055\n",
      "Iteration 706 : x = [1.97980439 1.36634614] f(x) = 0.0011386396446526042 gradient norm = 0.0031477424100540526\n",
      "Iteration 707 : x = [1.97984363 1.36665845] f(x) = 0.001137650038607114 gradient norm = 0.003139977549264958\n",
      "Iteration 708 : x = [1.97988277 1.36697   ] f(x) = 0.0011366653083106314 gradient norm = 0.003132235380473897\n",
      "Iteration 709 : x = [1.97992178 1.36728079] f(x) = 0.0011356854275287839 gradient norm = 0.003124515819785149\n",
      "Iteration 710 : x = [1.97996069 1.36759081] f(x) = 0.0011347103701847664 gradient norm = 0.0031168187837037134\n",
      "Iteration 711 : x = [1.97999948 1.36790007] f(x) = 0.00113374011035827 gradient norm = 0.0031091441891329045\n",
      "Iteration 712 : x = [1.98003816 1.36820857] f(x) = 0.001132774622284416 gradient norm = 0.003101491953371954\n",
      "Iteration 713 : x = [1.98007672 1.36851631] f(x) = 0.001131813880352698 gradient norm = 0.0030938619941136263\n",
      "Iteration 714 : x = [1.98011517 1.3688233 ] f(x) = 0.0011308578591059377 gradient norm = 0.0030862542294418857\n",
      "Iteration 715 : x = [1.98015351 1.36912953] f(x) = 0.0011299065332392396 gradient norm = 0.0030786685778295326\n",
      "Iteration 716 : x = [1.98019174 1.36943501] f(x) = 0.0011289598775989622 gradient norm = 0.0030711049581358773\n",
      "Iteration 717 : x = [1.98022986 1.36973975] f(x) = 0.0011280178671816917 gradient norm = 0.0030635632896044464\n",
      "Iteration 718 : x = [1.98026787 1.37004374] f(x) = 0.0011270804771332259 gradient norm = 0.003056043491860676\n",
      "Iteration 719 : x = [1.98030577 1.37034698] f(x) = 0.001126147682747567 gradient norm = 0.003048545484909663\n",
      "Iteration 720 : x = [1.98034356 1.37064949] f(x) = 0.0011252194594659187 gradient norm = 0.003041069189133865\n",
      "Iteration 721 : x = [1.98038124 1.37095125] f(x) = 0.0011242957828756972 gradient norm = 0.0030336145252909154\n",
      "Iteration 722 : x = [1.98041881 1.37125228] f(x) = 0.0011233766287095407 gradient norm = 0.003026181414511345\n",
      "Iteration 723 : x = [1.98045627 1.37155257] f(x) = 0.0011224619728443332 gradient norm = 0.0030187697782963993\n",
      "Iteration 724 : x = [1.98049362 1.37185213] f(x) = 0.0011215517913002373 gradient norm = 0.0030113795385158433\n",
      "Iteration 725 : x = [1.98053087 1.37215095] f(x) = 0.0011206460602397276 gradient norm = 0.0030040106174057855\n",
      "Iteration 726 : x = [1.98056801 1.37244905] f(x) = 0.0011197447559666343 gradient norm = 0.0029966629375664956\n",
      "Iteration 727 : x = [1.98060504 1.37274642] f(x) = 0.0011188478549252004 gradient norm = 0.002989336421960282\n",
      "Iteration 728 : x = [1.98064196 1.37304306] f(x) = 0.0011179553336991353 gradient norm = 0.0029820309939093573\n",
      "Iteration 729 : x = [1.98067878 1.37333898] f(x) = 0.0011170671690106833 gradient norm = 0.0029747465770937065\n",
      "Iteration 730 : x = [1.9807155  1.37363418] f(x) = 0.0011161833377196979 gradient norm = 0.0029674830955490113\n",
      "Iteration 731 : x = [1.9807521  1.37392866] f(x) = 0.0011153038168227184 gradient norm = 0.0029602404736645276\n",
      "Iteration 732 : x = [1.98078861 1.37422243] f(x) = 0.001114428583452063 gradient norm = 0.0029530186361810522\n",
      "Iteration 733 : x = [1.980825   1.37451548] f(x) = 0.0011135576148749162 gradient norm = 0.002945817508188843\n",
      "Iteration 734 : x = [1.9808613  1.37480782] f(x) = 0.0011126908884924367 gradient norm = 0.0029386370151255913\n",
      "Iteration 735 : x = [1.98089749 1.37509944] f(x) = 0.0011118283818388618 gradient norm = 0.002931477082774379\n",
      "Iteration 736 : x = [1.98093357 1.37539036] f(x) = 0.0011109700725806216 gradient norm = 0.00292433763726168\n",
      "Iteration 737 : x = [1.98096956 1.37568057] f(x) = 0.001110115938515463 gradient norm = 0.002917218605055352\n",
      "Iteration 738 : x = [1.98100544 1.37597008] f(x) = 0.0011092659575715755 gradient norm = 0.002910119912962661\n",
      "Iteration 739 : x = [1.98104122 1.37625888] f(x) = 0.0011084201078067275 gradient norm = 0.0029030414881282985\n",
      "Iteration 740 : x = [1.98107689 1.37654699] f(x) = 0.0011075783674074063 gradient norm = 0.0028959832580324374\n",
      "Iteration 741 : x = [1.98111247 1.37683439] f(x) = 0.0011067407146879656 gradient norm = 0.0028889451504887785\n",
      "Iteration 742 : x = [1.98114794 1.3771211 ] f(x) = 0.0011059071280897837 gradient norm = 0.0028819270936426347\n",
      "Iteration 743 : x = [1.98118331 1.37740712] f(x) = 0.0011050775861804162 gradient norm = 0.0028749290159689935\n",
      "Iteration 744 : x = [1.98121858 1.37769244] f(x) = 0.0011042520676527703 gradient norm = 0.0028679508462706393\n",
      "Iteration 745 : x = [1.98125375 1.37797707] f(x) = 0.0011034305513242736 gradient norm = 0.0028609925136762497\n",
      "Iteration 746 : x = [1.98128882 1.37826101] f(x) = 0.0011026130161360546 gradient norm = 0.0028540539476385168\n",
      "Iteration 747 : x = [1.98132379 1.37854426] f(x) = 0.0011017994411521275 gradient norm = 0.0028471350779322915\n",
      "Iteration 748 : x = [1.98135867 1.37882683] f(x) = 0.0011009898055585857 gradient norm = 0.002840235834652749\n",
      "Iteration 749 : x = [1.98139344 1.37910872] f(x) = 0.0011001840886627967 gradient norm = 0.0028333561482135165\n",
      "Iteration 750 : x = [1.98142812 1.37938993] f(x) = 0.0010993822698926058 gradient norm = 0.002826495949344872\n",
      "Iteration 751 : x = [1.98146269 1.37967045] f(x) = 0.0010985843287955497 gradient norm = 0.002819655169091946\n",
      "Iteration 752 : x = [1.98149717 1.3799503 ] f(x) = 0.0010977902450380647 gradient norm = 0.002812833738812881\n",
      "Iteration 753 : x = [1.98153155 1.38022948] f(x) = 0.0010969999984047141 gradient norm = 0.002806031590177087\n",
      "Iteration 754 : x = [1.98156584 1.38050798] f(x) = 0.0010962135687974136 gradient norm = 0.00279924865516345\n",
      "Iteration 755 : x = [1.98160003 1.38078581] f(x) = 0.0010954309362346602 gradient norm = 0.0027924848660585595\n",
      "Iteration 756 : x = [1.98163412 1.38106297] f(x) = 0.0010946520808507777 gradient norm = 0.0027857401554549884\n",
      "Iteration 757 : x = [1.98166811 1.38133946] f(x) = 0.001093876982895155 gradient norm = 0.002779014456249522\n",
      "Iteration 758 : x = [1.98170201 1.38161528] f(x) = 0.001093105622731497 gradient norm = 0.002772307701641458\n",
      "Iteration 759 : x = [1.98173582 1.38189045] f(x) = 0.0010923379808370824 gradient norm = 0.0027656198251308837\n",
      "Iteration 760 : x = [1.98176953 1.38216495] f(x) = 0.0010915740378020203 gradient norm = 0.0027589507605169632\n",
      "Iteration 761 : x = [1.98180314 1.38243879] f(x) = 0.0010908137743285207 gradient norm = 0.002752300441896268\n",
      "Iteration 762 : x = [1.98183666 1.38271197] f(x) = 0.0010900571712301628 gradient norm = 0.0027456688036610827\n",
      "Iteration 763 : x = [1.98187009 1.38298449] f(x) = 0.0010893042094311733 gradient norm = 0.002739055780497746\n",
      "Iteration 764 : x = [1.98190342 1.38325636] f(x) = 0.0010885548699657102 gradient norm = 0.0027324613073849975\n",
      "Iteration 765 : x = [1.98193666 1.38352758] f(x) = 0.0010878091339771461 gradient norm = 0.002725885319592311\n",
      "Iteration 766 : x = [1.9819698  1.38379814] f(x) = 0.0010870669827173656 gradient norm = 0.002719327752678293\n",
      "Iteration 767 : x = [1.98200286 1.38406806] f(x) = 0.0010863283975460613 gradient norm = 0.0027127885424890427\n",
      "Iteration 768 : x = [1.98203582 1.38433733] f(x) = 0.001085593359930037 gradient norm = 0.002706267625156544\n",
      "Iteration 769 : x = [1.98206869 1.38460595] f(x) = 0.0010848618514425158 gradient norm = 0.0026997649370970643\n",
      "Iteration 770 : x = [1.98210146 1.38487393] f(x) = 0.0010841338537624545 gradient norm = 0.00269328041500957\n",
      "Iteration 771 : x = [1.98213415 1.38514127] f(x) = 0.0010834093486738598 gradient norm = 0.0026868139958741376\n",
      "Iteration 772 : x = [1.98216674 1.38540797] f(x) = 0.0010826883180651136 gradient norm = 0.002680365616950396\n",
      "Iteration 773 : x = [1.98219925 1.38567403] f(x) = 0.0010819707439283024 gradient norm = 0.0026739352157759758\n",
      "Iteration 774 : x = [1.98223166 1.38593945] f(x) = 0.001081256608358546 gradient norm = 0.0026675227301649384\n",
      "Iteration 775 : x = [1.98226398 1.38620423] f(x) = 0.0010805458935533403 gradient norm = 0.0026611280982062648\n",
      "Iteration 776 : x = [1.98229621 1.38646839] f(x) = 0.0010798385818118971 gradient norm = 0.00265475125826231\n",
      "Iteration 777 : x = [1.98232836 1.38673191] f(x) = 0.0010791346555344933 gradient norm = 0.002648392148967307\n",
      "Iteration 778 : x = [1.98236041 1.3869948 ] f(x) = 0.001078434097221822 gradient norm = 0.002642050709225845\n",
      "Iteration 779 : x = [1.98239237 1.38725707] f(x) = 0.0010777368894743517 gradient norm = 0.002635726878211386\n",
      "Iteration 780 : x = [1.98242425 1.3875187 ] f(x) = 0.0010770430149916843 gradient norm = 0.002629420595364761\n",
      "Iteration 781 : x = [1.98245604 1.38777972] f(x) = 0.0010763524565719264 gradient norm = 0.002623131800392727\n",
      "Iteration 782 : x = [1.98248774 1.38804011] f(x) = 0.0010756651971110553 gradient norm = 0.002616860433266457\n",
      "Iteration 783 : x = [1.98251935 1.38829988] f(x) = 0.0010749812196022984 gradient norm = 0.002610606434220131\n",
      "Iteration 784 : x = [1.98255087 1.38855903] f(x) = 0.00107430050713551 gradient norm = 0.0026043697437494575\n",
      "Iteration 785 : x = [1.98258231 1.38881756] f(x) = 0.0010736230428965592 gradient norm = 0.0025981503026102568\n",
      "Iteration 786 : x = [1.98261366 1.38907548] f(x) = 0.0010729488101667152 gradient norm = 0.002591948051817012\n",
      "Iteration 787 : x = [1.98264492 1.38933278] f(x) = 0.0010722777923220434 gradient norm = 0.002585762932641479\n",
      "Iteration 788 : x = [1.9826761  1.38958947] f(x) = 0.0010716099728328007 gradient norm = 0.002579594886611253\n",
      "Iteration 789 : x = [1.98270719 1.38984555] f(x) = 0.0010709453352628407 gradient norm = 0.00257344385550839\n",
      "Iteration 790 : x = [1.9827382  1.39010102] f(x) = 0.0010702838632690157 gradient norm = 0.0025673097813680053\n",
      "Iteration 791 : x = [1.98276912 1.39035588] f(x) = 0.001069625540600591 gradient norm = 0.0025611926064768916\n",
      "Iteration 792 : x = [1.98279995 1.39061014] f(x) = 0.0010689703510986589 gradient norm = 0.0025550922733721705\n",
      "Iteration 793 : x = [1.9828307  1.39086379] f(x) = 0.001068318278695554 gradient norm = 0.002549008724839894\n",
      "Iteration 794 : x = [1.98286137 1.39111684] f(x) = 0.0010676693074142829 gradient norm = 0.0025429419039137238\n",
      "Iteration 795 : x = [1.98289195 1.39136929] f(x) = 0.0010670234213679452 gradient norm = 0.0025368917538735715\n",
      "Iteration 796 : x = [1.98292245 1.39162114] f(x) = 0.0010663806047591681 gradient norm = 0.002530858218244264\n",
      "Iteration 797 : x = [1.98295286 1.39187239] f(x) = 0.0010657408418795421 gradient norm = 0.0025248412407942234\n",
      "Iteration 798 : x = [1.98298319 1.39212304] f(x) = 0.0010651041171090584 gradient norm = 0.0025188407655341465\n",
      "Iteration 799 : x = [1.98301344 1.39237311] f(x) = 0.0010644704149155532 gradient norm = 0.0025128567367156897\n",
      "Iteration 800 : x = [1.98304361 1.39262257] f(x) = 0.0010638397198541566 gradient norm = 0.002506889098830179\n",
      "Iteration 801 : x = [1.98307369 1.39287145] f(x) = 0.0010632120165667404 gradient norm = 0.0025009377966073135\n",
      "Iteration 802 : x = [1.98310369 1.39311974] f(x) = 0.001062587289781376 gradient norm = 0.0024950027750138696\n",
      "Iteration 803 : x = [1.98313361 1.39336744] f(x) = 0.001061965524311794 gradient norm = 0.0024890839792524556\n",
      "Iteration 804 : x = [1.98316344 1.39361455] f(x) = 0.0010613467050568442 gradient norm = 0.002483181354760208\n",
      "Iteration 805 : x = [1.9831932  1.39386108] f(x) = 0.0010607308169999642 gradient norm = 0.0024772948472075633\n",
      "Iteration 806 : x = [1.98322287 1.39410703] f(x) = 0.0010601178452086502 gradient norm = 0.0024714244024969926\n",
      "Iteration 807 : x = [1.98325246 1.39435239] f(x) = 0.0010595077748339304 gradient norm = 0.0024655699667617626\n",
      "Iteration 808 : x = [1.98328197 1.39459718] f(x) = 0.0010589005911098423 gradient norm = 0.0024597314863647013\n",
      "Iteration 809 : x = [1.98331141 1.39484138] f(x) = 0.0010582962793529147 gradient norm = 0.002453908907896965\n",
      "Iteration 810 : x = [1.98334076 1.39508501] f(x) = 0.0010576948249616553 gradient norm = 0.0024481021781768376\n",
      "Iteration 811 : x = [1.98337003 1.39532807] f(x) = 0.0010570962134160348 gradient norm = 0.0024423112442484964\n",
      "Iteration 812 : x = [1.98339922 1.39557055] f(x) = 0.0010565004302769832 gradient norm = 0.0024365360533808323\n",
      "Iteration 813 : x = [1.98342833 1.39581245] f(x) = 0.0010559074611858866 gradient norm = 0.002430776553066244\n",
      "Iteration 814 : x = [1.98345737 1.39605379] f(x) = 0.0010553172918640811 gradient norm = 0.002425032691019445\n",
      "Iteration 815 : x = [1.98348632 1.39629456] f(x) = 0.0010547299081123621 gradient norm = 0.002419304415176297\n",
      "Iteration 816 : x = [1.9835152  1.39653476] f(x) = 0.0010541452958104868 gradient norm = 0.002413591673692621\n",
      "Iteration 817 : x = [1.983544  1.3967744] f(x) = 0.0010535634409166877 gradient norm = 0.0024078944149430546\n",
      "Iteration 818 : x = [1.98357272 1.39701347] f(x) = 0.001052984329467182 gradient norm = 0.002402212587519879\n",
      "Iteration 819 : x = [1.98360136 1.39725197] f(x) = 0.001052407947575692 gradient norm = 0.0023965461402318785\n",
      "Iteration 820 : x = [1.98362993 1.39748992] f(x) = 0.0010518342814329628 gradient norm = 0.002390895022103186\n",
      "Iteration 821 : x = [1.98365841 1.39772731] f(x) = 0.0010512633173062871 gradient norm = 0.002385259182372158\n",
      "Iteration 822 : x = [1.98368682 1.39796413] f(x) = 0.0010506950415390326 gradient norm = 0.002379638570490252\n",
      "Iteration 823 : x = [1.98371516 1.39820041] f(x) = 0.0010501294405501698 gradient norm = 0.002374033136120889\n",
      "Iteration 824 : x = [1.98374342 1.39843612] f(x) = 0.0010495665008338078 gradient norm = 0.0023684428291383566\n",
      "Iteration 825 : x = [1.9837716  1.39867128] f(x) = 0.0010490062089587309 gradient norm = 0.00236286759962669\n",
      "Iteration 826 : x = [1.9837997  1.39890589] f(x) = 0.0010484485515679363 gradient norm = 0.002357307397878585\n",
      "Iteration 827 : x = [1.98382773 1.39913995] f(x) = 0.001047893515378181 gradient norm = 0.0023517621743943035\n",
      "Iteration 828 : x = [1.98385569 1.39937346] f(x) = 0.001047341087179523 gradient norm = 0.002346231879880573\n",
      "Iteration 829 : x = [1.98388357 1.39960642] f(x) = 0.001046791253834875 gradient norm = 0.002340716465249524\n",
      "Iteration 830 : x = [1.98391137 1.39983883] f(x) = 0.0010462440022795554 gradient norm = 0.002335215881617621\n",
      "Iteration 831 : x = [1.9839391 1.4000707] f(x) = 0.0010456993195208427 gradient norm = 0.0023297300803045732\n",
      "Iteration 832 : x = [1.98396676 1.40030203] f(x) = 0.0010451571926375367 gradient norm = 0.002324259012832314\n",
      "Iteration 833 : x = [1.98399434 1.40053281] f(x) = 0.0010446176087795188 gradient norm = 0.0023188026309239225\n",
      "Iteration 834 : x = [1.98402185 1.40076306] f(x) = 0.0010440805551673149 gradient norm = 0.0023133608865025714\n",
      "Iteration 835 : x = [1.98404928 1.40099276] f(x) = 0.0010435460190916675 gradient norm = 0.00230793373169052\n",
      "Iteration 836 : x = [1.98407664 1.40122193] f(x) = 0.001043013987913103 gradient norm = 0.0023025211188080603\n",
      "Iteration 837 : x = [1.98410393 1.40145056] f(x) = 0.0010424844490615048 gradient norm = 0.0022971230003724897\n",
      "Iteration 838 : x = [1.98413114 1.40167865] f(x) = 0.0010419573900356954 gradient norm = 0.0022917393290971125\n",
      "Iteration 839 : x = [1.98415828 1.40190621] f(x) = 0.001041432798403007 gradient norm = 0.0022863700578902\n",
      "Iteration 840 : x = [1.98418535 1.40213324] f(x) = 0.0010409106617988724 gradient norm = 0.0022810151398540016\n",
      "Iteration 841 : x = [1.98421234 1.40235974] f(x) = 0.0010403909679264057 gradient norm = 0.0022756745282837463\n",
      "Iteration 842 : x = [1.98423927 1.40258571] f(x) = 0.0010398737045559908 gradient norm = 0.0022703481766666446\n",
      "Iteration 843 : x = [1.98426612 1.40281115] f(x) = 0.001039358859524874 gradient norm = 0.0022650360386808972\n",
      "Iteration 844 : x = [1.9842929  1.40303606] f(x) = 0.0010388464207367557 gradient norm = 0.0022597380681947162\n",
      "Iteration 845 : x = [1.98431961 1.40326045] f(x) = 0.0010383363761613871 gradient norm = 0.0022544542192653476\n",
      "Iteration 846 : x = [1.98434625 1.40348432] f(x) = 0.001037828713834173 gradient norm = 0.002249184446138119\n",
      "Iteration 847 : x = [1.98437282 1.40370766] f(x) = 0.0010373234218557666 gradient norm = 0.0022439287032454507\n",
      "Iteration 848 : x = [1.98439931 1.40393049] f(x) = 0.0010368204883916827 gradient norm = 0.0022386869452059146\n",
      "Iteration 849 : x = [1.98442574 1.40415279] f(x) = 0.0010363199016718988 gradient norm = 0.002233459126823289\n",
      "Iteration 850 : x = [1.98445209 1.40437458] f(x) = 0.001035821649990466 gradient norm = 0.0022282452030855876\n",
      "Iteration 851 : x = [1.98447838 1.40459584] f(x) = 0.0010353257217051261 gradient norm = 0.0022230451291641454\n",
      "Iteration 852 : x = [1.9845046 1.4048166] f(x) = 0.0010348321052369204 gradient norm = 0.0022178588604126756\n",
      "Iteration 853 : x = [1.98453074 1.40503684] f(x) = 0.001034340789069813 gradient norm = 0.0022126863523663407\n",
      "Iteration 854 : x = [1.98455682 1.40525656] f(x) = 0.0010338517617503077 gradient norm = 0.0022075275607408274\n",
      "Iteration 855 : x = [1.98458283 1.40547578] f(x) = 0.0010333650118870732 gradient norm = 0.002202382441431444\n",
      "Iteration 856 : x = [1.98460877 1.40569448] f(x) = 0.0010328805281505685 gradient norm = 0.0021972509505121867\n",
      "Iteration 857 : x = [1.98463464 1.40591268] f(x) = 0.0010323982992726714 gradient norm = 0.002192133044234861\n",
      "Iteration 858 : x = [1.98466044 1.40613037] f(x) = 0.0010319183140463063 gradient norm = 0.002187028679028164\n",
      "Iteration 859 : x = [1.98468618 1.40634755] f(x) = 0.0010314405613250806 gradient norm = 0.002181937811496788\n",
      "Iteration 860 : x = [1.98471184 1.40656423] f(x) = 0.0010309650300229195 gradient norm = 0.0021768603984205436\n",
      "Iteration 861 : x = [1.98473744 1.40678041] f(x) = 0.0010304917091137039 gradient norm = 0.0021717963967534714\n",
      "Iteration 862 : x = [1.98476297 1.40699608] f(x) = 0.0010300205876309094 gradient norm = 0.002166745763622959\n",
      "Iteration 863 : x = [1.98478843 1.40721126] f(x) = 0.0010295516546672536 gradient norm = 0.002161708456328884\n",
      "Iteration 864 : x = [1.98481383 1.40742593] f(x) = 0.0010290848993743352 gradient norm = 0.0021566844323427235\n",
      "Iteration 865 : x = [1.98483916 1.40764011] f(x) = 0.0010286203109622877 gradient norm = 0.0021516736493067093\n",
      "Iteration 866 : x = [1.98486442 1.40785378] f(x) = 0.001028157878699425 gradient norm = 0.002146676065032967\n",
      "Iteration 867 : x = [1.98488962 1.40806697] f(x) = 0.0010276975919118962 gradient norm = 0.002141691637502663\n",
      "Iteration 868 : x = [1.98491475 1.40827966] f(x) = 0.0010272394399833407 gradient norm = 0.002136720324865161\n",
      "Iteration 869 : x = [1.98493981 1.40849185] f(x) = 0.0010267834123545438 gradient norm = 0.002131762085437184\n",
      "Iteration 870 : x = [1.98496481 1.40870356] f(x) = 0.0010263294985230957 gradient norm = 0.0021268168777019546\n",
      "Iteration 871 : x = [1.98498974 1.40891478] f(x) = 0.0010258776880430556 gradient norm = 0.0021218846603084027\n",
      "Iteration 872 : x = [1.98501461 1.4091255 ] f(x) = 0.0010254279705246133 gradient norm = 0.002116965392070307\n",
      "Iteration 873 : x = [1.98503941 1.40933574] f(x) = 0.0010249803356337558 gradient norm = 0.002112059031965486\n",
      "Iteration 874 : x = [1.98506415 1.40954549] f(x) = 0.001024534773091937 gradient norm = 0.002107165539134994\n",
      "Iteration 875 : x = [1.98508882 1.40975476] f(x) = 0.0010240912726757455 gradient norm = 0.0021022848728822784\n",
      "Iteration 876 : x = [1.98511343 1.40996354] f(x) = 0.0010236498242165817 gradient norm = 0.0020974169926724112\n",
      "Iteration 877 : x = [1.98513797 1.41017184] f(x) = 0.0010232104176003264 gradient norm = 0.0020925618581312537\n",
      "Iteration 878 : x = [1.98516245 1.41037966] f(x) = 0.001022773042767024 gradient norm = 0.002087719429044682\n",
      "Iteration 879 : x = [1.98518686 1.410587  ] f(x) = 0.0010223376897105607 gradient norm = 0.002082889665357798\n",
      "Iteration 880 : x = [1.98521121 1.41079386] f(x) = 0.0010219043484783411 gradient norm = 0.002078072527174117\n",
      "Iteration 881 : x = [1.9852355  1.41100025] f(x) = 0.0010214730091709777 gradient norm = 0.0020732679747548026\n",
      "Iteration 882 : x = [1.98525973 1.41120615] f(x) = 0.0010210436619419714 gradient norm = 0.002068475968517896\n",
      "Iteration 883 : x = [1.98528389 1.41141159] f(x) = 0.0010206162969974037 gradient norm = 0.0020636964690375265\n",
      "Iteration 884 : x = [1.98530798 1.41161654] f(x) = 0.0010201909045956233 gradient norm = 0.002058929437043154\n",
      "Iteration 885 : x = [1.98533202 1.41182103] f(x) = 0.0010197674750469384 gradient norm = 0.002054174833418801\n",
      "Iteration 886 : x = [1.98535599 1.41202504] f(x) = 0.0010193459987133118 gradient norm = 0.002049432619202293\n",
      "Iteration 887 : x = [1.9853799  1.41222859] f(x) = 0.0010189264660080551 gradient norm = 0.0020447027555844984\n",
      "Iteration 888 : x = [1.98540375 1.41243166] f(x) = 0.0010185088673955265 gradient norm = 0.0020399852039085925\n",
      "Iteration 889 : x = [1.98542753 1.41263427] f(x) = 0.0010180931933908336 gradient norm = 0.002035279925669308\n",
      "Iteration 890 : x = [1.98545126 1.41283641] f(x) = 0.0010176794345595304 gradient norm = 0.002030586882512175\n",
      "Iteration 891 : x = [1.98547492 1.41303808] f(x) = 0.0010172675815173237 gradient norm = 0.002025906036232806\n",
      "Iteration 892 : x = [1.98549852 1.4132393 ] f(x) = 0.0010168576249297808 gradient norm = 0.0020212373487761494\n",
      "Iteration 893 : x = [1.98552206 1.41344004] f(x) = 0.001016449555512032 gradient norm = 0.0020165807822357705\n",
      "Iteration 894 : x = [1.98554554 1.41364033] f(x) = 0.001016043364028485 gradient norm = 0.0020119362988531265\n",
      "Iteration 895 : x = [1.98556896 1.41384016] f(x) = 0.0010156390412925324 gradient norm = 0.0020073038610168336\n",
      "Iteration 896 : x = [1.98559231 1.41403952] f(x) = 0.0010152365781662686 gradient norm = 0.0020026834312619687\n",
      "Iteration 897 : x = [1.98561561 1.41423843] f(x) = 0.001014835965560202 gradient norm = 0.001998074972269346\n",
      "Iteration 898 : x = [1.98563885 1.41443688] f(x) = 0.0010144371944329751 gradient norm = 0.0019934784468648233\n",
      "Iteration 899 : x = [1.98566202 1.41463488] f(x) = 0.0010140402557910792 gradient norm = 0.0019888938180185767\n",
      "Iteration 900 : x = [1.98568514 1.41483242] f(x) = 0.0010136451406885791 gradient norm = 0.001984321048844422\n",
      "Iteration 901 : x = [1.98570819 1.41502951] f(x) = 0.0010132518402268334 gradient norm = 0.00197976010259911\n",
      "Iteration 902 : x = [1.98573119 1.41522615] f(x) = 0.0010128603455542198 gradient norm = 0.001975210942681642\n",
      "Iteration 903 : x = [1.98575413 1.41542233] f(x) = 0.0010124706478658607 gradient norm = 0.0019706735326325848\n",
      "Iteration 904 : x = [1.98577701 1.41561806] f(x) = 0.0010120827384033522 gradient norm = 0.0019661478361333623\n",
      "Iteration 905 : x = [1.98579983 1.41581335] f(x) = 0.0010116966084544917 gradient norm = 0.00196163381700562\n",
      "Iteration 906 : x = [1.98582259 1.41600819] f(x) = 0.001011312249353011 gradient norm = 0.0019571314392105147\n",
      "Iteration 907 : x = [1.98584529 1.41620258] f(x) = 0.0010109296524783104 gradient norm = 0.00195264066684806\n",
      "Iteration 908 : x = [1.98586793 1.41639653] f(x) = 0.0010105488092551904 gradient norm = 0.001948161464156453\n",
      "Iteration 909 : x = [1.98589052 1.41659003] f(x) = 0.0010101697111535907 gradient norm = 0.0019436937955114176\n",
      "Iteration 910 : x = [1.98591304 1.41678309] f(x) = 0.0010097923496883289 gradient norm = 0.0019392376254255368\n",
      "Iteration 911 : x = [1.98593551 1.41697571] f(x) = 0.0010094167164188396 gradient norm = 0.0019347929185476083\n",
      "Iteration 912 : x = [1.98595792 1.41716788] f(x) = 0.0010090428029489156 gradient norm = 0.001930359639661978\n",
      "Iteration 913 : x = [1.98598028 1.41735962] f(x) = 0.0010086706009264518 gradient norm = 0.001925937753687909\n",
      "Iteration 914 : x = [1.98600257 1.41755092] f(x) = 0.0010083001020431911 gradient norm = 0.0019215272256789299\n",
      "Iteration 915 : x = [1.98602481 1.41774178] f(x) = 0.0010079312980344698 gradient norm = 0.0019171280208221844\n",
      "Iteration 916 : x = [1.98604699 1.41793221] f(x) = 0.001007564180678966 gradient norm = 0.00191274010443781\n",
      "Iteration 917 : x = [1.98606912 1.4181222 ] f(x) = 0.001007198741798451 gradient norm = 0.0019083634419783024\n",
      "Iteration 918 : x = [1.98609119 1.41831175] f(x) = 0.0010068349732575387 gradient norm = 0.001903997999027873\n",
      "Iteration 919 : x = [1.9861132  1.41850088] f(x) = 0.0010064728669634407 gradient norm = 0.0018996437413018508\n",
      "Iteration 920 : x = [1.98613516 1.41868957] f(x) = 0.001006112414865719 gradient norm = 0.0018953006346460206\n",
      "Iteration 921 : x = [1.98615706 1.41887783] f(x) = 0.0010057536089560445 gradient norm = 0.0018909686450360446\n",
      "Iteration 922 : x = [1.9861789  1.41906566] f(x) = 0.0010053964412679527 gradient norm = 0.0018866477385768154\n",
      "Iteration 923 : x = [1.98620069 1.41925306] f(x) = 0.0010050409038766053 gradient norm = 0.0018823378815018622\n",
      "Iteration 924 : x = [1.98622242 1.41944004] f(x) = 0.0010046869888985484 gradient norm = 0.0018780390401727492\n",
      "Iteration 925 : x = [1.98624409 1.41962659] f(x) = 0.0010043346884914784 gradient norm = 0.001873751181078446\n",
      "Iteration 926 : x = [1.98626572 1.41981271] f(x) = 0.0010039839948540027 gradient norm = 0.001869474270834751\n",
      "Iteration 927 : x = [1.98628728 1.41999841] f(x) = 0.0010036349002254068 gradient norm = 0.0018652082761836779\n",
      "Iteration 928 : x = [1.98630879 1.42018369] f(x) = 0.0010032873968854217 gradient norm = 0.0018609531639928762\n",
      "Iteration 929 : x = [1.98633025 1.42036854] f(x) = 0.0010029414771539915 gradient norm = 0.001856708901255019\n",
      "Iteration 930 : x = [1.98635165 1.42055297] f(x) = 0.001002597133391044 gradient norm = 0.0018524754550872408\n",
      "Iteration 931 : x = [1.986373   1.42073699] f(x) = 0.0010022543579962598 gradient norm = 0.0018482527927305295\n",
      "Iteration 932 : x = [1.98639429 1.42092058] f(x) = 0.0010019131434088496 gradient norm = 0.0018440408815491676\n",
      "Iteration 933 : x = [1.98641553 1.42110376] f(x) = 0.0010015734821073254 gradient norm = 0.0018398396890301392\n",
      "Iteration 934 : x = [1.98643671 1.42128652] f(x) = 0.0010012353666092755 gradient norm = 0.0018356491827825625\n",
      "Iteration 935 : x = [1.98645784 1.42146886] f(x) = 0.0010008987894711452 gradient norm = 0.0018314693305371164\n",
      "Iteration 936 : x = [1.98647892 1.42165079] f(x) = 0.0010005637432880113 gradient norm = 0.0018273001001454698\n",
      "Iteration 937 : x = [1.98649994 1.42183231] f(x) = 0.0010002302206933644 gradient norm = 0.0018231414595797225\n",
      "Iteration 938 : x = [1.98652091 1.42201341] f(x) = 0.0009998982143588915 gradient norm = 0.0018189933769318482\n",
      "Iteration 939 : x = [1.98654183 1.42219411] f(x) = 0.0009995677169942546 gradient norm = 0.0018148558204131194\n",
      "Iteration 940 : x = [1.9865627  1.42237439] f(x) = 0.0009992387213468787 gradient norm = 0.0018107287583535674\n",
      "Iteration 941 : x = [1.98658351 1.42255426] f(x) = 0.0009989112202017365 gradient norm = 0.0018066121592014335\n",
      "Iteration 942 : x = [1.98660426 1.42273373] f(x) = 0.0009985852063811337 gradient norm = 0.0018025059915226002\n",
      "Iteration 943 : x = [1.98662497 1.42291278] f(x) = 0.0009982606727444985 gradient norm = 0.0017984102240000655\n",
      "Iteration 944 : x = [1.98664562 1.42309143] f(x) = 0.000997937612188171 gradient norm = 0.00179432482543339\n",
      "Iteration 945 : x = [1.98666623 1.42326968] f(x) = 0.0009976160176451943 gradient norm = 0.0017902497647381637\n",
      "Iteration 946 : x = [1.98668677 1.42344752] f(x) = 0.0009972958820851053 gradient norm = 0.0017861850109454603\n",
      "Iteration 947 : x = [1.98670727 1.42362496] f(x) = 0.0009969771985137304 gradient norm = 0.0017821305332013145\n",
      "Iteration 948 : x = [1.98672772 1.423802  ] f(x) = 0.0009966599599729772 gradient norm = 0.0017780863007661747\n",
      "Iteration 949 : x = [1.98674811 1.42397863] f(x) = 0.0009963441595406339 gradient norm = 0.001774052283014399\n",
      "Iteration 950 : x = [1.98676845 1.42415487] f(x) = 0.0009960297903301646 gradient norm = 0.0017700284494337113\n",
      "Iteration 951 : x = [1.98678874 1.4243307 ] f(x) = 0.0009957168454905103 gradient norm = 0.0017660147696246897\n",
      "Iteration 952 : x = [1.98680898 1.42450614] f(x) = 0.0009954053182058826 gradient norm = 0.00176201121330024\n",
      "Iteration 953 : x = [1.98682917 1.42468118] f(x) = 0.000995095201695573 gradient norm = 0.001758017750285084\n",
      "Iteration 954 : x = [1.98684931 1.42485583] f(x) = 0.0009947864892137506 gradient norm = 0.0017540343505152453\n",
      "Iteration 955 : x = [1.9868694  1.42503008] f(x) = 0.000994479174049266 gradient norm = 0.0017500609840375486\n",
      "Iteration 956 : x = [1.98688944 1.42520393] f(x) = 0.000994173249525457 gradient norm = 0.0017460976210091\n",
      "Iteration 957 : x = [1.98690942 1.42537739] f(x) = 0.0009938687089999542 gradient norm = 0.0017421442316967702\n",
      "Iteration 958 : x = [1.98692936 1.42555046] f(x) = 0.0009935655458644884 gradient norm = 0.0017382007864767284\n",
      "Iteration 959 : x = [1.98694924 1.42572314] f(x) = 0.0009932637535446992 gradient norm = 0.0017342672558339112\n",
      "Iteration 960 : x = [1.98696908 1.42589543] f(x) = 0.0009929633254999448 gradient norm = 0.0017303436103615435\n",
      "Iteration 961 : x = [1.98698887 1.42606733] f(x) = 0.0009926642552231125 gradient norm = 0.0017264298207606422\n",
      "Iteration 962 : x = [1.9870086  1.42623884] f(x) = 0.0009923665362404307 gradient norm = 0.0017225258578395155\n",
      "Iteration 963 : x = [1.98702829 1.42640997] f(x) = 0.0009920701621112813 gradient norm = 0.0017186316925132804\n",
      "Iteration 964 : x = [1.98704793 1.4265807 ] f(x) = 0.0009917751264280172 gradient norm = 0.0017147472958033935\n",
      "Iteration 965 : x = [1.98706752 1.42675105] f(x) = 0.0009914814228157737 gradient norm = 0.0017108726388371342\n",
      "Iteration 966 : x = [1.98708706 1.42692102] f(x) = 0.0009911890449322872 gradient norm = 0.0017070076928471561\n",
      "Iteration 967 : x = [1.98710655 1.42709061] f(x) = 0.0009908979864677143 gradient norm = 0.001703152429170999\n",
      "Iteration 968 : x = [1.98712599 1.42725981] f(x) = 0.0009906082411444473 gradient norm = 0.0016993068192506019\n",
      "Iteration 969 : x = [1.98714538 1.42742863] f(x) = 0.0009903198027169371 gradient norm = 0.0016954708346318492\n",
      "Iteration 970 : x = [1.98716473 1.42759707] f(x) = 0.0009900326649715132 gradient norm = 0.0016916444469640879\n",
      "Iteration 971 : x = [1.98718402 1.42776513] f(x) = 0.0009897468217262063 gradient norm = 0.001687827627999665\n",
      "Iteration 972 : x = [1.98720327 1.42793281] f(x) = 0.0009894622668305713 gradient norm = 0.0016840203495934708\n",
      "Iteration 973 : x = [1.98722247 1.42810012] f(x) = 0.0009891789941655123 gradient norm = 0.0016802225837024651\n",
      "Iteration 974 : x = [1.98724162 1.42826704] f(x) = 0.0009888969976431078 gradient norm = 0.0016764343023852218\n",
      "Iteration 975 : x = [1.98726073 1.42843359] f(x) = 0.000988616271206437 gradient norm = 0.0016726554778014719\n",
      "Iteration 976 : x = [1.98727978 1.42859977] f(x) = 0.0009883368088294067 gradient norm = 0.0016688860822116412\n",
      "Iteration 977 : x = [1.98729879 1.42876557] f(x) = 0.0009880586045165828 gradient norm = 0.0016651260879764276\n",
      "Iteration 978 : x = [1.98731776 1.428931  ] f(x) = 0.0009877816523030177 gradient norm = 0.0016613754675563056\n",
      "Iteration 979 : x = [1.98733667 1.42909606] f(x) = 0.0009875059462540817 gradient norm = 0.0016576341935111154\n",
      "Iteration 980 : x = [1.98735554 1.42926075] f(x) = 0.0009872314804652948 gradient norm = 0.0016539022384996123\n",
      "Iteration 981 : x = [1.98737436 1.42942506] f(x) = 0.0009869582490621592 gradient norm = 0.0016501795752790044\n",
      "Iteration 982 : x = [1.98739313 1.42958901] f(x) = 0.0009866862461999956 gradient norm = 0.0016464661767045371\n",
      "Iteration 983 : x = [1.98741186 1.42975259] f(x) = 0.000986415466063774 gradient norm = 0.0016427620157290427\n",
      "Iteration 984 : x = [1.98743054 1.4299158 ] f(x) = 0.000986145902867953 gradient norm = 0.0016390670654025017\n",
      "Iteration 985 : x = [1.98744917 1.43007864] f(x) = 0.0009858775508563165 gradient norm = 0.0016353812988716308\n",
      "Iteration 986 : x = [1.98746776 1.43024112] f(x) = 0.0009856104043018093 gradient norm = 0.0016317046893794156\n",
      "Iteration 987 : x = [1.9874863  1.43040323] f(x) = 0.0009853444575063787 gradient norm = 0.001628037210264724\n",
      "Iteration 988 : x = [1.9875048  1.43056498] f(x) = 0.000985079704800811 gradient norm = 0.0016243788349618437\n",
      "Iteration 989 : x = [1.98752325 1.43072637] f(x) = 0.0009848161405445787 gradient norm = 0.001620729537000092\n",
      "Iteration 990 : x = [1.98754165 1.43088739] f(x) = 0.0009845537591256749 gradient norm = 0.001617089290003363\n",
      "Iteration 991 : x = [1.98756001 1.43104806] f(x) = 0.0009842925549604612 gradient norm = 0.0016134580676897341\n",
      "Iteration 992 : x = [1.98757832 1.43120836] f(x) = 0.0009840325224935097 gradient norm = 0.0016098358438710355\n",
      "Iteration 993 : x = [1.98759659 1.4313683 ] f(x) = 0.000983773656197447 gradient norm = 0.001606222592452432\n",
      "Iteration 994 : x = [1.98761482 1.43152789] f(x) = 0.000983515950572802 gradient norm = 0.0016026182874320303\n",
      "Iteration 995 : x = [1.98763299 1.43168712] f(x) = 0.0009832594001478504 gradient norm = 0.001599022902900439\n",
      "Iteration 996 : x = [1.98765113 1.43184599] f(x) = 0.000983003999478464 gradient norm = 0.0015954364130403899\n",
      "Iteration 997 : x = [1.98766921 1.4320045 ] f(x) = 0.0009827497431479587 gradient norm = 0.0015918587921263162\n",
      "Iteration 998 : x = [1.98768726 1.43216266] f(x) = 0.0009824966257669409 gradient norm = 0.0015882900145239532\n",
      "Iteration 999 : x = [1.98770525 1.43232047] f(x) = 0.0009822446419731634 gradient norm = 0.0015847300546899257\n",
      "\n",
      "\tStep size: 1\n",
      "Iteration 0 : x = [1.  0.5] f(x) = 0.11204289613814822 gradient norm = 0.16286411890444852\n",
      "Iteration 1 : x = [1.15222549 0.5578975 ] f(x) = 0.08475344454377579 gradient norm = 0.16841953951045324\n",
      "Iteration 2 : x = [1.31133537 0.61311695] f(x) = 0.057595375538533514 gradient norm = 0.15035675074933763\n",
      "Iteration 3 : x = [1.4544891  0.65909697] f(x) = 0.037229589005910196 gradient norm = 0.1187823949283841\n",
      "Iteration 4 : x = [1.5674612  0.69579252] f(x) = 0.024869737673810857 gradient norm = 0.08910112420449637\n",
      "Iteration 5 : x = [1.65102352 0.72671739] f(x) = 0.017922713540671348 gradient norm = 0.06714045798217308\n",
      "Iteration 6 : x = [1.7121463  0.75449953] f(x) = 0.013931377944164736 gradient norm = 0.05214192865476018\n",
      "Iteration 7 : x = [1.75740466 0.78039281] f(x) = 0.011484697860275523 gradient norm = 0.04204582385702029\n",
      "Iteration 8 : x = [1.79155272 0.80492362] f(x) = 0.009866934616627474 gradient norm = 0.03517412840913592\n",
      "Iteration 9 : x = [1.81782287 0.82831377] f(x) = 0.008717376118586613 gradient norm = 0.030386947176746247\n",
      "Iteration 10 : x = [1.838407   0.85066685] f(x) = 0.007848396201267762 gradient norm = 0.02694659396365914\n",
      "Iteration 11 : x = [1.85481369 0.87204299] f(x) = 0.007158103562453857 gradient norm = 0.024383154961225287\n",
      "Iteration 12 : x = [1.86810085 0.89248778] f(x) = 0.006588543377335588 gradient norm = 0.022399068950259803\n",
      "Iteration 13 : x = [1.87902404 0.91204289] f(x) = 0.0061051562604286505 gradient norm = 0.02080595302029925\n",
      "Iteration 14 : x = [1.88813175 0.9307495 ] f(x) = 0.005686330448856778 gradient norm = 0.019483894659984655\n",
      "Iteration 15 : x = [1.89582802 0.94864893] f(x) = 0.005317897998524893 gradient norm = 0.018355715037564398\n",
      "Iteration 16 : x = [1.90241422 0.96578235] f(x) = 0.004990135753789433 gradient norm = 0.017370924093724212\n",
      "Iteration 17 : x = [1.90811775 0.98219024] f(x) = 0.004696077358721962 gradient norm = 0.016495797694431817\n",
      "Iteration 18 : x = [1.91311186 0.99791189] f(x) = 0.0044305328043818945 gradient norm = 0.01570725337892199\n",
      "Iteration 19 : x = [1.91752985 1.01298502] f(x) = 0.004189500932882884 gradient norm = 0.014989058859417407\n",
      "Iteration 20 : x = [1.92147513 1.02744554] f(x) = 0.003969806227264088 gradient norm = 0.014329467891432668\n",
      "Iteration 21 : x = [1.9250286  1.04132741] f(x) = 0.0037688670546179403 gradient norm = 0.013719730899853882\n",
      "Iteration 22 : x = [1.92825403 1.05466262] f(x) = 0.0035845430026506257 gradient norm = 0.013153144592357537\n",
      "Iteration 23 : x = [1.93120212 1.06748112] f(x) = 0.003415031078796095 gradient norm = 0.01262443639679378\n",
      "Iteration 24 : x = [1.93391346 1.07981096] f(x) = 0.003258792915430037 gradient norm = 0.012129359033499288\n",
      "Iteration 25 : x = [1.93642081 1.09167833] f(x) = 0.0031145021926899325 gradient norm = 0.011664418542135667\n",
      "Iteration 26 : x = [1.93875082 1.10310767] f(x) = 0.0029810056104405736 gradient norm = 0.011226688195406667\n",
      "Iteration 27 : x = [1.94092532 1.11412175] f(x) = 0.002857293190868968 gradient norm = 0.010813678495572332\n",
      "Iteration 28 : x = [1.94296238 1.12474183] f(x) = 0.0027424751792159653 gradient norm = 0.010423244372447078\n",
      "Iteration 29 : x = [1.94487701 1.13498772] f(x) = 0.002635763729741155 gradient norm = 0.010053517477304753\n",
      "Iteration 30 : x = [1.94668185 1.1448779 ] f(x) = 0.0025364581448161657 gradient norm = 0.009702855710861946\n",
      "Iteration 31 : x = [1.94838758 1.15442965] f(x) = 0.002443932809596408 gradient norm = 0.009369804808877995\n",
      "Iteration 32 : x = [1.95000329 1.1636591 ] f(x) = 0.0023576272114603533 gradient norm = 0.00905306852678941\n",
      "Iteration 33 : x = [1.95153684 1.17258134] f(x) = 0.0022770375994763978 gradient norm = 0.008751485076516336\n",
      "Iteration 34 : x = [1.95299499 1.18121049] f(x) = 0.002201709953358351 gradient norm = 0.008464008196871334\n",
      "Iteration 35 : x = [1.95438368 1.1895598 ] f(x) = 0.0021312340115771313 gradient norm = 0.008189691722316449\n",
      "Iteration 36 : x = [1.95570809 1.19764169] f(x) = 0.0020652381657882595 gradient norm = 0.007927676839963923\n",
      "Iteration 37 : x = [1.95697283 1.20546783] f(x) = 0.0020033850707509406 gradient norm = 0.0076771814466164495\n",
      "Iteration 38 : x = [1.958182   1.21304919] f(x) = 0.0019453678501813818 gradient norm = 0.007437491171360494\n",
      "Iteration 39 : x = [1.95933924 1.2203961 ] f(x) = 0.0018909068026409918 gradient norm = 0.007207951737364637\n",
      "Iteration 40 : x = [1.96044787 1.22751829] f(x) = 0.0018397465297336586 gradient norm = 0.006987962413813013\n",
      "Iteration 41 : x = [1.96151087 1.23442492] f(x) = 0.0017916534230380384 gradient norm = 0.006776970365006064\n",
      "Iteration 42 : x = [1.96253094 1.24112468] f(x) = 0.0017464134573552845 gradient norm = 0.00657446574502894\n",
      "Iteration 43 : x = [1.96351056 1.24762576] f(x) = 0.0017038302467404934 gradient norm = 0.006379977417358779\n",
      "Iteration 44 : x = [1.964452   1.25393589] f(x) = 0.001663723326936114 gradient norm = 0.006193069202307688\n",
      "Iteration 45 : x = [1.96535734 1.26006243] f(x) = 0.0016259266336269146 gradient norm = 0.006013336573316144\n",
      "Iteration 46 : x = [1.9662285  1.26601233] f(x) = 0.0015902871506792422 gradient norm = 0.005840403737244859\n",
      "Iteration 47 : x = [1.96706727 1.27179219] f(x) = 0.001556663706431767 gradient norm = 0.0056739210449690165\n",
      "Iteration 48 : x = [1.96787528 1.27740828] f(x) = 0.0015249258993388576 gradient norm = 0.005513562687480782\n",
      "Iteration 49 : x = [1.96865407 1.28286657] f(x) = 0.0014949531369613173 gradient norm = 0.005359024639879623\n",
      "Iteration 50 : x = [1.96940507 1.28817271] f(x) = 0.00146663377455404 gradient norm = 0.00521002282146238\n",
      "Iteration 51 : x = [1.97012961 1.2933321 ] f(x) = 0.001439864341396641 gradient norm = 0.005066291444905701\n",
      "Iteration 52 : x = [1.97082895 1.2983499 ] f(x) = 0.0014145488446149716 gradient norm = 0.004927581531480436\n",
      "Iteration 53 : x = [1.97150424 1.30323099] f(x) = 0.0013905981415999302 gradient norm = 0.004793659572517811\n",
      "Iteration 54 : x = [1.97215658 1.30798005] f(x) = 0.001367929373286272 gradient norm = 0.00466430632008985\n",
      "Iteration 55 : x = [1.972787   1.31260156] f(x) = 0.0013464654515418705 gradient norm = 0.004539315692171968\n",
      "Iteration 56 : x = [1.97339647 1.31709977] f(x) = 0.0013261345947643032 gradient norm = 0.004418493779503415\n",
      "Iteration 57 : x = [1.9739859  1.32147878] f(x) = 0.0013068699065092715 gradient norm = 0.004301657943014392\n",
      "Iteration 58 : x = [1.97455616 1.32574247] f(x) = 0.001288608992602668 gradient norm = 0.004188635992097517\n",
      "Iteration 59 : x = [1.97510805 1.32989459] f(x) = 0.001271293612730476 gradient norm = 0.004079265435206981\n",
      "Iteration 60 : x = [1.97564234 1.33393871] f(x) = 0.0012548693629707724 gradient norm = 0.003973392795303938\n",
      "Iteration 61 : x = [1.97615975 1.33787827] f(x) = 0.0012392853861406988 gradient norm = 0.003870872983558947\n",
      "Iteration 62 : x = [1.97666098 1.34171655] f(x) = 0.0012244941071871047 gradient norm = 0.00377156872549346\n",
      "Iteration 63 : x = [1.97714668 1.34545672] f(x) = 0.0012104509911603674 gradient norm = 0.0036753500344112256\n",
      "Iteration 64 : x = [1.97761745 1.34910179] f(x) = 0.0011971143215827576 gradient norm = 0.0035820937275520028\n",
      "Iteration 65 : x = [1.97807388 1.35265469] f(x) = 0.0011844449972612282 gradient norm = 0.003491682980907223\n",
      "Iteration 66 : x = [1.97851654 1.3561182 ] f(x) = 0.0011724063458039813 gradient norm = 0.003404006919080413\n",
      "Iteration 67 : x = [1.97894595 1.35949501] f(x) = 0.001160963952284715 gradient norm = 0.003318960236964021\n",
      "Iteration 68 : x = [1.97936261 1.36278772] f(x) = 0.0011500855016611353 gradient norm = 0.0032364428503453835\n",
      "Iteration 69 : x = [1.979767  1.3659988] f(x) = 0.0011397406336981788 gradient norm = 0.0031563595728552746\n",
      "Iteration 70 : x = [1.98015957 1.36913065] f(x) = 0.0011299008092736807 gradient norm = 0.003078619816937594\n",
      "Iteration 71 : x = [1.98054076 1.37218558] f(x) = 0.0011205391870571515 gradient norm = 0.0030031373167531765\n",
      "Iteration 72 : x = [1.98091099 1.37516581] f(x) = 0.0011116305096526195 gradient norm = 0.0029298298711385702\n",
      "Iteration 73 : x = [1.98127063 1.37807348] f(x) = 0.0011031509983857105 gradient norm = 0.0028586191049248593\n",
      "Iteration 74 : x = [1.98162008 1.38091066] f(x) = 0.001095078255994664 gradient norm = 0.0027894302470856925\n",
      "Iteration 75 : x = [1.98195969 1.38367934] f(x) = 0.0010873911765559357 gradient norm = 0.002722191924329737\n",
      "Iteration 76 : x = [1.9822898  1.38638144] f(x) = 0.0010800698620384325 gradient norm = 0.002656835968883097\n",
      "Iteration 77 : x = [1.98261075 1.38901882] f(x) = 0.0010730955449372072 gradient norm = 0.002593297239323844\n",
      "Iteration 78 : x = [1.98292284 1.39159327] f(x) = 0.0010664505164882732 gradient norm = 0.00253151345343507\n",
      "Iteration 79 : x = [1.98322637 1.39410652] f(x) = 0.0010601180600118456 gradient norm = 0.002471425032136436\n",
      "Iteration 80 : x = [1.98352164 1.39656024] f(x) = 0.0010540823889723448 gradient norm = 0.0024129749536383124\n",
      "Iteration 81 : x = [1.98380891 1.39895606] f(x) = 0.0010483285893803653 gradient norm = 0.002356108617037981\n",
      "Iteration 82 : x = [1.98408846 1.40129552] f(x) = 0.0010428425661950574 gradient norm = 0.0023007737146456203\n",
      "Iteration 83 : x = [1.98436053 1.40358015] f(x) = 0.001037610993415354 gradient norm = 0.0022469201123890012\n",
      "Iteration 84 : x = [1.98462537 1.40581141] f(x) = 0.0010326212675755167 gradient norm = 0.0021944997377014177\n",
      "Iteration 85 : x = [1.9848832  1.40799071] f(x) = 0.0010278614643849477 gradient norm = 0.0021434664743473137\n",
      "Iteration 86 : x = [1.98513426 1.41011942] f(x) = 0.001023320298274343 gradient norm = 0.0020937760636856153\n",
      "Iteration 87 : x = [1.98537875 1.41219888] f(x) = 0.0010189870846303228 gradient norm = 0.0020453860119117404\n",
      "Iteration 88 : x = [1.98561689 1.41423035] f(x) = 0.0010148517045188458 gradient norm = 0.001998255502856787\n",
      "Iteration 89 : x = [1.98584886 1.4162151 ] f(x) = 0.0010109045717142313 gradient norm = 0.001952345315956045\n",
      "Iteration 90 : x = [1.98607487 1.41815432] f(x) = 0.0010071366018656023 gradient norm = 0.0019076177490301484\n",
      "Iteration 91 : x = [1.98629509 1.42004918] f(x) = 0.0010035391836462203 gradient norm = 0.001864036545549992\n",
      "Iteration 92 : x = [1.98650969 1.42190082] f(x) = 0.001000104151743572 gradient norm = 0.0018215668260822986\n",
      "Iteration 93 : x = [1.98671886 1.42371034] f(x) = 0.0009968237615594249 gradient norm = 0.0017801750236360553\n",
      "Iteration 94 : x = [1.98692275 1.4254788 ] f(x) = 0.000993690665499358 gradient norm = 0.0017398288226513831\n",
      "Iteration 95 : x = [1.98712151 1.42720724] f(x) = 0.0009906978907407195 gradient norm = 0.0017004971013918975\n",
      "Iteration 96 : x = [1.98731531 1.42889666] f(x) = 0.000987838818376556 gradient norm = 0.001662149877519483\n",
      "Iteration 97 : x = [1.98750428 1.43054803] f(x) = 0.0009851071638409517 gradient norm = 0.0016247582566468353\n",
      "Iteration 98 : x = [1.98768856 1.4321623 ] f(x) = 0.0009824969585284032 gradient norm = 0.0015882943836779929\n",
      "Iteration 99 : x = [1.9878683  1.43374039] f(x) = 0.000980002532526471 gradient norm = 0.0015527313967610029\n",
      "Iteration 100 : x = [1.98804362 1.4352832 ] f(x) = 0.0009776184983869888 gradient norm = 0.001518043383689352\n",
      "Iteration 101 : x = [1.98821465 1.43679157] f(x) = 0.0009753397358666774 gradient norm = 0.0014842053406006134\n",
      "Iteration 102 : x = [1.98838151 1.43826637] f(x) = 0.0009731613775730895 gradient norm = 0.0014511931328312396\n",
      "Iteration 103 : x = [1.98854432 1.4397084 ] f(x) = 0.0009710787954565089 gradient norm = 0.0014189834577964637\n",
      "Iteration 104 : x = [1.98870318 1.44111846] f(x) = 0.000969087588092735 gradient norm = 0.0013875538097732707\n",
      "Iteration 105 : x = [1.98885822 1.44249733] f(x) = 0.0009671835687056282 gradient norm = 0.0013568824464727685\n",
      "Iteration 106 : x = [1.98900954 1.44384575] f(x) = 0.000965362753881965 gradient norm = 0.0013269483572960264\n",
      "Iteration 107 : x = [1.98915723 1.44516445] f(x) = 0.000963621352934495 gradient norm = 0.0012977312331746535\n",
      "Iteration 108 : x = [1.98930141 1.44645415] f(x) = 0.0009619557578722022 gradient norm = 0.0012692114379038476\n",
      "Iteration 109 : x = [1.98944215 1.44771553] f(x) = 0.000960362533939629 gradient norm = 0.0012413699808819264\n",
      "Iteration 110 : x = [1.98957957 1.44894927] f(x) = 0.0009588384106897664 gradient norm = 0.0012141884911758426\n",
      "Iteration 111 : x = [1.98971374 1.45015603] f(x) = 0.0009573802735574473 gradient norm = 0.0011876491928375279\n",
      "Iteration 112 : x = [1.98984475 1.45133643] f(x) = 0.0009559851559024435 gradient norm = 0.0011617348814007655\n",
      "Iteration 113 : x = [1.9899727  1.45249109] f(x) = 0.0009546502314935502 gradient norm = 0.0011364289014926846\n",
      "Iteration 114 : x = [1.99009765 1.45362063] f(x) = 0.0009533728074068709 gradient norm = 0.0011117151254983048\n",
      "Iteration 115 : x = [1.99021969 1.45472563] f(x) = 0.0009521503173133079 gradient norm = 0.0010875779332202937\n",
      "Iteration 116 : x = [1.99033889 1.45580666] f(x) = 0.0009509803151319211 gradient norm = 0.0010640021924798323\n",
      "Iteration 117 : x = [1.99045533 1.45686427] f(x) = 0.000949860469027353 gradient norm = 0.0010409732406077752\n",
      "Iteration 118 : x = [1.99056909 1.45789901] f(x) = 0.0009487885557309465 gradient norm = 0.0010184768667783894\n",
      "Iteration 119 : x = [1.99068022 1.4589114 ] f(x) = 0.0009477624551665015 gradient norm = 0.000996499295140952\n",
      "Iteration 120 : x = [1.9907888  1.45990197] f(x) = 0.0009467801453628515 gradient norm = 0.0009750271687071024\n",
      "Iteration 121 : x = [1.99089489 1.46087121] f(x) = 0.0009458396976365818 gradient norm = 0.0009540475339544499\n",
      "Iteration 122 : x = [1.99099855 1.46181961] f(x) = 0.00094493927202927 gradient norm = 0.0009335478261092151\n",
      "Iteration 123 : x = [1.99109985 1.46274764] f(x) = 0.0009440771129846182 gradient norm = 0.0009135158550729412\n",
      "Iteration 124 : x = [1.99119885 1.46365578] f(x) = 0.0009432515452517777 gradient norm = 0.0008939397919603852\n",
      "Iteration 125 : x = [1.99129561 1.46454446] f(x) = 0.0009424609700020038 gradient norm = 0.0008748081562174986\n",
      "Iteration 126 : x = [1.99139017 1.46541415] f(x) = 0.0009417038611465915 gradient norm = 0.0008561098032903304\n",
      "Iteration 127 : x = [1.9914826  1.46626525] f(x) = 0.0009409787618447802 gradient norm = 0.0008378339128173229\n",
      "Iteration 128 : x = [1.99157295 1.4670982 ] f(x) = 0.0009402842811910145 gradient norm = 0.000819969977319\n",
      "Iteration 129 : x = [1.99166127 1.4679134 ] f(x) = 0.0009396190910715829 gradient norm = 0.0008025077913605254\n",
      "Iteration 130 : x = [1.99174761 1.46871125] f(x) = 0.0009389819231812782 gradient norm = 0.0007854374411640513\n",
      "Iteration 131 : x = [1.99183202 1.46949214] f(x) = 0.0009383715661912723 gradient norm = 0.0007687492946490235\n",
      "Iteration 132 : x = [1.99191454 1.47025645] f(x) = 0.000937786863059934 gradient norm = 0.0007524339918797156\n",
      "Iteration 133 : x = [1.99199523 1.47100454] f(x) = 0.0009372267084788032 gradient norm = 0.000736482435900655\n",
      "Iteration 134 : x = [1.99207412 1.47173679] f(x) = 0.000936690046446409 gradient norm = 0.0007208857839413595\n",
      "Iteration 135 : x = [1.99215126 1.47245353] f(x) = 0.0009361758679630297 gradient norm = 0.0007056354389730506\n",
      "Iteration 136 : x = [1.99222669 1.47315512] f(x) = 0.000935683208839917 gradient norm = 0.0006907230416007942\n",
      "Iteration 137 : x = [1.99230046 1.4738419 ] f(x) = 0.0009352111476168713 gradient norm = 0.0006761404622755165\n",
      "Iteration 138 : x = [1.9923726  1.47451418] f(x) = 0.0009347588035824121 gradient norm = 0.000661879793811038\n",
      "Iteration 139 : x = [1.99244315 1.47517229] f(x) = 0.0009343253348911164 gradient norm = 0.0006479333441921733\n",
      "Iteration 140 : x = [1.99251216 1.47581654] f(x) = 0.0009339099367730154 gradient norm = 0.0006342936296606353\n",
      "Iteration 141 : x = [1.99257965 1.47644723] f(x) = 0.0009335118398302272 gradient norm = 0.0006209533680661197\n",
      "Iteration 142 : x = [1.99264566 1.47706466] f(x) = 0.0009331303084162679 gradient norm = 0.0006079054724706922\n",
      "Iteration 143 : x = [1.99271022 1.47766913] f(x) = 0.0009327646390937586 gradient norm = 0.0005951430449951269\n",
      "Iteration 144 : x = [1.99277338 1.47826091] f(x) = 0.0009324141591664671 gradient norm = 0.0005826593708964762\n",
      "Iteration 145 : x = [1.99283516 1.47884029] f(x) = 0.0009320782252818649 gradient norm = 0.0005704479128666812\n",
      "Iteration 146 : x = [1.9928956  1.47940752] f(x) = 0.0009317562221005803 gradient norm = 0.0005585023055425385\n",
      "Iteration 147 : x = [1.99295473 1.47996289] f(x) = 0.0009314475610293343 gradient norm = 0.0005468163502178189\n",
      "Iteration 148 : x = [1.99301257 1.48050664] f(x) = 0.0009311516790141367 gradient norm = 0.0005353840097488163\n",
      "Iteration 149 : x = [1.99306916 1.48103902] f(x) = 0.0009308680373906862 gradient norm = 0.0005241994036450277\n",
      "Iteration 150 : x = [1.99312453 1.48156029] f(x) = 0.0009305961207890946 gradient norm = 0.0005132568033370423\n",
      "Iteration 151 : x = [1.9931787  1.48207068] f(x) = 0.000930335436090205 gradient norm = 0.0005025506276141361\n",
      "Iteration 152 : x = [1.99323171 1.48257043] f(x) = 0.000930085511430925 gradient norm = 0.0004920754382244569\n",
      "Iteration 153 : x = [1.99328357 1.48305976] f(x) = 0.0009298458952561315 gradient norm = 0.0004818259356309411\n",
      "Iteration 154 : x = [1.99333432 1.48353891] f(x) = 0.0009296161554148335 gradient norm = 0.0004717969549165332\n",
      "Iteration 155 : x = [1.99338398 1.48400808] f(x) = 0.0009293958782984084 gradient norm = 0.0004619834618325135\n",
      "Iteration 156 : x = [1.99343257 1.4844675 ] f(x) = 0.0009291846680188372 gradient norm = 0.0004523805489840828\n",
      "Iteration 157 : x = [1.99348013 1.48491738] f(x) = 0.0009289821456249717 gradient norm = 0.00044298343214756115\n",
      "Iteration 158 : x = [1.99352666 1.48535791] f(x) = 0.0009287879483549765 gradient norm = 0.00043378744671393173\n",
      "Iteration 159 : x = [1.99357221 1.4857893 ] f(x) = 0.0009286017289231838 gradient norm = 0.0004247880442535385\n",
      "Iteration 160 : x = [1.99361678 1.48621174] f(x) = 0.0009284231548396857 gradient norm = 0.00041598078919722893\n",
      "Iteration 161 : x = [1.9936604  1.48662543] f(x) = 0.0009282519077610813 gradient norm = 0.0004073613556291437\n",
      "Iteration 162 : x = [1.99370309 1.48703055] f(x) = 0.0009280876828708755 gradient norm = 0.00039892552418688217\n",
      "Iteration 163 : x = [1.99374487 1.48742728] f(x) = 0.0009279301882881031 gradient norm = 0.00039066917906471906\n",
      "Iteration 164 : x = [1.99378577 1.4878158 ] f(x) = 0.0009277791445028254 gradient norm = 0.0003825883051159162\n",
      "Iteration 165 : x = [1.9938258  1.48819629] f(x) = 0.0009276342838372161 gradient norm = 0.0003746789850502232\n",
      "Iteration 166 : x = [1.99386498 1.48856892] f(x) = 0.0009274953499310175 gradient norm = 0.00036693739672294287\n",
      "Iteration 167 : x = [1.99390333 1.48893384] f(x) = 0.0009273620972502089 gradient norm = 0.0003593598105120212\n",
      "Iteration 168 : x = [1.99394087 1.48929124] f(x) = 0.0009272342906177908 gradient norm = 0.00035194258677980237\n",
      "Iteration 169 : x = [1.99397762 1.48964126] f(x) = 0.0009271117047656394 gradient norm = 0.00034468217341625755\n",
      "Iteration 170 : x = [1.99401359 1.48998406] f(x) = 0.0009269941239064422 gradient norm = 0.00033757510346060207\n",
      "Iteration 171 : x = [1.9940488  1.49031979] f(x) = 0.0009268813413247693 gradient norm = 0.00033061799279835173\n",
      "Iteration 172 : x = [1.99408327 1.49064861] f(x) = 0.0009267731589863891 gradient norm = 0.00032380753793106174\n",
      "Iteration 173 : x = [1.99411702 1.49097065] f(x) = 0.000926669387164975 gradient norm = 0.0003171405138159845\n",
      "Iteration 174 : x = [1.99415006 1.49128606] f(x) = 0.000926569844085397 gradient norm = 0.0003106137717731366\n",
      "Iteration 175 : x = [1.9941824  1.49159499] f(x) = 0.0009264743555828241 gradient norm = 0.0003042242374572655\n",
      "Iteration 176 : x = [1.99421406 1.49189756] f(x) = 0.0009263827547769118 gradient norm = 0.00029796890889236324\n",
      "Iteration 177 : x = [1.99424506 1.49219391] f(x) = 0.0009262948817603743 gradient norm = 0.0002918448545664973\n",
      "Iteration 178 : x = [1.99427541 1.49248418] f(x) = 0.0009262105833012838 gradient norm = 0.00028584921158473917\n",
      "Iteration 179 : x = [1.99430512 1.49276848] f(x) = 0.0009261297125584619 gradient norm = 0.00027997918387817486\n",
      "Iteration 180 : x = [1.99433421 1.49304694] f(x) = 0.0009260521288093679 gradient norm = 0.00027423204046690415\n",
      "Iteration 181 : x = [1.9943627  1.49331969] f(x) = 0.0009259776971899127 gradient norm = 0.0002686051137752536\n",
      "Iteration 182 : x = [1.99439059 1.49358684] f(x) = 0.0009259062884456505 gradient norm = 0.00026309579799725164\n",
      "Iteration 183 : x = [1.99441789 1.49384852] f(x) = 0.0009258377786938413 gradient norm = 0.0002577015475106728\n",
      "Iteration 184 : x = [1.99444463 1.49410483] f(x) = 0.0009257720491958788 gradient norm = 0.00025241987533794713\n",
      "Iteration 185 : x = [1.99447081 1.49435589] f(x) = 0.0009257089861396266 gradient norm = 0.0002472483516523186\n",
      "Iteration 186 : x = [1.99449644 1.4946018 ] f(x) = 0.0009256484804312062 gradient norm = 0.0002421846023276608\n",
      "Iteration 187 : x = [1.99452154 1.49484268] f(x) = 0.0009255904274958177 gradient norm = 0.00023722630753054367\n",
      "Iteration 188 : x = [1.99454612 1.49507863] f(x) = 0.0009255347270871861 gradient norm = 0.00023237120035302723\n",
      "Iteration 189 : x = [1.99457019 1.49530976] f(x) = 0.0009254812831052415 gradient norm = 0.00022761706548482882\n",
      "Iteration 190 : x = [1.99459376 1.49553615] f(x) = 0.0009254300034216756 gradient norm = 0.00022296173792360466\n",
      "Iteration 191 : x = [1.99461684 1.49575791] f(x) = 0.0009253807997130093 gradient norm = 0.00021840310172196114\n",
      "Iteration 192 : x = [1.99463943 1.49597514] f(x) = 0.0009253335873008492 gradient norm = 0.00021393908877006496\n",
      "Iteration 193 : x = [1.99466157 1.49618793] f(x) = 0.0009252882849990074 gradient norm = 0.00020956767761264522\n",
      "Iteration 194 : x = [1.99468324 1.49639638] f(x) = 0.0009252448149671795 gradient norm = 0.000205286892299247\n",
      "Iteration 195 : x = [1.99470446 1.49660057] f(x) = 0.0009252031025708932 gradient norm = 0.00020109480126665545\n",
      "Iteration 196 : x = [1.99472524 1.49680058] f(x) = 0.000925163076247449 gradient norm = 0.00019698951625243642\n",
      "Iteration 197 : x = [1.9947456  1.49699652] f(x) = 0.0009251246673775902 gradient norm = 0.00019296919123862723\n",
      "Iteration 198 : x = [1.99476553 1.49718846] f(x) = 0.0009250878101626474 gradient norm = 0.00018903202142452793\n",
      "Iteration 199 : x = [1.99478505 1.49737648] f(x) = 0.0009250524415069193 gradient norm = 0.0001851762422277434\n",
      "Iteration 200 : x = [1.99480417 1.49756066] f(x) = 0.000925018500905059 gradient norm = 0.0001814001283125469\n",
      "Iteration 201 : x = [1.99482289 1.4977411 ] f(x) = 0.0009249859303342472 gradient norm = 0.0001777019926446511\n",
      "Iteration 202 : x = [1.99484123 1.49791785] f(x) = 0.0009249546741509438 gradient norm = 0.00017408018557164175\n",
      "Iteration 203 : x = [1.99485919 1.498091  ] f(x) = 0.000924924678992015 gradient norm = 0.00017053309392820167\n",
      "Iteration 204 : x = [1.99487678 1.49826062] f(x) = 0.000924895893680051 gradient norm = 0.00016705914016537914\n",
      "Iteration 205 : x = [1.99489401 1.49842679] f(x) = 0.0009248682691326847 gradient norm = 0.00016365678150314928\n",
      "Iteration 206 : x = [1.99491088 1.49858958] f(x) = 0.0009248417582757465 gradient norm = 0.00016032450910554528\n",
      "Iteration 207 : x = [1.9949274  1.49874905] f(x) = 0.0009248163159600799 gradient norm = 0.0001570608472776901\n",
      "Iteration 208 : x = [1.99494359 1.49890527] f(x) = 0.0009247918988818653 gradient norm = 0.00015386435268401413\n",
      "Iteration 209 : x = [1.99495944 1.49905832] f(x) = 0.0009247684655063013 gradient norm = 0.00015073361358704641\n",
      "Iteration 210 : x = [1.99497496 1.49920825] f(x) = 0.0009247459759944929 gradient norm = 0.000147667249106161\n",
      "Iteration 211 : x = [1.99499017 1.49935513] f(x) = 0.0009247243921334131 gradient norm = 0.00014466390849565897\n",
      "Iteration 212 : x = [1.99500507 1.49949903] f(x) = 0.0009247036772688051 gradient norm = 0.00014172227044161867\n",
      "Iteration 213 : x = [1.99501965 1.49964   ] f(x) = 0.000924683796240899 gradient norm = 0.00013884104237693574\n",
      "Iteration 214 : x = [1.99503394 1.4997781 ] f(x) = 0.0009246647153228184 gradient norm = 0.00013601895981404515\n",
      "Iteration 215 : x = [1.99504794 1.4999134 ] f(x) = 0.000924646402161568 gradient norm = 0.00013325478569479107\n",
      "Iteration 216 : x = [1.99506165 1.50004594] f(x) = 0.0009246288257214873 gradient norm = 0.0001305473097568989\n",
      "Iteration 217 : x = [1.99507508 1.5001758 ] f(x) = 0.0009246119562300655 gradient norm = 0.00012789534791664156\n",
      "Iteration 218 : x = [1.99508823 1.50030302] f(x) = 0.0009245957651260212 gradient norm = 0.0001252977416671624\n",
      "Iteration 219 : x = [1.99510111 1.50042765] f(x) = 0.0009245802250095408 gradient norm = 0.00012275335749204543\n",
      "Iteration 220 : x = [1.99511373 1.50054975] f(x) = 0.0009245653095945986 gradient norm = 0.00012026108629364\n",
      "Iteration 221 : x = [1.99512609 1.50066938] f(x) = 0.000924550993663252 gradient norm = 0.00011781984283579499\n",
      "Iteration 222 : x = [1.9951382  1.50078657] f(x) = 0.0009245372530218455 gradient norm = 0.00011542856520050472\n",
      "Iteration 223 : x = [1.99515006 1.50090139] f(x) = 0.0009245240644590289 gradient norm = 0.0001130862142581337\n",
      "Iteration 224 : x = [1.99516168 1.50101388] f(x) = 0.0009245114057055225 gradient norm = 0.00011079177315081829\n",
      "Iteration 225 : x = [1.99517306 1.50112408] f(x) = 0.0009244992553955491 gradient norm = 0.00010854424678864801\n",
      "Iteration 226 : x = [1.99518421 1.50123205] f(x) = 0.0009244875930298654 gradient norm = 0.00010634266135830425\n",
      "Iteration 227 : x = [1.99519513 1.50133784] f(x) = 0.000924476398940326 gradient norm = 0.00010418606384380273\n",
      "Iteration 228 : x = [1.99520583 1.50144147] f(x) = 0.0009244656542559095 gradient norm = 0.00010207352155897038\n",
      "Iteration 229 : x = [1.99521631 1.501543  ] f(x) = 0.0009244553408701582 gradient norm = 0.00010000412169137627\n",
      "Iteration 230 : x = [1.99522657 1.50164248] f(x) = 0.0009244454414099539 gradient norm = 9.797697085737104e-05\n",
      "Iteration 231 : x = [1.99523663 1.50173994] f(x) = 0.00092443593920559 gradient norm = 9.599119466792045e-05\n",
      "Iteration 232 : x = [1.99524648 1.50183542] f(x) = 0.0009244268182620752 gradient norm = 9.404593730500485e-05\n",
      "Iteration 233 : x = [1.99525613 1.50192897] f(x) = 0.0009244180632316226 gradient norm = 9.214036110819685e-05\n",
      "Iteration 234 : x = [1.99526558 1.50202063] f(x) = 0.0009244096593872725 gradient norm = 9.027364617122244e-05\n",
      "Iteration 235 : x = [1.99527484 1.50211043] f(x) = 0.0009244015925975996 gradient norm = 8.844498994818691e-05\n",
      "Iteration 236 : x = [1.99528391 1.5021984 ] f(x) = 0.0009243938493024626 gradient norm = 8.66536068692593e-05\n",
      "Iteration 237 : x = [1.9952928 1.5022846] f(x) = 0.000924386416489753 gradient norm = 8.489872796547948e-05\n",
      "Iteration 238 : x = [1.9953015  1.50236905] f(x) = 0.0009243792816730963 gradient norm = 8.317960050253119e-05\n",
      "Iteration 239 : x = [1.99531003 1.50245179] f(x) = 0.0009243724328704723 gradient norm = 8.149548762320611e-05\n",
      "Iteration 240 : x = [1.99531839 1.50253286] f(x) = 0.000924365858583711 gradient norm = 7.98456679982801e-05\n",
      "Iteration 241 : x = [1.99532657 1.50261229] f(x) = 0.0009243595477788309 gradient norm = 7.822943548569643e-05\n",
      "Iteration 242 : x = [1.99533459 1.5026901 ] f(x) = 0.0009243534898671847 gradient norm = 7.664609879772683e-05\n",
      "Iteration 243 : x = [1.99534245 1.50276635] f(x) = 0.0009243476746873737 gradient norm = 7.509498117594325e-05\n",
      "Iteration 244 : x = [1.99535014 1.50284104] f(x) = 0.0009243420924879098 gradient norm = 7.357542007381609e-05\n",
      "Iteration 245 : x = [1.99535768 1.50291423] f(x) = 0.0009243367339105807 gradient norm = 7.208676684672403e-05\n",
      "Iteration 246 : x = [1.99536506 1.50298594] f(x) = 0.0009243315899744993 gradient norm = 7.06283864491494e-05\n",
      "Iteration 247 : x = [1.9953723 1.5030562] f(x) = 0.0009243266520608046 gradient norm = 6.919965713896034e-05\n",
      "Iteration 248 : x = [1.99537939 1.50312503] f(x) = 0.0009243219118979888 gradient norm = 6.779997018849784e-05\n",
      "Iteration 249 : x = [1.99538633 1.50319248] f(x) = 0.0009243173615478226 gradient norm = 6.642872960237501e-05\n",
      "Iteration 250 : x = [1.99539314 1.50325856] f(x) = 0.0009243129933918559 gradient norm = 6.508535184176672e-05\n",
      "Iteration 251 : x = [1.9953998 1.5033233] f(x) = 0.00092430880011847 gradient norm = 6.376926555503069e-05\n",
      "Iteration 252 : x = [1.99540633 1.50338673] f(x) = 0.0009243047747104557 gradient norm = 6.24799113145408e-05\n",
      "Iteration 253 : x = [1.99541273 1.50344888] f(x) = 0.0009243009104331027 gradient norm = 6.121674135952778e-05\n",
      "Iteration 254 : x = [1.99541899 1.50350978] f(x) = 0.0009242972008227686 gradient norm = 5.9979219344799834e-05\n",
      "Iteration 255 : x = [1.99542513 1.50356944] f(x) = 0.000924293639675919 gradient norm = 5.8766820095176765e-05\n",
      "Iteration 256 : x = [1.99543115 1.5036279 ] f(x) = 0.0009242902210386089 gradient norm = 5.757902936554232e-05\n",
      "Iteration 257 : x = [1.99543704 1.50368518] f(x) = 0.0009242869391963972 gradient norm = 5.641534360629872e-05\n",
      "Iteration 258 : x = [1.99544282 1.5037413 ] f(x) = 0.000924283788664668 gradient norm = 5.527526973417602e-05\n",
      "Iteration 259 : x = [1.99544847 1.50379628] f(x) = 0.0009242807641793464 gradient norm = 5.415832490819631e-05\n",
      "Iteration 260 : x = [1.99545401 1.50385016] f(x) = 0.0009242778606879928 gradient norm = 5.306403631069177e-05\n",
      "Iteration 261 : x = [1.99545944 1.50390294] f(x) = 0.0009242750733412596 gradient norm = 5.199194093326536e-05\n",
      "Iteration 262 : x = [1.99546476 1.50395466] f(x) = 0.0009242723974846902 gradient norm = 5.094158536753365e-05\n",
      "Iteration 263 : x = [1.99546997 1.50400534] f(x) = 0.0009242698286508586 gradient norm = 4.991252560059111e-05\n",
      "Iteration 264 : x = [1.99547508 1.50405499] f(x) = 0.0009242673625518221 gradient norm = 4.8904326815025994e-05\n",
      "Iteration 265 : x = [1.99548008 1.50410363] f(x) = 0.0009242649950718819 gradient norm = 4.7916563193429345e-05\n",
      "Iteration 266 : x = [1.99548498 1.5041513 ] f(x) = 0.0009242627222606381 gradient norm = 4.6948817727221675e-05\n",
      "Iteration 267 : x = [1.99548979 1.504198  ] f(x) = 0.0009242605403263276 gradient norm = 4.600068202977164e-05\n",
      "Iteration 268 : x = [1.99549449 1.50424376] f(x) = 0.0009242584456294284 gradient norm = 4.507175615365055e-05\n",
      "Iteration 269 : x = [1.9954991 1.5042886] f(x) = 0.0009242564346765246 gradient norm = 4.416164841192996e-05\n",
      "Iteration 270 : x = [1.99550361 1.50433253] f(x) = 0.0009242545041144218 gradient norm = 4.326997520344289e-05\n",
      "Iteration 271 : x = [1.99550804 1.50437557] f(x) = 0.0009242526507244999 gradient norm = 4.2396360841901144e-05\n",
      "Iteration 272 : x = [1.99551237 1.50441774] f(x) = 0.0009242508714172918 gradient norm = 4.15404373887931e-05\n",
      "Iteration 273 : x = [1.99551662 1.50445907] f(x) = 0.0009242491632272848 gradient norm = 4.070184448993888e-05\n",
      "Iteration 274 : x = [1.99552078 1.50449956] f(x) = 0.0009242475233079316 gradient norm = 3.988022921566447e-05\n",
      "Iteration 275 : x = [1.99552486 1.50453923] f(x) = 0.0009242459489268622 gradient norm = 3.907524590445449e-05\n",
      "Iteration 276 : x = [1.99552885 1.5045781 ] f(x) = 0.00092424443746129 gradient norm = 3.828655601005393e-05\n",
      "Iteration 277 : x = [1.99553277 1.50461618] f(x) = 0.0009242429863936029 gradient norm = 3.751382795190603e-05\n",
      "Iteration 278 : x = [1.9955366 1.5046535] f(x) = 0.0009242415933071336 gradient norm = 3.6756736968850534e-05\n",
      "Iteration 279 : x = [1.99554036 1.50469007] f(x) = 0.0009242402558821 gradient norm = 3.601496497602957e-05\n",
      "Iteration 280 : x = [1.99554404 1.50472589] f(x) = 0.0009242389718917107 gradient norm = 3.528820042488914e-05\n",
      "Iteration 281 : x = [1.99554764 1.504761  ] f(x) = 0.0009242377391984256 gradient norm = 3.4576138166248715e-05\n",
      "Iteration 282 : x = [1.99555118 1.50479539] f(x) = 0.0009242365557503697 gradient norm = 3.387847931630725e-05\n",
      "Iteration 283 : x = [1.99555464 1.50482909] f(x) = 0.0009242354195778898 gradient norm = 3.319493112559692e-05\n",
      "Iteration 284 : x = [1.99555803 1.50486211] f(x) = 0.000924234328790251 gradient norm = 3.252520685075994e-05\n",
      "Iteration 285 : x = [1.99556135 1.50489447] f(x) = 0.0009242332815724688 gradient norm = 3.186902562906952e-05\n",
      "Iteration 286 : x = [1.99556461 1.50492617] f(x) = 0.0009242322761822626 gradient norm = 3.1226112355711136e-05\n",
      "Iteration 287 : x = [1.9955678  1.50495723] f(x) = 0.0009242313109471382 gradient norm = 3.059619756367354e-05\n",
      "Iteration 288 : x = [1.99557093 1.50498767] f(x) = 0.0009242303842615865 gradient norm = 2.9979017306227163e-05\n",
      "Iteration 289 : x = [1.99557399 1.50501749] f(x) = 0.0009242294945843928 gradient norm = 2.9374313041947938e-05\n",
      "Iteration 290 : x = [1.99557699 1.50504671] f(x) = 0.0009242286404360564 gradient norm = 2.8781831522212876e-05\n",
      "Iteration 291 : x = [1.99557993 1.50507534] f(x) = 0.0009242278203963132 gradient norm = 2.820132468109219e-05\n",
      "Iteration 292 : x = [1.99558281 1.5051034 ] f(x) = 0.0009242270331017604 gradient norm = 2.763254952759963e-05\n",
      "Iteration 293 : x = [1.99558563 1.50513088] f(x) = 0.000924226277243572 gradient norm = 2.7075268040283898e-05\n",
      "Iteration 294 : x = [1.9955884  1.50515782] f(x) = 0.0009242255515653125 gradient norm = 2.6529247064025217e-05\n",
      "Iteration 295 : x = [1.99559111 1.50518421] f(x) = 0.0009242248548608337 gradient norm = 2.5994258209079862e-05\n",
      "Iteration 296 : x = [1.99559376 1.50521007] f(x) = 0.0009242241859722573 gradient norm = 2.547007775224535e-05\n",
      "Iteration 297 : x = [1.99559636 1.5052354 ] f(x) = 0.000924223543788041 gradient norm = 2.4956486540145784e-05\n",
      "Iteration 298 : x = [1.99559891 1.50526023] f(x) = 0.0009242229272411178 gradient norm = 2.4453269894587586e-05\n",
      "Iteration 299 : x = [1.99560141 1.50528456] f(x) = 0.000924222335307116 gradient norm = 2.396021751990889e-05\n",
      "Iteration 300 : x = [1.99560386 1.50530839] f(x) = 0.0009242217670026456 gradient norm = 2.3477123412295268e-05\n",
      "Iteration 301 : x = [1.99560625 1.50533175] f(x) = 0.0009242212213836563 gradient norm = 2.3003785771043342e-05\n",
      "Iteration 302 : x = [1.9956086  1.50535463] f(x) = 0.0009242206975438605 gradient norm = 2.2540006911683314e-05\n",
      "Iteration 303 : x = [1.9956109  1.50537705] f(x) = 0.0009242201946132213 gradient norm = 2.2085593180941913e-05\n",
      "Iteration 304 : x = [1.99561316 1.50539902] f(x) = 0.000924219711756497 gradient norm = 2.1640354873527543e-05\n",
      "Iteration 305 : x = [1.99561537 1.50542055] f(x) = 0.0009242192481718511 gradient norm = 2.1204106150636423e-05\n",
      "Iteration 306 : x = [1.99561753 1.50544164] f(x) = 0.0009242188030895108 gradient norm = 2.0776664960229274e-05\n",
      "Iteration 307 : x = [1.99561965 1.50546231] f(x) = 0.0009242183757704837 gradient norm = 2.0357852958936587e-05\n",
      "Iteration 308 : x = [1.99562173 1.50548256] f(x) = 0.0009242179655053263 gradient norm = 1.9947495435639848e-05\n",
      "Iteration 309 : x = [1.99562377 1.5055024 ] f(x) = 0.0009242175716129578 gradient norm = 1.9545421236675857e-05\n",
      "Iteration 310 : x = [1.99562576 1.50552185] f(x) = 0.0009242171934395273 gradient norm = 1.9151462692582565e-05\n",
      "Iteration 311 : x = [1.99562772 1.5055409 ] f(x) = 0.0009242168303573216 gradient norm = 1.8765455546391554e-05\n",
      "Iteration 312 : x = [1.99562963 1.50555957] f(x) = 0.0009242164817637197 gradient norm = 1.8387238883450326e-05\n",
      "Iteration 313 : x = [1.99563151 1.50557786] f(x) = 0.0009242161470801879 gradient norm = 1.8016655062695478e-05\n",
      "Iteration 314 : x = [1.99563335 1.50559578] f(x) = 0.0009242158257513147 gradient norm = 1.765354964937878e-05\n",
      "Iteration 315 : x = [1.99563515 1.50561334] f(x) = 0.0009242155172438877 gradient norm = 1.7297771349175424e-05\n",
      "Iteration 316 : x = [1.99563692 1.50563055] f(x) = 0.000924215221046003 gradient norm = 1.6949171943730558e-05\n",
      "Iteration 317 : x = [1.99563865 1.50564741] f(x) = 0.0009242149366662133 gradient norm = 1.6607606227489726e-05\n",
      "Iteration 318 : x = [1.99564034 1.50566393] f(x) = 0.0009242146636327091 gradient norm = 1.6272931945897135e-05\n",
      "Iteration 319 : x = [1.995642   1.50568012] f(x) = 0.0009242144014925331 gradient norm = 1.5945009734843446e-05\n",
      "Iteration 320 : x = [1.99564363 1.50569598] f(x) = 0.0009242141498108266 gradient norm = 1.562370306142314e-05\n",
      "Iteration 321 : x = [1.99564523 1.50571152] f(x) = 0.0009242139081701038 gradient norm = 1.5308878165893064e-05\n",
      "Iteration 322 : x = [1.99564679 1.50572675] f(x) = 0.0009242136761695585 gradient norm = 1.5000404004870567e-05\n",
      "Iteration 323 : x = [1.99564832 1.50574167] f(x) = 0.0009242134534243961 gradient norm = 1.46981521956677e-05\n",
      "Iteration 324 : x = [1.99564982 1.50575629] f(x) = 0.0009242132395651931 gradient norm = 1.4401996961839445e-05\n",
      "Iteration 325 : x = [1.99565129 1.50577062] f(x) = 0.0009242130342372832 gradient norm = 1.4111815079838167e-05\n",
      "Iteration 326 : x = [1.99565273 1.50578466] f(x) = 0.000924212837100166 gradient norm = 1.3827485826765644e-05\n",
      "Iteration 327 : x = [1.99565414 1.50579842] f(x) = 0.0009242126478269414 gradient norm = 1.3548890929230074e-05\n",
      "Iteration 328 : x = [1.99565552 1.50581189] f(x) = 0.0009242124661037663 gradient norm = 1.327591451325952e-05\n",
      "Iteration 329 : x = [1.99565688 1.5058251 ] f(x) = 0.0009242122916293297 gradient norm = 1.3008443055268537e-05\n",
      "Iteration 330 : x = [1.9956582  1.50583804] f(x) = 0.0009242121241143554 gradient norm = 1.2746365334006099e-05\n",
      "Iteration 331 : x = [1.9956595  1.50585072] f(x) = 0.0009242119632811201 gradient norm = 1.248957238353006e-05\n",
      "Iteration 332 : x = [1.99566078 1.50586314] f(x) = 0.0009242118088629875 gradient norm = 1.2237957447148633e-05\n",
      "Iteration 333 : x = [1.99566203 1.50587532] f(x) = 0.000924211660603972 gradient norm = 1.1991415932320403e-05\n",
      "Iteration 334 : x = [1.99566325 1.50588725] f(x) = 0.0009242115182583066 gradient norm = 1.1749845366463757e-05\n",
      "Iteration 335 : x = [1.99566445 1.50589894] f(x) = 0.0009242113815900388 gradient norm = 1.1513145353719925e-05\n",
      "Iteration 336 : x = [1.99566562 1.50591039] f(x) = 0.000924211250372636 gradient norm = 1.1281217532566791e-05\n",
      "Iteration 337 : x = [1.99566678 1.50592161] f(x) = 0.0009242111243886101 gradient norm = 1.1053965534347903e-05\n",
      "Iteration 338 : x = [1.9956679  1.50593261] f(x) = 0.0009242110034291557 gradient norm = 1.0831294942619563e-05\n",
      "Iteration 339 : x = [1.99566901 1.50594338] f(x) = 0.0009242108872938039 gradient norm = 1.0613113253384506e-05\n",
      "Iteration 340 : x = [1.99567009 1.50595394] f(x) = 0.0009242107757900874 gradient norm = 1.0399329836086888e-05\n",
      "Iteration 341 : x = [1.99567115 1.50596429] f(x) = 0.0009242106687332233 gradient norm = 1.0189855895465687e-05\n",
      "Iteration 342 : x = [1.99567219 1.50597442] f(x) = 0.0009242105659458041 gradient norm = 9.984604434167483e-06\n",
      "Iteration 343 : x = [1.99567321 1.50598435] f(x) = 0.000924210467257504 gradient norm = 9.7834902161241e-06\n",
      "Iteration 344 : x = [1.99567421 1.50599409] f(x) = 0.0009242103725047951 gradient norm = 9.586429730708e-06\n",
      "Iteration 345 : x = [1.99567519 1.50600362] f(x) = 0.0009242102815306772 gradient norm = 9.393341157599507e-06\n",
      "Iteration 346 : x = [1.99567614 1.50601297] f(x) = 0.0009242101941844161 gradient norm = 9.204144332391623e-06\n",
      "Iteration 347 : x = [1.99567708 1.50602212] f(x) = 0.0009242101103212943 gradient norm = 9.018760712906688e-06\n",
      "Iteration 348 : x = [1.995678  1.5060311] f(x) = 0.000924210029802368 gradient norm = 8.837113346189051e-06\n",
      "Iteration 349 : x = [1.99567891 1.50603989] f(x) = 0.0009242099524942409 gradient norm = 8.659126836187383e-06\n",
      "Iteration 350 : x = [1.99567979 1.5060485 ] f(x) = 0.0009242098782688385 gradient norm = 8.484727312101615e-06\n",
      "Iteration 351 : x = [1.99568065 1.50605694] f(x) = 0.0009242098070031985 gradient norm = 8.313842397378488e-06\n",
      "Iteration 352 : x = [1.9956815  1.50606521] f(x) = 0.0009242097385792645 gradient norm = 8.14640117932194e-06\n",
      "Iteration 353 : x = [1.99568233 1.50607332] f(x) = 0.0009242096728836915 gradient norm = 7.982334179378045e-06\n",
      "Iteration 354 : x = [1.99568315 1.50608126] f(x) = 0.0009242096098076573 gradient norm = 7.821573323968843e-06\n",
      "Iteration 355 : x = [1.99568395 1.50608904] f(x) = 0.0009242095492466816 gradient norm = 7.66405191596689e-06\n",
      "Iteration 356 : x = [1.99568473 1.50609666] f(x) = 0.000924209491100454 gradient norm = 7.509704606745611e-06\n",
      "Iteration 357 : x = [1.99568549 1.50610413] f(x) = 0.0009242094352726653 gradient norm = 7.358467368783152e-06\n",
      "Iteration 358 : x = [1.99568624 1.50611145] f(x) = 0.0009242093816708491 gradient norm = 7.210277468839776e-06\n",
      "Iteration 359 : x = [1.99568698 1.50611862] f(x) = 0.0009242093302062295 gradient norm = 7.065073441709017e-06\n",
      "Iteration 360 : x = [1.9956877  1.50612565] f(x) = 0.0009242092807935711 gradient norm = 6.922795064452065e-06\n",
      "Iteration 361 : x = [1.99568841 1.50613254] f(x) = 0.00092420923335104 gradient norm = 6.783383331214207e-06\n",
      "Iteration 362 : x = [1.9956891  1.50613929] f(x) = 0.0009242091878000664 gradient norm = 6.646780428513214e-06\n",
      "Iteration 363 : x = [1.99568978 1.5061459 ] f(x) = 0.0009242091440652151 gradient norm = 6.512929711060724e-06\n",
      "Iteration 364 : x = [1.99569044 1.50615238] f(x) = 0.0009242091020740608 gradient norm = 6.38177567807513e-06\n",
      "Iteration 365 : x = [1.99569109 1.50615873] f(x) = 0.0009242090617570673 gradient norm = 6.253263950055375e-06\n",
      "Iteration 366 : x = [1.99569173 1.50616495] f(x) = 0.000924209023047472 gradient norm = 6.127341246061786e-06\n",
      "Iteration 367 : x = [1.99569235 1.50617104] f(x) = 0.0009242089858811756 gradient norm = 6.003955361424207e-06\n",
      "Iteration 368 : x = [1.99569297 1.50617702] f(x) = 0.0009242089501966358 gradient norm = 5.883055145957535e-06\n",
      "Iteration 369 : x = [1.99569357 1.50618287] f(x) = 0.0009242089159347652 gradient norm = 5.764590482553423e-06\n",
      "Iteration 370 : x = [1.99569415 1.5061886 ] f(x) = 0.0009242088830388338 gradient norm = 5.64851226627849e-06\n",
      "Iteration 371 : x = [1.99569473 1.50619422] f(x) = 0.0009242088514543741 gradient norm = 5.534772383838007e-06\n",
      "Iteration 372 : x = [1.99569529 1.50619973] f(x) = 0.0009242088211290905 gradient norm = 5.423323693507722e-06\n",
      "Iteration 373 : x = [1.99569585 1.50620512] f(x) = 0.0009242087920127745 gradient norm = 5.314120005433593e-06\n",
      "Iteration 374 : x = [1.99569639 1.50621041] f(x) = 0.0009242087640572199 gradient norm = 5.207116062365652e-06\n",
      "Iteration 375 : x = [1.99569692 1.50621559] f(x) = 0.0009242087372161416 gradient norm = 5.102267520780173e-06\n",
      "Iteration 376 : x = [1.99569744 1.50622066] f(x) = 0.000924208711445103 gradient norm = 4.9995309323499704e-06\n",
      "Iteration 377 : x = [1.99569795 1.50622564] f(x) = 0.0009242086867014379 gradient norm = 4.898863725845547e-06\n",
      "Iteration 378 : x = [1.99569845 1.50623051] f(x) = 0.0009242086629441834 gradient norm = 4.800224189357145e-06\n",
      "Iteration 379 : x = [1.99569894 1.50623529] f(x) = 0.0009242086401340087 gradient norm = 4.70357145293009e-06\n",
      "Iteration 380 : x = [1.99569942 1.50623997] f(x) = 0.0009242086182331528 gradient norm = 4.6088654714888895e-06\n",
      "Iteration 381 : x = [1.99569989 1.50624455] f(x) = 0.00092420859720536 gradient norm = 4.516067008174704e-06\n",
      "Iteration 382 : x = [1.99570035 1.50624904] f(x) = 0.0009242085770158204 gradient norm = 4.4251376179623e-06\n",
      "Iteration 383 : x = [1.9957008  1.50625345] f(x) = 0.0009242085576311132 gradient norm = 4.336039631669075e-06\n",
      "Iteration 384 : x = [1.99570124 1.50625776] f(x) = 0.0009242085390191494 gradient norm = 4.248736140232311e-06\n",
      "Iteration 385 : x = [1.99570168 1.50626199] f(x) = 0.0009242085211491198 gradient norm = 4.163190979346871e-06\n",
      "Iteration 386 : x = [1.9957021  1.50626613] f(x) = 0.0009242085039914454 gradient norm = 4.079368714406954e-06\n",
      "Iteration 387 : x = [1.99570252 1.50627018] f(x) = 0.0009242084875177238 gradient norm = 3.99723462572708e-06\n",
      "Iteration 388 : x = [1.99570292 1.50627416] f(x) = 0.0009242084717006881 gradient norm = 3.916754694102889e-06\n",
      "Iteration 389 : x = [1.99570332 1.50627806] f(x) = 0.0009242084565141567 gradient norm = 3.837895586641295e-06\n",
      "Iteration 390 : x = [1.99570372 1.50628188] f(x) = 0.0009242084419329933 gradient norm = 3.7606246428820043e-06\n",
      "Iteration 391 : x = [1.9957041  1.50628562] f(x) = 0.0009242084279330632 gradient norm = 3.684909861201523e-06\n",
      "Iteration 392 : x = [1.99570447 1.50628928] f(x) = 0.0009242084144911941 gradient norm = 3.610719885498365e-06\n",
      "Iteration 393 : x = [1.99570484 1.50629287] f(x) = 0.0009242084015851386 gradient norm = 3.5380239921455114e-06\n",
      "Iteration 394 : x = [1.9957052  1.50629639] f(x) = 0.0009242083891935349 gradient norm = 3.46679207719993e-06\n",
      "Iteration 395 : x = [1.99570556 1.50629984] f(x) = 0.0009242083772958743 gradient norm = 3.396994643882744e-06\n",
      "Iteration 396 : x = [1.9957059  1.50630322] f(x) = 0.0009242083658724651 gradient norm = 3.328602790316687e-06\n",
      "Iteration 397 : x = [1.99570624 1.50630653] f(x) = 0.0009242083549044013 gradient norm = 3.2615881974851653e-06\n",
      "Iteration 398 : x = [1.99570658 1.50630978] f(x) = 0.00092420834437353 gradient norm = 3.195923117478398e-06\n",
      "Iteration 399 : x = [1.9957069  1.50631296] f(x) = 0.0009242083342624227 gradient norm = 3.1315803619404133e-06\n",
      "Iteration 400 : x = [1.99570722 1.50631607] f(x) = 0.0009242083245543459 gradient norm = 3.0685332907615205e-06\n",
      "Iteration 401 : x = [1.99570753 1.50631912] f(x) = 0.0009242083152332325 gradient norm = 3.0067558010237743e-06\n",
      "Iteration 402 : x = [1.99570784 1.50632212] f(x) = 0.0009242083062836566 gradient norm = 2.946222316119589e-06\n",
      "Iteration 403 : x = [1.99570814 1.50632505] f(x) = 0.0009242082976908076 gradient norm = 2.8869077751516475e-06\n",
      "Iteration 404 : x = [1.99570844 1.50632792] f(x) = 0.0009242082894404649 gradient norm = 2.828787622497591e-06\n",
      "Iteration 405 : x = [1.99570872 1.50633073] f(x) = 0.0009242082815189752 gradient norm = 2.7718377976112423e-06\n",
      "Iteration 406 : x = [1.99570901 1.50633349] f(x) = 0.000924208273913229 gradient norm = 2.7160347250260136e-06\n",
      "Iteration 407 : x = [1.99570928 1.50633619] f(x) = 0.0009242082666106401 gradient norm = 2.6613553045667117e-06\n",
      "Iteration 408 : x = [1.99570955 1.50633884] f(x) = 0.0009242082595991236 gradient norm = 2.607776901728369e-06\n",
      "Iteration 409 : x = [1.99570982 1.50634143] f(x) = 0.0009242082528670767 gradient norm = 2.5552773383009035e-06\n",
      "Iteration 410 : x = [1.99571008 1.50634398] f(x) = 0.0009242082464033593 gradient norm = 2.5038348831555005e-06\n",
      "Iteration 411 : x = [1.99571034 1.50634647] f(x) = 0.0009242082401972753 gradient norm = 2.4534282432025367e-06\n",
      "Iteration 412 : x = [1.99571059 1.50634891] f(x) = 0.0009242082342385547 gradient norm = 2.404036554557016e-06\n",
      "Iteration 413 : x = [1.99571083 1.5063513 ] f(x) = 0.0009242082285173371 gradient norm = 2.3556393738792583e-06\n",
      "Iteration 414 : x = [1.99571107 1.50635364] f(x) = 0.0009242082230241558 gradient norm = 2.308216669878883e-06\n",
      "Iteration 415 : x = [1.99571131 1.50635594] f(x) = 0.0009242082177499205 gradient norm = 2.26174881500797e-06\n",
      "Iteration 416 : x = [1.99571154 1.50635819] f(x) = 0.0009242082126859042 gradient norm = 2.2162165773026296e-06\n",
      "Iteration 417 : x = [1.99571176 1.50636039] f(x) = 0.0009242082078237273 gradient norm = 2.17160111241142e-06\n",
      "Iteration 418 : x = [1.99571199 1.50636255] f(x) = 0.0009242082031553439 gradient norm = 2.127883955759451e-06\n",
      "Iteration 419 : x = [1.9957122  1.50636467] f(x) = 0.0009242081986730297 gradient norm = 2.0850470148910113e-06\n",
      "Iteration 420 : x = [1.99571241 1.50636674] f(x) = 0.0009242081943693681 gradient norm = 2.0430725619735384e-06\n",
      "Iteration 421 : x = [1.99571262 1.50636878] f(x) = 0.0009242081902372376 gradient norm = 2.001943226420164e-06\n",
      "Iteration 422 : x = [1.99571283 1.50637077] f(x) = 0.0009242081862698014 gradient norm = 1.9616419876953454e-06\n",
      "Iteration 423 : x = [1.99571303 1.50637272] f(x) = 0.0009242081824604945 gradient norm = 1.922152168241728e-06\n",
      "Iteration 424 : x = [1.99571322 1.50637463] f(x) = 0.0009242081788030142 gradient norm = 1.883457426573402e-06\n",
      "Iteration 425 : x = [1.99571342 1.5063765 ] f(x) = 0.0009242081752913085 gradient norm = 1.8455417504910091e-06\n",
      "Iteration 426 : x = [1.9957136  1.50637834] f(x) = 0.0009242081719195671 gradient norm = 1.8083894504394921e-06\n",
      "Iteration 427 : x = [1.99571379 1.50638014] f(x) = 0.0009242081686822116 gradient norm = 1.771985153000513e-06\n",
      "Iteration 428 : x = [1.99571397 1.5063819 ] f(x) = 0.000924208165573885 gradient norm = 1.7363137945138558e-06\n",
      "Iteration 429 : x = [1.99571415 1.50638363] f(x) = 0.000924208162589444 gradient norm = 1.701360614825633e-06\n",
      "Iteration 430 : x = [1.99571432 1.50638532] f(x) = 0.0009242081597239516 gradient norm = 1.6671111511779337e-06\n",
      "Iteration 431 : x = [1.99571449 1.50638698] f(x) = 0.0009242081569726658 gradient norm = 1.6335512322112854e-06\n",
      "Iteration 432 : x = [1.99571466 1.50638861] f(x) = 0.0009242081543310353 gradient norm = 1.6006669720680468e-06\n",
      "Iteration 433 : x = [1.99571482 1.5063902 ] f(x) = 0.0009242081517946889 gradient norm = 1.568444764664918e-06\n",
      "Iteration 434 : x = [1.99571498 1.50639176] f(x) = 0.0009242081493594308 gradient norm = 1.5368712780223376e-06\n",
      "Iteration 435 : x = [1.99571514 1.50639329] f(x) = 0.0009242081470212313 gradient norm = 1.505933448758925e-06\n",
      "Iteration 436 : x = [1.99571529 1.50639479] f(x) = 0.000924208144776222 gradient norm = 1.4756184766603835e-06\n",
      "Iteration 437 : x = [1.99571544 1.50639625] f(x) = 0.0009242081426206883 gradient norm = 1.4459138193881512e-06\n",
      "Iteration 438 : x = [1.99571559 1.50639769] f(x) = 0.0009242081405510645 gradient norm = 1.4168071872557299e-06\n",
      "Iteration 439 : x = [1.99571573 1.5063991 ] f(x) = 0.0009242081385639256 gradient norm = 1.3882865381694413e-06\n",
      "Iteration 440 : x = [1.99571587 1.50640048] f(x) = 0.000924208136655985 gradient norm = 1.3603400726110276e-06\n",
      "Iteration 441 : x = [1.99571601 1.50640184] f(x) = 0.0009242081348240856 gradient norm = 1.3329562287480627e-06\n",
      "Iteration 442 : x = [1.99571615 1.50640316] f(x) = 0.0009242081330651969 gradient norm = 1.3061236776575844e-06\n",
      "Iteration 443 : x = [1.99571628 1.50640446] f(x) = 0.0009242081313764082 gradient norm = 1.2798313186071002e-06\n",
      "Iteration 444 : x = [1.99571641 1.50640573] f(x) = 0.0009242081297549264 gradient norm = 1.254068274483289e-06\n",
      "Iteration 445 : x = [1.99571654 1.50640698] f(x) = 0.000924208128198068 gradient norm = 1.2288238872669138e-06\n",
      "Iteration 446 : x = [1.99571666 1.5064082 ] f(x) = 0.0009242081267032582 gradient norm = 1.2040877136136953e-06\n",
      "Iteration 447 : x = [1.99571679 1.5064094 ] f(x) = 0.0009242081252680235 gradient norm = 1.1798495205401982e-06\n",
      "Iteration 448 : x = [1.99571691 1.50641058] f(x) = 0.0009242081238899893 gradient norm = 1.156099281167736e-06\n",
      "Iteration 449 : x = [1.99571702 1.50641173] f(x) = 0.0009242081225668764 gradient norm = 1.1328271705861913e-06\n",
      "Iteration 450 : x = [1.99571714 1.50641285] f(x) = 0.0009242081212964953 gradient norm = 1.11002356176772e-06\n",
      "Iteration 451 : x = [1.99571725 1.50641396] f(x) = 0.0009242081200767443 gradient norm = 1.0876790215904216e-06\n",
      "Iteration 452 : x = [1.99571736 1.50641504] f(x) = 0.0009242081189056058 gradient norm = 1.0657843069166278e-06\n",
      "Iteration 453 : x = [1.99571747 1.5064161 ] f(x) = 0.0009242081177811423 gradient norm = 1.0443303607781216e-06\n",
      "Iteration 454 : x = [1.99571758 1.50641714] f(x) = 0.0009242081167014935 gradient norm = 1.0233083086193148e-06\n",
      "Iteration 455 : x = [1.99571768 1.50641816] f(x) = 0.0009242081156648731 gradient norm = 1.0027094546128617e-06\n",
      "Iteration 456 : x = [1.99571779 1.50641915] f(x) = 0.0009242081146695662 gradient norm = 9.825252780769442e-07\n",
      "Completed in 456 iterations\n",
      "\n",
      "\tStep size: 10\n",
      "Iteration 0 : x = [1.  0.5] f(x) = 0.11204289613814822 gradient norm = 0.16286411890444852\n",
      "Iteration 1 : x = [2.52225494 1.07897497] f(x) = 0.03297518381628216 gradient norm = 0.1026229039921045\n",
      "Iteration 2 : x = [1.53175519 1.34740798] f(x) = 0.02018798366930032 gradient norm = 0.0834984848136996\n",
      "Iteration 3 : x = [2.36663541 1.36062563] f(x) = 0.014550487122493752 gradient norm = 0.06933056399007932\n",
      "Iteration 4 : x = [1.68356105 1.47929379] f(x) = 0.009679650572145608 gradient norm = 0.05621359625143872\n",
      "Iteration 5 : x = [2.2452764  1.45755197] f(x) = 0.006771401570407506 gradient norm = 0.045853917830979106\n",
      "Iteration 6 : x = [1.79090986 1.51927088] f(x) = 0.004764775770348937 gradient norm = 0.03730705274296187\n",
      "Iteration 7 : x = [2.1630621  1.49311117] f(x) = 0.003487520288000109 gradient norm = 0.03045628276212984\n",
      "Iteration 8 : x = [1.86048086 1.52779704] f(x) = 0.0026285770030769684 gradient norm = 0.024883528588231948\n",
      "Iteration 9 : x = [2.10831552 1.50550396] f(x) = 0.0020696070048897715 gradient norm = 0.02038396790966268\n",
      "Iteration 10 : x = [1.9055222  1.52613128] f(x) = 0.0016925134791755479 gradient norm = 0.01671677340822635\n",
      "Iteration 11 : x = [2.07181857 1.5090852 ] f(x) = 0.0014438564368652181 gradient norm = 0.013738319942078926\n",
      "Iteration 12 : x = [1.93503498 1.52190672] f(x) = 0.0012751007831297981 gradient norm = 0.011300570261067015\n",
      "Iteration 13 : x = [2.04735756 1.50950003] f(x) = 0.0011626733358758496 gradient norm = 0.00931050686270939\n",
      "Iteration 14 : x = [1.95461837 1.51774601] f(x) = 0.0010860282883230613 gradient norm = 0.007675624658919948\n",
      "Iteration 15 : x = [2.03086918 1.50895199] f(x) = 0.0010345458268667396 gradient norm = 0.006335394045302452\n",
      "Iteration 16 : x = [1.96774915 1.51439107] f(x) = 0.000999348410605043 gradient norm = 0.0052312914120902845\n",
      "Iteration 17 : x = [2.01970081 1.50825376] f(x) = 0.0009755571663390749 gradient norm = 0.004323279512109985\n",
      "Iteration 18 : x = [1.9766226 1.5119065] f(x) = 0.0009592640138452718 gradient norm = 0.0035737904329865644\n",
      "Iteration 19 : x = [2.01210779 1.50766394] f(x) = 0.0009481997735818928 gradient norm = 0.0029559752753216357\n",
      "Iteration 20 : x = [1.98265254 1.51014739] f(x) = 0.0009406151820002831 gradient norm = 0.0024453533759661193\n",
      "Iteration 21 : x = [2.00693168 1.50723213] f(x) = 0.0009354476563653523 gradient norm = 0.0020237506405489138\n",
      "Iteration 22 : x = [1.98676589 1.50893435] f(x) = 0.0009319033618595806 gradient norm = 0.0016749985909046922\n",
      "Iteration 23 : x = [2.00339656 1.50693869] f(x) = 0.0009294829939542935 gradient norm = 0.0013867226245917773\n",
      "Iteration 24 : x = [1.98957902 1.50811146] f(x) = 0.0009278224215613249 gradient norm = 0.0011481269283255373\n",
      "Iteration 25 : x = [2.0009791  1.50674852] f(x) = 0.0009266866301178555 gradient norm = 0.000950755865278704\n",
      "Iteration 26 : x = [1.99150616 1.50755904] f(x) = 0.0009259072600298934 gradient norm = 0.0007873409930370175\n",
      "Iteration 27 : x = [1.99932451 1.50662953] f(x) = 0.0009253736119824733 gradient norm = 0.000652092555209318\n",
      "Iteration 28 : x = [1.99282777 1.50719068] f(x) = 0.0009250073976159694 gradient norm = 0.000540087431658515\n",
      "Iteration 29 : x = [1.99819137 1.50655726] f(x) = 0.0009247564597346609 gradient norm = 0.0004473565739467951\n",
      "Iteration 30 : x = [1.99373474 1.50694609] f(x) = 0.0009245842474597634 gradient norm = 0.0003705512576443694\n",
      "Iteration 31 : x = [1.99741504 1.5065146 ] f(x) = 0.000924466184984422 gradient norm = 0.0003069488102732394\n",
      "Iteration 32 : x = [1.99435741 1.50678411] f(x) = 0.0009243851601784896 gradient norm = 0.0002542647502705321\n",
      "Iteration 33 : x = [1.99688301 1.50649021] f(x) = 0.0009243295936618958 gradient norm = 0.000210630745135201\n",
      "Iteration 34 : x = [1.994785   1.50667699] f(x) = 0.0009242914587188866 gradient norm = 0.00017448523095201301\n",
      "Iteration 35 : x = [1.99651833 1.50647678] f(x) = 0.0009242652998627362 gradient norm = 0.00014454591507503562\n",
      "Iteration 36 : x = [1.99507868 1.5066062 ] f(x) = 0.0009242473471291849 gradient norm = 0.00011974395258562223\n",
      "Iteration 37 : x = [1.99626832 1.50646979] f(x) = 0.000924235030408735 gradient norm = 9.919920148316373e-05\n",
      "Iteration 38 : x = [1.99528039 1.50655942] f(x) = 0.0009242265774611774 gradient norm = 8.217940951284655e-05\n",
      "Iteration 39 : x = [1.9960969  1.50646645] f(x) = 0.0009242207775654237 gradient norm = 6.808044860855594e-05\n",
      "Iteration 40 : x = [1.99541893 1.50652849] f(x) = 0.0009242167970945312 gradient norm = 5.640035964974522e-05\n",
      "Iteration 41 : x = [1.99597936 1.50646511] f(x) = 0.0009242140657307563 gradient norm = 4.6724470217511726e-05\n",
      "Iteration 42 : x = [1.9955141  1.50650803] f(x) = 0.0009242121911890039 gradient norm = 3.8708548723847586e-05\n",
      "Iteration 43 : x = [1.99589876 1.50646481] f(x) = 0.0009242109048261636 gradient norm = 3.2067967914884435e-05\n",
      "Iteration 44 : x = [1.99557946 1.50649449] f(x) = 0.0009242100219891394 gradient norm = 2.6566598551838623e-05\n",
      "Iteration 45 : x = [1.99584348 1.50646501] f(x) = 0.0009242094161386196 gradient norm = 2.200907797780398e-05\n",
      "Iteration 46 : x = [1.99562435 1.50648552] f(x) = 0.0009242090003389403 gradient norm = 1.8233401809930702e-05\n",
      "Iteration 47 : x = [1.99580557 1.5064654 ] f(x) = 0.0009242087149868423 gradient norm = 1.510547878561819e-05\n",
      "Iteration 48 : x = [1.99565518 1.50647957] f(x) = 0.000924208519146834 gradient norm = 1.2514147019324651e-05\n",
      "Iteration 49 : x = [1.99577957 1.50646583] f(x) = 0.0009242083847444052 gradient norm = 1.0367371290382263e-05\n",
      "Iteration 50 : x = [1.99567635 1.50647561] f(x) = 0.0009242082925023098 gradient norm = 8.588869964220887e-06\n",
      "Iteration 51 : x = [1.99576173 1.50646623] f(x) = 0.0009242082291968165 gradient norm = 7.115474145659195e-06\n",
      "Iteration 52 : x = [1.9956909  1.50647298] f(x) = 0.0009242081857492867 gradient norm = 5.894834935577963e-06\n",
      "Iteration 53 : x = [1.99574949 1.50646657] f(x) = 0.0009242081559310274 gradient norm = 4.8835963431568155e-06\n",
      "Iteration 54 : x = [1.99570088 1.50647123] f(x) = 0.0009242081354662253 gradient norm = 4.045832197246089e-06\n",
      "Iteration 55 : x = [1.9957411  1.50646685] f(x) = 0.000924208121421005 gradient norm = 3.351785274775039e-06\n",
      "Iteration 56 : x = [1.99570774 1.50647007] f(x) = 0.0009242081117814876 gradient norm = 2.7767994399352697e-06\n",
      "Iteration 57 : x = [1.99573534 1.50646707] f(x) = 0.0009242081051657348 gradient norm = 2.3004510210475113e-06\n",
      "Iteration 58 : x = [1.99571245 1.50646929] f(x) = 0.0009242081006251964 gradient norm = 1.9058182259210113e-06\n",
      "Iteration 59 : x = [1.99573139 1.50646724] f(x) = 0.0009242080975089361 gradient norm = 1.5788834464772714e-06\n",
      "Iteration 60 : x = [1.99571568 1.50646877] f(x) = 0.0009242080953701713 gradient norm = 1.30803292776317e-06\n",
      "Iteration 61 : x = [1.99572869 1.50646737] f(x) = 0.0009242080939022883 gradient norm = 1.0836458278071044e-06\n",
      "Iteration 62 : x = [1.9957179  1.50646842] f(x) = 0.0009242080928948425 gradient norm = 8.977513382059403e-07\n",
      "Completed in 62 iterations\n",
      "\n",
      "\tStep size: 100\n",
      "Iteration 0 : x = [1.  0.5] f(x) = 0.11204289613814822 gradient norm = 0.16286411890444852\n",
      "Iteration 1 : x = [16.22254941  6.28974971] f(x) = 0.15953847830810355 gradient norm = 1.666234572099103e-11\n",
      "Completed in 1 iterations\n",
      "\n",
      "--------------- Starting point: [0.5, 1] ---------------\n",
      "\n",
      "\tStep size: 0.1\n",
      "Iteration 0 : x = [0.5 1. ] f(x) = 0.15009253657239355 gradient norm = 0.09611715372728168\n",
      "Iteration 1 : x = [0.50924018 1.00264652] f(x) = 0.1491632968265689 gradient norm = 0.09724064703051918\n",
      "Iteration 2 : x = [0.51858313 1.00534221] f(x) = 0.1482121476595743 gradient norm = 0.09838914216466928\n",
      "Iteration 3 : x = [0.52803181 1.00808572] f(x) = 0.14723834556942536 gradient norm = 0.09956158154337673\n",
      "Iteration 4 : x = [0.53758908 1.01087561] f(x) = 0.1462411514474776 gradient norm = 0.10075682493664644\n",
      "Iteration 5 : x = [0.54725777 1.01371036] f(x) = 0.14521983294475604 gradient norm = 0.10197364426662608\n",
      "Iteration 6 : x = [0.55704058 1.01658838] f(x) = 0.1441736670976069 gradient norm = 0.10321071832862398\n",
      "Iteration 7 : x = [0.56694011 1.01950795] f(x) = 0.14310194322448497 gradient norm = 0.10446662749173016\n",
      "Iteration 8 : x = [0.57695884 1.02246729] f(x) = 0.14200396610429666 gradient norm = 0.10573984844085105\n",
      "Iteration 9 : x = [0.58709914 1.02546452] f(x) = 0.14087905944491225 gradient norm = 0.10702874902977244\n",
      "Iteration 10 : x = [0.59736324 1.02849766] f(x) = 0.13972656964820737 gradient norm = 0.10833158332294351\n",
      "Iteration 11 : x = [0.60775318 1.03156465] f(x) = 0.1385458698752386 gradient norm = 0.10964648691191003\n",
      "Iteration 12 : x = [0.61827087 1.03466332] f(x) = 0.13733636441186822 gradient norm = 0.11097147260057331\n",
      "Iteration 13 : x = [0.62891802 1.0377914 ] f(x) = 0.1360974933312913 gradient norm = 0.1123044265615246\n",
      "Iteration 14 : x = [0.63969614 1.04094653] f(x) = 0.1348287374454564 gradient norm = 0.11364310507338912\n",
      "Iteration 15 : x = [0.65060654 1.04412627] f(x) = 0.13352962353229514 gradient norm = 0.11498513195614762\n",
      "Iteration 16 : x = [0.66165029 1.04732807] f(x) = 0.13219972981998182 gradient norm = 0.11632799682749276\n",
      "Iteration 17 : x = [0.6728282  1.05054928] f(x) = 0.13083869170314816 gradient norm = 0.11766905430809535\n",
      "Iteration 18 : x = [0.68414085 1.05378718] f(x) = 0.12944620765911602 gradient norm = 0.1190055243068367\n",
      "Iteration 19 : x = [0.69558852 1.05703895] f(x) = 0.1280220453248388 gradient norm = 0.12033449351822437\n",
      "Iteration 20 : x = [0.7071712 1.0603017] f(x) = 0.12656604768745158 gradient norm = 0.12165291826294766\n",
      "Iteration 21 : x = [0.71888856 1.06357245] f(x) = 0.12507813933323514 gradient norm = 0.12295762879844263\n",
      "Iteration 22 : x = [0.73073995 1.06684815] f(x) = 0.12355833269154594 gradient norm = 0.12424533521902767\n",
      "Iteration 23 : x = [0.74272439 1.07012569] f(x) = 0.12200673420204083 gradient norm = 0.12551263505427923\n",
      "Iteration 24 : x = [0.75484053 1.0734019 ] f(x) = 0.12042355032554357 gradient norm = 0.126756022659527\n",
      "Iteration 25 : x = [0.76708663 1.07667355] f(x) = 0.11880909331140599 gradient norm = 0.1279719004734202\n",
      "Iteration 26 : x = [0.77946062 1.07993737] f(x) = 0.11716378662749129 gradient norm = 0.12915659219430567\n",
      "Iteration 27 : x = [0.79195999 1.08319008] f(x) = 0.11548816995324222 gradient norm = 0.13030635789964742\n",
      "Iteration 28 : x = [0.80458184 1.08642834] f(x) = 0.11378290363201503 gradient norm = 0.1314174111010293\n",
      "Iteration 29 : x = [0.81732286 1.08964884] f(x) = 0.11204877247627018 gradient norm = 0.13248593769171652\n",
      "Iteration 30 : x = [0.83017934 1.09284824] f(x) = 0.11028668881863746 gradient norm = 0.1335081167047811\n",
      "Iteration 31 : x = [0.84314714 1.09602322] f(x) = 0.108497694703596 gradient norm = 0.13448014275811096\n",
      "Iteration 32 : x = [0.85622168 1.09917049] f(x) = 0.10668296311879243 gradient norm = 0.13539825001908432\n",
      "Iteration 33 : x = [0.869398   1.10228682] f(x) = 0.10484379817205686 gradient norm = 0.1362587374773874\n",
      "Iteration 34 : x = [0.8826707 1.105369 ] f(x) = 0.10298163413010197 gradient norm = 0.13705799527061724\n",
      "Iteration 35 : x = [0.89603399 1.10841391] f(x) = 0.10109803324774301 gradient norm = 0.1377925317653422\n",
      "Iteration 36 : x = [0.90948167 1.11141852] f(x) = 0.09919468233220499 gradient norm = 0.1384590010576784\n",
      "Iteration 37 : x = [0.92300718 1.11437987] f(x) = 0.09727338800551377 gradient norm = 0.13905423052372262\n",
      "Iteration 38 : x = [0.93660358 1.11729515] f(x) = 0.09533607064881812 gradient norm = 0.1395752480228802\n",
      "Iteration 39 : x = [0.95026358 1.12016163] f(x) = 0.09338475703535018 gradient norm = 0.14001930833767554\n",
      "Iteration 40 : x = [0.9639796  1.12297676] f(x) = 0.09142157168308977 gradient norm = 0.1403839184232933\n",
      "Iteration 41 : x = [0.97774373 1.12573812] f(x) = 0.08944872698342483 gradient norm = 0.14066686103989395\n",
      "Iteration 42 : x = [0.99154782 1.12844346] f(x) = 0.08746851218749782 gradient norm = 0.14086621635139138\n",
      "Iteration 43 : x = [1.00538346 1.1310907 ] f(x) = 0.0854832813567312 gradient norm = 0.1409803810962036\n",
      "Iteration 44 : x = [1.01924206 1.13367794] f(x) = 0.0834954404074398 gradient norm = 0.14100808496841524\n",
      "Iteration 45 : x = [1.03311486 1.13620348] f(x) = 0.08150743340068564 gradient norm = 0.1409484038913069\n",
      "Iteration 46 : x = [1.04699295 1.13866582] f(x) = 0.0795217282468582 gradient norm = 0.14080076991833962\n",
      "Iteration 47 : x = [1.06086735 1.14106366] f(x) = 0.07754080200921386 gradient norm = 0.14056497755806524\n",
      "Iteration 48 : x = [1.07472901 1.14339589] f(x) = 0.07556712600122284 gradient norm = 0.14024118638730793\n",
      "Iteration 49 : x = [1.08856889 1.14566165] f(x) = 0.07360315087863706 gradient norm = 0.1398299198892785\n",
      "Iteration 50 : x = [1.10237795 1.14786026] f(x) = 0.07165129192846319 gradient norm = 0.13933206052778815\n",
      "Iteration 51 : x = [1.11614723 1.14999126] f(x) = 0.06971391475342267 gradient norm = 0.13874884114304117\n",
      "Iteration 52 : x = [1.12986787 1.1520544 ] f(x) = 0.06779332154211935 gradient norm = 0.13808183282625797\n",
      "Iteration 53 : x = [1.14353114 1.15404963] f(x) = 0.06589173810229951 gradient norm = 0.13733292949734086\n",
      "Iteration 54 : x = [1.1571285  1.15597711] f(x) = 0.06401130181773057 gradient norm = 0.13650432946992716\n",
      "Iteration 55 : x = [1.17065161 1.15783718] f(x) = 0.06215405066893011 gradient norm = 0.1355985143397326\n",
      "Iteration 56 : x = [1.18409237 1.15963037] f(x) = 0.0603219134349494 gradient norm = 0.13461822557373415\n",
      "Iteration 57 : x = [1.19744295 1.16135739] f(x) = 0.05851670116842856 gradient norm = 0.13356643920854025\n",
      "Iteration 58 : x = [1.21069582 1.16301911] f(x) = 0.05674010001000951 gradient norm = 0.1324463390857789\n",
      "Iteration 59 : x = [1.22384377 1.16461656] f(x) = 0.054993665381733545 gradient norm = 0.13126128906046447\n",
      "Iteration 60 : x = [1.23687991 1.16615091] f(x) = 0.05327881757304418 gradient norm = 0.13001480461548243\n",
      "Iteration 61 : x = [1.24979774 1.16762345] f(x) = 0.05159683870818078 gradient norm = 0.12871052430232416\n",
      "Iteration 62 : x = [1.26259108 1.16903563] f(x) = 0.04994887106070981 gradient norm = 0.12735218140609728\n",
      "Iteration 63 : x = [1.27525419 1.17038896] f(x) = 0.04833591666021686 gradient norm = 0.12594357620295896\n",
      "Iteration 64 : x = [1.28778168 1.17168506] f(x) = 0.04675883811816582 gradient norm = 0.1244885491419659\n",
      "Iteration 65 : x = [1.30016856 1.17292566] f(x) = 0.045218360584894805 gradient norm = 0.12299095524247516\n",
      "Iteration 66 : x = [1.31241026 1.17411251] f(x) = 0.04371507473780095 gradient norm = 0.12145463995426266\n",
      "Iteration 67 : x = [1.32450258 1.17524747] f(x) = 0.042249440691997577 gradient norm = 0.11988341668197683\n",
      "Iteration 68 : x = [1.33644173 1.17633239] f(x) = 0.040821792719027354 gradient norm = 0.118281046129836\n",
      "Iteration 69 : x = [1.3482243  1.17736921] f(x) = 0.03943234465641444 gradient norm = 0.11665121757787614\n",
      "Iteration 70 : x = [1.35984728 1.17835986] f(x) = 0.03808119589069752 gradient norm = 0.11499753215863444\n",
      "Iteration 71 : x = [1.37130802 1.17930629] f(x) = 0.036768337798807116 gradient norm = 0.11332348816379378\n",
      "Iteration 72 : x = [1.38260424 1.18021045] f(x) = 0.035493660536904906 gradient norm = 0.1116324683746704\n",
      "Iteration 73 : x = [1.39373402 1.18107431] f(x) = 0.03425696007174029 gradient norm = 0.10992772937896679\n",
      "Iteration 74 : x = [1.40469575 1.18189981] f(x) = 0.03305794535684526 gradient norm = 0.10821239280919434\n",
      "Iteration 75 : x = [1.41548818 1.18268886] f(x) = 0.03189624556414284 gradient norm = 0.10648943841569297\n",
      "Iteration 76 : x = [1.42611037 1.18344336] f(x) = 0.030771417290459895 gradient norm = 0.10476169886917198\n",
      "Iteration 77 : x = [1.43656164 1.18416517] f(x) = 0.02968295166772042 gradient norm = 0.10303185617399571\n",
      "Iteration 78 : x = [1.44684163 1.18485613] f(x) = 0.028630281314986964 gradient norm = 0.10130243956375003\n",
      "Iteration 79 : x = [1.45695023 1.18551802] f(x) = 0.027612787079792395 gradient norm = 0.099575824744607\n",
      "Iteration 80 : x = [1.46688757 1.18615258] f(x) = 0.026629804525175417 gradient norm = 0.09785423434925132\n",
      "Iteration 81 : x = [1.47665403 1.1867615 ] f(x) = 0.02568063012735087 gradient norm = 0.09613973946422222\n",
      "Iteration 82 : x = [1.48625019 1.18734642] f(x) = 0.024764527156899755 gradient norm = 0.09443426209602226\n",
      "Iteration 83 : x = [1.49567685 1.18790893] f(x) = 0.023880731223670387 gradient norm = 0.09273957844582843\n",
      "Iteration 84 : x = [1.50493498 1.18845056] f(x) = 0.02302845547219417 gradient norm = 0.09105732286870241\n",
      "Iteration 85 : x = [1.51402573 1.18897278] f(x) = 0.02220689542030961 gradient norm = 0.08938899240046279\n",
      "Iteration 86 : x = [1.52295039 1.18947701] f(x) = 0.021415233438854778 gradient norm = 0.08773595174350539\n",
      "Iteration 87 : x = [1.53171043 1.18996461] f(x) = 0.02065264287474615 gradient norm = 0.08609943861154427\n",
      "Iteration 88 : x = [1.54030741 1.19043688] f(x) = 0.01991829182353796 gradient norm = 0.08448056934221862\n",
      "Iteration 89 : x = [1.54874303 1.19089507] f(x) = 0.019211346560692552 gradient norm = 0.08288034469556226\n",
      "Iteration 90 : x = [1.55701909 1.19134037] f(x) = 0.01853097464333262 gradient norm = 0.08129965576526223\n",
      "Iteration 91 : x = [1.56513749 1.19177389] f(x) = 0.017876347696245333 gradient norm = 0.07973928993830585\n",
      "Iteration 92 : x = [1.5731002  1.19219672] f(x) = 0.01724664389741767 gradient norm = 0.07819993684690403\n",
      "Iteration 93 : x = [1.58090928 1.19260988] f(x) = 0.016641050179458293 gradient norm = 0.07668219426440762\n",
      "Iteration 94 : x = [1.58856682 1.19301434] f(x) = 0.01605876416395723 gradient norm = 0.07518657390423322\n",
      "Iteration 95 : x = [1.59607501 1.193411  ] f(x) = 0.015498995846202035 gradient norm = 0.07371350708755367\n",
      "Iteration 96 : x = [1.60343605 1.19380074] f(x) = 0.014960969047758144 gradient norm = 0.07226335025166689\n",
      "Iteration 97 : x = [1.61065219 1.19418436] f(x) = 0.014443922654275488 gradient norm = 0.07083639027652608\n",
      "Iteration 98 : x = [1.61772572 1.19456265] f(x) = 0.013947111655546757 gradient norm = 0.06943284961191361\n",
      "Iteration 99 : x = [1.62465895 1.19493631] f(x) = 0.013469808004350626 gradient norm = 0.06805289119217588\n",
      "Iteration 100 : x = [1.63145419 1.19530604] f(x) = 0.013011301310000912 gradient norm = 0.06669662312934602\n",
      "Iteration 101 : x = [1.63811377 1.19567246] f(x) = 0.012570899381818582 gradient norm = 0.0653641031788869\n",
      "Iteration 102 : x = [1.64464006 1.19603617] f(x) = 0.012147928636973738 gradient norm = 0.0640553429752298\n",
      "Iteration 103 : x = [1.65103538 1.19639773] f(x) = 0.011741734386331087 gradient norm = 0.0627703120367939\n",
      "Iteration 104 : x = [1.65730208 1.19675766] f(x) = 0.011351681011094324 gradient norm = 0.061508941542296906\n",
      "Iteration 105 : x = [1.6634425  1.19711645] f(x) = 0.010977152042196759 gradient norm = 0.06027112788193061\n",
      "Iteration 106 : x = [1.66945897 1.19747454] f(x) = 0.010617550153541806 gradient norm = 0.05905673598842678\n",
      "Iteration 107 : x = [1.67535379 1.19783236] f(x) = 0.010272297079366794 gradient norm = 0.057865602454204565\n",
      "Iteration 108 : x = [1.68112927 1.19819029] f(x) = 0.00994083346519597 gradient norm = 0.05669753844170707\n",
      "Iteration 109 : x = [1.68678769 1.19854869] f(x) = 0.009622618661070071 gradient norm = 0.055552332394732964\n",
      "Iteration 110 : x = [1.6923313 1.1989079] f(x) = 0.009317130464994616 gradient norm = 0.05442975255907647\n",
      "Iteration 111 : x = [1.69776233 1.19926822] f(x) = 0.009023864823840792 gradient norm = 0.05332954932113171\n",
      "Iteration 112 : x = [1.70308301 1.19962993] f(x) = 0.008742335498264453 gradient norm = 0.05225145737332159\n",
      "Iteration 113 : x = [1.7082955  1.19999329] f(x) = 0.008472073697579987 gradient norm = 0.05119519771529483\n",
      "Iteration 114 : x = [1.71340198 1.20035853] f(x) = 0.008212627689938617 gradient norm = 0.05016047949981968\n",
      "Iteration 115 : x = [1.71840456 1.20072588] f(x) = 0.007963562392614195 gradient norm = 0.04914700173220628\n",
      "Iteration 116 : x = [1.72330534 1.20109551] f(x) = 0.007724458946692672 gradient norm = 0.04815445483192365\n",
      "Iteration 117 : x = [1.72810638 1.20146762] f(x) = 0.007494914279994034 gradient norm = 0.04718252206485968\n",
      "Iteration 118 : x = [1.73280973 1.20184235] f(x) = 0.0072745406616249635 gradient norm = 0.04623088085441077\n",
      "Iteration 119 : x = [1.73741738 1.20221986] f(x) = 0.007062965251166254 gradient norm = 0.045299203979295426\n",
      "Iteration 120 : x = [1.7419313  1.20260026] f(x) = 0.0068598296451382705 gradient norm = 0.04438716066566743\n",
      "Iteration 121 : x = [1.74635342 1.20298368] f(x) = 0.0066647894230595925 gradient norm = 0.043494417580773014\n",
      "Iteration 122 : x = [1.75068566 1.2033702 ] f(x) = 0.006477513695115341 gradient norm = 0.042620639735050744\n",
      "Iteration 123 : x = [1.75492987 1.20375992] f(x) = 0.0062976846531816325 gradient norm = 0.0417654912992259\n",
      "Iteration 124 : x = [1.75908788 1.20415292] f(x) = 0.00612499712670845 gradient norm = 0.04092863634260128\n",
      "Iteration 125 : x = [1.76316151 1.20454925] f(x) = 0.005959158144743359 gradient norm = 0.040109739498400576\n",
      "Iteration 126 : x = [1.76715252 1.20494896] f(x) = 0.005799886505181017 gradient norm = 0.03930846656168036\n",
      "Iteration 127 : x = [1.77106264 1.20535211] f(x) = 0.0056469123521464505 gradient norm = 0.03852448502499418\n",
      "Iteration 128 : x = [1.77489357 1.20575872] f(x) = 0.005499976762262284 gradient norm = 0.03775746455667097\n",
      "Iteration 129 : x = [1.77864698 1.20616882] f(x) = 0.005358831340409154 gradient norm = 0.03700707742625887\n",
      "Iteration 130 : x = [1.7823245  1.20658243] f(x) = 0.005223237825463791 gradient norm = 0.036272998881387235\n",
      "Iteration 131 : x = [1.78592774 1.20699956] f(x) = 0.0050929677063886285 gradient norm = 0.03555490748001454\n",
      "Iteration 132 : x = [1.78945826 1.20742021] f(x) = 0.004967801848949225 gradient norm = 0.034852485381757774\n",
      "Iteration 133 : x = [1.7929176  1.20784439] f(x) = 0.004847530133250158 gradient norm = 0.034165418601741236\n",
      "Iteration 134 : x = [1.79630726 1.20827207] f(x) = 0.004731951102204936 gradient norm = 0.033493397230157804\n",
      "Iteration 135 : x = [1.79962873 1.20870326] f(x) = 0.004620871620990094 gradient norm = 0.032836115620505237\n",
      "Iteration 136 : x = [1.80288345 1.20913793] f(x) = 0.004514106547476884 gradient norm = 0.03219327254924268\n",
      "Iteration 137 : x = [1.80607282 1.20957605] f(x) = 0.004411478413584971 gradient norm = 0.031564571349407815\n",
      "Iteration 138 : x = [1.80919824 1.21001761] f(x) = 0.004312817117460546 gradient norm = 0.030949720020543987\n",
      "Iteration 139 : x = [1.81226106 1.21046257] f(x) = 0.004217959626345543 gradient norm = 0.03034843131710662\n",
      "Iteration 140 : x = [1.81526261 1.21091089] f(x) = 0.004126749689974261 gradient norm = 0.02976042281735046\n",
      "Iteration 141 : x = [1.81820418 1.21136254] f(x) = 0.004039037564308627 gradient norm = 0.029185416974543278\n",
      "Iteration 142 : x = [1.82108704 1.21181748] f(x) = 0.003954679745402228 gradient norm = 0.02862314115220446\n",
      "Iteration 143 : x = [1.82391245 1.21227566] f(x) = 0.0038735387131663634 gradient norm = 0.028073327644932568\n",
      "Iteration 144 : x = [1.82668161 1.21273704] f(x) = 0.0037954826847977647 gradient norm = 0.02753571368625864\n",
      "Iteration 145 : x = [1.82939571 1.21320157] f(x) = 0.003720385377617018 gradient norm = 0.027010041444845402\n",
      "Iteration 146 : x = [1.83205593 1.2136692 ] f(x) = 0.0036481257810588755 gradient norm = 0.026496058010243587\n",
      "Iteration 147 : x = [1.83466339 1.21413988] f(x) = 0.0035785879375500236 gradient norm = 0.025993515369316173\n",
      "Iteration 148 : x = [1.83721922 1.21461356] f(x) = 0.0035116607320063893 gradient norm = 0.02550217037434839\n",
      "Iteration 149 : x = [1.8397245  1.21509018] f(x) = 0.0034472376896801556 gradient norm = 0.025021784703774617\n",
      "Iteration 150 : x = [1.84218031 1.21556968] f(x) = 0.003385216782086467 gradient norm = 0.024552124816374463\n",
      "Iteration 151 : x = [1.84458768 1.21605202] f(x) = 0.003325500240740868 gradient norm = 0.024092961899716978\n",
      "Iteration 152 : x = [1.84694763 1.21653713] f(x) = 0.0032679943784405105 gradient norm = 0.023644071813563657\n",
      "Iteration 153 : x = [1.84926117 1.21702495] f(x) = 0.0032126094178254938 gradient norm = 0.023205235028879424\n",
      "Iteration 154 : x = [1.85152926 1.21751542] f(x) = 0.0031592593269604 gradient norm = 0.022776236563042895\n",
      "Iteration 155 : x = [1.85375288 1.21800849] f(x) = 0.0031078616616808125 gradient norm = 0.022356865911795004\n",
      "Iteration 156 : x = [1.85593294 1.21850409] f(x) = 0.003058337414454643 gradient norm = 0.021946916978416057\n",
      "Iteration 157 : x = [1.85807036 1.21900217] f(x) = 0.0030106108695136936 gradient norm = 0.021546188000577348\n",
      "Iteration 158 : x = [1.86016605 1.21950267] f(x) = 0.0029646094640168393 gradient norm = 0.02115448147527235\n",
      "Iteration 159 : x = [1.86222086 1.22000552] f(x) = 0.002920263655012388 gradient norm = 0.020771604082195222\n",
      "Iteration 160 : x = [1.86423566 1.22051066] f(x) = 0.0028775067919736353 gradient norm = 0.020397366605900174\n",
      "Iteration 161 : x = [1.86621129 1.22101803] f(x) = 0.0028362749946881653 gradient norm = 0.020031583857043622\n",
      "Iteration 162 : x = [1.86814856 1.22152758] f(x) = 0.002796507036288144 gradient norm = 0.019674074592982788\n",
      "Iteration 163 : x = [1.87004827 1.22203924] f(x) = 0.0027581442312155546 gradient norm = 0.019324661437977668\n",
      "Iteration 164 : x = [1.8719112  1.22255295] f(x) = 0.0027211303279230424 gradient norm = 0.01898317080321989\n",
      "Iteration 165 : x = [1.87373813 1.22306866] f(x) = 0.0026854114061177258 gradient norm = 0.01864943280688962\n",
      "Iteration 166 : x = [1.87552979 1.2235863 ] f(x) = 0.0026509357783620438 gradient norm = 0.01832328119442231\n",
      "Iteration 167 : x = [1.87728693 1.22410582] f(x) = 0.0026176538958521695 gradient norm = 0.018004553259148123\n",
      "Iteration 168 : x = [1.87901025 1.22462715] f(x) = 0.0025855182582011017 gradient norm = 0.017693089763451384\n",
      "Iteration 169 : x = [1.88070047 1.22515024] f(x) = 0.00255448332705984 gradient norm = 0.01738873486058119\n",
      "Iteration 170 : x = [1.88235826 1.22567503] f(x) = 0.0025245054434162558 gradient norm = 0.017091336017231375\n",
      "Iteration 171 : x = [1.8839843  1.22620146] f(x) = 0.0024955427484174802 gradient norm = 0.0168007439369956\n",
      "Iteration 172 : x = [1.88557925 1.22672948] f(x) = 0.002467555107567391 gradient norm = 0.01651681248479116\n",
      "Iteration 173 : x = [1.88714373 1.22725903] f(x) = 0.002440504038156716 gradient norm = 0.016239398612335885\n",
      "Iteration 174 : x = [1.8886784  1.22779006] f(x) = 0.0024143526397888 gradient norm = 0.01596836228475222\n",
      "Iteration 175 : x = [1.89018385 1.22832252] f(x) = 0.0023890655278695763 gradient norm = 0.015703566408364688\n",
      "Iteration 176 : x = [1.89166069 1.22885634] f(x) = 0.002364608769935546 gradient norm = 0.015444876759748635\n",
      "Iteration 177 : x = [1.8931095  1.22939147] f(x) = 0.002340949824698716 gradient norm = 0.015192161916081658\n",
      "Iteration 178 : x = [1.89453088 1.22992787] f(x) = 0.0023180574836923454 gradient norm = 0.014945293186842061\n",
      "Iteration 179 : x = [1.89592536 1.23046548] f(x) = 0.002295901815406196 gradient norm = 0.014704144546893328\n",
      "Iteration 180 : x = [1.89729352 1.23100424] f(x) = 0.002274454111804514 gradient norm = 0.01446859257098778\n",
      "Iteration 181 : x = [1.89863588 1.23154412] f(x) = 0.002253686837124487 gradient norm = 0.014238516369717942\n",
      "Iteration 182 : x = [1.89995297 1.23208506] f(x) = 0.002233573578857176 gradient norm = 0.014013797526939539\n",
      "Iteration 183 : x = [1.90124532 1.23262701] f(x) = 0.0022140890008170277 gradient norm = 0.01379432003868563\n",
      "Iteration 184 : x = [1.90251342 1.23316992] f(x) = 0.0021952087982100837 gradient norm = 0.013579970253587908\n",
      "Iteration 185 : x = [1.90375777 1.23371374] f(x) = 0.0021769096546147724 gradient norm = 0.013370636814817061\n",
      "Iteration 186 : x = [1.90497886 1.23425844] f(x) = 0.0021591692007928752 gradient norm = 0.013166210603551184\n",
      "Iteration 187 : x = [1.90617715 1.23480395] f(x) = 0.0021419659752517483 gradient norm = 0.012966584683977662\n",
      "Iteration 188 : x = [1.90735311 1.23535025] f(x) = 0.0021252793864823026 gradient norm = 0.012771654249831522\n",
      "Iteration 189 : x = [1.90850719 1.23589728] f(x) = 0.002109089676800431 gradient norm = 0.012581316572469418\n",
      "Iteration 190 : x = [1.90963985 1.236445  ] f(x) = 0.002093377887722754 gradient norm = 0.012395470950476831\n",
      "Iteration 191 : x = [1.9107515  1.23699336] f(x) = 0.0020781258268104726 gradient norm = 0.012214018660802519\n",
      "Iteration 192 : x = [1.91184258 1.23754233] f(x) = 0.0020633160359180376 gradient norm = 0.012036862911412566\n",
      "Iteration 193 : x = [1.9129135  1.23809187] f(x) = 0.0020489317607860417 gradient norm = 0.011863908795453033\n",
      "Iteration 194 : x = [1.91396467 1.23864192] f(x) = 0.002034956921920392 gradient norm = 0.011695063246908754\n",
      "Iteration 195 : x = [1.91499649 1.23919246] f(x) = 0.0020213760867023333 gradient norm = 0.011530234997743015\n",
      "Iteration 196 : x = [1.91600935 1.23974345] f(x) = 0.0020081744426763003 gradient norm = 0.01136933453650061\n",
      "Iteration 197 : x = [1.91700362 1.24029484] f(x) = 0.0019953377719648716 gradient norm = 0.011212274068354901\n",
      "Iteration 198 : x = [1.91797969 1.24084659] f(x) = 0.001982852426762342 gradient norm = 0.011058967476577225\n",
      "Iteration 199 : x = [1.91893793 1.24139868] f(x) = 0.0019707053058604816 gradient norm = 0.010909330285404554\n",
      "Iteration 200 : x = [1.91987867 1.24195107] f(x) = 0.0019588838321621636 gradient norm = 0.01076327962428018\n",
      "Iteration 201 : x = [1.92080229 1.24250371] f(x) = 0.001947375931140369 gradient norm = 0.010620734193439365\n",
      "Iteration 202 : x = [1.92170912 1.24305658] f(x) = 0.0019361700102020157 gradient norm = 0.010481614230810243\n",
      "Iteration 203 : x = [1.9225995  1.24360963] f(x) = 0.001925254938917789 gradient norm = 0.01034584148019885\n",
      "Iteration 204 : x = [1.92347375 1.24416284] f(x) = 0.00191462003008085 gradient norm = 0.010213339160724975\n",
      "Iteration 205 : x = [1.9243322  1.24471618] f(x) = 0.001904255021558913 gradient norm = 0.010084031937473722\n",
      "Iteration 206 : x = [1.92517517 1.24526961] f(x) = 0.0018941500589057492 gradient norm = 0.00995784589332678\n",
      "Iteration 207 : x = [1.92600296 1.2458231 ] f(x) = 0.0018842956786996338 gradient norm = 0.009834708501935194\n",
      "Iteration 208 : x = [1.92681588 1.24637662] f(x) = 0.0018746827925776772 gradient norm = 0.009714548601794411\n",
      "Iteration 209 : x = [1.92761422 1.24693013] f(x) = 0.001865302671936337 gradient norm = 0.009597296371381252\n",
      "Iteration 210 : x = [1.92839826 1.24748362] f(x) = 0.0018561469332697021 gradient norm = 0.009482883305310866\n",
      "Iteration 211 : x = [1.92916831 1.24803705] f(x) = 0.0018472075241183692 gradient norm = 0.00937124219147152\n",
      "Iteration 212 : x = [1.92992463 1.24859039] f(x) = 0.0018384767096029189 gradient norm = 0.0092623070890933\n",
      "Iteration 213 : x = [1.93066749 1.24914361] f(x) = 0.0018299470595171347 gradient norm = 0.009156013307706929\n",
      "Iteration 214 : x = [1.93139717 1.24969669] f(x) = 0.0018216114359571717 gradient norm = 0.009052297386947832\n",
      "Iteration 215 : x = [1.93211392 1.25024961] f(x) = 0.0018134629814639373 gradient norm = 0.008951097077160533\n",
      "Iteration 216 : x = [1.93281799 1.25080232] f(x) = 0.0018054951076569151 gradient norm = 0.008852351320758095\n",
      "Iteration 217 : x = [1.93350965 1.25135482] f(x) = 0.0017977014843386127 gradient norm = 0.00875600023429143\n",
      "Iteration 218 : x = [1.93418913 1.25190707] f(x) = 0.0017900760290497182 gradient norm = 0.008661985091183065\n",
      "Iteration 219 : x = [1.93485667 1.25245906] f(x) = 0.0017826128970559105 gradient norm = 0.008570248305080932\n",
      "Iteration 220 : x = [1.93551252 1.25301074] f(x) = 0.0017753064717480923 gradient norm = 0.008480733413787448\n",
      "Iteration 221 : x = [1.93615689 1.25356212] f(x) = 0.0017681513554385986 gradient norm = 0.008393385063720378\n",
      "Iteration 222 : x = [1.93679002 1.25411315] f(x) = 0.001761142360536696 gradient norm = 0.008308148994862444\n",
      "Iteration 223 : x = [1.93741212 1.25466382] f(x) = 0.0017542745010874035 gradient norm = 0.008224972026157755\n",
      "Iteration 224 : x = [1.93802342 1.25521411] f(x) = 0.0017475429846583463 gradient norm = 0.008143802041314159\n",
      "Iteration 225 : x = [1.93862412 1.255764  ] f(x) = 0.0017409432045600152 gradient norm = 0.008064587974971789\n",
      "Iteration 226 : x = [1.93921443 1.25631346] f(x) = 0.0017344707323854523 gradient norm = 0.007987279799199665\n",
      "Iteration 227 : x = [1.93979456 1.25686247] f(x) = 0.0017281213108559493 gradient norm = 0.007911828510283462\n",
      "Iteration 228 : x = [1.9403647  1.25741103] f(x) = 0.0017218908469599514 gradient norm = 0.007838186115769332\n",
      "Iteration 229 : x = [1.94092505 1.25795909] f(x) = 0.0017157754053728864 gradient norm = 0.007766305621730229\n",
      "Iteration 230 : x = [1.9414758  1.25850666] f(x) = 0.0017097712021461892 gradient norm = 0.007696141020223034\n",
      "Iteration 231 : x = [1.94201714 1.2590537 ] f(x) = 0.0017038745986542587 gradient norm = 0.007627647276906718\n",
      "Iteration 232 : x = [1.94254925 1.25960021] f(x) = 0.001698082095788608 gradient norm = 0.00756078031879354\n",
      "Iteration 233 : x = [1.94307231 1.26014616] f(x) = 0.0016923903283888823 gradient norm = 0.007495497022107208\n",
      "Iteration 234 : x = [1.9435865  1.26069154] f(x) = 0.0016867960599009045 gradient norm = 0.007431755200224299\n",
      "Iteration 235 : x = [1.94409199 1.26123632] f(x) = 0.0016812961772522759 gradient norm = 0.0073695135916765605\n",
      "Iteration 236 : x = [1.94458894 1.26178051] f(x) = 0.0016758876859365314 gradient norm = 0.007308731848194574\n",
      "Iteration 237 : x = [1.94507753 1.26232407] f(x) = 0.0016705677052971455 gradient norm = 0.00724937052277448\n",
      "Iteration 238 : x = [1.94555791 1.26286699] f(x) = 0.0016653334640031384 gradient norm = 0.0071913910577520125\n",
      "Iteration 239 : x = [1.94603025 1.26340926] f(x) = 0.0016601822957083173 gradient norm = 0.007134755772869726\n",
      "Iteration 240 : x = [1.9464947  1.26395086] f(x) = 0.0016551116348865723 gradient norm = 0.00707942785332549\n",
      "Iteration 241 : x = [1.94695141 1.26449179] f(x) = 0.0016501190128359242 gradient norm = 0.007025371337791905\n",
      "Iteration 242 : x = [1.94740053 1.26503202] f(x) = 0.001645202053844376 gradient norm = 0.00697255110639833\n",
      "Iteration 243 : x = [1.94784221 1.26557154] f(x) = 0.0016403584715108642 gradient norm = 0.006920932868668784\n",
      "Iteration 244 : x = [1.94827659 1.26611034] f(x) = 0.0016355860652149399 gradient norm = 0.006870483151410912\n",
      "Iteration 245 : x = [1.94870382 1.2666484 ] f(x) = 0.0016308827167290354 gradient norm = 0.0068211692865524625\n",
      "Iteration 246 : x = [1.94912402 1.26718572] f(x) = 0.0016262463869674477 gradient norm = 0.006772959398923368\n",
      "Iteration 247 : x = [1.94953734 1.26772228] f(x) = 0.0016216751128664223 gradient norm = 0.0067258223939831155\n",
      "Iteration 248 : x = [1.9499439  1.26825808] f(x) = 0.0016171670043899561 gradient norm = 0.006679727945493953\n",
      "Iteration 249 : x = [1.95034385 1.26879308] f(x) = 0.001612720241656141 gradient norm = 0.006634646483142274\n",
      "Iteration 250 : x = [1.95073729 1.2693273 ] f(x) = 0.0016083330721791253 gradient norm = 0.006590549180111088\n",
      "Iteration 251 : x = [1.95112436 1.26986071] f(x) = 0.0016040038082219465 gradient norm = 0.0065474079406079065\n",
      "Iteration 252 : x = [1.95150519 1.27039331] f(x) = 0.0015997308242556819 gradient norm = 0.00650519538735293\n",
      "Iteration 253 : x = [1.95187988 1.27092508] f(x) = 0.0015955125545206055 gradient norm = 0.006463884849033787\n",
      "Iteration 254 : x = [1.95224855 1.27145602] f(x) = 0.0015913474906851383 gradient norm = 0.006423450347733024\n",
      "Iteration 255 : x = [1.95261133 1.27198611] f(x) = 0.001587234179598632 gradient norm = 0.006383866586335962\n",
      "Iteration 256 : x = [1.95296832 1.27251535] f(x) = 0.0015831712211341437 gradient norm = 0.006345108935926497\n",
      "Iteration 257 : x = [1.95331964 1.27304373] f(x) = 0.001579157266117536 gradient norm = 0.006307153423179119\n",
      "Iteration 258 : x = [1.95366538 1.27357124] f(x) = 0.0015751910143393794 gradient norm = 0.0062699767177557975\n",
      "Iteration 259 : x = [1.95400567 1.27409786] f(x) = 0.0015712712126463052 gradient norm = 0.006233556119716542\n",
      "Iteration 260 : x = [1.95434059 1.2746236 ] f(x) = 0.0015673966531085592 gradient norm = 0.006197869546952716\n",
      "Iteration 261 : x = [1.95467025 1.27514844] f(x) = 0.001563566171260668 gradient norm = 0.006162895522652266\n",
      "Iteration 262 : x = [1.95499476 1.27567237] f(x) = 0.0015597786444122564 gradient norm = 0.006128613162806266\n",
      "Iteration 263 : x = [1.95531421 1.27619539] f(x) = 0.0015560329900261532 gradient norm = 0.006095002163765729\n",
      "Iteration 264 : x = [1.95562869 1.2767175 ] f(x) = 0.0015523281641610788 gradient norm = 0.006062042789858255\n",
      "Iteration 265 : x = [1.9559383  1.27723867] f(x) = 0.0015486631599762866 gradient norm = 0.006029715861073248\n",
      "Iteration 266 : x = [1.95624313 1.27775892] f(x) = 0.0015450370062956395 gradient norm = 0.005998002740824726\n",
      "Iteration 267 : x = [1.95654328 1.27827822] f(x) = 0.001541448766228755 gradient norm = 0.0059668853238005245\n",
      "Iteration 268 : x = [1.95683882 1.27879657] f(x) = 0.0015378975358468709 gradient norm = 0.0059363460239061595\n",
      "Iteration 269 : x = [1.95712984 1.27931398] f(x) = 0.001534382442911249 gradient norm = 0.005906367762311585\n",
      "Iteration 270 : x = [1.95741644 1.27983042] f(x) = 0.001530902645651983 gradient norm = 0.005876933955608723\n",
      "Iteration 271 : x = [1.95769869 1.2803459 ] f(x) = 0.0015274573315951945 gradient norm = 0.005848028504087264\n",
      "Iteration 272 : x = [1.95797668 1.2808604 ] f(x) = 0.0015240457164366458 gradient norm = 0.005819635780135763\n",
      "Iteration 273 : x = [1.95825048 1.28137394] f(x) = 0.0015206670429599174 gradient norm = 0.005791740616775013\n",
      "Iteration 274 : x = [1.95852018 1.28188649] f(x) = 0.0015173205799973552 gradient norm = 0.005764328296329884\n",
      "Iteration 275 : x = [1.95878584 1.28239805] f(x) = 0.0015140056214320585 gradient norm = 0.0057373845392456515\n",
      "Iteration 276 : x = [1.95904755 1.28290862] f(x) = 0.0015107214852392748 gradient norm = 0.005710895493054442\n",
      "Iteration 277 : x = [1.95930538 1.2834182 ] f(x) = 0.0015074675125656043 gradient norm = 0.005684847721496862\n",
      "Iteration 278 : x = [1.9595594  1.28392677] f(x) = 0.0015042430668445062 gradient norm = 0.0056592281938034885\n",
      "Iteration 279 : x = [1.95980968 1.28443434] f(x) = 0.0015010475329466542 gradient norm = 0.005634024274140698\n",
      "Iteration 280 : x = [1.9600563 1.2849409] f(x) = 0.0014978803163637328 gradient norm = 0.005609223711224498\n",
      "Iteration 281 : x = [1.96029931 1.28544645] f(x) = 0.0014947408424243504 gradient norm = 0.005584814628106084\n",
      "Iteration 282 : x = [1.96053879 1.28595098] f(x) = 0.0014916285555407751 gradient norm = 0.005560785512131996\n",
      "Iteration 283 : x = [1.96077481 1.28645449] f(x) = 0.0014885429184852586 gradient norm = 0.005537125205081641\n",
      "Iteration 284 : x = [1.96100742 1.28695697] f(x) = 0.0014854834116947797 gradient norm = 0.0055138228934845275\n",
      "Iteration 285 : x = [1.96123668 1.28745843] f(x) = 0.0014824495326030513 gradient norm = 0.005490868099119045\n",
      "Iteration 286 : x = [1.96146267 1.28795885] f(x) = 0.0014794407949987262 gradient norm = 0.005468250669694421\n",
      "Iteration 287 : x = [1.96168544 1.28845825] f(x) = 0.0014764567284087427 gradient norm = 0.0054459607697170545\n",
      "Iteration 288 : x = [1.96190505 1.2889566 ] f(x) = 0.001473496877505801 gradient norm = 0.005423988871542068\n",
      "Iteration 289 : x = [1.96212156 1.28945391] f(x) = 0.0014705608015390399 gradient norm = 0.005402325746610684\n",
      "Iteration 290 : x = [1.96233502 1.28995018] f(x) = 0.001467648073786951 gradient norm = 0.0053809624568736695\n",
      "Iteration 291 : x = [1.9625455  1.29044541] f(x) = 0.001464758281031672 gradient norm = 0.005359890346400772\n",
      "Iteration 292 : x = [1.96275304 1.29093959] f(x) = 0.0014618910230538087 gradient norm = 0.005339101033175898\n",
      "Iteration 293 : x = [1.9629577  1.29143271] f(x) = 0.0014590459121469521 gradient norm = 0.005318586401077397\n",
      "Iteration 294 : x = [1.96315954 1.29192479] f(x) = 0.0014562225726511282 gradient norm = 0.005298338592042654\n",
      "Iteration 295 : x = [1.96335859 1.2924158 ] f(x) = 0.0014534206405044162 gradient norm = 0.005278349998415957\n",
      "Iteration 296 : x = [1.96355493 1.29290577] f(x) = 0.0014506397628120265 gradient norm = 0.005258613255478344\n",
      "Iteration 297 : x = [1.96374858 1.29339467] f(x) = 0.0014478795974321298 gradient norm = 0.005239121234157974\n",
      "Iteration 298 : x = [1.96393961 1.29388252] f(x) = 0.0014451398125777924 gradient norm = 0.005219867033919363\n",
      "Iteration 299 : x = [1.96412806 1.2943693 ] f(x) = 0.00144242008643437 gradient norm = 0.005200843975829709\n",
      "Iteration 300 : x = [1.96431398 1.29485502] f(x) = 0.0014397201067917445 gradient norm = 0.005182045595800218\n",
      "Iteration 301 : x = [1.96449741 1.29533967] f(x) = 0.001437039570690828 gradient norm = 0.005163465638000398\n",
      "Iteration 302 : x = [1.9646784  1.29582326] f(x) = 0.0014343781840837613 gradient norm = 0.005145098048443057\n",
      "Iteration 303 : x = [1.96485699 1.29630578] f(x) = 0.0014317356615072719 gradient norm = 0.005126936968737562\n",
      "Iteration 304 : x = [1.96503323 1.29678723] f(x) = 0.0014291117257686694 gradient norm = 0.005108976730008924\n",
      "Iteration 305 : x = [1.96520716 1.29726761] f(x) = 0.0014265061076439733 gradient norm = 0.0050912118469801475\n",
      "Iteration 306 : x = [1.96537881 1.29774692] f(x) = 0.0014239185455877123 gradient norm = 0.005073637012215113\n",
      "Iteration 307 : x = [1.96554824 1.29822516] f(x) = 0.001421348785453919 gradient norm = 0.005056247090519347\n",
      "Iteration 308 : x = [1.96571547 1.29870233] f(x) = 0.0014187965802278828 gradient norm = 0.005039037113495797\n",
      "Iteration 309 : x = [1.96588056 1.29917842] f(x) = 0.0014162616897682408 gradient norm = 0.005022002274252751\n",
      "Iteration 310 : x = [1.96604353 1.29965344] f(x) = 0.0014137438805590023 gradient norm = 0.0050051379222611015\n",
      "Iteration 311 : x = [1.96620443 1.30012739] f(x) = 0.0014112429254711058 gradient norm = 0.00498843955835791\n",
      "Iteration 312 : x = [1.96636329 1.30060026] f(x) = 0.001408758603533148 gradient norm = 0.004971902829893339\n",
      "Iteration 313 : x = [1.96652016 1.30107206] f(x) = 0.001406290699710912 gradient norm = 0.004955523526017989\n",
      "Iteration 314 : x = [1.96667505 1.30154278] f(x) = 0.0014038390046953607 gradient norm = 0.004939297573107592\n",
      "Iteration 315 : x = [1.96682802 1.30201243] f(x) = 0.0014014033146987476 gradient norm = 0.0049232210303220775\n",
      "Iteration 316 : x = [1.96697909 1.302481  ] f(x) = 0.0013989834312585503 gradient norm = 0.004907290085296003\n",
      "Iteration 317 : x = [1.96712829 1.30294849] f(x) = 0.001396579161048896 gradient norm = 0.00489150104995732\n",
      "Iteration 318 : x = [1.96727567 1.30341491] f(x) = 0.001394190315699201 gradient norm = 0.004875850356471483\n",
      "Iteration 319 : x = [1.96742125 1.30388026] f(x) = 0.0013918167116197325 gradient norm = 0.004860334553307915\n",
      "Iteration 320 : x = [1.96756506 1.30434453] f(x) = 0.0013894581698338365 gradient norm = 0.004844950301425875\n",
      "Iteration 321 : x = [1.96770714 1.30480772] f(x) = 0.0013871145158165486 gradient norm = 0.004829694370576744\n",
      "Iteration 322 : x = [1.96784751 1.30526984] f(x) = 0.0013847855793393635 gradient norm = 0.004814563635719879\n",
      "Iteration 323 : x = [1.96798621 1.30573089] f(x) = 0.001382471194320896 gradient norm = 0.004799555073549031\n",
      "Iteration 324 : x = [1.96812326 1.30619086] f(x) = 0.001380171198683233 gradient norm = 0.004784665759126598\n",
      "Iteration 325 : x = [1.9682587  1.30664976] f(x) = 0.001377885434213728 gradient norm = 0.0047698928626228295\n",
      "Iteration 326 : x = [1.96839255 1.30710758] f(x) = 0.0013756137464320426 gradient norm = 0.004755233646157163\n",
      "Iteration 327 : x = [1.96852483 1.30756434] f(x) = 0.0013733559844622256 gradient norm = 0.004740685460739019\n",
      "Iteration 328 : x = [1.96865559 1.30802002] f(x) = 0.0013711120009096262 gradient norm = 0.004726245743305289\n",
      "Iteration 329 : x = [1.96878483 1.30847462] f(x) = 0.001368881651742468 gradient norm = 0.004711912013851931\n",
      "Iteration 330 : x = [1.9689126  1.30892816] f(x) = 0.0013666647961778952 gradient norm = 0.00469768187265699\n",
      "Iteration 331 : x = [1.96903891 1.30938063] f(x) = 0.0013644612965723086 gradient norm = 0.004683552997592494\n",
      "Iteration 332 : x = [1.96916378 1.30983203] f(x) = 0.001362271018315838 gradient norm = 0.0046695231415227545\n",
      "Iteration 333 : x = [1.96928726 1.31028236] f(x) = 0.001360093829730786 gradient norm = 0.0046555901297865325\n",
      "Iteration 334 : x = [1.96940935 1.31073163] f(x) = 0.0013579296019738862 gradient norm = 0.004641751857760698\n",
      "Iteration 335 : x = [1.96953008 1.31117983] f(x) = 0.001355778208942228 gradient norm = 0.004628006288502975\n",
      "Iteration 336 : x = [1.96964948 1.31162696] f(x) = 0.001353639527182714 gradient norm = 0.0046143514504715195\n",
      "Iteration 337 : x = [1.96976757 1.31207303] f(x) = 0.001351513435804898 gradient norm = 0.004600785435318945\n",
      "Iteration 338 : x = [1.96988437 1.31251804] f(x) = 0.0013493998163970902 gradient norm = 0.004587306395758722\n",
      "Iteration 339 : x = [1.96999989 1.31296198] f(x) = 0.0013472985529455871 gradient norm = 0.004573912543501628\n",
      "Iteration 340 : x = [1.97011418 1.31340487] f(x) = 0.0013452095317569221 gradient norm = 0.00456060214726028\n",
      "Iteration 341 : x = [1.97022724 1.31384669] f(x) = 0.0013431326413829968 gradient norm = 0.004547373530819554\n",
      "Iteration 342 : x = [1.97033909 1.31428746] f(x) = 0.0013410677725490122 gradient norm = 0.004534225071170981\n",
      "Iteration 343 : x = [1.97044976 1.31472717] f(x) = 0.0013390148180840605 gradient norm = 0.0045211551967090586\n",
      "Iteration 344 : x = [1.97055926 1.31516582] f(x) = 0.0013369736728542983 gradient norm = 0.004508162385487655\n",
      "Iteration 345 : x = [1.97066762 1.31560342] f(x) = 0.0013349442336985917 gradient norm = 0.004495245163534535\n",
      "Iteration 346 : x = [1.97077486 1.31603997] f(x) = 0.0013329263993665367 gradient norm = 0.004482402103222303\n",
      "Iteration 347 : x = [1.97088099 1.31647546] f(x) = 0.0013309200704587658 gradient norm = 0.004469631821693891\n",
      "Iteration 348 : x = [1.97098603 1.31690991] f(x) = 0.0013289251493694579 gradient norm = 0.004456932979340904\n",
      "Iteration 349 : x = [1.97109   1.3173433] f(x) = 0.0013269415402309584 gradient norm = 0.004444304278333216\n",
      "Iteration 350 : x = [1.97119291 1.31777565] f(x) = 0.00132496914886043 gradient norm = 0.00443174446119802\n",
      "Iteration 351 : x = [1.9712948  1.31820696] f(x) = 0.0013230078827084625 gradient norm = 0.0044192523094469536\n",
      "Iteration 352 : x = [1.97139566 1.31863722] f(x) = 0.0013210576508095597 gradient norm = 0.0044068266422495565\n",
      "Iteration 353 : x = [1.97149553 1.31906644] f(x) = 0.0013191183637344356 gradient norm = 0.0043944663151517325\n",
      "Iteration 354 : x = [1.97159441 1.31949461] f(x) = 0.0013171899335440455 gradient norm = 0.004382170218837647\n",
      "Iteration 355 : x = [1.97169232 1.31992175] f(x) = 0.0013152722737452924 gradient norm = 0.0043699372779337\n",
      "Iteration 356 : x = [1.97178928 1.32034785] f(x) = 0.0013133652992483398 gradient norm = 0.004357766449853193\n",
      "Iteration 357 : x = [1.9718853  1.32077292] f(x) = 0.0013114689263254724 gradient norm = 0.004345656723680359\n",
      "Iteration 358 : x = [1.9719804  1.32119695] f(x) = 0.0013095830725714356 gradient norm = 0.004333607119092426\n",
      "Iteration 359 : x = [1.97207459 1.32161995] f(x) = 0.0013077076568652213 gradient norm = 0.004321616685318563\n",
      "Iteration 360 : x = [1.97216789 1.32204192] f(x) = 0.0013058425993332143 gradient norm = 0.004309684500134364\n",
      "Iteration 361 : x = [1.97226031 1.32246286] f(x) = 0.001303987821313667 gradient norm = 0.0042978096688907706\n",
      "Iteration 362 : x = [1.97235187 1.32288278] f(x) = 0.0013021432453224552 gradient norm = 0.0042859913235763145\n",
      "Iteration 363 : x = [1.97244258 1.32330167] f(x) = 0.0013003087950200411 gradient norm = 0.004274228621911447\n",
      "Iteration 364 : x = [1.97253246 1.32371954] f(x) = 0.0012984843951796344 gradient norm = 0.0042625207464740515\n",
      "Iteration 365 : x = [1.97262151 1.32413638] f(x) = 0.0012966699716564685 gradient norm = 0.004250866903854956\n",
      "Iteration 366 : x = [1.97270975 1.32455221] f(x) = 0.0012948654513581783 gradient norm = 0.004239266323842506\n",
      "Iteration 367 : x = [1.9727972  1.32496702] f(x) = 0.0012930707622162251 gradient norm = 0.0042277182586352375\n",
      "Iteration 368 : x = [1.97288386 1.32538081] f(x) = 0.0012912858331583235 gradient norm = 0.004216221982081651\n",
      "Iteration 369 : x = [1.97296975 1.32579359] f(x) = 0.0012895105940818497 gradient norm = 0.004204776788946189\n",
      "Iteration 370 : x = [1.97305488 1.32620536] f(x) = 0.0012877449758281743 gradient norm = 0.004193381994200581\n",
      "Iteration 371 : x = [1.97313926 1.32661612] f(x) = 0.0012859889101578998 gradient norm = 0.004182036932339603\n",
      "Iteration 372 : x = [1.97322291 1.32702588] f(x) = 0.00128424232972696 gradient norm = 0.0041707409567205206\n",
      "Iteration 373 : x = [1.97330583 1.32743462] f(x) = 0.001282505168063554 gradient norm = 0.004159493438925338\n",
      "Iteration 374 : x = [1.97338804 1.32784237] f(x) = 0.0012807773595458762 gradient norm = 0.0041482937681451195\n",
      "Iteration 375 : x = [1.97346955 1.32824911] f(x) = 0.0012790588393806234 gradient norm = 0.0041371413505856035\n",
      "Iteration 376 : x = [1.97355037 1.32865486] f(x) = 0.0012773495435822397 gradient norm = 0.004126035608893405\n",
      "Iteration 377 : x = [1.9736305 1.3290596] f(x) = 0.0012756494089528735 gradient norm = 0.004114975981602086\n",
      "Iteration 378 : x = [1.97370997 1.32946335] f(x) = 0.0012739583730630253 gradient norm = 0.004103961922597414\n",
      "Iteration 379 : x = [1.97378878 1.32986611] f(x) = 0.0012722763742328558 gradient norm = 0.004092992900601155\n",
      "Iteration 380 : x = [1.97386694 1.33026788] f(x) = 0.001270603351514125 gradient norm = 0.004082068398672779\n",
      "Iteration 381 : x = [1.97394446 1.33066866] f(x) = 0.0012689392446727508 gradient norm = 0.0040711879137284215\n",
      "Iteration 382 : x = [1.97402135 1.33106845] f(x) = 0.001267283994171961 gradient norm = 0.004060350956076563\n",
      "Iteration 383 : x = [1.97409761 1.33146726] f(x) = 0.0012656375411559933 gradient norm = 0.004049557048969784\n",
      "Iteration 384 : x = [1.97417327 1.33186508] f(x) = 0.0012639998274343674 gradient norm = 0.004038805728172117\n",
      "Iteration 385 : x = [1.97424833 1.33226193] f(x) = 0.0012623707954666616 gradient norm = 0.004028096541541373\n",
      "Iteration 386 : x = [1.97432279 1.3326578 ] f(x) = 0.0012607503883478122 gradient norm = 0.0040174290486260115\n",
      "Iteration 387 : x = [1.97439667 1.33305269] f(x) = 0.0012591385497938898 gradient norm = 0.004006802820275979\n",
      "Iteration 388 : x = [1.97446998 1.3334466 ] f(x) = 0.0012575352241283465 gradient norm = 0.003996217438267059\n",
      "Iteration 389 : x = [1.97454272 1.33383955] f(x) = 0.0012559403562687227 gradient norm = 0.003985672494938292\n",
      "Iteration 390 : x = [1.9746149  1.33423153] f(x) = 0.0012543538917137804 gradient norm = 0.003975167592841954\n",
      "Iteration 391 : x = [1.97468653 1.33462254] f(x) = 0.00125277577653106 gradient norm = 0.00396470234440572\n",
      "Iteration 392 : x = [1.97475761 1.33501258] f(x) = 0.0012512059573448401 gradient norm = 0.00395427637160654\n",
      "Iteration 393 : x = [1.97482817 1.33540166] f(x) = 0.0012496443813244875 gradient norm = 0.00394388930565584\n",
      "Iteration 394 : x = [1.9748982  1.33578979] f(x) = 0.00124809099617318 gradient norm = 0.003933540786695668\n",
      "Iteration 395 : x = [1.97496771 1.33617695] f(x) = 0.0012465457501169893 gradient norm = 0.003923230463505371\n",
      "Iteration 396 : x = [1.97503671 1.33656316] f(x) = 0.0012450085918943167 gradient norm = 0.0039129579932184735\n",
      "Iteration 397 : x = [1.9751052  1.33694841] f(x) = 0.0012434794707456528 gradient norm = 0.0039027230410493496\n",
      "Iteration 398 : x = [1.9751732  1.33733271] f(x) = 0.0012419583364036745 gradient norm = 0.003892525280029436\n",
      "Iteration 399 : x = [1.97524071 1.33771607] f(x) = 0.0012404451390836378 gradient norm = 0.003882364390752523\n",
      "Iteration 400 : x = [1.97530774 1.33809847] f(x) = 0.0012389398294740837 gradient norm = 0.0038722400611289603\n",
      "Iteration 401 : x = [1.9753743  1.33847994] f(x) = 0.0012374423587278192 gradient norm = 0.003862151986148319\n",
      "Iteration 402 : x = [1.97544038 1.33886046] f(x) = 0.0012359526784531877 gradient norm = 0.0038520998676503217\n",
      "Iteration 403 : x = [1.975506   1.33924004] f(x) = 0.0012344707407056007 gradient norm = 0.003842083414103696\n",
      "Iteration 404 : x = [1.97557117 1.33961868] f(x) = 0.0012329964979793306 gradient norm = 0.0038321023403926962\n",
      "Iteration 405 : x = [1.97563589 1.33999638] f(x) = 0.00123152990319955 gradient norm = 0.0038221563676110117\n",
      "Iteration 406 : x = [1.97570016 1.34037315] f(x) = 0.001230070909714613 gradient norm = 0.00381224522286282\n",
      "Iteration 407 : x = [1.975764 1.340749] f(x) = 0.001228619471288566 gradient norm = 0.0038023686390707147\n",
      "Iteration 408 : x = [1.97582741 1.34112391] f(x) = 0.001227175542093885 gradient norm = 0.0037925263547902944\n",
      "Iteration 409 : x = [1.97589039 1.34149789] f(x) = 0.0012257390767044215 gradient norm = 0.0037827181140311383\n",
      "Iteration 410 : x = [1.97595296 1.34187096] f(x) = 0.0012243100300885605 gradient norm = 0.0037729436660839865\n",
      "Iteration 411 : x = [1.97601511 1.3422431 ] f(x) = 0.0012228883576025794 gradient norm = 0.00376320276535389\n",
      "Iteration 412 : x = [1.97607686 1.34261432] f(x) = 0.0012214740149841918 gradient norm = 0.0037534951711991086\n",
      "Iteration 413 : x = [1.9761382  1.34298462] f(x) = 0.001220066958346287 gradient norm = 0.003743820647775587\n",
      "Iteration 414 : x = [1.97619914 1.34335401] f(x) = 0.0012186671441708422 gradient norm = 0.0037341789638867763\n",
      "Iteration 415 : x = [1.9762597  1.34372248] f(x) = 0.0012172745293030087 gradient norm = 0.003724569892838638\n",
      "Iteration 416 : x = [1.97631987 1.34409005] f(x) = 0.0012158890709453676 gradient norm = 0.0037149932122996533\n",
      "Iteration 417 : x = [1.97637965 1.34445671] f(x) = 0.0012145107266523405 gradient norm = 0.0037054487041656235\n",
      "Iteration 418 : x = [1.97643907 1.34482246] f(x) = 0.0012131394543247625 gradient norm = 0.003695936154429161\n",
      "Iteration 419 : x = [1.97649811 1.3451873 ] f(x) = 0.0012117752122046022 gradient norm = 0.003686455353053638\n",
      "Iteration 420 : x = [1.97655678 1.34555125] f(x) = 0.0012104179588698198 gradient norm = 0.0036770060938514583\n",
      "Iteration 421 : x = [1.9766151 1.3459143] f(x) = 0.0012090676532293756 gradient norm = 0.003667588174366529\n",
      "Iteration 422 : x = [1.97667305 1.34627645] f(x) = 0.001207724254518366 gradient norm = 0.003658201395760771\n",
      "Iteration 423 : x = [1.97673066 1.3466377 ] f(x) = 0.0012063877222932928 gradient norm = 0.0036488455627044815\n",
      "Iteration 424 : x = [1.97678792 1.34699807] f(x) = 0.0012050580164274507 gradient norm = 0.003639520483270475\n",
      "Iteration 425 : x = [1.97684484 1.34735754] f(x) = 0.001203735097106448 gradient norm = 0.0036302259688318532\n",
      "Iteration 426 : x = [1.97690141 1.34771613] f(x) = 0.0012024189248238332 gradient norm = 0.003620961833963248\n",
      "Iteration 427 : x = [1.97695766 1.34807383] f(x) = 0.0012011094603768425 gradient norm = 0.003611727896345458\n",
      "Iteration 428 : x = [1.97701357 1.34843065] f(x) = 0.0011998066648622465 gradient norm = 0.0036025239766733154\n",
      "Iteration 429 : x = [1.97706916 1.34878659] f(x) = 0.0011985104996723164 gradient norm = 0.0035933498985667224\n",
      "Iteration 430 : x = [1.97712442 1.34914165] f(x) = 0.001197220926490878 gradient norm = 0.003584205488484688\n",
      "Iteration 431 : x = [1.97717937 1.34949583] f(x) = 0.00119593790728947 gradient norm = 0.003575090575642302\n",
      "Iteration 432 : x = [1.97723401 1.34984914] f(x) = 0.0011946614043235983 gradient norm = 0.0035660049919305293\n",
      "Iteration 433 : x = [1.97728833 1.35020158] f(x) = 0.0011933913801290828 gradient norm = 0.0035569485718387364\n",
      "Iteration 434 : x = [1.97734235 1.35055315] f(x) = 0.0011921277975184851 gradient norm = 0.003547921152379813\n",
      "Iteration 435 : x = [1.97739607 1.35090385] f(x) = 0.0011908706195776352 gradient norm = 0.0035389225730178783\n",
      "Iteration 436 : x = [1.97744949 1.35125369] f(x) = 0.0011896198096622247 gradient norm = 0.003529952675598372\n",
      "Iteration 437 : x = [1.97750261 1.35160266] f(x) = 0.0011883753313944975 gradient norm = 0.0035210113042805718\n",
      "Iteration 438 : x = [1.97755544 1.35195078] f(x) = 0.0011871371486600003 gradient norm = 0.0035120983054723253\n",
      "Iteration 439 : x = [1.97760798 1.35229803] f(x) = 0.0011859052256044237 gradient norm = 0.0035032135277670265\n",
      "Iteration 440 : x = [1.97766024 1.35264443] f(x) = 0.0011846795266305058 gradient norm = 0.0034943568218826922\n",
      "Iteration 441 : x = [1.97771222 1.35298998] f(x) = 0.001183460016395009 gradient norm = 0.0034855280406030907\n",
      "Iteration 442 : x = [1.97776392 1.35333468] f(x) = 0.0011822466598057646 gradient norm = 0.003476727038720833\n",
      "Iteration 443 : x = [1.97781535 1.35367853] f(x) = 0.0011810394220187837 gradient norm = 0.0034679536729824117\n",
      "Iteration 444 : x = [1.9778665  1.35402153] f(x) = 0.0011798382684354279 gradient norm = 0.0034592078020350093\n",
      "Iteration 445 : x = [1.97791739 1.35436369] f(x) = 0.0011786431646996485 gradient norm = 0.0034504892863751573\n",
      "Iteration 446 : x = [1.97796801 1.354705  ] f(x) = 0.0011774540766952759 gradient norm = 0.003441797988299053\n",
      "Iteration 447 : x = [1.97801837 1.35504548] f(x) = 0.001176270970543376 gradient norm = 0.0034331337718545604\n",
      "Iteration 448 : x = [1.97806847 1.35538512] f(x) = 0.001175093812599653 gradient norm = 0.0034244965027947828\n",
      "Iteration 449 : x = [1.97811832 1.35572392] f(x) = 0.0011739225694519155 gradient norm = 0.003415886048533214\n",
      "Iteration 450 : x = [1.97816791 1.35606189] f(x) = 0.001172757207917587 gradient norm = 0.003407302278100329\n",
      "Iteration 451 : x = [1.97821725 1.35639903] f(x) = 0.0011715976950412716 gradient norm = 0.003398745062101644\n",
      "Iteration 452 : x = [1.97826634 1.35673534] f(x) = 0.0011704439980923678 gradient norm = 0.0033902142726771442\n",
      "Iteration 453 : x = [1.97831519 1.35707082] f(x) = 0.0011692960845627277 gradient norm = 0.00338170978346205\n",
      "Iteration 454 : x = [1.9783638  1.35740548] f(x) = 0.0011681539221643676 gradient norm = 0.0033732314695488932\n",
      "Iteration 455 : x = [1.97841217 1.35773932] f(x) = 0.001167017478827214 gradient norm = 0.003364779207450792\n",
      "Iteration 456 : x = [1.9784603  1.35807234] f(x) = 0.0011658867226969059 gradient norm = 0.0033563528750659827\n",
      "Iteration 457 : x = [1.97850819 1.35840454] f(x) = 0.0011647616221326267 gradient norm = 0.0033479523516434812\n",
      "Iteration 458 : x = [1.97855586 1.35873592] f(x) = 0.0011636421457049818 gradient norm = 0.0033395775177498537\n",
      "Iteration 459 : x = [1.97860329 1.35906649] f(x) = 0.0011625282621939201 gradient norm = 0.0033312282552370918\n",
      "Iteration 460 : x = [1.9786505  1.35939625] f(x) = 0.0011614199405866844 gradient norm = 0.0033229044472115293\n",
      "Iteration 461 : x = [1.97869749 1.35972521] f(x) = 0.00116031715007581 gradient norm = 0.0033146059780037557\n",
      "Iteration 462 : x = [1.97874425 1.36005335] f(x) = 0.0011592198600571487 gradient norm = 0.0033063327331394965\n",
      "Iteration 463 : x = [1.97879079 1.36038069] f(x) = 0.0011581280401279333 gradient norm = 0.0032980845993114427\n",
      "Iteration 464 : x = [1.97883712 1.36070723] f(x) = 0.0011570416600848793 gradient norm = 0.0032898614643519955\n",
      "Iteration 465 : x = [1.97888323 1.36103297] f(x) = 0.0011559606899223134 gradient norm = 0.0032816632172068664\n",
      "Iteration 466 : x = [1.97892913 1.36135791] f(x) = 0.001154885099830336 gradient norm = 0.003273489747909529\n",
      "Iteration 467 : x = [1.97897481 1.36168205] f(x) = 0.0011538148601930186 gradient norm = 0.0032653409475564958\n",
      "Iteration 468 : x = [1.97902029 1.36200541] f(x) = 0.0011527499415866242 gradient norm = 0.0032572167082833554\n",
      "Iteration 469 : x = [1.97906557 1.36232797] f(x) = 0.0011516903147778652 gradient norm = 0.0032491169232416123\n",
      "Iteration 470 : x = [1.97911063 1.36264974] f(x) = 0.001150635950722185 gradient norm = 0.0032410414865762095\n",
      "Iteration 471 : x = [1.9791555  1.36297072] f(x) = 0.0011495868205620675 gradient norm = 0.0032329902934038084\n",
      "Iteration 472 : x = [1.97920017 1.36329092] f(x) = 0.0011485428956253781 gradient norm = 0.003224963239791724\n",
      "Iteration 473 : x = [1.97924463 1.36361034] f(x) = 0.0011475041474237242 gradient norm = 0.003216960222737522\n",
      "Iteration 474 : x = [1.9792889  1.36392897] f(x) = 0.001146470547650847 gradient norm = 0.0032089811401492595\n",
      "Iteration 475 : x = [1.97933298 1.36424683] f(x) = 0.001145442068181036 gradient norm = 0.0032010258908263516\n",
      "Iteration 476 : x = [1.97937686 1.36456391] f(x) = 0.0011444186810675658 gradient norm = 0.003193094374441002\n",
      "Iteration 477 : x = [1.97942056 1.36488021] f(x) = 0.0011434003585411626 gradient norm = 0.003185186491520251\n",
      "Iteration 478 : x = [1.97946406 1.36519575] f(x) = 0.0011423870730084872 gradient norm = 0.0031773021434285463\n",
      "Iteration 479 : x = [1.97950738 1.36551051] f(x) = 0.0011413787970506433 gradient norm = 0.003169441232350857\n",
      "Iteration 480 : x = [1.97955051 1.36582451] f(x) = 0.0011403755034217079 gradient norm = 0.003161603661276309\n",
      "Iteration 481 : x = [1.97959346 1.36613774] f(x) = 0.0011393771650472816 gradient norm = 0.003153789333982317\n",
      "Iteration 482 : x = [1.97963623 1.3664502 ] f(x) = 0.0011383837550230616 gradient norm = 0.0031459981550192046\n",
      "Iteration 483 : x = [1.97967881 1.36676191] f(x) = 0.0011373952466134337 gradient norm = 0.0031382300296952837\n",
      "Iteration 484 : x = [1.97972122 1.36707285] f(x) = 0.0011364116132500822 gradient norm = 0.003130484864062389\n",
      "Iteration 485 : x = [1.97976345 1.36738304] f(x) = 0.001135432828530623 gradient norm = 0.003122762564901845\n",
      "Iteration 486 : x = [1.97980551 1.36769247] f(x) = 0.0011344588662172538 gradient norm = 0.0031150630397108604\n",
      "Iteration 487 : x = [1.97984739 1.36800115] f(x) = 0.0011334897002354195 gradient norm = 0.0031073861966893026\n",
      "Iteration 488 : x = [1.9798891  1.36830907] f(x) = 0.0011325253046724996 gradient norm = 0.00309973194472691\n",
      "Iteration 489 : x = [1.97993064 1.36861625] f(x) = 0.001131565653776513 gradient norm = 0.003092100193390846\n",
      "Iteration 490 : x = [1.97997202 1.36892268] f(x) = 0.0011306107219548357 gradient norm = 0.0030844908529136235\n",
      "Iteration 491 : x = [1.98001322 1.36922836] f(x) = 0.0011296604837729392 gradient norm = 0.0030769038341814108\n",
      "Iteration 492 : x = [1.98005426 1.36953331] f(x) = 0.0011287149139531428 gradient norm = 0.0030693390487226296\n",
      "Iteration 493 : x = [1.98009513 1.36983751] f(x) = 0.0011277739873733845 gradient norm = 0.0030617964086969434\n",
      "Iteration 494 : x = [1.98013584 1.37014097] f(x) = 0.0011268376790660028 gradient norm = 0.003054275826884518\n",
      "Iteration 495 : x = [1.98017639 1.37044369] f(x) = 0.001125905964216538 gradient norm = 0.0030467772166756072\n",
      "Iteration 496 : x = [1.98021678 1.37074568] f(x) = 0.0011249788181625481 gradient norm = 0.003039300492060449\n",
      "Iteration 497 : x = [1.98025701 1.37104694] f(x) = 0.0011240562163924335 gradient norm = 0.003031845567619413\n",
      "Iteration 498 : x = [1.98029708 1.37134746] f(x) = 0.001123138134544283 gradient norm = 0.0030244123585134717\n",
      "Iteration 499 : x = [1.98033699 1.37164726] f(x) = 0.0011222245484047307 gradient norm = 0.003017000780474921\n",
      "Iteration 500 : x = [1.98037675 1.37194632] f(x) = 0.0011213154339078262 gradient norm = 0.003009610749798345\n",
      "Iteration 501 : x = [1.98041636 1.37224467] f(x) = 0.0011204107671339174 gradient norm = 0.003002242183331861\n",
      "Iteration 502 : x = [1.98045582 1.37254229] f(x) = 0.0011195105243085484 gradient norm = 0.0029948949984685827\n",
      "Iteration 503 : x = [1.98049512 1.37283919] f(x) = 0.001118614681801367 gradient norm = 0.0029875691131383466\n",
      "Iteration 504 : x = [1.98053427 1.37313537] f(x) = 0.00111772321612505 gradient norm = 0.0029802644457996297\n",
      "Iteration 505 : x = [1.98057328 1.37343083] f(x) = 0.0011168361039342331 gradient norm = 0.0029729809154317123\n",
      "Iteration 506 : x = [1.98061213 1.37372558] f(x) = 0.0011159533220244594 gradient norm = 0.0029657184415270545\n",
      "Iteration 507 : x = [1.98065084 1.37401961] f(x) = 0.0011150748473311366 gradient norm = 0.00295847694408387\n",
      "Iteration 508 : x = [1.98068941 1.37431294] f(x) = 0.0011142006569285065 gradient norm = 0.0029512563435988882\n",
      "Iteration 509 : x = [1.98072783 1.37460555] f(x) = 0.0011133307280286238 gradient norm = 0.0029440565610603284\n",
      "Iteration 510 : x = [1.98076611 1.37489746] f(x) = 0.0011124650379803497 gradient norm = 0.0029368775179410547\n",
      "Iteration 511 : x = [1.98080424 1.37518866] f(x) = 0.0011116035642683515 gradient norm = 0.0029297191361918945\n",
      "Iteration 512 : x = [1.98084224 1.37547916] f(x) = 0.0011107462845121189 gradient norm = 0.0029225813382351565\n",
      "Iteration 513 : x = [1.98088009 1.37576895] f(x) = 0.0011098931764649848 gradient norm = 0.0029154640469583096\n",
      "Iteration 514 : x = [1.98091781 1.37605805] f(x) = 0.0011090442180131587 gradient norm = 0.0029083671857077923\n",
      "Iteration 515 : x = [1.98095539 1.37634645] f(x) = 0.0011081993871747701 gradient norm = 0.002901290678283027\n",
      "Iteration 516 : x = [1.98099283 1.37663415] f(x) = 0.0011073586620989242 gradient norm = 0.0028942344489305714\n",
      "Iteration 517 : x = [1.98103014 1.37692116] f(x) = 0.0011065220210647623 gradient norm = 0.002887198422338394\n",
      "Iteration 518 : x = [1.98106731 1.37720748] f(x) = 0.001105689442480536 gradient norm = 0.002880182523630325\n",
      "Iteration 519 : x = [1.98110435 1.3774931 ] f(x) = 0.001104860904882686 gradient norm = 0.002873186678360618\n",
      "Iteration 520 : x = [1.98114126 1.37777804] f(x) = 0.0011040363869349384 gradient norm = 0.0028662108125086677\n",
      "Iteration 521 : x = [1.98117804 1.37806229] f(x) = 0.001103215867427399 gradient norm = 0.0028592548524738466\n",
      "Iteration 522 : x = [1.98121468 1.37834586] f(x) = 0.0011023993252756658 gradient norm = 0.002852318725070454\n",
      "Iteration 523 : x = [1.9812512  1.37862875] f(x) = 0.001101586739519946 gradient norm = 0.0028454023575228285\n",
      "Iteration 524 : x = [1.98128758 1.37891095] f(x) = 0.0011007780893241815 gradient norm = 0.00283850567746052\n",
      "Iteration 525 : x = [1.98132384 1.37919248] f(x) = 0.001099973353975182 gradient norm = 0.0028316286129136167\n",
      "Iteration 526 : x = [1.98135997 1.37947332] f(x) = 0.0010991725128817716 gradient norm = 0.0028247710923081644\n",
      "Iteration 527 : x = [1.98139598 1.3797535 ] f(x) = 0.0010983755455739356 gradient norm = 0.0028179330444617116\n",
      "Iteration 528 : x = [1.98143186 1.380033  ] f(x) = 0.001097582431701983 gradient norm = 0.002811114398578932\n",
      "Iteration 529 : x = [1.98146762 1.38031182] f(x) = 0.0010967931510357095 gradient norm = 0.002804315084247357\n",
      "Iteration 530 : x = [1.98150325 1.38058998] f(x) = 0.0010960076834635748 gradient norm = 0.0027975350314332083\n",
      "Iteration 531 : x = [1.98153876 1.38086747] f(x) = 0.0010952260089918872 gradient norm = 0.002790774170477342\n",
      "Iteration 532 : x = [1.98157415 1.3811443 ] f(x) = 0.0010944481077439874 gradient norm = 0.0027840324320912452\n",
      "Iteration 533 : x = [1.98160942 1.38142046] f(x) = 0.0010936739599594482 gradient norm = 0.002777309747353127\n",
      "Iteration 534 : x = [1.98164456 1.38169596] f(x) = 0.0010929035459932822 gradient norm = 0.002770606047704146\n",
      "Iteration 535 : x = [1.98167959 1.38197079] f(x) = 0.0010921368463151478 gradient norm = 0.0027639212649446516\n",
      "Iteration 536 : x = [1.9817145  1.38224497] f(x) = 0.001091373841508574 gradient norm = 0.0027572553312305522\n",
      "Iteration 537 : x = [1.98174929 1.38251849] f(x) = 0.0010906145122701804 gradient norm = 0.0027506081790697368\n",
      "Iteration 538 : x = [1.98178397 1.38279136] f(x) = 0.0010898588394089137 gradient norm = 0.0027439797413185826\n",
      "Iteration 539 : x = [1.98181853 1.38306357] f(x) = 0.0010891068038452853 gradient norm = 0.0027373699511785412\n",
      "Iteration 540 : x = [1.98185297 1.38333513] f(x) = 0.0010883583866106176 gradient norm = 0.002730778742192771\n",
      "Iteration 541 : x = [1.9818873  1.38360605] f(x) = 0.0010876135688462976 gradient norm = 0.002724206048242881\n",
      "Iteration 542 : x = [1.98192151 1.38387631] f(x) = 0.0010868723318030336 gradient norm = 0.0027176518035456837\n",
      "Iteration 543 : x = [1.98195561 1.38414593] f(x) = 0.001086134656840125 gradient norm = 0.002711115942650073\n",
      "Iteration 544 : x = [1.9819896 1.3844149] f(x) = 0.00108540052542473 gradient norm = 0.00270459840043393\n",
      "Iteration 545 : x = [1.98202348 1.38468323] f(x) = 0.0010846699191311444 gradient norm = 0.00269809911210107\n",
      "Iteration 546 : x = [1.98205724 1.38495092] f(x) = 0.0010839428196400896 gradient norm = 0.0026916180131783224\n",
      "Iteration 547 : x = [1.9820909  1.38521797] f(x) = 0.0010832192087379977 gradient norm = 0.002685155039512573\n",
      "Iteration 548 : x = [1.98212444 1.38548438] f(x) = 0.0010824990683163114 gradient norm = 0.002678710127267936\n",
      "Iteration 549 : x = [1.98215788 1.38575016] f(x) = 0.001081782380370785 gradient norm = 0.0026722832129229546\n",
      "Iteration 550 : x = [1.9821912 1.3860153] f(x) = 0.0010810691270007923 gradient norm = 0.0026658742332678308\n",
      "Iteration 551 : x = [1.98222442 1.38627981] f(x) = 0.0010803592904086413 gradient norm = 0.002659483125401754\n",
      "Iteration 552 : x = [1.98225754 1.38654369] f(x) = 0.0010796528528988912 gradient norm = 0.0026531098267302193\n",
      "Iteration 553 : x = [1.98229054 1.38680694] f(x) = 0.0010789497968776826 gradient norm = 0.0026467542749624693\n",
      "Iteration 554 : x = [1.98232344 1.38706956] f(x) = 0.0010782501048520626 gradient norm = 0.002640416408108909\n",
      "Iteration 555 : x = [1.98235624 1.38733156] f(x) = 0.0010775537594293256 gradient norm = 0.0026340961644786107\n",
      "Iteration 556 : x = [1.98238893 1.38759293] f(x) = 0.0010768607433163505 gradient norm = 0.0026277934826768393\n",
      "Iteration 557 : x = [1.98242151 1.38785368] f(x) = 0.001076171039318952 gradient norm = 0.002621508301602646\n",
      "Iteration 558 : x = [1.98245399 1.38811381] f(x) = 0.0010754846303412304 gradient norm = 0.002615240560446482\n",
      "Iteration 559 : x = [1.98248637 1.38837332] f(x) = 0.0010748014993849282 gradient norm = 0.0026089901986878464\n",
      "Iteration 560 : x = [1.98251865 1.38863222] f(x) = 0.001074121629548795 gradient norm = 0.0026027571560929973\n",
      "Iteration 561 : x = [1.98255083 1.3888905 ] f(x) = 0.0010734450040279556 gradient norm = 0.0025965413727127087\n",
      "Iteration 562 : x = [1.9825829  1.38914816] f(x) = 0.0010727716061132784 gradient norm = 0.0025903427888799967\n",
      "Iteration 563 : x = [1.98261487 1.38940522] f(x) = 0.001072101419190759 gradient norm = 0.002584161345207986\n",
      "Iteration 564 : x = [1.98264675 1.38966166] f(x) = 0.0010714344267408983 gradient norm = 0.002577996982587712\n",
      "Iteration 565 : x = [1.98267852 1.38991749] f(x) = 0.001070770612338092 gradient norm = 0.0025718496421860294\n",
      "Iteration 566 : x = [1.9827102  1.39017272] f(x) = 0.0010701099596500245 gradient norm = 0.0025657192654435193\n",
      "Iteration 567 : x = [1.98274178 1.39042734] f(x) = 0.0010694524524370614 gradient norm = 0.0025596057940724206\n",
      "Iteration 568 : x = [1.98277325 1.39068136] f(x) = 0.0010687980745516569 gradient norm = 0.0025535091700546308\n",
      "Iteration 569 : x = [1.98280464 1.39093477] f(x) = 0.0010681468099377565 gradient norm = 0.0025474293356397043\n",
      "Iteration 570 : x = [1.98283592 1.39118759] f(x) = 0.0010674986426302095 gradient norm = 0.0025413662333428843\n",
      "Iteration 571 : x = [1.98286711 1.3914398 ] f(x) = 0.0010668535567541838 gradient norm = 0.002535319805943172\n",
      "Iteration 572 : x = [1.9828982  1.39169142] f(x) = 0.0010662115365245876 gradient norm = 0.0025292899964814374\n",
      "Iteration 573 : x = [1.9829292  1.39194244] f(x) = 0.0010655725662454929 gradient norm = 0.002523276748258531\n",
      "Iteration 574 : x = [1.9829601  1.39219287] f(x) = 0.0010649366303095652 gradient norm = 0.0025172800048334364\n",
      "Iteration 575 : x = [1.98299091 1.39244271] f(x) = 0.0010643037131974958 gradient norm = 0.0025112997100214334\n",
      "Iteration 576 : x = [1.98302163 1.39269195] f(x) = 0.0010636737994774404 gradient norm = 0.0025053358078923334\n",
      "Iteration 577 : x = [1.98305225 1.39294061] f(x) = 0.0010630468738044626 gradient norm = 0.0024993882427686736\n",
      "Iteration 578 : x = [1.98308278 1.39318868] f(x) = 0.0010624229209199767 gradient norm = 0.002493456959223989\n",
      "Iteration 579 : x = [1.98311322 1.39343616] f(x) = 0.001061801925651201 gradient norm = 0.00248754190208107\n",
      "Iteration 580 : x = [1.98314356 1.39368305] f(x) = 0.0010611838729106117 gradient norm = 0.0024816430164102824\n",
      "Iteration 581 : x = [1.98317382 1.39392937] f(x) = 0.0010605687476954006 gradient norm = 0.002475760247527867\n",
      "Iteration 582 : x = [1.98320398 1.3941751 ] f(x) = 0.0010599565350869393 gradient norm = 0.002469893540994308\n",
      "Iteration 583 : x = [1.98323405 1.39442025] f(x) = 0.0010593472202502449 gradient norm = 0.0024640428426126637\n",
      "Iteration 584 : x = [1.98326403 1.39466482] f(x) = 0.0010587407884334525 gradient norm = 0.0024582080984269913\n",
      "Iteration 585 : x = [1.98329393 1.39490882] f(x) = 0.0010581372249672879 gradient norm = 0.0024523892547207164\n",
      "Iteration 586 : x = [1.98332373 1.39515224] f(x) = 0.0010575365152645459 gradient norm = 0.002446586258015081\n",
      "Iteration 587 : x = [1.98335345 1.39539509] f(x) = 0.0010569386448195748 gradient norm = 0.0024407990550675772\n",
      "Iteration 588 : x = [1.98338307 1.39563736] f(x) = 0.0010563435992077632 gradient norm = 0.002435027592870429\n",
      "Iteration 589 : x = [1.98341261 1.39587907] f(x) = 0.0010557513640850268 gradient norm = 0.002429271818649058\n",
      "Iteration 590 : x = [1.98344206 1.3961202 ] f(x) = 0.0010551619251873063 gradient norm = 0.0024235316798605954\n",
      "Iteration 591 : x = [1.98347143 1.39636077] f(x) = 0.0010545752683300603 gradient norm = 0.002417807124192388\n",
      "Iteration 592 : x = [1.98350071 1.39660077] f(x) = 0.0010539913794077715 gradient norm = 0.0024120980995605496\n",
      "Iteration 593 : x = [1.9835299  1.39684021] f(x) = 0.0010534102443934493 gradient norm = 0.0024064045541085173\n",
      "Iteration 594 : x = [1.98355901 1.39707908] f(x) = 0.0010528318493381373 gradient norm = 0.002400726436205598\n",
      "Iteration 595 : x = [1.98358803 1.39731739] f(x) = 0.0010522561803704281 gradient norm = 0.002395063694445587\n",
      "Iteration 596 : x = [1.98361696 1.39755515] f(x) = 0.0010516832236959761 gradient norm = 0.0023894162776453448\n",
      "Iteration 597 : x = [1.98364582 1.39779234] f(x) = 0.00105111296559702 gradient norm = 0.002383784134843431\n",
      "Iteration 598 : x = [1.98367458 1.39802898] f(x) = 0.0010505453924319012 gradient norm = 0.002378167215298725\n",
      "Iteration 599 : x = [1.98370327 1.39826506] f(x) = 0.001049980490634595 gradient norm = 0.002372565468489093\n",
      "Iteration 600 : x = [1.98373187 1.39850058] f(x) = 0.0010494182467142368 gradient norm = 0.0023669788441100293\n",
      "Iteration 601 : x = [1.98376039 1.39873556] f(x) = 0.0010488586472546543 gradient norm = 0.0023614072920733436\n",
      "Iteration 602 : x = [1.98378882 1.39896998] f(x) = 0.001048301678913908 gradient norm = 0.0023558507625058636\n",
      "Iteration 603 : x = [1.98381717 1.39920385] f(x) = 0.0010477473284238267 gradient norm = 0.0023503092057481265\n",
      "Iteration 604 : x = [1.98384544 1.39943718] f(x) = 0.0010471955825895522 gradient norm = 0.0023447825723530917\n",
      "Iteration 605 : x = [1.98387363 1.39966995] f(x) = 0.001046646428289086 gradient norm = 0.0023392708130848946\n",
      "Iteration 606 : x = [1.98390174 1.39990219] f(x) = 0.0010460998524728378 gradient norm = 0.002333773878917572\n",
      "Iteration 607 : x = [1.98392977 1.40013387] f(x) = 0.0010455558421631783 gradient norm = 0.002328291721033826\n",
      "Iteration 608 : x = [1.98395772 1.40036502] f(x) = 0.001045014384453995 gradient norm = 0.00232282429082379\n",
      "Iteration 609 : x = [1.98398559 1.40059562] f(x) = 0.0010444754665102532 gradient norm = 0.00231737153988383\n",
      "Iteration 610 : x = [1.98401337 1.40082569] f(x) = 0.0010439390755675546 gradient norm = 0.0023119334200153085\n",
      "Iteration 611 : x = [1.98404108 1.40105522] f(x) = 0.0010434051989317056 gradient norm = 0.002306509883223414\n",
      "Iteration 612 : x = [1.98406871 1.40128421] f(x) = 0.0010428738239782838 gradient norm = 0.0023011008817159636\n",
      "Iteration 613 : x = [1.98409626 1.40151266] f(x) = 0.0010423449381522108 gradient norm = 0.002295706367902253\n",
      "Iteration 614 : x = [1.98412374 1.40174058] f(x) = 0.001041818528967325 gradient norm = 0.002290326294391858\n",
      "Iteration 615 : x = [1.98415113 1.40196797] f(x) = 0.0010412945840059605 gradient norm = 0.002284960613993528\n",
      "Iteration 616 : x = [1.98417845 1.40219483] f(x) = 0.001040773090918527 gradient norm = 0.002279609279714023\n",
      "Iteration 617 : x = [1.98420569 1.40242116] f(x) = 0.0010402540374230918 gradient norm = 0.002274272244756986\n",
      "Iteration 618 : x = [1.98423285 1.40264695] f(x) = 0.0010397374113049688 gradient norm = 0.002268949462521835\n",
      "Iteration 619 : x = [1.98425994 1.40287223] f(x) = 0.0010392232004163048 gradient norm = 0.0022636408866026493\n",
      "Iteration 620 : x = [1.98428695 1.40309697] f(x) = 0.0010387113926756738 gradient norm = 0.002258346470787077\n",
      "Iteration 621 : x = [1.98431388 1.4033212 ] f(x) = 0.0010382019760676693 gradient norm = 0.0022530661690552335\n",
      "Iteration 622 : x = [1.98434074 1.4035449 ] f(x) = 0.0010376949386425045 gradient norm = 0.0022477999355786414\n",
      "Iteration 623 : x = [1.98436752 1.40376808] f(x) = 0.0010371902685156113 gradient norm = 0.002242547724719149\n",
      "Iteration 624 : x = [1.98439423 1.40399073] f(x) = 0.0010366879538672446 gradient norm = 0.00223730949102788\n",
      "Iteration 625 : x = [1.98442087 1.40421287] f(x) = 0.0010361879829420858 gradient norm = 0.0022320851892441668\n",
      "Iteration 626 : x = [1.98444742 1.4044345 ] f(x) = 0.001035690344048856 gradient norm = 0.002226874774294538\n",
      "Iteration 627 : x = [1.98447391 1.4046556 ] f(x) = 0.0010351950255599234 gradient norm = 0.0022216782012916617\n",
      "Iteration 628 : x = [1.98450032 1.4048762 ] f(x) = 0.0010347020159109182 gradient norm = 0.002216495425533329\n",
      "Iteration 629 : x = [1.98452666 1.40509627] f(x) = 0.001034211303600351 gradient norm = 0.002211326402501434\n",
      "Iteration 630 : x = [1.98455292 1.40531584] f(x) = 0.0010337228771892305 gradient norm = 0.0022061710878609865\n",
      "Iteration 631 : x = [1.98457911 1.4055349 ] f(x) = 0.001033236725300687 gradient norm = 0.002201029437459086\n",
      "Iteration 632 : x = [1.98460523 1.40575345] f(x) = 0.001032752836619596 gradient norm = 0.0021959014073239555\n",
      "Iteration 633 : x = [1.98463128 1.40597149] f(x) = 0.001032271199892205 gradient norm = 0.0021907869536639487\n",
      "Iteration 634 : x = [1.98465726 1.40618902] f(x) = 0.0010317918039257652 gradient norm = 0.0021856860328665698\n",
      "Iteration 635 : x = [1.98468316 1.40640605] f(x) = 0.0010313146375881621 gradient norm = 0.0021805986014975243\n",
      "Iteration 636 : x = [1.98470899 1.40662257] f(x) = 0.0010308396898075498 gradient norm = 0.002175524616299749\n",
      "Iteration 637 : x = [1.98473475 1.40683859] f(x) = 0.0010303669495719918 gradient norm = 0.00217046403419246\n",
      "Iteration 638 : x = [1.98476044 1.40705412] f(x) = 0.0010298964059290954 gradient norm = 0.0021654168122702193\n",
      "Iteration 639 : x = [1.98478606 1.40726914] f(x) = 0.001029428047985659 gradient norm = 0.002160382907801987\n",
      "Iteration 640 : x = [1.98481161 1.40748366] f(x) = 0.0010289618649073136 gradient norm = 0.0021553622782302024\n",
      "Iteration 641 : x = [1.98483709 1.40769768] f(x) = 0.0010284978459181716 gradient norm = 0.0021503548811698543\n",
      "Iteration 642 : x = [1.9848625  1.40791121] f(x) = 0.0010280359803004748 gradient norm = 0.0021453606744075734\n",
      "Iteration 643 : x = [1.98488783 1.40812425] f(x) = 0.0010275762573942482 gradient norm = 0.002140379615900727\n",
      "Iteration 644 : x = [1.98491311 1.40833679] f(x) = 0.0010271186665969517 gradient norm = 0.0021354116637765067\n",
      "Iteration 645 : x = [1.98493831 1.40854884] f(x) = 0.00102666319736314 gradient norm = 0.002130456776331048\n",
      "Iteration 646 : x = [1.98496344 1.40876039] f(x) = 0.0010262098392041182 gradient norm = 0.0021255149120285384\n",
      "Iteration 647 : x = [1.9849885  1.40897146] f(x) = 0.0010257585816876042 gradient norm = 0.0021205860295003295\n",
      "Iteration 648 : x = [1.9850135  1.40918204] f(x) = 0.0010253094144373938 gradient norm = 0.0021156700875440853\n",
      "Iteration 649 : x = [1.98503843 1.40939214] f(x) = 0.0010248623271330232 gradient norm = 0.002110767045122877\n",
      "Iteration 650 : x = [1.98506329 1.40960174] f(x) = 0.0010244173095094408 gradient norm = 0.002105876861364372\n",
      "Iteration 651 : x = [1.98508808 1.40981087] f(x) = 0.0010239743513566738 gradient norm = 0.0021009994955599356\n",
      "Iteration 652 : x = [1.98511281 1.41001951] f(x) = 0.001023533442519503 gradient norm = 0.0020961349071638006\n",
      "Iteration 653 : x = [1.98513746 1.41022767] f(x) = 0.0010230945728971373 gradient norm = 0.002091283055792237\n",
      "Iteration 654 : x = [1.98516206 1.41043534] f(x) = 0.001022657732442888 gradient norm = 0.00208644390122269\n",
      "Iteration 655 : x = [1.98518658 1.41064254] f(x) = 0.0010222229111638522 gradient norm = 0.0020816174033929644\n",
      "Iteration 656 : x = [1.98521104 1.41084926] f(x) = 0.0010217900991205894 gradient norm = 0.0020768035224004054\n",
      "Iteration 657 : x = [1.98523544 1.4110555 ] f(x) = 0.0010213592864268086 gradient norm = 0.0020720022185010747\n",
      "Iteration 658 : x = [1.98525976 1.41126127] f(x) = 0.0010209304632490506 gradient norm = 0.002067213452108934\n",
      "Iteration 659 : x = [1.98528403 1.41146656] f(x) = 0.001020503619806376 gradient norm = 0.002062437183795035\n",
      "Iteration 660 : x = [1.98530823 1.41167138] f(x) = 0.0010200787463700586 gradient norm = 0.002057673374286738\n",
      "Iteration 661 : x = [1.98533236 1.41187573] f(x) = 0.001019655833263271 gradient norm = 0.0020529219844668957\n",
      "Iteration 662 : x = [1.98535643 1.41207961] f(x) = 0.0010192348708607823 gradient norm = 0.0020481829753730687\n",
      "Iteration 663 : x = [1.98538043 1.41228301] f(x) = 0.0010188158495886522 gradient norm = 0.0020434563081967415\n",
      "Iteration 664 : x = [1.98540437 1.41248595] f(x) = 0.0010183987599239304 gradient norm = 0.0020387419442825577\n",
      "Iteration 665 : x = [1.98542824 1.41268842] f(x) = 0.0010179835923943533 gradient norm = 0.0020340398451275106\n",
      "Iteration 666 : x = [1.98545206 1.41289043] f(x) = 0.0010175703375780497 gradient norm = 0.0020293499723802134\n",
      "Iteration 667 : x = [1.9854758  1.41309197] f(x) = 0.0010171589861032396 gradient norm = 0.0020246722878401154\n",
      "Iteration 668 : x = [1.98549949 1.41329305] f(x) = 0.0010167495286479461 gradient norm = 0.0020200067534567444\n",
      "Iteration 669 : x = [1.98552311 1.41349366] f(x) = 0.0010163419559396968 gradient norm = 0.002015353331328965\n",
      "Iteration 670 : x = [1.98554667 1.41369381] f(x) = 0.0010159362587552354 gradient norm = 0.0020107119837041985\n",
      "Iteration 671 : x = [1.98557016 1.41389351] f(x) = 0.0010155324279202361 gradient norm = 0.0020060826729777314\n",
      "Iteration 672 : x = [1.9855936  1.41409274] f(x) = 0.001015130454309013 gradient norm = 0.002001465361691934\n",
      "Iteration 673 : x = [1.98561697 1.41429152] f(x) = 0.0010147303288442367 gradient norm = 0.001996860012535539\n",
      "Iteration 674 : x = [1.98564028 1.41448984] f(x) = 0.0010143320424966518 gradient norm = 0.001992266588342931\n",
      "Iteration 675 : x = [1.98566353 1.41468771] f(x) = 0.0010139355862847964 gradient norm = 0.0019876850520933955\n",
      "Iteration 676 : x = [1.98568671 1.41488512] f(x) = 0.0010135409512747199 gradient norm = 0.001983115366910415\n",
      "Iteration 677 : x = [1.98570984 1.41508208] f(x) = 0.0010131481285797093 gradient norm = 0.001978557496060953\n",
      "Iteration 678 : x = [1.9857329  1.41527858] f(x) = 0.0010127571093600128 gradient norm = 0.0019740114029547506\n",
      "Iteration 679 : x = [1.98575591 1.41547464] f(x) = 0.0010123678848225624 gradient norm = 0.0019694770511436053\n",
      "Iteration 680 : x = [1.98577885 1.41567025] f(x) = 0.0010119804462207075 gradient norm = 0.0019649544043206873\n",
      "Iteration 681 : x = [1.98580173 1.41586541] f(x) = 0.00101159478485394 gradient norm = 0.001960443426319829\n",
      "Iteration 682 : x = [1.98582455 1.41606012] f(x) = 0.0010112108920676292 gradient norm = 0.0019559440811148503\n",
      "Iteration 683 : x = [1.98584731 1.41625438] f(x) = 0.0010108287592527525 gradient norm = 0.001951456332818852\n",
      "Iteration 684 : x = [1.98587002 1.4164482 ] f(x) = 0.0010104483778456328 gradient norm = 0.0019469801456835566\n",
      "Iteration 685 : x = [1.98589266 1.41664158] f(x) = 0.0010100697393276722 gradient norm = 0.0019425154840986038\n",
      "Iteration 686 : x = [1.98591524 1.41683451] f(x) = 0.0010096928352250948 gradient norm = 0.0019380623125909056\n",
      "Iteration 687 : x = [1.98593777 1.41702701] f(x) = 0.0010093176571086824 gradient norm = 0.0019336205958239466\n",
      "Iteration 688 : x = [1.98596023 1.41721906] f(x) = 0.0010089441965935196 gradient norm = 0.0019291902985971415\n",
      "Iteration 689 : x = [1.98598264 1.41741067] f(x) = 0.0010085724453387345 gradient norm = 0.0019247713858451595\n",
      "Iteration 690 : x = [1.98600498 1.41760185] f(x) = 0.0010082023950472474 gradient norm = 0.0019203638226372864\n",
      "Iteration 691 : x = [1.98602727 1.41779259] f(x) = 0.0010078340374655138 gradient norm = 0.0019159675741767406\n",
      "Iteration 692 : x = [1.9860495  1.41798289] f(x) = 0.001007467364383276 gradient norm = 0.001911582605800053\n",
      "Iteration 693 : x = [1.98607168 1.41817276] f(x) = 0.0010071023676333111 gradient norm = 0.0019072088829764117\n",
      "Iteration 694 : x = [1.98609379 1.41836219] f(x) = 0.0010067390390911843 gradient norm = 0.0019028463713070135\n",
      "Iteration 695 : x = [1.98611585 1.41855119] f(x) = 0.0010063773706750008 gradient norm = 0.0018984950365244448\n",
      "Iteration 696 : x = [1.98613785 1.41873976] f(x) = 0.0010060173543451614 gradient norm = 0.001894154844492033\n",
      "Iteration 697 : x = [1.98615979 1.41892791] f(x) = 0.0010056589821041196 gradient norm = 0.0018898257612032217\n",
      "Iteration 698 : x = [1.98618168 1.41911562] f(x) = 0.0010053022459961375 gradient norm = 0.0018855077527809463\n",
      "Iteration 699 : x = [1.9862035 1.4193029] f(x) = 0.0010049471381070475 gradient norm = 0.0018812007854770102\n",
      "Iteration 700 : x = [1.98622528 1.41948976] f(x) = 0.0010045936505640135 gradient norm = 0.001876904825671482\n",
      "Iteration 701 : x = [1.98624699 1.41967619] f(x) = 0.001004241775535292 gradient norm = 0.0018726198398720513\n",
      "Iteration 702 : x = [1.98626865 1.41986219] f(x) = 0.0010038915052299965 gradient norm = 0.0018683457947134548\n",
      "Iteration 703 : x = [1.98629025 1.42004777] f(x) = 0.001003542831897865 gradient norm = 0.0018640826569568377\n",
      "Iteration 704 : x = [1.9863118  1.42023293] f(x) = 0.001003195747829025 gradient norm = 0.0018598303934891783\n",
      "Iteration 705 : x = [1.98633329 1.42041767] f(x) = 0.0010028502453537644 gradient norm = 0.0018555889713226673\n",
      "Iteration 706 : x = [1.98635473 1.42060198] f(x) = 0.0010025063168422979 gradient norm = 0.0018513583575941127\n",
      "Iteration 707 : x = [1.98637611 1.42078588] f(x) = 0.001002163954704544 gradient norm = 0.00184713851956438\n",
      "Iteration 708 : x = [1.98639743 1.42096936] f(x) = 0.0010018231513898939 gradient norm = 0.001842929424617761\n",
      "Iteration 709 : x = [1.9864187  1.42115242] f(x) = 0.0010014838993869873 gradient norm = 0.0018387310402614163\n",
      "Iteration 710 : x = [1.98643992 1.42133507] f(x) = 0.001001146191223487 gradient norm = 0.0018345433341247735\n",
      "Iteration 711 : x = [1.98646108 1.4215173 ] f(x) = 0.0010008100194658614 gradient norm = 0.0018303662739589843\n",
      "Iteration 712 : x = [1.98648219 1.42169911] f(x) = 0.0010004753767191552 gradient norm = 0.0018261998276363055\n",
      "Iteration 713 : x = [1.98650324 1.42188051] f(x) = 0.0010001422556267776 gradient norm = 0.0018220439631495685\n",
      "Iteration 714 : x = [1.98652424 1.4220615 ] f(x) = 0.0009998106488702783 gradient norm = 0.0018178986486115745\n",
      "Iteration 715 : x = [1.98654518 1.42224208] f(x) = 0.0009994805491691321 gradient norm = 0.0018137638522545579\n",
      "Iteration 716 : x = [1.98656607 1.42242225] f(x) = 0.0009991519492805255 gradient norm = 0.0018096395424296258\n",
      "Iteration 717 : x = [1.98658691 1.42260201] f(x) = 0.000998824841999139 gradient norm = 0.0018055256876061746\n",
      "Iteration 718 : x = [1.98660769 1.42278137] f(x) = 0.000998499220156936 gradient norm = 0.001801422256371363\n",
      "Iteration 719 : x = [1.98662842 1.42296031] f(x) = 0.0009981750766229513 gradient norm = 0.0017973292174295443\n",
      "Iteration 720 : x = [1.9866491  1.42313885] f(x) = 0.0009978524043030806 gradient norm = 0.001793246539601729\n",
      "Iteration 721 : x = [1.98666972 1.42331699] f(x) = 0.0009975311961398713 gradient norm = 0.0017891741918250293\n",
      "Iteration 722 : x = [1.9866903  1.42349472] f(x) = 0.0009972114451123144 gradient norm = 0.001785112143152128\n",
      "Iteration 723 : x = [1.98671082 1.42367204] f(x) = 0.0009968931442356408 gradient norm = 0.001781060362750734\n",
      "Iteration 724 : x = [1.98673128 1.42384897] f(x) = 0.0009965762865611117 gradient norm = 0.0017770188199030443\n",
      "Iteration 725 : x = [1.9867517 1.4240255] f(x) = 0.0009962608651758204 gradient norm = 0.0017729874840052306\n",
      "Iteration 726 : x = [1.98677206 1.42420162] f(x) = 0.0009959468732024857 gradient norm = 0.0017689663245668765\n",
      "Iteration 727 : x = [1.98679237 1.42437735] f(x) = 0.0009956343037992516 gradient norm = 0.0017649553112104874\n",
      "Iteration 728 : x = [1.98681263 1.42455268] f(x) = 0.0009953231501594886 gradient norm = 0.0017609544136709386\n",
      "Iteration 729 : x = [1.98683283 1.42472761] f(x) = 0.0009950134055115955 gradient norm = 0.0017569636017949759\n",
      "Iteration 730 : x = [1.98685299 1.42490215] f(x) = 0.000994705063118799 gradient norm = 0.0017529828455406867\n",
      "Iteration 731 : x = [1.9868731  1.42507629] f(x) = 0.0009943981162789614 gradient norm = 0.0017490121149769992\n",
      "Iteration 732 : x = [1.98689315 1.42525004] f(x) = 0.0009940925583243826 gradient norm = 0.0017450513802831432\n",
      "Iteration 733 : x = [1.98691315 1.42542339] f(x) = 0.0009937883826216076 gradient norm = 0.0017411006117481836\n",
      "Iteration 734 : x = [1.9869331  1.42559635] f(x) = 0.0009934855825712336 gradient norm = 0.0017371597797704672\n",
      "Iteration 735 : x = [1.986953   1.42576893] f(x) = 0.0009931841516077212 gradient norm = 0.001733228854857173\n",
      "Iteration 736 : x = [1.98697285 1.42594111] f(x) = 0.000992884083199199 gradient norm = 0.0017293078076237548\n",
      "Iteration 737 : x = [1.98699266 1.4261129 ] f(x) = 0.0009925853708472809 gradient norm = 0.001725396608793507\n",
      "Iteration 738 : x = [1.98701241 1.42628431] f(x) = 0.0009922880080868721 gradient norm = 0.0017214952291970094\n",
      "Iteration 739 : x = [1.98703211 1.42645533] f(x) = 0.0009919919884859901 gradient norm = 0.0017176036397716905\n",
      "Iteration 740 : x = [1.98705176 1.42662596] f(x) = 0.0009916973056455706 gradient norm = 0.0017137218115613048\n",
      "Iteration 741 : x = [1.98707136 1.42679621] f(x) = 0.00099140395319929 gradient norm = 0.0017098497157154423\n",
      "Iteration 742 : x = [1.98709091 1.42696607] f(x) = 0.000991111924813379 gradient norm = 0.0017059873234890764\n",
      "Iteration 743 : x = [1.98711041 1.42713555] f(x) = 0.0009908212141864414 gradient norm = 0.0017021346062420695\n",
      "Iteration 744 : x = [1.98712986 1.42730465] f(x) = 0.000990531815049274 gradient norm = 0.001698291535438685\n",
      "Iteration 745 : x = [1.98714927 1.42747337] f(x) = 0.0009902437211646857 gradient norm = 0.0016944580826471246\n",
      "Iteration 746 : x = [1.98716862 1.4276417 ] f(x) = 0.0009899569263273195 gradient norm = 0.0016906342195390513\n",
      "Iteration 747 : x = [1.98718793 1.42780966] f(x) = 0.0009896714243634746 gradient norm = 0.0016868199178891271\n",
      "Iteration 748 : x = [1.98720719 1.42797724] f(x) = 0.0009893872091309304 gradient norm = 0.0016830151495745326\n",
      "Iteration 749 : x = [1.98722639 1.42814444] f(x) = 0.0009891042745187716 gradient norm = 0.0016792198865745232\n",
      "Iteration 750 : x = [1.98724556 1.42831127] f(x) = 0.0009888226144472117 gradient norm = 0.0016754341009699374\n",
      "Iteration 751 : x = [1.98726467 1.42847772] f(x) = 0.000988542222867424 gradient norm = 0.0016716577649427751\n",
      "Iteration 752 : x = [1.98728373 1.42864379] f(x) = 0.0009882630937613642 gradient norm = 0.0016678908507757105\n",
      "Iteration 753 : x = [1.98730275 1.42880949] f(x) = 0.0009879852211416044 gradient norm = 0.0016641333308516529\n",
      "Iteration 754 : x = [1.98732172 1.42897482] f(x) = 0.0009877085990511593 gradient norm = 0.0016603851776532917\n",
      "Iteration 755 : x = [1.98734064 1.42913978] f(x) = 0.0009874332215633198 gradient norm = 0.0016566463637626482\n",
      "Iteration 756 : x = [1.98735951 1.42930436] f(x) = 0.0009871590827814835 gradient norm = 0.0016529168618606286\n",
      "Iteration 757 : x = [1.98737834 1.42946858] f(x) = 0.0009868861768389887 gradient norm = 0.0016491966447265821\n",
      "Iteration 758 : x = [1.98739712 1.42963243] f(x) = 0.0009866144978989487 gradient norm = 0.0016454856852378553\n",
      "Iteration 759 : x = [1.98741585 1.4297959 ] f(x) = 0.0009863440401540848 gradient norm = 0.0016417839563693543\n",
      "Iteration 760 : x = [1.98743454 1.42995902] f(x) = 0.0009860747978265665 gradient norm = 0.0016380914311931092\n",
      "Iteration 761 : x = [1.98745318 1.43012176] f(x) = 0.0009858067651678443 gradient norm = 0.0016344080828778434\n",
      "Iteration 762 : x = [1.98747177 1.43028414] f(x) = 0.0009855399364584914 gradient norm = 0.0016307338846885298\n",
      "Iteration 763 : x = [1.98749032 1.43044616] f(x) = 0.0009852743060080413 gradient norm = 0.0016270688099859856\n",
      "Iteration 764 : x = [1.98750882 1.43060781] f(x) = 0.0009850098681548267 gradient norm = 0.0016234128322264135\n",
      "Iteration 765 : x = [1.98752727 1.4307691 ] f(x) = 0.0009847466172658236 gradient norm = 0.0016197659249609984\n",
      "Iteration 766 : x = [1.98754568 1.43093002] f(x) = 0.000984484547736491 gradient norm = 0.0016161280618354826\n",
      "Iteration 767 : x = [1.98756404 1.43109059] f(x) = 0.000984223653990615 gradient norm = 0.0016124992165897352\n",
      "Iteration 768 : x = [1.98758236 1.4312508 ] f(x) = 0.0009839639304801513 gradient norm = 0.0016088793630573343\n",
      "Iteration 769 : x = [1.98760063 1.43141064] f(x) = 0.0009837053716850732 gradient norm = 0.0016052684751651826\n",
      "Iteration 770 : x = [1.98761885 1.43157013] f(x) = 0.000983447972113215 gradient norm = 0.0016016665269330454\n",
      "Iteration 771 : x = [1.98763703 1.43172926] f(x) = 0.0009831917263001188 gradient norm = 0.0015980734924731725\n",
      "Iteration 772 : x = [1.98765517 1.43188804] f(x) = 0.0009829366288088839 gradient norm = 0.0015944893459898747\n",
      "Iteration 773 : x = [1.98767326 1.43204646] f(x) = 0.0009826826742300133 gradient norm = 0.0015909140617791297\n",
      "Iteration 774 : x = [1.9876913  1.43220452] f(x) = 0.000982429857181267 gradient norm = 0.0015873476142281718\n",
      "Iteration 775 : x = [1.9877093  1.43236223] f(x) = 0.0009821781723075072 gradient norm = 0.0015837899778150713\n",
      "Iteration 776 : x = [1.98772726 1.43251959] f(x) = 0.0009819276142805547 gradient norm = 0.0015802411271083742\n",
      "Iteration 777 : x = [1.98774517 1.4326766 ] f(x) = 0.0009816781777990387 gradient norm = 0.0015767010367666626\n",
      "Iteration 778 : x = [1.98776304 1.43283325] f(x) = 0.00098142985758825 gradient norm = 0.00157316968153819\n",
      "Iteration 779 : x = [1.98778086 1.43298956] f(x) = 0.0009811826483999955 gradient norm = 0.0015696470362604644\n",
      "Iteration 780 : x = [1.98779864 1.43314551] f(x) = 0.0009809365450124544 gradient norm = 0.001566133075859873\n",
      "Iteration 781 : x = [1.98781637 1.43330112] f(x) = 0.0009806915422300316 gradient norm = 0.0015626277753512869\n",
      "Iteration 782 : x = [1.98783406 1.43345638] f(x) = 0.0009804476348832163 gradient norm = 0.0015591311098376655\n",
      "Iteration 783 : x = [1.98785171 1.43361129] f(x) = 0.0009802048178284394 gradient norm = 0.0015556430545096906\n",
      "Iteration 784 : x = [1.98786931 1.43376585] f(x) = 0.0009799630859479319 gradient norm = 0.0015521635846453626\n",
      "Iteration 785 : x = [1.98788687 1.43392007] f(x) = 0.0009797224341495819 gradient norm = 0.0015486926756096287\n",
      "Iteration 786 : x = [1.98790439 1.43407395] f(x) = 0.0009794828573667991 gradient norm = 0.0015452303028540056\n",
      "Iteration 787 : x = [1.98792186 1.43422748] f(x) = 0.0009792443505583733 gradient norm = 0.0015417764419161984\n",
      "Iteration 788 : x = [1.98793929 1.43438067] f(x) = 0.0009790069087083346 gradient norm = 0.001538331068419726\n",
      "Iteration 789 : x = [1.98795668 1.43453352] f(x) = 0.00097877052682582 gradient norm = 0.0015348941580735518\n",
      "Iteration 790 : x = [1.98797402 1.43468602] f(x) = 0.000978535199944933 gradient norm = 0.0015314656866717005\n",
      "Iteration 791 : x = [1.98799132 1.43483819] f(x) = 0.0009783009231246105 gradient norm = 0.00152804563009291\n",
      "Iteration 792 : x = [1.98800858 1.43499002] f(x) = 0.0009780676914484874 gradient norm = 0.0015246339643002354\n",
      "Iteration 793 : x = [1.9880258 1.4351415] f(x) = 0.0009778355000247623 gradient norm = 0.0015212306653407126\n",
      "Iteration 794 : x = [1.98804297 1.43529265] f(x) = 0.0009776043439860627 gradient norm = 0.0015178357093449729\n",
      "Iteration 795 : x = [1.9880601  1.43544347] f(x) = 0.0009773742184893152 gradient norm = 0.0015144490725268955\n",
      "Iteration 796 : x = [1.98807719 1.43559395] f(x) = 0.0009771451187156118 gradient norm = 0.0015110707311832355\n",
      "Iteration 797 : x = [1.98809424 1.43574409] f(x) = 0.0009769170398700809 gradient norm = 0.0015077006616932853\n",
      "Iteration 798 : x = [1.98811125 1.4358939 ] f(x) = 0.0009766899771817548 gradient norm = 0.0015043388405184936\n",
      "Iteration 799 : x = [1.98812821 1.43604337] f(x) = 0.0009764639259034421 gradient norm = 0.001500985244202133\n",
      "Iteration 800 : x = [1.98814514 1.43619251] f(x) = 0.0009762388813115987 gradient norm = 0.0014976398493689294\n",
      "Iteration 801 : x = [1.98816202 1.43634132] f(x) = 0.0009760148387062001 gradient norm = 0.001494302632724733\n",
      "Iteration 802 : x = [1.98817886 1.4364898 ] f(x) = 0.000975791793410613 gradient norm = 0.0014909735710561484\n",
      "Iteration 803 : x = [1.98819565 1.43663795] f(x) = 0.0009755697407714714 gradient norm = 0.0014876526412302012\n",
      "Iteration 804 : x = [1.98821241 1.43678577] f(x) = 0.0009753486761585497 gradient norm = 0.0014843398201939927\n",
      "Iteration 805 : x = [1.98822913 1.43693326] f(x) = 0.000975128594964638 gradient norm = 0.0014810350849743478\n",
      "Iteration 806 : x = [1.9882458  1.43708042] f(x) = 0.0009749094926054172 gradient norm = 0.0014777384126774833\n",
      "Iteration 807 : x = [1.98826244 1.43722725] f(x) = 0.0009746913645193373 gradient norm = 0.0014744497804886592\n",
      "Iteration 808 : x = [1.98827903 1.43737376] f(x) = 0.0009744742061674936 gradient norm = 0.0014711691656718521\n",
      "Iteration 809 : x = [1.98829559 1.43751994] f(x) = 0.0009742580130335065 gradient norm = 0.0014678965455694189\n",
      "Iteration 810 : x = [1.9883121 1.4376658] f(x) = 0.0009740427806233987 gradient norm = 0.0014646318976017452\n",
      "Iteration 811 : x = [1.98832857 1.43781133] f(x) = 0.0009738285044654738 gradient norm = 0.0014613751992669332\n",
      "Iteration 812 : x = [1.98834501 1.43795655] f(x) = 0.0009736151801101996 gradient norm = 0.001458126428140449\n",
      "Iteration 813 : x = [1.9883614  1.43810143] f(x) = 0.0009734028031300872 gradient norm = 0.0014548855618748276\n",
      "Iteration 814 : x = [1.98837775 1.438246  ] f(x) = 0.0009731913691195722 gradient norm = 0.0014516525781993065\n",
      "Iteration 815 : x = [1.98839406 1.43839025] f(x) = 0.000972980873694899 gradient norm = 0.0014484274549195293\n",
      "Iteration 816 : x = [1.98841034 1.43853417] f(x) = 0.0009727713124940035 gradient norm = 0.0014452101699172133\n",
      "Iteration 817 : x = [1.98842657 1.43867778] f(x) = 0.0009725626811763936 gradient norm = 0.0014420007011498104\n",
      "Iteration 818 : x = [1.98844277 1.43882107] f(x) = 0.000972354975423038 gradient norm = 0.0014387990266502143\n",
      "Iteration 819 : x = [1.98845892 1.43896404] f(x) = 0.0009721481909362505 gradient norm = 0.0014356051245264208\n",
      "Iteration 820 : x = [1.98847504 1.43910669] f(x) = 0.0009719423234395729 gradient norm = 0.0014324189729612194\n",
      "Iteration 821 : x = [1.98849111 1.43924903] f(x) = 0.0009717373686776641 gradient norm = 0.0014292405502118757\n",
      "Iteration 822 : x = [1.98850715 1.43939105] f(x) = 0.0009715333224161879 gradient norm = 0.0014260698346098193\n",
      "Iteration 823 : x = [1.98852315 1.43953275] f(x) = 0.0009713301804416982 gradient norm = 0.001422906804560327\n",
      "Iteration 824 : x = [1.98853911 1.43967415] f(x) = 0.0009711279385615292 gradient norm = 0.0014197514385422127\n",
      "Iteration 825 : x = [1.98855503 1.43981523] f(x) = 0.0009709265926036847 gradient norm = 0.001416603715107522\n",
      "Iteration 826 : x = [1.98857091 1.43995599] f(x) = 0.0009707261384167269 gradient norm = 0.001413463612881222\n",
      "Iteration 827 : x = [1.98858675 1.44009645] f(x) = 0.0009705265718696664 gradient norm = 0.0014103311105608859\n",
      "Iteration 828 : x = [1.98860256 1.44023659] f(x) = 0.0009703278888518568 gradient norm = 0.0014072061869164127\n",
      "Iteration 829 : x = [1.98861833 1.44037643] f(x) = 0.0009701300852728809 gradient norm = 0.0014040888207896974\n",
      "Iteration 830 : x = [1.98863405 1.44051595] f(x) = 0.0009699331570624479 gradient norm = 0.0014009789910943446\n",
      "Iteration 831 : x = [1.98864975 1.44065517] f(x) = 0.0009697371001702829 gradient norm = 0.0013978766768153702\n",
      "Iteration 832 : x = [1.9886654  1.44079408] f(x) = 0.0009695419105660233 gradient norm = 0.001394781857008892\n",
      "Iteration 833 : x = [1.98868101 1.44093268] f(x) = 0.0009693475842391104 gradient norm = 0.0013916945108018294\n",
      "Iteration 834 : x = [1.98869659 1.44107098] f(x) = 0.0009691541171986867 gradient norm = 0.0013886146173916285\n",
      "Iteration 835 : x = [1.98871213 1.44120896] f(x) = 0.0009689615054734893 gradient norm = 0.0013855421560459555\n",
      "Iteration 836 : x = [1.98872763 1.44134665] f(x) = 0.0009687697451117468 gradient norm = 0.0013824771061024023\n",
      "Iteration 837 : x = [1.9887431  1.44148403] f(x) = 0.0009685788321810768 gradient norm = 0.001379419446968202\n",
      "Iteration 838 : x = [1.98875852 1.44162111] f(x) = 0.0009683887627683812 gradient norm = 0.001376369158119927\n",
      "Iteration 839 : x = [1.98877391 1.44175788] f(x) = 0.0009681995329797456 gradient norm = 0.0013733262191032174\n",
      "Iteration 840 : x = [1.98878927 1.44189435] f(x) = 0.0009680111389403376 gradient norm = 0.0013702906095324871\n",
      "Iteration 841 : x = [1.98880458 1.44203052] f(x) = 0.0009678235767943048 gradient norm = 0.0013672623090906332\n",
      "Iteration 842 : x = [1.98881986 1.44216639] f(x) = 0.0009676368427046766 gradient norm = 0.001364241297528757\n",
      "Iteration 843 : x = [1.9888351  1.44230196] f(x) = 0.0009674509328532608 gradient norm = 0.0013612275546658866\n",
      "Iteration 844 : x = [1.98885031 1.44243723] f(x) = 0.0009672658434405477 gradient norm = 0.0013582210603886894\n",
      "Iteration 845 : x = [1.98886548 1.4425722 ] f(x) = 0.0009670815706856112 gradient norm = 0.0013552217946511938\n",
      "Iteration 846 : x = [1.98888061 1.44270688] f(x) = 0.0009668981108260081 gradient norm = 0.0013522297374745085\n",
      "Iteration 847 : x = [1.98889571 1.44284126] f(x) = 0.0009667154601176829 gradient norm = 0.0013492448689465574\n",
      "Iteration 848 : x = [1.98891077 1.44297534] f(x) = 0.000966533614834871 gradient norm = 0.0013462671692217858\n",
      "Iteration 849 : x = [1.98892579 1.44310912] f(x) = 0.0009663525712700003 gradient norm = 0.0013432966185209054\n",
      "Iteration 850 : x = [1.98894078 1.44324261] f(x) = 0.0009661723257335976 gradient norm = 0.0013403331971306033\n",
      "Iteration 851 : x = [1.98895573 1.44337581] f(x) = 0.0009659928745541917 gradient norm = 0.001337376885403289\n",
      "Iteration 852 : x = [1.98897065 1.44350871] f(x) = 0.0009658142140782198 gradient norm = 0.0013344276637568102\n",
      "Iteration 853 : x = [1.98898553 1.44364133] f(x) = 0.0009656363406699326 gradient norm = 0.0013314855126741968\n",
      "Iteration 854 : x = [1.98900037 1.44377364] f(x) = 0.0009654592507113009 gradient norm = 0.0013285504127033777\n",
      "Iteration 855 : x = [1.98901518 1.44390567] f(x) = 0.0009652829406019229 gradient norm = 0.001325622344456932\n",
      "Iteration 856 : x = [1.98902995 1.44403741] f(x) = 0.0009651074067589308 gradient norm = 0.0013227012886118151\n",
      "Iteration 857 : x = [1.98904469 1.44416885] f(x) = 0.0009649326456168992 gradient norm = 0.0013197872259090903\n",
      "Iteration 858 : x = [1.98905939 1.44430001] f(x) = 0.0009647586536277536 gradient norm = 0.0013168801371536859\n",
      "Iteration 859 : x = [1.98907406 1.44443088] f(x) = 0.0009645854272606798 gradient norm = 0.001313980003214106\n",
      "Iteration 860 : x = [1.98908869 1.44456146] f(x) = 0.000964412963002033 gradient norm = 0.0013110868050222083\n",
      "Iteration 861 : x = [1.98910329 1.44469175] f(x) = 0.0009642412573552468 gradient norm = 0.0013082005235729001\n",
      "Iteration 862 : x = [1.98911785 1.44482176] f(x) = 0.0009640703068407474 gradient norm = 0.0013053211399239278\n",
      "Iteration 863 : x = [1.98913238 1.44495148] f(x) = 0.000963900107995859 gradient norm = 0.0013024486351955909\n",
      "Iteration 864 : x = [1.98914687 1.44508092] f(x) = 0.000963730657374721 gradient norm = 0.0012995829905704979\n",
      "Iteration 865 : x = [1.98916133 1.44521007] f(x) = 0.0009635619515481964 gradient norm = 0.001296724187293306\n",
      "Iteration 866 : x = [1.98917575 1.44533894] f(x) = 0.0009633939871037867 gradient norm = 0.001293872206670491\n",
      "Iteration 867 : x = [1.98919014 1.44546752] f(x) = 0.0009632267606455432 gradient norm = 0.0012910270300700722\n",
      "Iteration 868 : x = [1.9892045  1.44559582] f(x) = 0.0009630602687939813 gradient norm = 0.0012881886389213622\n",
      "Iteration 869 : x = [1.98921882 1.44572384] f(x) = 0.0009628945081859959 gradient norm = 0.0012853570147147544\n",
      "Iteration 870 : x = [1.98923311 1.44585158] f(x) = 0.0009627294754747726 gradient norm = 0.0012825321390014248\n",
      "Iteration 871 : x = [1.98924736 1.44597904] f(x) = 0.0009625651673297072 gradient norm = 0.0012797139933931265\n",
      "Iteration 872 : x = [1.98926158 1.44610622] f(x) = 0.0009624015804363172 gradient norm = 0.0012769025595619273\n",
      "Iteration 873 : x = [1.98927576 1.44623312] f(x) = 0.0009622387114961611 gradient norm = 0.0012740978192399774\n",
      "Iteration 874 : x = [1.98928991 1.44635974] f(x) = 0.0009620765572267523 gradient norm = 0.0012712997542192476\n",
      "Iteration 875 : x = [1.98930403 1.44648609] f(x) = 0.0009619151143614778 gradient norm = 0.0012685083463513057\n",
      "Iteration 876 : x = [1.98931811 1.44661215] f(x) = 0.0009617543796495143 gradient norm = 0.0012657235775470708\n",
      "Iteration 877 : x = [1.98933216 1.44673794] f(x) = 0.0009615943498557486 gradient norm = 0.0012629454297765914\n",
      "Iteration 878 : x = [1.98934618 1.44686346] f(x) = 0.0009614350217606924 gradient norm = 0.0012601738850687666\n",
      "Iteration 879 : x = [1.98936016 1.4469887 ] f(x) = 0.0009612763921604038 gradient norm = 0.0012574089255111601\n",
      "Iteration 880 : x = [1.98937411 1.44711366] f(x) = 0.0009611184578664062 gradient norm = 0.0012546505332497219\n",
      "Iteration 881 : x = [1.98938803 1.44723835] f(x) = 0.0009609612157056068 gradient norm = 0.001251898690488584\n",
      "Iteration 882 : x = [1.98940191 1.44736277] f(x) = 0.0009608046625202192 gradient norm = 0.0012491533794898176\n",
      "Iteration 883 : x = [1.98941577 1.44748692] f(x) = 0.0009606487951676811 gradient norm = 0.001246414582573196\n",
      "Iteration 884 : x = [1.98942958 1.44761079] f(x) = 0.0009604936105205778 gradient norm = 0.0012436822821159717\n",
      "Iteration 885 : x = [1.98944337 1.44773439] f(x) = 0.0009603391054665626 gradient norm = 0.0012409564605526423\n",
      "Iteration 886 : x = [1.98945712 1.44785772] f(x) = 0.0009601852769082793 gradient norm = 0.001238237100374728\n",
      "Iteration 887 : x = [1.98947084 1.44798078] f(x) = 0.0009600321217632843 gradient norm = 0.0012355241841305344\n",
      "Iteration 888 : x = [1.98948453 1.44810357] f(x) = 0.0009598796369639699 gradient norm = 0.0012328176944249353\n",
      "Iteration 889 : x = [1.98949818 1.4482261 ] f(x) = 0.0009597278194574877 gradient norm = 0.0012301176139191516\n",
      "Iteration 890 : x = [1.98951181 1.44834835] f(x) = 0.0009595766662056711 gradient norm = 0.0012274239253305074\n",
      "Iteration 891 : x = [1.9895254  1.44847034] f(x) = 0.0009594261741849613 gradient norm = 0.0012247366114322296\n",
      "Iteration 892 : x = [1.98953896 1.44859206] f(x) = 0.0009592763403863308 gradient norm = 0.0012220556550532142\n",
      "Iteration 893 : x = [1.98955248 1.44871352] f(x) = 0.0009591271618152078 gradient norm = 0.0012193810390778072\n",
      "Iteration 894 : x = [1.98956598 1.44883471] f(x) = 0.0009589786354914056 gradient norm = 0.0012167127464455907\n",
      "Iteration 895 : x = [1.98957944 1.44895563] f(x) = 0.0009588307584490409 gradient norm = 0.0012140507601511477\n",
      "Iteration 896 : x = [1.98959287 1.44907629] f(x) = 0.0009586835277364682 gradient norm = 0.0012113950632438707\n",
      "Iteration 897 : x = [1.98960627 1.44919669] f(x) = 0.000958536940416201 gradient norm = 0.0012087456388277182\n",
      "Iteration 898 : x = [1.98961964 1.44931682] f(x) = 0.0009583909935648427 gradient norm = 0.0012061024700610217\n",
      "Iteration 899 : x = [1.98963297 1.44943669] f(x) = 0.0009582456842730106 gradient norm = 0.001203465540156257\n",
      "Iteration 900 : x = [1.98964628 1.4495563 ] f(x) = 0.0009581010096452659 gradient norm = 0.0012008348323798309\n",
      "Iteration 901 : x = [1.98965955 1.44967565] f(x) = 0.0009579569668000417 gradient norm = 0.0011982103300518787\n",
      "Iteration 902 : x = [1.98967279 1.44979473] f(x) = 0.0009578135528695718 gradient norm = 0.0011955920165460465\n",
      "Iteration 903 : x = [1.989686   1.44991356] f(x) = 0.0009576707649998206 gradient norm = 0.0011929798752892797\n",
      "Iteration 904 : x = [1.98969918 1.45003213] f(x) = 0.0009575286003504105 gradient norm = 0.0011903738897616136\n",
      "Iteration 905 : x = [1.98971233 1.45015044] f(x) = 0.000957387056094553 gradient norm = 0.001187774043495968\n",
      "Iteration 906 : x = [1.98972545 1.45026849] f(x) = 0.0009572461294189804 gradient norm = 0.0011851803200779412\n",
      "Iteration 907 : x = [1.98973854 1.45038628] f(x) = 0.0009571058175238743 gradient norm = 0.0011825927031455968\n",
      "Iteration 908 : x = [1.98975159 1.45050382] f(x) = 0.0009569661176227975 gradient norm = 0.001180011176389259\n",
      "Iteration 909 : x = [1.98976462 1.4506211 ] f(x) = 0.0009568270269426257 gradient norm = 0.001177435723551317\n",
      "Iteration 910 : x = [1.98977761 1.45073812] f(x) = 0.0009566885427234798 gradient norm = 0.0011748663284260157\n",
      "Iteration 911 : x = [1.98979057 1.45085489] f(x) = 0.0009565506622186565 gradient norm = 0.0011723029748592476\n",
      "Iteration 912 : x = [1.98980351 1.45097141] f(x) = 0.0009564133826945637 gradient norm = 0.0011697456467483673\n",
      "Iteration 913 : x = [1.98981641 1.45108767] f(x) = 0.00095627670143065 gradient norm = 0.0011671943280419685\n",
      "Iteration 914 : x = [1.98982928 1.45120367] f(x) = 0.000956140615719341 gradient norm = 0.0011646490027396995\n",
      "Iteration 915 : x = [1.98984213 1.45131943] f(x) = 0.0009560051228659708 gradient norm = 0.0011621096548920648\n",
      "Iteration 916 : x = [1.98985494 1.45143493] f(x) = 0.0009558702201887185 gradient norm = 0.0011595762686002192\n",
      "Iteration 917 : x = [1.98986772 1.45155018] f(x) = 0.0009557359050185408 gradient norm = 0.0011570488280157813\n",
      "Iteration 918 : x = [1.98988047 1.45166518] f(x) = 0.0009556021746991067 gradient norm = 0.0011545273173406247\n",
      "Iteration 919 : x = [1.98989319 1.45177993] f(x) = 0.0009554690265867344 gradient norm = 0.0011520117208266914\n",
      "Iteration 920 : x = [1.98990589 1.45189443] f(x) = 0.0009553364580503253 gradient norm = 0.001149502022775794\n",
      "Iteration 921 : x = [1.98991855 1.45200868] f(x) = 0.0009552044664713003 gradient norm = 0.0011469982075394294\n",
      "Iteration 922 : x = [1.98993118 1.45212268] f(x) = 0.0009550730492435368 gradient norm = 0.0011445002595185817\n",
      "Iteration 923 : x = [1.98994379 1.45223644] f(x) = 0.0009549422037733035 gradient norm = 0.0011420081631635273\n",
      "Iteration 924 : x = [1.98995636 1.45234994] f(x) = 0.0009548119274792005 gradient norm = 0.0011395219029736445\n",
      "Iteration 925 : x = [1.98996891 1.4524632 ] f(x) = 0.0009546822177920925 gradient norm = 0.0011370414634972346\n",
      "Iteration 926 : x = [1.98998142 1.45257622] f(x) = 0.0009545530721550507 gradient norm = 0.0011345668293313207\n",
      "Iteration 927 : x = [1.98999391 1.45268898] f(x) = 0.0009544244880232868 gradient norm = 0.0011320979851214654\n",
      "Iteration 928 : x = [1.99000636 1.45280151] f(x) = 0.0009542964628640946 gradient norm = 0.0011296349155615851\n",
      "Iteration 929 : x = [1.99001879 1.45291379] f(x) = 0.0009541689941567872 gradient norm = 0.0011271776053937623\n",
      "Iteration 930 : x = [1.99003119 1.45302582] f(x) = 0.0009540420793926354 gradient norm = 0.0011247260394080536\n",
      "Iteration 931 : x = [1.99004356 1.45313761] f(x) = 0.0009539157160748087 gradient norm = 0.0011222802024423199\n",
      "Iteration 932 : x = [1.9900559  1.45324916] f(x) = 0.0009537899017183141 gradient norm = 0.0011198400793820274\n",
      "Iteration 933 : x = [1.99006821 1.45336046] f(x) = 0.000953664633849936 gradient norm = 0.0011174056551600837\n",
      "Iteration 934 : x = [1.9900805  1.45347153] f(x) = 0.0009535399100081762 gradient norm = 0.001114976914756629\n",
      "Iteration 935 : x = [1.99009275 1.45358235] f(x) = 0.0009534157277431961 gradient norm = 0.0011125538431988817\n",
      "Iteration 936 : x = [1.99010498 1.45369293] f(x) = 0.0009532920846167554 gradient norm = 0.001110136425560941\n",
      "Iteration 937 : x = [1.99011717 1.45380327] f(x) = 0.0009531689782021564 gradient norm = 0.001107724646963621\n",
      "Iteration 938 : x = [1.99012934 1.45391337] f(x) = 0.0009530464060841827 gradient norm = 0.00110531849257426\n",
      "Iteration 939 : x = [1.99014148 1.45402324] f(x) = 0.0009529243658590431 gradient norm = 0.0011029179476065415\n",
      "Iteration 940 : x = [1.9901536  1.45413286] f(x) = 0.0009528028551343122 gradient norm = 0.0011005229973203325\n",
      "Iteration 941 : x = [1.99016568 1.45424225] f(x) = 0.000952681871528876 gradient norm = 0.001098133627021503\n",
      "Iteration 942 : x = [1.99017774 1.4543514 ] f(x) = 0.0009525614126728712 gradient norm = 0.001095749822061732\n",
      "Iteration 943 : x = [1.99018976 1.45446031] f(x) = 0.0009524414762076314 gradient norm = 0.0010933715678383639\n",
      "Iteration 944 : x = [1.99020176 1.45456899] f(x) = 0.0009523220597856276 gradient norm = 0.0010909988497942\n",
      "Iteration 945 : x = [1.99021374 1.45467743] f(x) = 0.0009522031610704155 gradient norm = 0.0010886316534173598\n",
      "Iteration 946 : x = [1.99022568 1.45478563] f(x) = 0.0009520847777365772 gradient norm = 0.0010862699642410838\n",
      "Iteration 947 : x = [1.9902376 1.4548936] f(x) = 0.0009519669074696667 gradient norm = 0.0010839137678435812\n",
      "Iteration 948 : x = [1.99024949 1.45500134] f(x) = 0.0009518495479661547 gradient norm = 0.0010815630498478422\n",
      "Iteration 949 : x = [1.99026135 1.45510885] f(x) = 0.0009517326969333724 gradient norm = 0.0010792177959214775\n",
      "Iteration 950 : x = [1.99027318 1.45521612] f(x) = 0.0009516163520894581 gradient norm = 0.0010768779917765432\n",
      "Iteration 951 : x = [1.99028499 1.45532316] f(x) = 0.0009515005111633039 gradient norm = 0.0010745436231693946\n",
      "Iteration 952 : x = [1.99029677 1.45542996] f(x) = 0.0009513851718944985 gradient norm = 0.0010722146759004798\n",
      "Iteration 953 : x = [1.99030852 1.45553654] f(x) = 0.0009512703320332762 gradient norm = 0.0010698911358142118\n",
      "Iteration 954 : x = [1.99032024 1.45564288] f(x) = 0.0009511559893404638 gradient norm = 0.001067572988798783\n",
      "Iteration 955 : x = [1.99033194 1.455749  ] f(x) = 0.000951042141587424 gradient norm = 0.0010652602207860014\n",
      "Iteration 956 : x = [1.99034361 1.45585488] f(x) = 0.0009509287865560056 gradient norm = 0.0010629528177511236\n",
      "Iteration 957 : x = [1.99035525 1.45596054] f(x) = 0.0009508159220384903 gradient norm = 0.0010606507657126988\n",
      "Iteration 958 : x = [1.99036687 1.45606596] f(x) = 0.0009507035458375408 gradient norm = 0.0010583540507324081\n",
      "Iteration 959 : x = [1.99037846 1.45617116] f(x) = 0.0009505916557661459 gradient norm = 0.0010560626589148894\n",
      "Iteration 960 : x = [1.99039002 1.45627614] f(x) = 0.0009504802496475734 gradient norm = 0.0010537765764075896\n",
      "Iteration 961 : x = [1.99040155 1.45638088] f(x) = 0.0009503693253153154 gradient norm = 0.0010514957894005982\n",
      "Iteration 962 : x = [1.99041306 1.4564854 ] f(x) = 0.0009502588806130373 gradient norm = 0.00104922028412648\n",
      "Iteration 963 : x = [1.99042454 1.45658969] f(x) = 0.0009501489133945285 gradient norm = 0.0010469500468601343\n",
      "Iteration 964 : x = [1.990436   1.45669376] f(x) = 0.0009500394215236501 gradient norm = 0.0010446850639186235\n",
      "Iteration 965 : x = [1.99044743 1.4567976 ] f(x) = 0.0009499304028742861 gradient norm = 0.0010424253216610106\n",
      "Iteration 966 : x = [1.99045883 1.45690121] f(x) = 0.0009498218553302919 gradient norm = 0.0010401708064882117\n",
      "Iteration 967 : x = [1.99047021 1.45700461] f(x) = 0.0009497137767854454 gradient norm = 0.001037921504842844\n",
      "Iteration 968 : x = [1.99048156 1.45710778] f(x) = 0.0009496061651433962 gradient norm = 0.0010356774032090539\n",
      "Iteration 969 : x = [1.99049288 1.45721072] f(x) = 0.00094949901831762 gradient norm = 0.0010334384881123778\n",
      "Iteration 970 : x = [1.99050418 1.45731345] f(x) = 0.000949392334231363 gradient norm = 0.001031204746119577\n",
      "Iteration 971 : x = [1.99051545 1.45741595] f(x) = 0.0009492861108176008 gradient norm = 0.0010289761638384962\n",
      "Iteration 972 : x = [1.9905267  1.45751823] f(x) = 0.0009491803460189836 gradient norm = 0.0010267527279179006\n",
      "Iteration 973 : x = [1.99053792 1.45762029] f(x) = 0.0009490750377877912 gradient norm = 0.0010245344250473171\n",
      "Iteration 974 : x = [1.99054911 1.45772213] f(x) = 0.0009489701840858858 gradient norm = 0.0010223212419569073\n",
      "Iteration 975 : x = [1.99056028 1.45782375] f(x) = 0.0009488657828846611 gradient norm = 0.001020113165417296\n",
      "Iteration 976 : x = [1.99057142 1.45792515] f(x) = 0.0009487618321649978 gradient norm = 0.0010179101822394216\n",
      "Iteration 977 : x = [1.99058253 1.45802634] f(x) = 0.0009486583299172147 gradient norm = 0.0010157122792744007\n",
      "Iteration 978 : x = [1.99059363 1.4581273 ] f(x) = 0.0009485552741410222 gradient norm = 0.0010135194434133603\n",
      "Iteration 979 : x = [1.99060469 1.45822805] f(x) = 0.0009484526628454762 gradient norm = 0.0010113316615873076\n",
      "Iteration 980 : x = [1.99061573 1.45832858] f(x) = 0.0009483504940489313 gradient norm = 0.0010091489207669786\n",
      "Iteration 981 : x = [1.99062674 1.45842889] f(x) = 0.0009482487657789944 gradient norm = 0.0010069712079626787\n",
      "Iteration 982 : x = [1.99063773 1.45852898] f(x) = 0.0009481474760724787 gradient norm = 0.0010047985102241482\n",
      "Iteration 983 : x = [1.9906487  1.45862886] f(x) = 0.0009480466229753588 gradient norm = 0.0010026308146404237\n",
      "Iteration 984 : x = [1.99065964 1.45872853] f(x) = 0.0009479462045427242 gradient norm = 0.0010004681083396656\n",
      "Iteration 985 : x = [1.99067055 1.45882798] f(x) = 0.0009478462188387339 gradient norm = 0.0009983103784890492\n",
      "Iteration 986 : x = [1.99068144 1.45892721] f(x) = 0.0009477466639365738 gradient norm = 0.0009961576122945936\n",
      "Iteration 987 : x = [1.9906923  1.45902623] f(x) = 0.0009476475379184099 gradient norm = 0.0009940097970010421\n",
      "Iteration 988 : x = [1.99070314 1.45912504] f(x) = 0.0009475488388753427 gradient norm = 0.0009918669198916916\n",
      "Iteration 989 : x = [1.99071395 1.45922364] f(x) = 0.0009474505649073659 gradient norm = 0.0009897289682882838\n",
      "Iteration 990 : x = [1.99072474 1.45932202] f(x) = 0.0009473527141233219 gradient norm = 0.0009875959295508293\n",
      "Iteration 991 : x = [1.9907355  1.45942019] f(x) = 0.000947255284640854 gradient norm = 0.0009854677910775013\n",
      "Iteration 992 : x = [1.99074624 1.45951815] f(x) = 0.0009471582745863695 gradient norm = 0.0009833445403044704\n",
      "Iteration 993 : x = [1.99075696 1.4596159 ] f(x) = 0.0009470616820949905 gradient norm = 0.000981226164705775\n",
      "Iteration 994 : x = [1.99076765 1.45971344] f(x) = 0.0009469655053105135 gradient norm = 0.0009791126517931844\n",
      "Iteration 995 : x = [1.99077831 1.45981077] f(x) = 0.0009468697423853677 gradient norm = 0.000977003989116058\n",
      "Iteration 996 : x = [1.99078895 1.45990789] f(x) = 0.0009467743914805699 gradient norm = 0.0009749001642612161\n",
      "Iteration 997 : x = [1.99079957 1.4600048 ] f(x) = 0.0009466794507656827 gradient norm = 0.000972801164852786\n",
      "Iteration 998 : x = [1.99081016 1.4601015 ] f(x) = 0.000946584918418774 gradient norm = 0.0009707069785520822\n",
      "Iteration 999 : x = [1.99082073 1.46019799] f(x) = 0.000946490792626373 gradient norm = 0.0009686175930574688\n",
      "\n",
      "\tStep size: 1\n",
      "Iteration 0 : x = [0.5 1. ] f(x) = 0.15009253657239355 gradient norm = 0.09611715372728168\n",
      "Iteration 1 : x = [0.59240185 1.02646519] f(x) = 0.14030267670664018 gradient norm = 0.1076842745515344\n",
      "Iteration 2 : x = [0.6956692  1.05698987] f(x) = 0.12801430172477463 gradient norm = 0.12034319802578917\n",
      "Iteration 3 : x = [0.81150413 1.08962046] f(x) = 0.1127962240339639 gradient norm = 0.13198155555891766\n",
      "Iteration 4 : x = [0.93953773 1.12165991] f(x) = 0.09481067251808631 gradient norm = 0.13954178796761957\n",
      "Iteration 5 : x = [1.07615652 1.15007148] f(x) = 0.07521952474879591 gradient norm = 0.1398970107169359\n",
      "Iteration 6 : x = [1.21425545 1.172429  ] f(x) = 0.056125132565479914 gradient norm = 0.13170610704269423\n",
      "Iteration 7 : x = [1.34504383 1.18794991] f(x) = 0.039698195460101136 gradient norm = 0.11667685326561716\n",
      "Iteration 8 : x = [1.46131423 1.19768039] f(x) = 0.027106755243199644 gradient norm = 0.09851717529588755\n",
      "Iteration 9 : x = [1.55965289 1.20360843] f(x) = 0.018266929347264486 gradient norm = 0.0806331009688263\n",
      "Iteration 10 : x = [1.64018703 1.20760204] f(x) = 0.012394541258355752 gradient norm = 0.06490778607761898\n",
      "Iteration 11 : x = [1.7050097  1.21092511] f(x) = 0.0086028606799269 gradient norm = 0.05189995281408418\n",
      "Iteration 12 : x = [1.7568022  1.21426315] f(x) = 0.006180266715887409 gradient norm = 0.04147031695261087\n",
      "Iteration 13 : x = [1.79811127 1.21791661] f(x) = 0.00463189038483057 gradient norm = 0.03323384781281339\n",
      "Iteration 14 : x = [1.83109669 1.22197256] f(x) = 0.0036353178646301395 gradient norm = 0.02677694179249531\n",
      "Iteration 15 : x = [1.85750265 1.22641438] f(x) = 0.0029863619584934915 gradient norm = 0.021735666179882353\n",
      "Iteration 16 : x = [1.87870891 1.23118237] f(x) = 0.002557036272486883 gradient norm = 0.017812528591588116\n",
      "Iteration 17 : x = [1.89579883 1.23620441] f(x) = 0.0022672449180973827 gradient norm = 0.014770966844302166\n",
      "Iteration 18 : x = [1.90962199 1.24141034] f(x) = 0.0020667372841164386 gradient norm = 0.01242394058682433\n",
      "Iteration 19 : x = [1.92084569 1.24673789] f(x) = 0.0019238512601352342 gradient norm = 0.010622689466663891\n",
      "Iteration 20 : x = [1.92999548 1.25213446] f(x) = 0.0018185362244593235 gradient norm = 0.00924763082940454\n",
      "Iteration 21 : x = [1.93748649 1.25755695] f(x) = 0.0017380264182514944 gradient norm = 0.008201805977789578\n",
      "Iteration 22 : x = [1.94364762 1.26297083] f(x) = 0.0016741482851877765 gradient norm = 0.00740657273424145\n",
      "Iteration 23 : x = [1.94874014 1.26834889] f(x) = 0.0016216367730920818 gradient norm = 0.006798841713404931\n",
      "Iteration 24 : x = [1.95297211 1.27367004] f(x) = 0.0015770773142737234 gradient norm = 0.006329049751291342\n",
      "Iteration 25 : x = [1.95650956 1.27891822] f(x) = 0.0015382378146849781 gradient norm = 0.005959280103699062\n",
      "Iteration 26 : x = [1.95948525 1.28408138] f(x) = 0.0015036450321224066 gradient norm = 0.0056613072197551385\n",
      "Iteration 27 : x = [1.96200553 1.28915076] f(x) = 0.0014723148562585438 gradient norm = 0.0054146282898662815\n",
      "Iteration 28 : x = [1.9641557  1.29412016] f(x) = 0.0014435799455624334 gradient norm = 0.005204642695331107\n",
      "Iteration 29 : x = [1.9660043  1.29898545] f(x) = 0.0014169792007883242 gradient norm = 0.005021104065396892\n",
      "Iteration 30 : x = [1.96760648 1.30374407] f(x) = 0.0013921866560867972 gradient norm = 0.0048568909868425365\n",
      "Iteration 31 : x = [1.96900668 1.30839475] f(x) = 0.0013689655782609114 gradient norm = 0.00470707961238778\n",
      "Iteration 32 : x = [1.97024073 1.31293719] f(x) = 0.0013471387345434101 gradient norm = 0.00456826950704253\n",
      "Iteration 33 : x = [1.97133759 1.31737182] f(x) = 0.0013265690593287408 gradient norm = 0.004438106234502881\n",
      "Iteration 34 : x = [1.97232069 1.32169967] f(x) = 0.0013071470266984716 gradient norm = 0.004314949324987296\n",
      "Iteration 35 : x = [1.97320903 1.32592219] f(x) = 0.0012887823585188219 gradient norm = 0.004197644161715254\n",
      "Iteration 36 : x = [1.97401799 1.33004115] f(x) = 0.001271398543289222 gradient norm = 0.0040853665194349005\n",
      "Iteration 37 : x = [1.97476011 1.33405854] f(x) = 0.0012549291825858988 gradient norm = 0.003977517150949635\n",
      "Iteration 38 : x = [1.9754456  1.33797655] f(x) = 0.001239315529822078 gradient norm = 0.003873650515627065\n",
      "Iteration 39 : x = [1.97608278 1.34179743] f(x) = 0.001224504809947536 gradient norm = 0.0037734266522413055\n",
      "Iteration 40 : x = [1.97667847 1.34552354] f(x) = 0.0012104490531050134 gradient norm = 0.00367657867915484\n",
      "Iteration 41 : x = [1.97723827 1.34915725] f(x) = 0.001197104268557757 gradient norm = 0.0035828908221826475\n",
      "Iteration 42 : x = [1.97776676 1.35270095] f(x) = 0.0011844298455943947 gradient norm = 0.0034921835269285865\n",
      "Iteration 43 : x = [1.97826777 1.35615701] f(x) = 0.0011723881072815028 gradient norm = 0.0034043033376097705\n",
      "Iteration 44 : x = [1.97874443 1.35952778] f(x) = 0.0011609439683804915 gradient norm = 0.003319115984490169\n",
      "Iteration 45 : x = [1.97919936 1.36281557] f(x) = 0.001150064665312264 gradient norm = 0.0032365016337062924\n",
      "Iteration 46 : x = [1.97963475 1.36602265] f(x) = 0.0011397195368632622 gradient norm = 0.0031563515969667594\n",
      "Iteration 47 : x = [1.98005245 1.36915124] f(x) = 0.0011298798413982797 gradient norm = 0.0030785660292176062\n",
      "Iteration 48 : x = [1.98045401 1.37220351] f(x) = 0.0011205186009856565 gradient norm = 0.0030030522970254637\n",
      "Iteration 49 : x = [1.98084073 1.37518156] f(x) = 0.0011116104658960865 gradient norm = 0.0029297238041562285\n",
      "Iteration 50 : x = [1.98121376 1.37808743] f(x) = 0.00110313159495739 gradient norm = 0.002858499130419106\n",
      "Iteration 51 : x = [1.98157405 1.38092314] f(x) = 0.001095059548591743 gradient norm = 0.0027893013865680116\n",
      "Iteration 52 : x = [1.98192246 1.38369059] f(x) = 0.0010873731922618755 gradient norm = 0.0027220577194491807\n",
      "Iteration 53 : x = [1.9822597  1.38639168] f(x) = 0.0010800526086605822 gradient norm = 0.0026566989227063045\n",
      "Iteration 54 : x = [1.98258643 1.38902821] f(x) = 0.001073079017392699 gradient norm = 0.0025931591225849633\n",
      "Iteration 55 : x = [1.98290321 1.39160195] f(x) = 0.0010664347011855012 gradient norm = 0.0025313755179810753\n",
      "Iteration 56 : x = [1.98321055 1.3941146 ] f(x) = 0.0010601029378649173 gradient norm = 0.00247128816037177\n",
      "Iteration 57 : x = [1.98350891 1.39656781] f(x) = 0.0010540679374789954 gradient norm = 0.002412839763668262\n",
      "Iteration 58 : x = [1.98379868 1.39896318] f(x) = 0.0010483147840553513 gradient norm = 0.0023559755370225837\n",
      "Iteration 59 : x = [1.98408026 1.40130227] f(x) = 0.001042829381557964 gradient norm = 0.0023006430356608625\n",
      "Iteration 60 : x = [1.98435397 1.40358658] f(x) = 0.0010375984036689865 gradient norm = 0.002246792026214433\n",
      "Iteration 61 : x = [1.98462014 1.40581755] f(x) = 0.001032609247068545 gradient norm = 0.0021943743639830354\n",
      "Iteration 62 : x = [1.98487906 1.40799659] f(x) = 0.0010278499879235624 gradient norm = 0.002143343880231921\n",
      "Iteration 63 : x = [1.98513099 1.41012508] f(x) = 0.0010233093413279312 gradient norm = 0.002093656278091018\n",
      "Iteration 64 : x = [1.98537619 1.41220433] f(x) = 0.0010189766234626 gradient norm = 0.0020452690359531213\n",
      "Iteration 65 : x = [1.9856149  1.41423562] f(x) = 0.0010148417162665231 gradient norm = 0.0019981413175024433\n",
      "Iteration 66 : x = [1.98584734 1.41622019] f(x) = 0.0010108950344287914 gradient norm = 0.001952233887674393\n",
      "Iteration 67 : x = [1.98607372 1.41815926] f(x) = 0.0010071274945292357 gradient norm = 0.0019075090339717186\n",
      "Iteration 68 : x = [1.98629424 1.42005398] f(x) = 0.0010035304861697647 gradient norm = 0.0018639304926547958\n",
      "Iteration 69 : x = [1.98650909 1.42190548] f(x) = 0.001000095844952089 gradient norm = 0.001821463379394528\n",
      "Iteration 70 : x = [1.98671846 1.42371487] f(x) = 0.000996815827169419 gradient norm = 0.0017800741240309983\n",
      "Iteration 71 : x = [1.9869225  1.42548321] f(x) = 0.0009936830860905292 gradient norm = 0.001739730409124234\n",
      "Iteration 72 : x = [1.98712139 1.42721154] f(x) = 0.0009906906497243121 gradient norm = 0.0017004011120186002\n",
      "Iteration 73 : x = [1.98731529 1.42890085] f(x) = 0.0009878318999617924 gradient norm = 0.001662056250171038\n",
      "Iteration 74 : x = [1.98750434 1.43055212] f(x) = 0.0009851005530006015 gradient norm = 0.001624666929517601\n",
      "Iteration 75 : x = [1.98768869 1.43216629] f(x) = 0.0009824906409642382 gradient norm = 0.0015882052956732666\n",
      "Iteration 76 : x = [1.98786848 1.43374429] f(x) = 0.000979996494635134 gradient norm = 0.0015526444877778992\n",
      "Iteration 77 : x = [1.98804383 1.435287  ] f(x) = 0.000977612727226633 gradient norm = 0.001517958594816669\n",
      "Iteration 78 : x = [1.98821489 1.43679529] f(x) = 0.0009753342191246216 gradient norm = 0.001484122614257082\n",
      "Iteration 79 : x = [1.98838177 1.43827   ] f(x) = 0.0009731561035346447 gradient norm = 0.0014511124128570574\n",
      "Iteration 80 : x = [1.9885446  1.43971195] f(x) = 0.0009710737529750671 gradient norm = 0.0014189046895093135\n",
      "Iteration 81 : x = [1.98870348 1.44112193] f(x) = 0.0009690827665611662 gradient norm = 0.0013874769399975278\n",
      "Iteration 82 : x = [1.98885852 1.44250072] f(x) = 0.0009671789580290039 gradient norm = 0.0013568074235485166\n",
      "Iteration 83 : x = [1.98900984 1.44384906] f(x) = 0.0009653583444515928 gradient norm = 0.0013268751310729593\n",
      "Iteration 84 : x = [1.98915754 1.44516769] f(x) = 0.0009636171356032431 gradient norm = 0.0012976597549947807\n",
      "Iteration 85 : x = [1.98930172 1.44645731] f(x) = 0.0009619517239310743 gradient norm = 0.0012691416605760447\n",
      "Iteration 86 : x = [1.98944246 1.44771863] f(x) = 0.0009603586750955468 gradient norm = 0.0012413018586506135\n",
      "Iteration 87 : x = [1.98957988 1.4489523 ] f(x) = 0.0009588347190445081 gradient norm = 0.0012141219796855808\n",
      "Iteration 88 : x = [1.98971405 1.45015898] f(x) = 0.0009573767415876955 gradient norm = 0.0011875842490949226\n",
      "Iteration 89 : x = [1.98984506 1.45133932] f(x) = 0.0009559817764408852 gradient norm = 0.0011616714637346754\n",
      "Iteration 90 : x = [1.989973   1.45249392] f(x) = 0.0009546469977109801 gradient norm = 0.001136366969513584\n",
      "Iteration 91 : x = [1.99009794 1.4536234 ] f(x) = 0.0009533697127952439 gradient norm = 0.001111654640057334\n",
      "Iteration 92 : x = [1.99021998 1.45472834] f(x) = 0.0009521473556696951 gradient norm = 0.0010875188563685323\n",
      "Iteration 93 : x = [1.99033918 1.4558093 ] f(x) = 0.0009509774805433157 gradient norm = 0.001063944487428055\n",
      "Iteration 94 : x = [1.99045561 1.45686686] f(x) = 0.000949857755856283 gradient norm = 0.0010409168716869696\n",
      "Iteration 95 : x = [1.99056936 1.45790154] f(x) = 0.0009487859586018499 gradient norm = 0.0010184217994012135\n",
      "Iteration 96 : x = [1.99068048 1.45891388] f(x) = 0.0009477599689528207 gradient norm = 0.0009964454957642442\n",
      "Iteration 97 : x = [1.99078906 1.4599044 ] f(x) = 0.0009467777651748096 gradient norm = 0.0009749746047955206\n",
      "Iteration 98 : x = [1.99089514 1.46087358] f(x) = 0.0009458374188095966 gradient norm = 0.0009539961739452896\n",
      "Iteration 99 : x = [1.9909988  1.46182193] f(x) = 0.0009449370901129761 gradient norm = 0.0009334976393784327\n",
      "Iteration 100 : x = [1.9911001  1.46274991] f(x) = 0.0009440750237324644 gradient norm = 0.0009134668119024101\n",
      "Iteration 101 : x = [1.99119909 1.463658  ] f(x) = 0.0009432495446111614 gradient norm = 0.0008938918635063199\n",
      "Iteration 102 : x = [1.99129584 1.46454664] f(x) = 0.0009424590541049169 gradient norm = 0.0008747613144800735\n",
      "Iteration 103 : x = [1.9913904  1.46541628] f(x) = 0.0009417020263007474 gradient norm = 0.0008560640210844809\n",
      "Iteration 104 : x = [1.99148283 1.46626734] f(x) = 0.0009409770045251991 gradient norm = 0.0008377891637446381\n",
      "Iteration 105 : x = [1.99157317 1.46710024] f(x) = 0.0009402825980320358 gradient norm = 0.000819926235740727\n",
      "Iteration 106 : x = [1.99166149 1.4679154 ] f(x) = 0.0009396174788592862 gradient norm = 0.0008024650323716312\n",
      "Iteration 107 : x = [1.99174782 1.4687132 ] f(x) = 0.0009389803788462882 gradient norm = 0.0007853956405683069\n",
      "Iteration 108 : x = [1.99183222 1.46949405] f(x) = 0.0009383700868019271 gradient norm = 0.0007687084289350434\n",
      "Iteration 109 : x = [1.99191474 1.47025832] f(x) = 0.0009377854458157968 gradient norm = 0.000752394038197977\n",
      "Iteration 110 : x = [1.99199542 1.47100637] f(x) = 0.0009372253507045009 gradient norm = 0.0007364433720413762\n",
      "Iteration 111 : x = [1.99207431 1.47173858] f(x) = 0.0009366887455857742 gradient norm = 0.0007208475883132787\n",
      "Iteration 112 : x = [1.99215145 1.47245529] f(x) = 0.0009361746215735402 gradient norm = 0.0007055980905830174\n",
      "Iteration 113 : x = [1.99222688 1.47315684] f(x) = 0.0009356820145874047 gradient norm = 0.0006906865200341656\n",
      "Iteration 114 : x = [1.99230064 1.47384358] f(x) = 0.0009352100032704955 gradient norm = 0.0006761047476772881\n",
      "Iteration 115 : x = [1.99237278 1.47451583] f(x) = 0.0009347577070098792 gradient norm = 0.0006618448668677365\n",
      "Iteration 116 : x = [1.99244333 1.4751739 ] f(x) = 0.0009343242840541329 gradient norm = 0.0006478991861144267\n",
      "Iteration 117 : x = [1.99251233 1.47581811] f(x) = 0.0009339089297229657 gradient norm = 0.0006342602221663997\n",
      "Iteration 118 : x = [1.99257981 1.47644877] f(x) = 0.0009335108747040565 gradient norm = 0.0006209206933645654\n",
      "Iteration 119 : x = [1.99264582 1.47706618] f(x) = 0.0009331293834325693 gradient norm = 0.0006078735132466781\n",
      "Iteration 120 : x = [1.99271038 1.47767061] f(x) = 0.0009327637525490465 gradient norm = 0.0005951117843942629\n",
      "Iteration 121 : x = [1.99277354 1.47826236] f(x) = 0.0009324133094316307 gradient norm = 0.0005826287925107506\n",
      "Iteration 122 : x = [1.99283532 1.47884171] f(x) = 0.0009320774107987917 gradient norm = 0.0005704180007206026\n",
      "Iteration 123 : x = [1.99289575 1.47940891] f(x) = 0.0009317554413789402 gradient norm = 0.0005584730440798095\n",
      "Iteration 124 : x = [1.99295487 1.47996425] f(x) = 0.0009314468126435189 gradient norm = 0.0005467877242884889\n",
      "Iteration 125 : x = [1.99301271 1.48050797] f(x) = 0.0009311509616003417 gradient norm = 0.0005353560045968985\n",
      "Iteration 126 : x = [1.9930693  1.48104033] f(x) = 0.0009308673496441325 gradient norm = 0.0005241720048965677\n",
      "Iteration 127 : x = [1.99312467 1.48156157] f(x) = 0.0009305954614613815 gradient norm = 0.0005132299969886076\n",
      "Iteration 128 : x = [1.99317884 1.48207193] f(x) = 0.0009303348039867873 gradient norm = 0.0005025244000217403\n",
      "Iteration 129 : x = [1.99323184 1.48257165] f(x) = 0.0009300849054087064 gradient norm = 0.0004920497760928328\n",
      "Iteration 130 : x = [1.9932837  1.48306096] f(x) = 0.0009298453142211746 gradient norm = 0.0004818008260032492\n",
      "Iteration 131 : x = [1.99333445 1.48354008] f(x) = 0.0009296155983201732 gradient norm = 0.0004717723851643768\n",
      "Iteration 132 : x = [1.9933841  1.48400923] f(x) = 0.0009293953441419688 gradient norm = 0.0004619594196463461\n",
      "Iteration 133 : x = [1.99343269 1.48446863] f(x) = 0.000929184155841443 gradient norm = 0.0004523570223639011\n",
      "Iteration 134 : x = [1.99348024 1.48491848] f(x) = 0.0009289816545084532 gradient norm = 0.0004429604093939733\n",
      "Iteration 135 : x = [1.99352678 1.48535899] f(x) = 0.0009287874774203624 gradient norm = 0.00043376491641947075\n",
      "Iteration 136 : x = [1.99357232 1.48579036] f(x) = 0.0009286012773289752 gradient norm = 0.0004247659952943272\n",
      "Iteration 137 : x = [1.99361689 1.48621278] f(x) = 0.0009284227217802103 gradient norm = 0.0004159592107248848\n",
      "Iteration 138 : x = [1.9936605  1.48662644] f(x) = 0.000928251492464924 gradient norm = 0.0004073402370629793\n",
      "Iteration 139 : x = [1.99370319 1.48703154] f(x) = 0.0009280872845993779 gradient norm = 0.000398904855206356\n",
      "Iteration 140 : x = [1.99374498 1.48742825] f(x) = 0.0009279298063339332 gradient norm = 0.0003906489496021377\n",
      "Iteration 141 : x = [1.99378587 1.48781675] f(x) = 0.0009277787781886122 gradient norm = 0.00038256850534936334\n",
      "Iteration 142 : x = [1.9938259  1.48819722] f(x) = 0.0009276339325142453 gradient norm = 0.00037465960539675194\n",
      "Iteration 143 : x = [1.99386508 1.48856983] f(x) = 0.0009274950129779855 gradient norm = 0.00036691842783197085\n",
      "Iteration 144 : x = [1.99390343 1.48893474] f(x) = 0.0009273617740720354 gradient norm = 0.00035934124325893464\n",
      "Iteration 145 : x = [1.99394096 1.48929211] f(x) = 0.0009272339806444826 gradient norm = 0.0003519244122597749\n",
      "Iteration 146 : x = [1.99397771 1.48964211] f(x) = 0.0009271114074512049 gradient norm = 0.00034466438293825815\n",
      "Iteration 147 : x = [1.99401368 1.4899849 ] f(x) = 0.0009269938387278569 gradient norm = 0.00033755768854160155\n",
      "Iteration 148 : x = [1.99404889 1.49032061] f(x) = 0.0009268810677809841 gradient norm = 0.0003306009451577211\n",
      "Iteration 149 : x = [1.99408336 1.49064941] f(x) = 0.0009267728965973867 gradient norm = 0.0003237908494851207\n",
      "Iteration 150 : x = [1.9941171  1.49097144] f(x) = 0.000926669135470865 gradient norm = 0.00031712417667275066\n",
      "Iteration 151 : x = [1.99415014 1.49128684] f(x) = 0.0009265696026455521 gradient norm = 0.0003105977782272112\n",
      "Iteration 152 : x = [1.99418248 1.49159575] f(x) = 0.0009264741239750555 gradient norm = 0.00030420857998488524\n",
      "Iteration 153 : x = [1.99421414 1.4918983 ] f(x) = 0.0009263825325966807 gradient norm = 0.0002979535801466244\n",
      "Iteration 154 : x = [1.99424514 1.49219464] f(x) = 0.0009262946686200359 gradient norm = 0.00029182984737270316\n",
      "Iteration 155 : x = [1.99427548 1.49248489] f(x) = 0.0009262103788293697 gradient norm = 0.00028583451893589415\n",
      "Iteration 156 : x = [1.9943052  1.49276917] f(x) = 0.0009261295163989884 gradient norm = 0.00027996479893060966\n",
      "Iteration 157 : x = [1.99433429 1.49304762] f(x) = 0.0009260519406211774 gradient norm = 0.00027421795653605375\n",
      "Iteration 158 : x = [1.99436277 1.49332036] f(x) = 0.0009259775166460448 gradient norm = 0.00026859132433153395\n",
      "Iteration 159 : x = [1.99439065 1.4935875 ] f(x) = 0.0009259061152327385 gradient norm = 0.00026308229666208453\n",
      "Iteration 160 : x = [1.99441796 1.49384916] f(x) = 0.000925837612511536 gradient norm = 0.00025768832805260846\n",
      "Iteration 161 : x = [1.99444469 1.49410546] f(x) = 0.0009257718897562978 gradient norm = 0.00025240693166890917\n",
      "Iteration 162 : x = [1.99447087 1.4943565 ] f(x) = 0.0009257088331668264 gradient norm = 0.0002472356778239617\n",
      "Iteration 163 : x = [1.99449651 1.49460241] f(x) = 0.0009256483336606785 gradient norm = 0.0002421721925278356\n",
      "Iteration 164 : x = [1.99452161 1.49484327] f(x) = 0.0009255902866740072 gradient norm = 0.00023721415607985384\n",
      "Iteration 165 : x = [1.99454618 1.49507921] f(x) = 0.0009255345919710283 gradient norm = 0.0002323593017014909\n",
      "Iteration 166 : x = [1.99457025 1.49531032] f(x) = 0.0009254811534617218 gradient norm = 0.0002276054142086483\n",
      "Iteration 167 : x = [1.99459381 1.4955367 ] f(x) = 0.0009254298790274052 gradient norm = 0.00022295032872200572\n",
      "Iteration 168 : x = [1.99461689 1.49575846] f(x) = 0.0009253806803538222 gradient norm = 0.00021839192941414365\n",
      "Iteration 169 : x = [1.99463949 1.49597568] f(x) = 0.0009253334727714151 gradient norm = 0.00021392814829223516\n",
      "Iteration 170 : x = [1.99466162 1.49618846] f(x) = 0.0009252881751024614 gradient norm = 0.00020955696401511468\n",
      "Iteration 171 : x = [1.99468329 1.49639689] f(x) = 0.0009252447095147659 gradient norm = 0.0002052764007436318\n",
      "Iteration 172 : x = [1.99470451 1.49660107] f(x) = 0.0009252030013816287 gradient norm = 0.000201084527023145\n",
      "Iteration 173 : x = [1.9947253  1.49680107] f(x) = 0.000925162979147796 gradient norm = 0.00019697945469714773\n",
      "Iteration 174 : x = [1.99474565 1.496997  ] f(x) = 0.0009251245742011474 gradient norm = 0.00019295933785100816\n",
      "Iteration 175 : x = [1.99476558 1.49718893] f(x) = 0.0009250877207498506 gradient norm = 0.00018902237178486508\n",
      "Iteration 176 : x = [1.9947851  1.49737694] f(x) = 0.0009250523557047572 gradient norm = 0.00018516679201472673\n",
      "Iteration 177 : x = [1.99480422 1.49756112] f(x) = 0.0009250184185668 gradient norm = 0.00018139087330087207\n",
      "Iteration 178 : x = [1.99482294 1.49774154] f(x) = 0.0009249858513191785 gradient norm = 0.00017769292870273306\n",
      "Iteration 179 : x = [1.99484128 1.49791828] f(x) = 0.0009249545983241211 gradient norm = 0.0001740713086593545\n",
      "Iteration 180 : x = [1.99485923 1.49809142] f(x) = 0.0009249246062240225 gradient norm = 0.00017052440009470067\n",
      "Iteration 181 : x = [1.99487682 1.49826104] f(x) = 0.0009248958238467728 gradient norm = 0.00016705062554697695\n",
      "Iteration 182 : x = [1.99489405 1.4984272 ] f(x) = 0.0009248682021150835 gradient norm = 0.00016364844232122838\n",
      "Iteration 183 : x = [1.99491092 1.49858998] f(x) = 0.0009248416939596546 gradient norm = 0.0001603163416645659\n",
      "Iteration 184 : x = [1.99492744 1.49874944] f(x) = 0.0009248162542359968 gradient norm = 0.00015705284796320692\n",
      "Iteration 185 : x = [1.99494363 1.49890566] f(x) = 0.0009247918396447657 gradient norm = 0.00015385651796077351\n",
      "Iteration 186 : x = [1.99495948 1.49905869] f(x) = 0.0009247684086554482 gradient norm = 0.0001507259399971337\n",
      "Iteration 187 : x = [1.994975   1.49920862] f(x) = 0.0009247459214332617 gradient norm = 0.00014765973326717993\n",
      "Iteration 188 : x = [1.99499021 1.49935549] f(x) = 0.0009247243397691222 gradient norm = 0.00014465654709897217\n",
      "Iteration 189 : x = [1.9950051  1.49949938] f(x) = 0.0009247036270125519 gradient norm = 0.00014171506025061767\n",
      "Iteration 190 : x = [1.99501969 1.49964034] f(x) = 0.0009246837480074052 gradient norm = 0.00013883398022538005\n",
      "Iteration 191 : x = [1.99503398 1.49977844] f(x) = 0.0009246646690302803 gradient norm = 0.0001360120426044316\n",
      "Iteration 192 : x = [1.99504797 1.49991373] f(x) = 0.0009246463577315134 gradient norm = 0.00013324801039675137\n",
      "Iteration 193 : x = [1.99506168 1.50004627] f(x) = 0.0009246287830786383 gradient norm = 0.00013054067340565788\n",
      "Iteration 194 : x = [1.99507511 1.50017612] f(x) = 0.0009246119153022081 gradient norm = 0.000127888847611519\n",
      "Iteration 195 : x = [1.99508826 1.50030333] f(x) = 0.0009245957258438775 gradient norm = 0.00012529137457008177\n",
      "Iteration 196 : x = [1.99510114 1.50042796] f(x) = 0.0009245801873066507 gradient norm = 0.0001227471208261148\n",
      "Iteration 197 : x = [1.99511376 1.50055005] f(x) = 0.0009245652734072022 gradient norm = 0.00012025497734174537\n",
      "Iteration 198 : x = [1.99512612 1.50066967] f(x) = 0.0009245509589301804 gradient norm = 0.00011781385893924393\n",
      "Iteration 199 : x = [1.99513823 1.50078686] f(x) = 0.0009245372196844127 gradient norm = 0.00011542270375768977\n",
      "Iteration 200 : x = [1.99515009 1.50090167] f(x) = 0.0009245240324609323 gradient norm = 0.00011308047272325129\n",
      "Iteration 201 : x = [1.99516171 1.50101415] f(x) = 0.0009245113749927439 gradient norm = 0.00011078614903258928\n",
      "Iteration 202 : x = [1.99517309 1.50112435] f(x) = 0.0009244992259162609 gradient norm = 0.00010853873764908923\n",
      "Iteration 203 : x = [1.99518424 1.50123232] f(x) = 0.0009244875647343428 gradient norm = 0.00010633726481153255\n",
      "Iteration 204 : x = [1.99519516 1.50133809] f(x) = 0.0009244763717808581 gradient norm = 0.00010418077755486808\n",
      "Iteration 205 : x = [1.99520585 1.50144172] f(x) = 0.0009244656281867207 gradient norm = 0.00010206834324269214\n",
      "Iteration 206 : x = [1.99521633 1.50154325] f(x) = 0.000924455315847326 gradient norm = 9.99990491112478e-05\n",
      "Iteration 207 : x = [1.9952266  1.50164272] f(x) = 0.000924445417391335 gradient norm = 9.797200182445387e-05\n",
      "Iteration 208 : x = [1.99523665 1.50174018] f(x) = 0.0009244359161507462 gradient norm = 9.598632703979908e-05\n",
      "Iteration 209 : x = [1.9952465  1.50183566] f(x) = 0.0009244267961322057 gradient norm = 9.404116898473781e-05\n",
      "Iteration 210 : x = [1.99525615 1.5019292 ] f(x) = 0.0009244180419894965 gradient norm = 9.213569004331068e-05\n",
      "Iteration 211 : x = [1.9952656  1.50202085] f(x) = 0.0009244096389971638 gradient norm = 9.026907035271949e-05\n",
      "Iteration 212 : x = [1.99527486 1.50211065] f(x) = 0.0009244015730252272 gradient norm = 8.844050740959538e-05\n",
      "Iteration 213 : x = [1.99528393 1.50219862] f(x) = 0.0009243938305149313 gradient norm = 8.664921568567302e-05\n",
      "Iteration 214 : x = [1.99529282 1.50228481] f(x) = 0.0009243863984554968 gradient norm = 8.489442625265319e-05\n",
      "Iteration 215 : x = [1.99530153 1.50236926] f(x) = 0.0009243792643618244 gradient norm = 8.317538641598674e-05\n",
      "Iteration 216 : x = [1.99531005 1.502452  ] f(x) = 0.0009243724162531167 gradient norm = 8.14913593573449e-05\n",
      "Iteration 217 : x = [1.99531841 1.50253306] f(x) = 0.0009243658426323781 gradient norm = 7.984162378554318e-05\n",
      "Iteration 218 : x = [1.99532659 1.50261248] f(x) = 0.0009243595324667527 gradient norm = 7.822547359572339e-05\n",
      "Iteration 219 : x = [1.99533461 1.50269029] f(x) = 0.0009243534751686729 gradient norm = 7.664221753653744e-05\n",
      "Iteration 220 : x = [1.99534246 1.50276653] f(x) = 0.0009243476605777775 gradient norm = 7.509117888514033e-05\n",
      "Iteration 221 : x = [1.99535016 1.50284123] f(x) = 0.0009243420789435725 gradient norm = 7.35716951298231e-05\n",
      "Iteration 222 : x = [1.9953577  1.50291441] f(x) = 0.0009243367209087983 gradient norm = 7.208311766001082e-05\n",
      "Iteration 223 : x = [1.99536508 1.50298612] f(x) = 0.0009243315774934842 gradient norm = 7.062481146350348e-05\n",
      "Iteration 224 : x = [1.99537232 1.50305637] f(x) = 0.000924326640079647 gradient norm = 6.919615483075205e-05\n",
      "Iteration 225 : x = [1.99537941 1.5031252 ] f(x) = 0.0009243219003966224 gradient norm = 6.779653906598308e-05\n",
      "Iteration 226 : x = [1.99538635 1.50319264] f(x) = 0.0009243173505069884 gradient norm = 6.642536820499978e-05\n",
      "Iteration 227 : x = [1.99539315 1.50325872] f(x) = 0.0009243129827930707 gradient norm = 6.508205873947995e-05\n",
      "Iteration 228 : x = [1.99539982 1.50332346] f(x) = 0.0009243087899439954 gradient norm = 6.376603934764863e-05\n",
      "Iteration 229 : x = [1.99540635 1.50338689] f(x) = 0.0009243047649432675 gradient norm = 6.247675063109288e-05\n",
      "Iteration 230 : x = [1.99541274 1.50344904] f(x) = 0.0009243009010568618 gradient norm = 6.121364485761603e-05\n",
      "Iteration 231 : x = [1.99541901 1.50350993] f(x) = 0.000924297191821793 gradient norm = 5.997618570999544e-05\n",
      "Iteration 232 : x = [1.99542515 1.50356959] f(x) = 0.0009242936310351587 gradient norm = 5.8763848040421035e-05\n",
      "Iteration 233 : x = [1.99543116 1.50362805] f(x) = 0.000924290212743619 gradient norm = 5.757611763054145e-05\n",
      "Iteration 234 : x = [1.99543706 1.50368532] f(x) = 0.0009242869312333131 gradient norm = 5.641249095697369e-05\n",
      "Iteration 235 : x = [1.99544283 1.50374144] f(x) = 0.0009242837810201831 gradient norm = 5.5272474962087396e-05\n",
      "Iteration 236 : x = [1.99544849 1.50379642] f(x) = 0.0009242807568406897 gradient norm = 5.4155586829998595e-05\n",
      "Iteration 237 : x = [1.99545403 1.50385029] f(x) = 0.0009242778536429066 gradient norm = 5.30613537676014e-05\n",
      "Iteration 238 : x = [1.99545946 1.50390307] f(x) = 0.0009242750665779775 gradient norm = 5.1989312790522345e-05\n",
      "Iteration 239 : x = [1.99546478 1.50395479] f(x) = 0.0009242723909919204 gradient norm = 5.093901051390538e-05\n",
      "Iteration 240 : x = [1.99546999 1.50400546] f(x) = 0.0009242698224177622 gradient norm = 4.9910002947861676e-05\n",
      "Iteration 241 : x = [1.99547509 1.50405511] f(x) = 0.0009242673565679954 gradient norm = 4.890185529751991e-05\n",
      "Iteration 242 : x = [1.99548009 1.50410375] f(x) = 0.0009242649893273394 gradient norm = 4.7914141767509105e-05\n",
      "Iteration 243 : x = [1.995485   1.50415142] f(x) = 0.0009242627167457953 gradient norm = 4.69464453708419e-05\n",
      "Iteration 244 : x = [1.9954898  1.50419812] f(x) = 0.000924260535031985 gradient norm = 4.599835774201167e-05\n",
      "Iteration 245 : x = [1.9954945  1.50424387] f(x) = 0.000924258440546755 gradient norm = 4.506947895426906e-05\n",
      "Iteration 246 : x = [1.99549911 1.50428871] f(x) = 0.0009242564297970449 gradient norm = 4.415941734091745e-05\n",
      "Iteration 247 : x = [1.99550363 1.50433263] f(x) = 0.0009242544994300007 gradient norm = 4.326778932061091e-05\n",
      "Iteration 248 : x = [1.99550805 1.50437568] f(x) = 0.0009242526462273274 gradient norm = 4.239421922645512e-05\n",
      "Iteration 249 : x = [1.99551238 1.50441785] f(x) = 0.0009242508670998721 gradient norm = 4.153833913892116e-05\n",
      "Iteration 250 : x = [1.99551663 1.50445917] f(x) = 0.0009242491590824229 gradient norm = 4.069978872241841e-05\n",
      "Iteration 251 : x = [1.99552079 1.50449966] f(x) = 0.0009242475193287217 gradient norm = 3.9878215065455076e-05\n",
      "Iteration 252 : x = [1.99552487 1.50453932] f(x) = 0.0009242459451066741 gradient norm = 3.90732725243354e-05\n",
      "Iteration 253 : x = [1.99552886 1.50457819] f(x) = 0.0009242444337937598 gradient norm = 3.828462257024167e-05\n",
      "Iteration 254 : x = [1.99553278 1.50461628] f(x) = 0.0009242429828726223 gradient norm = 3.7511933639677465e-05\n",
      "Iteration 255 : x = [1.99553661 1.50465359] f(x) = 0.0009242415899268391 gradient norm = 3.675488098820025e-05\n",
      "Iteration 256 : x = [1.99554037 1.50469016] f(x) = 0.0009242402526368635 gradient norm = 3.601314654731537e-05\n",
      "Iteration 257 : x = [1.99554405 1.50472598] f(x) = 0.000924238968776129 gradient norm = 3.5286418784481e-05\n",
      "Iteration 258 : x = [1.99554765 1.50476108] f(x) = 0.0009242377362073122 gradient norm = 3.457439256619608e-05\n",
      "Iteration 259 : x = [1.99555119 1.50479547] f(x) = 0.0009242365528787462 gradient norm = 3.387676902401623e-05\n",
      "Iteration 260 : x = [1.99555465 1.50482917] f(x) = 0.000924235416820977 gradient norm = 3.319325542351278e-05\n",
      "Iteration 261 : x = [1.99555804 1.50486219] f(x) = 0.0009242343261434618 gradient norm = 3.2523565036040445e-05\n",
      "Iteration 262 : x = [1.99556136 1.50489455] f(x) = 0.0009242332790313988 gradient norm = 3.1867417013289465e-05\n",
      "Iteration 263 : x = [1.99556462 1.50492625] f(x) = 0.0009242322737426846 gradient norm = 3.122453626455017e-05\n",
      "Iteration 264 : x = [1.99556781 1.50495731] f(x) = 0.0009242313086049943 gradient norm = 3.0594653336624675e-05\n",
      "Iteration 265 : x = [1.99557093 1.50498774] f(x) = 0.0009242303820129813 gradient norm = 2.9977504296315662e-05\n",
      "Iteration 266 : x = [1.995574   1.50501756] f(x) = 0.0009242294924255868 gradient norm = 2.9372830615451222e-05\n",
      "Iteration 267 : x = [1.995577   1.50504678] f(x) = 0.0009242286383634592 gradient norm = 2.878037905837031e-05\n",
      "Iteration 268 : x = [1.99557994 1.50507541] f(x) = 0.0009242278184064791 gradient norm = 2.8199901571845834e-05\n",
      "Iteration 269 : x = [1.99558282 1.50510347] f(x) = 0.0009242270311913809 gradient norm = 2.7631155177340958e-05\n",
      "Iteration 270 : x = [1.99558564 1.50513095] f(x) = 0.0009242262754094718 gradient norm = 2.707390186557643e-05\n",
      "Iteration 271 : x = [1.99558841 1.50515788] f(x) = 0.0009242255498044431 gradient norm = 2.6527908493354634e-05\n",
      "Iteration 272 : x = [1.99559111 1.50518427] f(x) = 0.0009242248531702683 gradient norm = 2.5992946682611718e-05\n",
      "Iteration 273 : x = [1.99559377 1.50521013] f(x) = 0.0009242241843491866 gradient norm = 2.5468792721586935e-05\n",
      "Iteration 274 : x = [1.99559637 1.50523547] f(x) = 0.0009242235422297671 gradient norm = 2.4955227468108355e-05\n",
      "Iteration 275 : x = [1.99559892 1.50526029] f(x) = 0.0009242229257450528 gradient norm = 2.4452036254939727e-05\n",
      "Iteration 276 : x = [1.99560142 1.50528462] f(x) = 0.0009242223338707732 gradient norm = 2.395900879716568e-05\n",
      "Iteration 277 : x = [1.99560386 1.50530845] f(x) = 0.0009242217656236394 gradient norm = 2.347593910149038e-05\n",
      "Iteration 278 : x = [1.99560626 1.5053318 ] f(x) = 0.0009242212200596964 gradient norm = 2.3002625377514278e-05\n",
      "Iteration 279 : x = [1.99560861 1.50535468] f(x) = 0.0009242206962727477 gradient norm = 2.253886995085263e-05\n",
      "Iteration 280 : x = [1.99561091 1.50537711] f(x) = 0.0009242201933928437 gradient norm = 2.208447917810867e-05\n",
      "Iteration 281 : x = [1.99561316 1.50539907] f(x) = 0.0009242197105848293 gradient norm = 2.16392633636721e-05\n",
      "Iteration 282 : x = [1.99561537 1.5054206 ] f(x) = 0.0009242192470469467 gradient norm = 2.1203036678218236e-05\n",
      "Iteration 283 : x = [1.99561754 1.50544169] f(x) = 0.000924218802009502 gradient norm = 2.0775617078987372e-05\n",
      "Iteration 284 : x = [1.99561966 1.50546236] f(x) = 0.0009242183747335779 gradient norm = 2.035682623169197e-05\n",
      "Iteration 285 : x = [1.99562174 1.50548261] f(x) = 0.0009242179645098016 gradient norm = 1.9946489434131205e-05\n",
      "Iteration 286 : x = [1.99562377 1.50550245] f(x) = 0.0009242175706571619 gradient norm = 1.9544435541349878e-05\n",
      "Iteration 287 : x = [1.99562577 1.5055219 ] f(x) = 0.0009242171925218735 gradient norm = 1.9150496892427874e-05\n",
      "Iteration 288 : x = [1.99562772 1.50554095] f(x) = 0.0009242168294762869 gradient norm = 1.876450923876248e-05\n",
      "Iteration 289 : x = [1.99562964 1.50555961] f(x) = 0.0009242164809178417 gradient norm = 1.8386311673894765e-05\n",
      "Iteration 290 : x = [1.99563152 1.5055779 ] f(x) = 0.0009242161462680625 gradient norm = 1.8015746564782623e-05\n",
      "Iteration 291 : x = [1.99563336 1.50559582] f(x) = 0.0009242158249715949 gradient norm = 1.765265948453468e-05\n",
      "Iteration 292 : x = [1.99563516 1.50561338] f(x) = 0.0009242155164952795 gradient norm = 1.729689914653196e-05\n",
      "Iteration 293 : x = [1.99563692 1.50563059] f(x) = 0.0009242152203272639 gradient norm = 1.6948317339949604e-05\n",
      "Iteration 294 : x = [1.99563865 1.50564745] f(x) = 0.0009242149359761511 gradient norm = 1.660676886662346e-05\n",
      "Iteration 295 : x = [1.99564035 1.50566397] f(x) = 0.0009242146629701789 gradient norm = 1.6272111479224953e-05\n",
      "Iteration 296 : x = [1.99564201 1.50568016] f(x) = 0.0009242144008564362 gradient norm = 1.5944205820732607e-05\n",
      "Iteration 297 : x = [1.99564364 1.50569602] f(x) = 0.000924214149200107 gradient norm = 1.562291536518536e-05\n",
      "Iteration 298 : x = [1.99564523 1.50571156] f(x) = 0.0009242139075837489 gradient norm = 1.5308106359637484e-05\n",
      "Iteration 299 : x = [1.99564679 1.50572679] f(x) = 0.0009242136756065959 gradient norm = 1.4999647767355471e-05\n",
      "Iteration 300 : x = [1.99564832 1.50574171] f(x) = 0.0009242134528838916 gradient norm = 1.4697411212178056e-05\n",
      "Iteration 301 : x = [1.99564982 1.50575633] f(x) = 0.000924213239046251 gradient norm = 1.440127092405347e-05\n",
      "Iteration 302 : x = [1.99565129 1.50577066] f(x) = 0.0009242130337390423 gradient norm = 1.411110368568203e-05\n",
      "Iteration 303 : x = [1.99565273 1.50578469] f(x) = 0.0009242128366218006 gradient norm = 1.3826788780299368e-05\n",
      "Iteration 304 : x = [1.99565414 1.50579845] f(x) = 0.0009242126473676582 gradient norm = 1.3548207940517965e-05\n",
      "Iteration 305 : x = [1.99565553 1.50581193] f(x) = 0.0009242124656628031 gradient norm = 1.3275245298255938e-05\n",
      "Iteration 306 : x = [1.99565688 1.50582513] f(x) = 0.0009242122912059558 gradient norm = 1.300778733567494e-05\n",
      "Iteration 307 : x = [1.99565821 1.50583807] f(x) = 0.0009242121237078698 gradient norm = 1.2745722837173608e-05\n",
      "Iteration 308 : x = [1.99565951 1.50585075] f(x) = 0.0009242119628908472 gradient norm = 1.2488942842338553e-05\n",
      "Iteration 309 : x = [1.99566078 1.50586318] f(x) = 0.0009242118084882817 gradient norm = 1.2237340599897888e-05\n",
      "Iteration 310 : x = [1.99566203 1.50587535] f(x) = 0.0009242116602442112 gradient norm = 1.1990811522605912e-05\n",
      "Iteration 311 : x = [1.99566325 1.50588728] f(x) = 0.0009242115179128951 gradient norm = 1.1749253143083571e-05\n",
      "Iteration 312 : x = [1.99566445 1.50589896] f(x) = 0.0009242113812584034 gradient norm = 1.151256507055916e-05\n",
      "Iteration 313 : x = [1.99566563 1.50591042] f(x) = 0.0009242112500542275 gradient norm = 1.1280648948502275e-05\n",
      "Iteration 314 : x = [1.99566678 1.50592164] f(x) = 0.0009242111240829005 gradient norm = 1.1053408413132766e-05\n",
      "Iteration 315 : x = [1.99566791 1.50593263] f(x) = 0.0009242110031356389 gradient norm = 1.0830749052807715e-05\n",
      "Iteration 316 : x = [1.99566901 1.50594341] f(x) = 0.0009242108870119927 gradient norm = 1.0612578368200813e-05\n",
      "Iteration 317 : x = [1.99567009 1.50595397] f(x) = 0.0009242107755195154 gradient norm = 1.039880573335579e-05\n",
      "Iteration 318 : x = [1.99567116 1.50596431] f(x) = 0.0009242106684734418 gradient norm = 1.0189342357514412e-05\n",
      "Iteration 319 : x = [1.99567219 1.50597445] f(x) = 0.0009242105656963827 gradient norm = 9.984101247724912e-06\n",
      "Iteration 320 : x = [1.99567321 1.50598438] f(x) = 0.0009242104670180291 gradient norm = 9.782997172238933e-06\n",
      "Iteration 321 : x = [1.99567421 1.50599411] f(x) = 0.0009242103722748704 gradient norm = 9.585946624659499e-06\n",
      "Iteration 322 : x = [1.99567519 1.50600365] f(x) = 0.0009242102813099213 gradient norm = 9.392867788802298e-06\n",
      "Iteration 323 : x = [1.99567615 1.50601299] f(x) = 0.0009242101939724636 gradient norm = 9.203680504328468e-06\n",
      "Iteration 324 : x = [1.99567709 1.50602215] f(x) = 0.0009242101101177935 gradient norm = 9.018306233035746e-06\n",
      "Iteration 325 : x = [1.99567801 1.50603112] f(x) = 0.0009242100296069825 gradient norm = 8.836668025863154e-06\n",
      "Iteration 326 : x = [1.99567891 1.50603991] f(x) = 0.0009242099523066466 gradient norm = 8.658690490575098e-06\n",
      "Iteration 327 : x = [1.99567979 1.50604852] f(x) = 0.0009242098780887248 gradient norm = 8.484299760112732e-06\n",
      "Iteration 328 : x = [1.99568066 1.50605696] f(x) = 0.0009242098068302668 gradient norm = 8.313423461576204e-06\n",
      "Iteration 329 : x = [1.9956815  1.50606523] f(x) = 0.0009242097384132281 gradient norm = 8.145990685876012e-06\n",
      "Iteration 330 : x = [1.99568234 1.50607334] f(x) = 0.0009242096727242758 gradient norm = 7.981931957956229e-06\n",
      "Iteration 331 : x = [1.99568315 1.50608128] f(x) = 0.0009242096096545978 gradient norm = 7.82117920769171e-06\n",
      "Iteration 332 : x = [1.99568395 1.50608906] f(x) = 0.0009242095490997256 gradient norm = 7.663665741325731e-06\n",
      "Iteration 333 : x = [1.99568473 1.50609668] f(x) = 0.0009242094909593571 gradient norm = 7.509326213539176e-06\n",
      "Iteration 334 : x = [1.99568549 1.50610415] f(x) = 0.0009242094351371942 gradient norm = 7.358096600047165e-06\n",
      "Iteration 335 : x = [1.99568625 1.50611147] f(x) = 0.0009242093815407799 gradient norm = 7.209914170792475e-06\n",
      "Iteration 336 : x = [1.99568698 1.50611864] f(x) = 0.0009242093300813464 gradient norm = 7.064717463660518e-06\n",
      "Iteration 337 : x = [1.9956877  1.50612567] f(x) = 0.0009242092806736674 gradient norm = 6.9224462587738585e-06\n",
      "Iteration 338 : x = [1.99568841 1.50613256] f(x) = 0.0009242092332359169 gradient norm = 6.783041553245417e-06\n",
      "Iteration 339 : x = [1.9956891 1.5061393] f(x) = 0.0009242091876895331 gradient norm = 6.646445536522316e-06\n",
      "Iteration 340 : x = [1.99568978 1.50614592] f(x) = 0.0009242091439590888 gradient norm = 6.512601566191008e-06\n",
      "Iteration 341 : x = [1.99569044 1.50615239] f(x) = 0.0009242091019721656 gradient norm = 6.381454144265251e-06\n",
      "Iteration 342 : x = [1.99569109 1.50615874] f(x) = 0.0009242090616592346 gradient norm = 6.252948893989741e-06\n",
      "Iteration 343 : x = [1.99569173 1.50616496] f(x) = 0.0009242090229535396 gradient norm = 6.127032537120736e-06\n",
      "Iteration 344 : x = [1.99569235 1.50617106] f(x) = 0.0009242089857909878 gradient norm = 6.003652871630173e-06\n",
      "Iteration 345 : x = [1.99569297 1.50617703] f(x) = 0.0009242089501100438 gradient norm = 5.882758749914882e-06\n",
      "Iteration 346 : x = [1.99569357 1.50618288] f(x) = 0.0009242089158516259 gradient norm = 5.764300057400912e-06\n",
      "Iteration 347 : x = [1.99569415 1.50618862] f(x) = 0.000924208882959009 gradient norm = 5.648227691630529e-06\n",
      "Iteration 348 : x = [1.99569473 1.50619424] f(x) = 0.0009242088513777318 gradient norm = 5.534493541751879e-06\n",
      "Iteration 349 : x = [1.9956953  1.50619974] f(x) = 0.0009242088210555036 gradient norm = 5.423050468405328e-06\n",
      "Iteration 350 : x = [1.99569585 1.50620514] f(x) = 0.0009242087919421213 gradient norm = 5.313852284082412e-06\n",
      "Iteration 351 : x = [1.99569639 1.50621042] f(x) = 0.0009242087639893829 gradient norm = 5.20685373382333e-06\n",
      "Iteration 352 : x = [1.99569692 1.5062156 ] f(x) = 0.0009242087371510094 gradient norm = 5.102010476332024e-06\n",
      "Iteration 353 : x = [1.99569744 1.50622068] f(x) = 0.000924208711382567 gradient norm = 4.999279065482857e-06\n",
      "Iteration 354 : x = [1.99569795 1.50622565] f(x) = 0.0009242086866413953 gradient norm = 4.898616932190057e-06\n",
      "Iteration 355 : x = [1.99569845 1.50623052] f(x) = 0.0009242086628865339 gradient norm = 4.7999823666632035e-06\n",
      "Iteration 356 : x = [1.99569894 1.5062353 ] f(x) = 0.0009242086400786575 gradient norm = 4.70333450100238e-06\n",
      "Iteration 357 : x = [1.99569942 1.50623998] f(x) = 0.0009242086181800083 gradient norm = 4.60863329215294e-06\n",
      "Iteration 358 : x = [1.99569989 1.50624456] f(x) = 0.0009242085971543339 gradient norm = 4.515839505235529e-06\n",
      "Iteration 359 : x = [1.99570035 1.50624905] f(x) = 0.0009242085769668288 gradient norm = 4.424914697177522e-06\n",
      "Iteration 360 : x = [1.9957008  1.50625346] f(x) = 0.0009242085575840745 gradient norm = 4.335821200689682e-06\n",
      "Iteration 361 : x = [1.99570124 1.50625777] f(x) = 0.0009242085389739854 gradient norm = 4.24852210857472e-06\n",
      "Iteration 362 : x = [1.99570168 1.506262  ] f(x) = 0.0009242085211057569 gradient norm = 4.162981258356658e-06\n",
      "Iteration 363 : x = [1.9957021  1.50626614] f(x) = 0.0009242085039498105 gradient norm = 4.079163217210868e-06\n",
      "Iteration 364 : x = [1.99570252 1.50627019] f(x) = 0.0009242084874777484 gradient norm = 3.997033267209264e-06\n",
      "Iteration 365 : x = [1.99570293 1.50627417] f(x) = 0.0009242084716623065 gradient norm = 3.916557390866044e-06\n",
      "Iteration 366 : x = [1.99570333 1.50627807] f(x) = 0.0009242084564773051 gradient norm = 3.8377022569673085e-06\n",
      "Iteration 367 : x = [1.99570372 1.50628188] f(x) = 0.0009242084418976104 gradient norm = 3.7604352066995023e-06\n",
      "Iteration 368 : x = [1.9957041  1.50628563] f(x) = 0.0009242084278990909 gradient norm = 3.6847242400611777e-06\n",
      "Iteration 369 : x = [1.99570448 1.50628929] f(x) = 0.0009242084144585763 gradient norm = 3.610538002528027e-06\n",
      "Iteration 370 : x = [1.99570484 1.50629288] f(x) = 0.0009242084015538206 gradient norm = 3.5378457720243046e-06\n",
      "Iteration 371 : x = [1.9957052 1.5062964] f(x) = 0.0009242083891634656 gradient norm = 3.4666174461281382e-06\n",
      "Iteration 372 : x = [1.99570556 1.50629985] f(x) = 0.0009242083772670035 gradient norm = 3.396823529545263e-06\n",
      "Iteration 373 : x = [1.9957059  1.50630323] f(x) = 0.000924208365844745 gradient norm = 3.328435121859525e-06\n",
      "Iteration 374 : x = [1.99570624 1.50630654] f(x) = 0.0009242083548777863 gradient norm = 3.261423905484428e-06\n",
      "Iteration 375 : x = [1.99570658 1.50630979] f(x) = 0.0009242083443479758 gradient norm = 3.1957621339107126e-06\n",
      "Iteration 376 : x = [1.9957069  1.50631296] f(x) = 0.0009242083342378872 gradient norm = 3.1314226201478798e-06\n",
      "Iteration 377 : x = [1.99570722 1.50631608] f(x) = 0.0009242083245307882 gradient norm = 3.06837872543986e-06\n",
      "Iteration 378 : x = [1.99570753 1.50631913] f(x) = 0.0009242083152106136 gradient norm = 3.006604348172347e-06\n",
      "Iteration 379 : x = [1.99570784 1.50632212] f(x) = 0.0009242083062619396 gradient norm = 2.9460739130403046e-06\n",
      "Iteration 380 : x = [1.99570814 1.50632505] f(x) = 0.0009242082976699564 gradient norm = 2.8867623604052242e-06\n",
      "Iteration 381 : x = [1.99570844 1.50632793] f(x) = 0.0009242082894204448 gradient norm = 2.8286451358882058e-06\n",
      "Iteration 382 : x = [1.99570872 1.50633074] f(x) = 0.0009242082814997529 gradient norm = 2.7716981801500733e-06\n",
      "Iteration 383 : x = [1.99570901 1.5063335 ] f(x) = 0.000924208273894773 gradient norm = 2.7158979189153927e-06\n",
      "Iteration 384 : x = [1.99570928 1.5063362 ] f(x) = 0.0009242082665929195 gradient norm = 2.661221253171243e-06\n",
      "Iteration 385 : x = [1.99570956 1.50633885] f(x) = 0.0009242082595821094 gradient norm = 2.6076455495640356e-06\n",
      "Iteration 386 : x = [1.99570982 1.50634144] f(x) = 0.000924208252850741 gradient norm = 2.555148630998764e-06\n",
      "Iteration 387 : x = [1.99571008 1.50634398] f(x) = 0.0009242082463876747 gradient norm = 2.5037087674387482e-06\n",
      "Iteration 388 : x = [1.99571034 1.50634647] f(x) = 0.0009242082401822156 gradient norm = 2.4533046668669773e-06\n",
      "Iteration 389 : x = [1.99571059 1.50634891] f(x) = 0.0009242082342240952 gradient norm = 2.403915466451132e-06\n",
      "Iteration 390 : x = [1.99571083 1.5063513 ] f(x) = 0.0009242082285034542 gradient norm = 2.355520723886539e-06\n",
      "Iteration 391 : x = [1.99571107 1.50635365] f(x) = 0.0009242082230108258 gradient norm = 2.308100408895857e-06\n",
      "Iteration 392 : x = [1.99571131 1.50635594] f(x) = 0.0009242082177371222 gradient norm = 2.2616348949139035e-06\n",
      "Iteration 393 : x = [1.99571154 1.50635819] f(x) = 0.000924208212673616 gradient norm = 2.216104950949101e-06\n",
      "Iteration 394 : x = [1.99571176 1.5063604 ] f(x) = 0.0009242082078119285 gradient norm = 2.171491733603493e-06\n",
      "Iteration 395 : x = [1.99571199 1.50636256] f(x) = 0.0009242082031440152 gradient norm = 2.1277767792261243e-06\n",
      "Iteration 396 : x = [1.9957122  1.50636467] f(x) = 0.000924208198662153 gradient norm = 2.0849419962835197e-06\n",
      "Iteration 397 : x = [1.99571242 1.50636675] f(x) = 0.0009242081943589248 gradient norm = 2.0429696578250098e-06\n",
      "Iteration 398 : x = [1.99571262 1.50636878] f(x) = 0.0009242081902272103 gradient norm = 2.001842394144295e-06\n",
      "Iteration 399 : x = [1.99571283 1.50637077] f(x) = 0.000924208186260174 gradient norm = 1.9615431855652234e-06\n",
      "Iteration 400 : x = [1.99571303 1.50637272] f(x) = 0.0009242081824512509 gradient norm = 1.922055355369691e-06\n",
      "Iteration 401 : x = [1.99571322 1.50637464] f(x) = 0.000924208178794139 gradient norm = 1.8833625628995695e-06\n",
      "Iteration 402 : x = [1.99571342 1.50637651] f(x) = 0.000924208175282787 gradient norm = 1.8454487967613097e-06\n",
      "Iteration 403 : x = [1.9957136  1.50637835] f(x) = 0.0009242081719113856 gradient norm = 1.8082983681938519e-06\n",
      "Iteration 404 : x = [1.99571379 1.50638014] f(x) = 0.0009242081686743556 gradient norm = 1.7718959045447162e-06\n",
      "Iteration 405 : x = [1.99571397 1.50638191] f(x) = 0.0009242081655663421 gradient norm = 1.736226342917574e-06\n",
      "Iteration 406 : x = [1.99571415 1.50638363] f(x) = 0.0009242081625822018 gradient norm = 1.701274923908698e-06\n",
      "Iteration 407 : x = [1.99571432 1.50638533] f(x) = 0.0009242081597169978 gradient norm = 1.6670271854811983e-06\n",
      "Iteration 408 : x = [1.99571449 1.50638698] f(x) = 0.0009242081569659895 gradient norm = 1.6334689569926288e-06\n",
      "Iteration 409 : x = [1.99571466 1.50638861] f(x) = 0.0009242081543246253 gradient norm = 1.6005863532839584e-06\n",
      "Iteration 410 : x = [1.99571482 1.5063902 ] f(x) = 0.0009242081517885349 gradient norm = 1.5683657689578848e-06\n",
      "Iteration 411 : x = [1.99571498 1.50639176] f(x) = 0.0009242081493535213 gradient norm = 1.536793872711016e-06\n",
      "Iteration 412 : x = [1.99571514 1.50639329] f(x) = 0.0009242081470155572 gradient norm = 1.5058576018126151e-06\n",
      "Iteration 413 : x = [1.99571529 1.50639479] f(x) = 0.000924208144770774 gradient norm = 1.4755441567077674e-06\n",
      "Iteration 414 : x = [1.99571544 1.50639626] f(x) = 0.0009242081426154577 gradient norm = 1.4458409956686045e-06\n",
      "Iteration 415 : x = [1.99571559 1.50639769] f(x) = 0.0009242081405460422 gradient norm = 1.4167358296512228e-06\n",
      "Iteration 416 : x = [1.99571573 1.5063991 ] f(x) = 0.0009242081385591039 gradient norm = 1.3882166171534552e-06\n",
      "Iteration 417 : x = [1.99571587 1.50640049] f(x) = 0.0009242081366513553 gradient norm = 1.3602715592552582e-06\n",
      "Iteration 418 : x = [1.99571601 1.50640184] f(x) = 0.0009242081348196404 gradient norm = 1.3328890947082996e-06\n",
      "Iteration 419 : x = [1.99571615 1.50640316] f(x) = 0.0009242081330609284 gradient norm = 1.3060578951584955e-06\n",
      "Iteration 420 : x = [1.99571628 1.50640446] f(x) = 0.0009242081313723102 gradient norm = 1.2797668604389086e-06\n",
      "Iteration 421 : x = [1.99571641 1.50640574] f(x) = 0.0009242081297509915 gradient norm = 1.2540051139776823e-06\n",
      "Iteration 422 : x = [1.99571654 1.50640698] f(x) = 0.0009242081281942903 gradient norm = 1.2287619982936725e-06\n",
      "Iteration 423 : x = [1.99571666 1.50640821] f(x) = 0.0009242081266996308 gradient norm = 1.2040270705754233e-06\n",
      "Iteration 424 : x = [1.99571679 1.5064094 ] f(x) = 0.0009242081252645405 gradient norm = 1.179790098342495e-06\n",
      "Iteration 425 : x = [1.99571691 1.50641058] f(x) = 0.0009242081238866453 gradient norm = 1.1560410552319557e-06\n",
      "Iteration 426 : x = [1.99571703 1.50641173] f(x) = 0.0009242081225636656 gradient norm = 1.132770116827825e-06\n",
      "Iteration 427 : x = [1.99571714 1.50641285] f(x) = 0.0009242081212934124 gradient norm = 1.1099676565836698e-06\n",
      "Iteration 428 : x = [1.99571725 1.50641396] f(x) = 0.0009242081200737846 gradient norm = 1.0876242418532164e-06\n",
      "Iteration 429 : x = [1.99571736 1.50641504] f(x) = 0.0009242081189027642 gradient norm = 1.065730629963061e-06\n",
      "Iteration 430 : x = [1.99571747 1.5064161 ] f(x) = 0.0009242081177784138 gradient norm = 1.0442777644085432e-06\n",
      "Iteration 431 : x = [1.99571758 1.50641714] f(x) = 0.0009242081166988734 gradient norm = 1.0232567710765781e-06\n",
      "Iteration 432 : x = [1.99571768 1.50641816] f(x) = 0.0009242081156623578 gradient norm = 1.0026589545824257e-06\n",
      "Iteration 433 : x = [1.99571779 1.50641916] f(x) = 0.0009242081146671509 gradient norm = 9.824757946626936e-07\n",
      "Completed in 433 iterations\n",
      "\n",
      "\tStep size: 10\n",
      "Iteration 0 : x = [0.5 1. ] f(x) = 0.15009253657239355 gradient norm = 0.09611715372728168\n",
      "Iteration 1 : x = [1.42401846 1.26465186] f(x) = 0.030481340136620086 gradient norm = 0.10270451071604282\n",
      "Iteration 2 : x = [2.44968703 1.31780859] f(x) = 0.02141247159099913 gradient norm = 0.08430127490462397\n",
      "Iteration 3 : x = [1.62041015 1.46936833] f(x) = 0.01355421141421842 gradient norm = 0.06712649687905896\n",
      "Iteration 4 : x = [2.29145663 1.45224279] f(x) = 0.009092887451488311 gradient norm = 0.05403491616143214\n",
      "Iteration 5 : x = [1.75609321 1.52547683] f(x) = 0.006185944520974511 gradient norm = 0.04352192689764584\n",
      "Iteration 6 : x = [2.1903722  1.49688366] f(x) = 0.004364710155442123 gradient norm = 0.03521865711536351\n",
      "Iteration 7 : x = [1.84038734 1.53620262] f(x) = 0.003183811143927136 gradient norm = 0.028586589778713773\n",
      "Iteration 8 : x = [2.12510792 1.51063884] f(x) = 0.0024233369901550702 gradient norm = 0.02328223830363137\n",
      "Iteration 9 : x = [1.89338974 1.53328721] f(x) = 0.0019212859685486159 gradient norm = 0.01900932720625035\n",
      "Iteration 10 : x = [2.08244807 1.51347811] f(x) = 0.0015931046839982351 gradient norm = 0.015562844977167945\n",
      "Iteration 11 : x = [1.92743026 1.52725104] f(x) = 0.001373215520735057 gradient norm = 0.01276310734458005\n",
      "Iteration 12 : x = [2.05423766 1.51277432] f(x) = 0.0012277547731348304 gradient norm = 0.01048908372897261\n",
      "Iteration 13 : x = [1.94971124 1.52151028] f(x) = 0.0011293499090737752 gradient norm = 0.008629932745786106\n",
      "Iteration 14 : x = [2.03539745 1.51124148] f(x) = 0.001063609078998474 gradient norm = 0.007111350680306336\n",
      "Iteration 15 : x = [1.96451424 1.51695996] f(x) = 0.0010188740767353435 gradient norm = 0.005864214943452817\n",
      "Iteration 16 : x = [2.02271747 1.50979856] f(x) = 0.000988756226518071 gradient norm = 0.0048411435162083035\n",
      "Iteration 17 : x = [1.97445764 1.51362694] f(x) = 0.0009681904776945208 gradient norm = 0.00399837689177652\n",
      "Iteration 18 : x = [2.01413464 1.50868347] f(x) = 0.0009542644359824742 gradient norm = 0.0033048557922469132\n",
      "Iteration 19 : x = [1.98118871 1.51128603] f(x) = 0.0009447356855836083 gradient norm = 0.0027324029651570564\n",
      "Iteration 20 : x = [2.00830153 1.50789517] f(x) = 0.0009382564732720899 gradient norm = 0.0022602880924592434\n",
      "Iteration 21 : x = [1.9857694  1.50968218] f(x) = 0.0009338178140555921 gradient norm = 0.0018700757286170208\n",
      "Iteration 22 : x = [2.0043261  1.50736546] f(x) = 0.0009307908803633807 gradient norm = 0.0015477729246729088\n",
      "Iteration 23 : x = [1.98889769 1.50860016] f(x) = 0.0009287157815947858 gradient norm = 0.0012811562105910807\n",
      "Iteration 24 : x = [2.00161158 1.50702114] f(x) = 0.0009272978250749824 gradient norm = 0.0010607154108036871\n",
      "Iteration 25 : x = [1.99103904 1.50787735] f(x) = 0.0009263253486643186 gradient norm = 0.0008782619901849211\n",
      "Iteration 26 : x = [1.99975566 1.50680267] f(x) = 0.0009256599222981001 gradient norm = 0.0007273058159200787\n",
      "Iteration 27 : x = [1.99250697 1.50739757] f(x) = 0.0009252034411964304 gradient norm = 0.0006023197882548545\n",
      "Iteration 28 : x = [1.99848566 1.5066667 ] f(x) = 0.0009248907974970848 gradient norm = 0.0004988639525216536\n",
      "Iteration 29 : x = [1.9935142 1.5070804] f(x) = 0.0009246762931166488 gradient norm = 0.0004131876220049181\n",
      "Iteration 30 : x = [1.99761609 1.5065835 ] f(x) = 0.0009245292858424007 gradient norm = 0.0003422490313594887\n",
      "Iteration 31 : x = [1.99420572 1.50687124] f(x) = 0.000924428415370787 gradient norm = 0.0002834935352358326\n",
      "Iteration 32 : x = [1.99702046 1.50653343] f(x) = 0.0009243592554686406 gradient norm = 0.00023483552218329432\n",
      "Iteration 33 : x = [1.99468064 1.50673351] f(x) = 0.00092431179807232 gradient norm = 0.00019453059950330244\n",
      "Iteration 34 : x = [1.99661234 1.50650381] f(x) = 0.000924279250211502 gradient norm = 0.00016114807409761385\n",
      "Iteration 35 : x = [1.99500687 1.50664286] f(x) = 0.000924256915107904 gradient norm = 0.0001334947955481042\n",
      "Iteration 36 : x = [1.99633264 1.50648663] f(x) = 0.0009242415938406614 gradient norm = 0.00011058907484611196\n",
      "Iteration 37 : x = [1.99523098 1.50658321] f(x) = 0.0009242310797583067 gradient norm = 9.161387829328168e-05\n",
      "Iteration 38 : x = [1.99614093 1.50647691] f(x) = 0.0009242238663711438 gradient norm = 7.589551130161439e-05\n",
      "Iteration 39 : x = [1.99538494 1.50654394] f(x) = 0.0009242189161537484 gradient norm = 6.287406894638622e-05\n",
      "Iteration 40 : x = [1.9960095  1.50647158] f(x) = 0.0009242155196273065 gradient norm = 5.208718732430945e-05\n",
      "Iteration 41 : x = [1.99549071 1.50651807] f(x) = 0.000924213188711064 gradient norm = 4.315097526628233e-05\n",
      "Iteration 42 : x = [1.9959194 1.5064688] f(x) = 0.0009242115892715841 gradient norm = 3.5748096362780064e-05\n",
      "Iteration 43 : x = [1.99556337 1.50650102] f(x) = 0.000924210491618672 gradient norm = 2.9615252277470798e-05\n",
      "Iteration 44 : x = [1.99585761 1.50646745] f(x) = 0.0009242097383878717 gradient norm = 2.453464088821739e-05\n",
      "Iteration 45 : x = [1.99561328 1.50648977] f(x) = 0.000924209221459821 gradient norm = 2.032563402496343e-05\n",
      "Iteration 46 : x = [1.99581525 1.50646689] f(x) = 0.0009242088667206539 gradient norm = 1.6838743797654402e-05\n",
      "Iteration 47 : x = [1.99564757 1.50648233] f(x) = 0.0009242086232674945 gradient norm = 1.3950036962941834e-05\n",
      "Iteration 48 : x = [1.9957862  1.50646674] f(x) = 0.0009242084561944618 gradient norm = 1.1556913010462919e-05\n",
      "Iteration 49 : x = [1.99567112 1.50647742] f(x) = 0.00092420834153328 gradient norm = 9.574329916230513e-06\n",
      "Iteration 50 : x = [1.99576627 1.50646678] f(x) = 0.0009242082628438585 gradient norm = 7.931868360288465e-06\n",
      "Iteration 51 : x = [1.9956873  1.50647416] f(x) = 0.0009242082088393777 gradient norm = 6.571169255742393e-06\n",
      "Iteration 52 : x = [1.99575261 1.5064669 ] f(x) = 0.0009242081717767117 gradient norm = 5.443900824769718e-06\n",
      "Iteration 53 : x = [1.99569841 1.506472  ] f(x) = 0.0009242081463404594 gradient norm = 4.51001302392498e-06\n",
      "Iteration 54 : x = [1.99574324 1.50646705] f(x) = 0.0009242081288836291 gradient norm = 3.7363337898070185e-06\n",
      "Iteration 55 : x = [1.99570604 1.50647057] f(x) = 0.0009242081169028634 gradient norm = 3.0953771726899454e-06\n",
      "Iteration 56 : x = [1.99573681 1.50646719] f(x) = 0.0009242081086804156 gradient norm = 2.5643758889506985e-06\n",
      "Iteration 57 : x = [1.99571128 1.50646962] f(x) = 0.0009242081030372512 gradient norm = 2.1244662113491814e-06\n",
      "Iteration 58 : x = [1.9957324  1.50646731] f(x) = 0.0009242080991642937 gradient norm = 1.7600220894752095e-06\n",
      "Iteration 59 : x = [1.99571488 1.50646899] f(x) = 0.000924208096506224 gradient norm = 1.4580970814163133e-06\n",
      "Iteration 60 : x = [1.99572937 1.50646741] f(x) = 0.0009242080946819531 gradient norm = 1.2079664482886878e-06\n",
      "Iteration 61 : x = [1.99571735 1.50646856] f(x) = 0.0009242080934299227 gradient norm = 1.0007447777701924e-06\n",
      "Iteration 62 : x = [1.9957273  1.50646748] f(x) = 0.000924208092570632 gradient norm = 8.290712885724756e-07\n",
      "Completed in 62 iterations\n",
      "\n",
      "\tStep size: 100\n",
      "Iteration 0 : x = [0.5 1. ] f(x) = 0.15009253657239355 gradient norm = 0.09611715372728168\n",
      "Iteration 1 : x = [9.7401846  3.64651864] f(x) = 0.1595467634753491 gradient norm = 3.8764642167510455e-05\n",
      "Iteration 2 : x = [9.74364317 3.64476784] f(x) = 0.15954661451359956 gradient norm = 3.809162544688371e-05\n",
      "Iteration 3 : x = [9.74704097 3.64304601] f(x) = 0.1595464706591233 gradient norm = 3.744087376876629e-05\n",
      "Iteration 4 : x = [9.75038001 3.64135221] f(x) = 0.15954633165887827 gradient norm = 3.6811315042639136e-05\n",
      "Iteration 5 : x = [9.75366224 3.63968556] f(x) = 0.15954619727607536 gradient norm = 3.620194444662632e-05\n",
      "Iteration 6 : x = [9.75688948 3.63804521] f(x) = 0.1595460672889037 gradient norm = 3.561181925435833e-05\n",
      "Iteration 7 : x = [9.76006348 3.63643036] f(x) = 0.15954594148937307 gradient norm = 3.504005413075736e-05\n",
      "Iteration 8 : x = [9.76318591 3.63484024] f(x) = 0.15954581968226209 gradient norm = 3.448581684798518e-05\n",
      "Iteration 9 : x = [9.76625835 3.6332741 ] f(x) = 0.15954570168415994 gradient norm = 3.394832437848729e-05\n",
      "Iteration 10 : x = [9.76928234 3.63173124] f(x) = 0.15954558732259325 gradient norm = 3.342683932703863e-05\n",
      "Iteration 11 : x = [9.77225931 3.630211  ] f(x) = 0.15954547643522862 gradient norm = 3.292066666802299e-05\n",
      "Iteration 12 : x = [9.77519067 3.62871272] f(x) = 0.1595453688691434 gradient norm = 3.2429150757966e-05\n",
      "Iteration 13 : x = [9.77807774 3.62723578] f(x) = 0.15954526448015868 gradient norm = 3.195167259665364e-05\n",
      "Iteration 14 : x = [9.78092179 3.6257796 ] f(x) = 0.15954516313222766 gradient norm = 3.1487647313079656e-05\n",
      "Iteration 15 : x = [9.78372405 3.6243436 ] f(x) = 0.15954506469687427 gradient norm = 3.103652185501814e-05\n",
      "Iteration 16 : x = [9.78648567 3.62292725] f(x) = 0.1595449690526776 gradient norm = 3.059777286327433e-05\n",
      "Iteration 17 : x = [9.7892078 3.62153  ] f(x) = 0.1595448760847978 gradient norm = 3.017090471364622e-05\n",
      "Iteration 18 : x = [9.79189149 3.62015137] f(x) = 0.15954478568453928 gradient norm = 2.975544771139307e-05\n",
      "Iteration 19 : x = [9.79453779 3.61879087] f(x) = 0.1595446977489482 gradient norm = 2.9350956424552985e-05\n",
      "Iteration 20 : x = [9.79714769 3.61744803] f(x) = 0.15954461218044086 gradient norm = 2.8957008143834613e-05\n",
      "Iteration 21 : x = [9.79972214 3.6161224 ] f(x) = 0.15954452888646098 gradient norm = 2.857320145803011e-05\n",
      "Iteration 22 : x = [9.80226206 3.61481356] f(x) = 0.15954444777916188 gradient norm = 2.81991549349821e-05\n",
      "Iteration 23 : x = [9.80476834 3.61352109] f(x) = 0.15954436877511322 gradient norm = 2.783450589911058e-05\n",
      "Iteration 24 : x = [9.80724183 3.61224458] f(x) = 0.1595442917950287 gradient norm = 2.7478909297367403e-05\n",
      "Iteration 25 : x = [9.80968334 3.61098366] f(x) = 0.15954421676351385 gradient norm = 2.7132036646259395e-05\n",
      "Iteration 26 : x = [9.81209366 3.60973794] f(x) = 0.15954414360883182 gradient norm = 2.6793575053270033e-05\n",
      "Iteration 27 : x = [9.81447356 3.60850708] f(x) = 0.15954407226268577 gradient norm = 2.6463226306632316e-05\n",
      "Iteration 28 : x = [9.81682378 3.60729072] f(x) = 0.1595440026600167 gradient norm = 2.6140706027955918e-05\n",
      "Iteration 29 : x = [9.81914501 3.60608853] f(x) = 0.159543934738815 gradient norm = 2.5825742882713892e-05\n",
      "Iteration 30 : x = [9.82143794 3.60490019] f(x) = 0.1595438684399453 gradient norm = 2.5518077844038892e-05\n",
      "Iteration 31 : x = [9.82370323 3.60372539] f(x) = 0.15954380370698304 gradient norm = 2.521746350568554e-05\n",
      "Iteration 32 : x = [9.82594152 3.60256381] f(x) = 0.15954374048606174 gradient norm = 2.4923663440378083e-05\n",
      "Iteration 33 : x = [9.82815343 3.60141518] f(x) = 0.15954367872573108 gradient norm = 2.4636451600089083e-05\n",
      "Iteration 34 : x = [9.83033955 3.6002792 ] f(x) = 0.15954361837682354 gradient norm = 2.4355611755094268e-05\n",
      "Iteration 35 : x = [9.83250045 3.59915561] f(x) = 0.15954355939233025 gradient norm = 2.4080936968915307e-05\n",
      "Iteration 36 : x = [9.83463669 3.59804414] f(x) = 0.15954350172728465 gradient norm = 2.3812229106504715e-05\n",
      "Iteration 37 : x = [9.83674882 3.59694453] f(x) = 0.15954344533865347 gradient norm = 2.354929837324866e-05\n",
      "Iteration 38 : x = [9.83883735 3.59585654] f(x) = 0.15954339018523478 gradient norm = 2.329196288256221e-05\n",
      "Iteration 39 : x = [9.84090279 3.59477992] f(x) = 0.15954333622756212 gradient norm = 2.304004825003309e-05\n",
      "Iteration 40 : x = [9.84294563 3.59371444] f(x) = 0.15954328342781485 gradient norm = 2.2793387212236392e-05\n",
      "Iteration 41 : x = [9.84496635 3.59265987] f(x) = 0.1595432317497338 gradient norm = 2.2551819268489778e-05\n",
      "Iteration 42 : x = [9.84696539 3.591616  ] f(x) = 0.15954318115854213 gradient norm = 2.2315190343959736e-05\n",
      "Iteration 43 : x = [9.84894321 3.59058261] f(x) = 0.15954313162087072 gradient norm = 2.2083352472650027e-05\n",
      "Iteration 44 : x = [9.85090025 3.5895595 ] f(x) = 0.1595430831046883 gradient norm = 2.1856163498921452e-05\n",
      "Iteration 45 : x = [9.85283691 3.58854646] f(x) = 0.15954303557923552 gradient norm = 2.1633486796291517e-05\n",
      "Iteration 46 : x = [9.85475361 3.5875433 ] f(x) = 0.15954298901496275 gradient norm = 2.1415191002362365e-05\n",
      "Iteration 47 : x = [9.85665075 3.58654983] f(x) = 0.1595429433834718 gradient norm = 2.1201149768809644e-05\n",
      "Iteration 48 : x = [9.8585287  3.58556586] f(x) = 0.1595428986574606 gradient norm = 2.099124152544439e-05\n",
      "Iteration 49 : x = [9.86038784 3.58459122] f(x) = 0.1595428548106713 gradient norm = 2.078534925743535e-05\n",
      "Iteration 50 : x = [9.86222853 3.58362574] f(x) = 0.15954281181784094 gradient norm = 2.0583360294844136e-05\n",
      "Iteration 51 : x = [9.86405112 3.58266923] f(x) = 0.15954276965465547 gradient norm = 2.0385166113689422e-05\n",
      "Iteration 52 : x = [9.86585596 3.58172155] f(x) = 0.15954272829770566 gradient norm = 2.0190662147809542e-05\n",
      "Iteration 53 : x = [9.86764338 3.58078253] f(x) = 0.15954268772444566 gradient norm = 1.9999747610848574e-05\n",
      "Iteration 54 : x = [9.8694137 3.579852 ] f(x) = 0.15954264791315395 gradient norm = 1.981232532773749e-05\n",
      "Iteration 55 : x = [9.87116723 3.57892983] f(x) = 0.1595426088428963 gradient norm = 1.962830157508462e-05\n",
      "Iteration 56 : x = [9.87290429 3.57801587] f(x) = 0.1595425704934905 gradient norm = 1.9447585929933612e-05\n",
      "Iteration 57 : x = [9.87462517 3.57710996] f(x) = 0.15954253284547318 gradient norm = 1.927009112638064e-05\n",
      "Iteration 58 : x = [9.87633016 3.57621197] f(x) = 0.15954249588006852 gradient norm = 1.909573291958091e-05\n",
      "Iteration 59 : x = [9.87801954 3.57532177] f(x) = 0.159542459579158 gradient norm = 1.892442995670482e-05\n",
      "Iteration 60 : x = [9.87969359 3.57443922] f(x) = 0.15954242392525236 gradient norm = 1.875610365443262e-05\n",
      "Iteration 61 : x = [9.88135257 3.57356419] f(x) = 0.15954238890146458 gradient norm = 1.8590678082606324e-05\n",
      "Iteration 62 : x = [9.88299676 3.57269655] f(x) = 0.15954235449148432 gradient norm = 1.8428079853680675e-05\n",
      "Iteration 63 : x = [9.88462639 3.57183618] f(x) = 0.15954232067955385 gradient norm = 1.82682380176406e-05\n",
      "Iteration 64 : x = [9.88624173 3.57098296] f(x) = 0.15954228745044483 gradient norm = 1.8111083962071223e-05\n",
      "Iteration 65 : x = [9.887843   3.57013678] f(x) = 0.15954225478943643 gradient norm = 1.795655131709095e-05\n",
      "Iteration 66 : x = [9.88943046 3.56929752] f(x) = 0.15954222268229465 gradient norm = 1.78045758648719e-05\n",
      "Iteration 67 : x = [9.89100432 3.56846506] f(x) = 0.15954219111525228 gradient norm = 1.7655095453493918e-05\n",
      "Iteration 68 : x = [9.89256482 3.5676393 ] f(x) = 0.15954216007499017 gradient norm = 1.7508049914891535e-05\n",
      "Iteration 69 : x = [9.89411217 3.56682014] f(x) = 0.15954212954861935 gradient norm = 1.7363380986669428e-05\n",
      "Iteration 70 : x = [9.89564658 3.56600746] f(x) = 0.1595420995236638 gradient norm = 1.7221032237575792e-05\n",
      "Iteration 71 : x = [9.89716827 3.56520117] f(x) = 0.15954206998804407 gradient norm = 1.7080948996435924e-05\n",
      "Iteration 72 : x = [9.89867743 3.56440116] f(x) = 0.159542040930062 gradient norm = 1.6943078284359955e-05\n",
      "Iteration 73 : x = [9.90017427 3.56360735] f(x) = 0.1595420123383857 gradient norm = 1.68073687500512e-05\n",
      "Iteration 74 : x = [9.90165899 3.56281963] f(x) = 0.15954198420203536 gradient norm = 1.6673770608051147e-05\n",
      "Iteration 75 : x = [9.90313176 3.56203791] f(x) = 0.15954195651037012 gradient norm = 1.6542235579766007e-05\n",
      "Iteration 76 : x = [9.90459278 3.56126211] f(x) = 0.1595419292530748 gradient norm = 1.6412716837131396e-05\n",
      "Iteration 77 : x = [9.90604223 3.56049213] f(x) = 0.1595419024201477 gradient norm = 1.6285168948778688e-05\n",
      "Iteration 78 : x = [9.90748029 3.55972789] f(x) = 0.15954187600188913 gradient norm = 1.615954782857301e-05\n",
      "Iteration 79 : x = [9.90890712 3.5589693 ] f(x) = 0.1595418499888897 gradient norm = 1.603581068640465e-05\n",
      "Iteration 80 : x = [9.9103229  3.55821628] f(x) = 0.1595418243720201 gradient norm = 1.5913915981117244e-05\n",
      "Iteration 81 : x = [9.9117278  3.55746875] f(x) = 0.1595417991424204 gradient norm = 1.579382337546785e-05\n",
      "Iteration 82 : x = [9.91312196 3.55672663] f(x) = 0.15954177429149066 gradient norm = 1.5675493693015683e-05\n",
      "Iteration 83 : x = [9.91450557 3.55598984] f(x) = 0.1595417498108811 gradient norm = 1.5558888876845104e-05\n",
      "Iteration 84 : x = [9.91587876 3.55525831] f(x) = 0.15954172569248345 gradient norm = 1.5443971950032395e-05\n",
      "Iteration 85 : x = [9.91724169 3.55453196] f(x) = 0.15954170192842226 gradient norm = 1.533070697777099e-05\n",
      "Iteration 86 : x = [9.91859451 3.55381072] f(x) = 0.15954167851104656 gradient norm = 1.5219059031074704e-05\n",
      "Iteration 87 : x = [9.91993736 3.55309452] f(x) = 0.15954165543292198 gradient norm = 1.5108994151983283e-05\n",
      "Iteration 88 : x = [9.92127039 3.55238328] f(x) = 0.1595416326868234 gradient norm = 1.5000479320198108e-05\n",
      "Iteration 89 : x = [9.92259373 3.55167695] f(x) = 0.1595416102657274 gradient norm = 1.489348242108038e-05\n",
      "Iteration 90 : x = [9.92390752 3.55097545] f(x) = 0.15954158816280553 gradient norm = 1.4787972214946447e-05\n",
      "Iteration 91 : x = [9.9252119  3.55027872] f(x) = 0.1595415663714174 gradient norm = 1.4683918307601134e-05\n",
      "Iteration 92 : x = [9.926507   3.54958669] f(x) = 0.15954154488510466 gradient norm = 1.4581291122050173e-05\n",
      "Iteration 93 : x = [9.92779294 3.5488993 ] f(x) = 0.15954152369758448 gradient norm = 1.448006187133727e-05\n",
      "Iteration 94 : x = [9.92906984 3.54821649] f(x) = 0.15954150280274376 gradient norm = 1.4380202532454091e-05\n",
      "Iteration 95 : x = [9.93033784 3.5475382 ] f(x) = 0.15954148219463368 gradient norm = 1.4281685821275393e-05\n",
      "Iteration 96 : x = [9.93159705 3.54686436] f(x) = 0.15954146186746399 gradient norm = 1.4184485168470103e-05\n",
      "Iteration 97 : x = [9.9328476  3.54619493] f(x) = 0.15954144181559793 gradient norm = 1.4088574696347212e-05\n",
      "Iteration 98 : x = [9.93408958 3.54552984] f(x) = 0.1595414220335472 gradient norm = 1.3993929196592816e-05\n",
      "Iteration 99 : x = [9.93532313 3.54486904] f(x) = 0.1595414025159671 gradient norm = 1.3900524108858988e-05\n",
      "Iteration 100 : x = [9.93654835 3.54421247] f(x) = 0.15954138325765183 gradient norm = 1.3808335500166984e-05\n",
      "Iteration 101 : x = [9.93776535 3.54356008] f(x) = 0.15954136425353022 gradient norm = 1.3717340045088514e-05\n",
      "Iteration 102 : x = [9.93897424 3.54291181] f(x) = 0.15954134549866134 gradient norm = 1.3627515006672177e-05\n",
      "Iteration 103 : x = [9.94017512 3.54226762] f(x) = 0.1595413269882303 gradient norm = 1.35388382180809e-05\n",
      "Iteration 104 : x = [9.94136809 3.54162745] f(x) = 0.15954130871754427 gradient norm = 1.3451288064911364e-05\n",
      "Iteration 105 : x = [9.94255326 3.54099126] f(x) = 0.15954129068202888 gradient norm = 1.3364843468164987e-05\n",
      "Iteration 106 : x = [9.94373072 3.54035899] f(x) = 0.15954127287722433 gradient norm = 1.3279483867843438e-05\n",
      "Iteration 107 : x = [9.94490058 3.53973059] f(x) = 0.15954125529878183 gradient norm = 1.3195189207141823e-05\n",
      "Iteration 108 : x = [9.94606293 3.53910603] f(x) = 0.1595412379424603 gradient norm = 1.3111939917214173e-05\n",
      "Iteration 109 : x = [9.94721786 3.53848525] f(x) = 0.1595412208041231 gradient norm = 1.3029716902487319e-05\n",
      "Iteration 110 : x = [9.94836546 3.5378682 ] f(x) = 0.15954120387973464 gradient norm = 1.2948501526501109e-05\n",
      "Iteration 111 : x = [9.94950582 3.53725484] f(x) = 0.1595411871653576 gradient norm = 1.2868275598251842e-05\n",
      "Iteration 112 : x = [9.95063904 3.53664514] f(x) = 0.15954117065714982 gradient norm = 1.2789021359019131e-05\n",
      "Iteration 113 : x = [9.9517652  3.53603903] f(x) = 0.15954115435136143 gradient norm = 1.2710721469656124e-05\n",
      "Iteration 114 : x = [9.95288438 3.53543649] f(x) = 0.15954113824433233 gradient norm = 1.2633358998323972e-05\n",
      "Iteration 115 : x = [9.95399667 3.53483748] f(x) = 0.15954112233248918 gradient norm = 1.255691740865344e-05\n",
      "Iteration 116 : x = [9.95510216 3.53424194] f(x) = 0.15954110661234325 gradient norm = 1.2481380548314844e-05\n",
      "Iteration 117 : x = [9.95620091 3.53364984] f(x) = 0.1595410910804876 gradient norm = 1.2406732637981984e-05\n",
      "Iteration 118 : x = [9.95729302 3.53306114] f(x) = 0.15954107573359502 gradient norm = 1.2332958260672501e-05\n",
      "Iteration 119 : x = [9.95837856 3.5324758 ] f(x) = 0.1595410605684154 gradient norm = 1.226004235145133e-05\n",
      "Iteration 120 : x = [9.95945761 3.53189378] f(x) = 0.15954104558177393 gradient norm = 1.2187970187481775e-05\n",
      "Iteration 121 : x = [9.96053024 3.53131505] f(x) = 0.15954103077056847 gradient norm = 1.2116727378411528e-05\n",
      "Iteration 122 : x = [9.96159653 3.53073957] f(x) = 0.15954101613176783 gradient norm = 1.2046299857079404e-05\n",
      "Iteration 123 : x = [9.96265655 3.5301673 ] f(x) = 0.15954100166240973 gradient norm = 1.1976673870532194e-05\n",
      "Iteration 124 : x = [9.96371037 3.5295982 ] f(x) = 0.1595409873595988 gradient norm = 1.1907835971337638e-05\n",
      "Iteration 125 : x = [9.96475806 3.52903225] f(x) = 0.15954097322050464 gradient norm = 1.1839773009183557e-05\n",
      "Iteration 126 : x = [9.9657997 3.5284694] f(x) = 0.15954095924236014 gradient norm = 1.1772472122752331e-05\n",
      "Iteration 127 : x = [9.96683534 3.52790963] f(x) = 0.15954094542245967 gradient norm = 1.1705920731858885e-05\n",
      "Iteration 128 : x = [9.96786507 3.52735289] f(x) = 0.15954093175815748 gradient norm = 1.1640106529843764e-05\n",
      "Iteration 129 : x = [9.96888894 3.52679916] f(x) = 0.15954091824686592 gradient norm = 1.1575017476211266e-05\n",
      "Iteration 130 : x = [9.96990701 3.52624841] f(x) = 0.15954090488605402 gradient norm = 1.1510641789502913e-05\n",
      "Iteration 131 : x = [9.97091936 3.52570059] f(x) = 0.15954089167324575 gradient norm = 1.1446967940398328e-05\n",
      "Iteration 132 : x = [9.97192604 3.52515569] f(x) = 0.15954087860601873 gradient norm = 1.1383984645034833e-05\n",
      "Iteration 133 : x = [9.97292712 3.52461366] f(x) = 0.15954086568200282 gradient norm = 1.1321680858537465e-05\n",
      "Iteration 134 : x = [9.97392266 3.52407449] f(x) = 0.15954085289887848 gradient norm = 1.1260045768752107e-05\n",
      "Iteration 135 : x = [9.97491271 3.52353813] f(x) = 0.15954084025437573 gradient norm = 1.1199068790174428e-05\n",
      "Iteration 136 : x = [9.97589734 3.52300456] f(x) = 0.15954082774627257 gradient norm = 1.113873955806678e-05\n",
      "Iteration 137 : x = [9.97687661 3.52247376] f(x) = 0.15954081537239403 gradient norm = 1.107904792275753e-05\n",
      "Iteration 138 : x = [9.97785057 3.52194568] f(x) = 0.15954080313061067 gradient norm = 1.101998394411513e-05\n",
      "Iteration 139 : x = [9.97881927 3.52142031] f(x) = 0.1595407910188375 gradient norm = 1.096153788619126e-05\n",
      "Iteration 140 : x = [9.97978278 3.52089762] f(x) = 0.15954077903503283 gradient norm = 1.0903700212027306e-05\n",
      "Iteration 141 : x = [9.98074114 3.52037758] f(x) = 0.15954076717719723 gradient norm = 1.0846461578617778e-05\n",
      "Iteration 142 : x = [9.98169441 3.51986015] f(x) = 0.1595407554433723 gradient norm = 1.0789812832025562e-05\n",
      "Iteration 143 : x = [9.98264265 3.51934533] f(x) = 0.15954074383163983 gradient norm = 1.0733745002643554e-05\n",
      "Iteration 144 : x = [9.9835859  3.51883307] f(x) = 0.15954073234012048 gradient norm = 1.0678249300598132e-05\n",
      "Iteration 145 : x = [9.98452422 3.51832336] f(x) = 0.15954072096697317 gradient norm = 1.062331711128838e-05\n",
      "Iteration 146 : x = [9.98545766 3.51781617] f(x) = 0.15954070971039377 gradient norm = 1.0568939991057456e-05\n",
      "Iteration 147 : x = [9.98638626 3.51731147] f(x) = 0.15954069856861455 gradient norm = 1.0515109662991594e-05\n",
      "Iteration 148 : x = [9.98731008 3.51680924] f(x) = 0.15954068753990286 gradient norm = 1.0461818012841458e-05\n",
      "Iteration 149 : x = [9.98822916 3.51630945] f(x) = 0.15954067662256063 gradient norm = 1.04090570850624e-05\n",
      "Iteration 150 : x = [9.98914356 3.51581209] f(x) = 0.15954066581492332 gradient norm = 1.0356819078970024e-05\n",
      "Iteration 151 : x = [9.99005331 3.51531713] f(x) = 0.15954065511535906 gradient norm = 1.0305096345005677e-05\n",
      "Iteration 152 : x = [9.99095846 3.51482454] f(x) = 0.15954064452226807 gradient norm = 1.0253881381110142e-05\n",
      "Iteration 153 : x = [9.99185907 3.5143343 ] f(x) = 0.1595406340340817 gradient norm = 1.0203166829200379e-05\n",
      "Iteration 154 : x = [9.99275517 3.51384639] f(x) = 0.15954062364926175 gradient norm = 1.015294547174667e-05\n",
      "Iteration 155 : x = [9.9936468  3.51336079] f(x) = 0.15954061336629968 gradient norm = 1.0103210228446604e-05\n",
      "Iteration 156 : x = [9.99453402 3.51287747] f(x) = 0.15954060318371593 gradient norm = 1.0053954152992803e-05\n",
      "Iteration 157 : x = [9.99541686 3.51239642] f(x) = 0.15954059310005939 gradient norm = 1.0005170429931356e-05\n",
      "Iteration 158 : x = [9.99629537 3.51191761] f(x) = 0.15954058311390637 gradient norm = 9.956852371608082e-06\n",
      "Iteration 159 : x = [9.99716958 3.51144103] f(x) = 0.15954057322386034 gradient norm = 9.908993415199176e-06\n",
      "Iteration 160 : x = [9.99803955 3.51096664] f(x) = 0.15954056342855102 gradient norm = 9.861587119824831e-06\n",
      "Iteration 161 : x = [9.9989053  3.51049443] f(x) = 0.15954055372663395 gradient norm = 9.814627163741458e-06\n",
      "Iteration 162 : x = [9.99976689 3.51002439] f(x) = 0.15954054411678967 gradient norm = 9.76810734161153e-06\n",
      "Iteration 163 : x = [10.00062434  3.50955648] f(x) = 0.1595405345977234 gradient norm = 9.722021561847979e-06\n",
      "Iteration 164 : x = [10.0014777  3.5090907] f(x) = 0.15954052516816433 gradient norm = 9.676363844030053e-06\n",
      "Iteration 165 : x = [10.002327    3.50862702] f(x) = 0.1595405158268651 gradient norm = 9.631128316390021e-06\n",
      "Iteration 166 : x = [10.00317229  3.50816542] f(x) = 0.15954050657260113 gradient norm = 9.58630921336682e-06\n",
      "Iteration 167 : x = [10.0040136   3.50770589] f(x) = 0.1595404974041704 gradient norm = 9.541900873225714e-06\n",
      "Iteration 168 : x = [10.00485097  3.5072484 ] f(x) = 0.15954048832039264 gradient norm = 9.497897735741325e-06\n",
      "Iteration 169 : x = [10.00568443  3.50679294] f(x) = 0.15954047932010906 gradient norm = 9.454294339942447e-06\n",
      "Iteration 170 : x = [10.00651402  3.50633948] f(x) = 0.15954047040218172 gradient norm = 9.41108532191628e-06\n",
      "Iteration 171 : x = [10.00733977  3.50588802] f(x) = 0.15954046156549306 gradient norm = 9.368265412670753e-06\n",
      "Iteration 172 : x = [10.00816172  3.50543854] f(x) = 0.15954045280894566 gradient norm = 9.325829436052716e-06\n",
      "Iteration 173 : x = [10.00897991  3.50499101] f(x) = 0.1595404441314615 gradient norm = 9.283772306720868e-06\n",
      "Iteration 174 : x = [10.00979436  3.50454542] f(x) = 0.1595404355319818 gradient norm = 9.242089028171077e-06\n",
      "Iteration 175 : x = [10.01060512  3.50410175] f(x) = 0.15954042700946633 gradient norm = 9.200774690812911e-06\n",
      "Iteration 176 : x = [10.0114122   3.50365999] f(x) = 0.15954041856289322 gradient norm = 9.159824470095892e-06\n",
      "Iteration 177 : x = [10.01221566  3.50322011] f(x) = 0.15954041019125847 gradient norm = 9.119233624684062e-06\n",
      "Iteration 178 : x = [10.01301551  3.50278211] f(x) = 0.15954040189357568 gradient norm = 9.078997494676554e-06\n",
      "Iteration 179 : x = [10.01381179  3.50234597] f(x) = 0.15954039366887537 gradient norm = 9.039111499874422e-06\n",
      "Iteration 180 : x = [10.01460453  3.50191167] f(x) = 0.159540385516205 gradient norm = 8.999571138090667e-06\n",
      "Iteration 181 : x = [10.01539376  3.5014792 ] f(x) = 0.15954037743462826 gradient norm = 8.96037198350333e-06\n",
      "Iteration 182 : x = [10.01617951  3.50104853] f(x) = 0.15954036942322505 gradient norm = 8.921509685049916e-06\n",
      "Iteration 183 : x = [10.01696182  3.50061966] f(x) = 0.15954036148109085 gradient norm = 8.882979964862078e-06\n",
      "Iteration 184 : x = [10.01774071  3.50019257] f(x) = 0.1595403536073366 gradient norm = 8.844778616739217e-06\n",
      "Iteration 185 : x = [10.01851621  3.49976725] f(x) = 0.1595403458010882 gradient norm = 8.80690150466025e-06\n",
      "Iteration 186 : x = [10.01928835  3.49934368] f(x) = 0.15954033806148635 gradient norm = 8.769344561331949e-06\n",
      "Iteration 187 : x = [10.02005716  3.49892184] f(x) = 0.15954033038768614 gradient norm = 8.732103786773398e-06\n",
      "Iteration 188 : x = [10.02082267  3.49850172] f(x) = 0.15954032277885688 gradient norm = 8.695175246934678e-06\n",
      "Iteration 189 : x = [10.0215849   3.49808331] f(x) = 0.15954031523418155 gradient norm = 8.658555072349842e-06\n",
      "Iteration 190 : x = [10.02234388  3.4976666 ] f(x) = 0.15954030775285677 gradient norm = 8.622239456822389e-06\n",
      "Iteration 191 : x = [10.02309964  3.49725156] f(x) = 0.15954030033409247 gradient norm = 8.586224656142848e-06\n",
      "Iteration 192 : x = [10.02385221  3.4968382 ] f(x) = 0.15954029297711156 gradient norm = 8.550506986836932e-06\n",
      "Iteration 193 : x = [10.02460161  3.49642648] f(x) = 0.1595402856811496 gradient norm = 8.515082824944256e-06\n",
      "Iteration 194 : x = [10.02534787  3.4960164 ] f(x) = 0.15954027844545476 gradient norm = 8.479948604826329e-06\n",
      "Iteration 195 : x = [10.02609101  3.49560795] f(x) = 0.15954027126928724 gradient norm = 8.445100818002431e-06\n",
      "Iteration 196 : x = [10.02683107  3.49520112] f(x) = 0.15954026415191944 gradient norm = 8.41053601201395e-06\n",
      "Iteration 197 : x = [10.02756806  3.49479588] f(x) = 0.15954025709263533 gradient norm = 8.376250789314926e-06\n",
      "Iteration 198 : x = [10.02830201  3.49439223] f(x) = 0.15954025009073047 gradient norm = 8.34224180618933e-06\n",
      "Iteration 199 : x = [10.02903295  3.49399016] f(x) = 0.15954024314551168 gradient norm = 8.308505771693404e-06\n",
      "Iteration 200 : x = [10.02976089  3.49358965] f(x) = 0.15954023625629685 gradient norm = 8.275039446623039e-06\n",
      "Iteration 201 : x = [10.03048587  3.49319069] f(x) = 0.15954022942241458 gradient norm = 8.24183964250505e-06\n",
      "Iteration 202 : x = [10.0312079   3.49279327] f(x) = 0.15954022264320428 gradient norm = 8.208903220611873e-06\n",
      "Iteration 203 : x = [10.03192702  3.49239737] f(x) = 0.1595402159180156 gradient norm = 8.176227090999437e-06\n",
      "Iteration 204 : x = [10.03264324  3.49200299] f(x) = 0.1595402092462085 gradient norm = 8.143808211566511e-06\n",
      "Iteration 205 : x = [10.03335659  3.49161011] f(x) = 0.1595402026271529 gradient norm = 8.111643587136467e-06\n",
      "Iteration 206 : x = [10.03406708  3.49121873] f(x) = 0.15954019606022857 gradient norm = 8.079730268559445e-06\n",
      "Iteration 207 : x = [10.03477475  3.49082882] f(x) = 0.1595401895448249 gradient norm = 8.048065351835397e-06\n",
      "Iteration 208 : x = [10.03547961  3.49044039] f(x) = 0.15954018308034068 gradient norm = 8.016645977256728e-06\n",
      "Iteration 209 : x = [10.03618169  3.49005341] f(x) = 0.15954017666618403 gradient norm = 7.985469328570584e-06\n",
      "Iteration 210 : x = [10.03688101  3.48966787] f(x) = 0.15954017030177206 gradient norm = 7.954532632159952e-06\n",
      "Iteration 211 : x = [10.03757758  3.48928378] f(x) = 0.15954016398653084 gradient norm = 7.923833156243081e-06\n",
      "Iteration 212 : x = [10.03827143  3.4889011 ] f(x) = 0.15954015771989524 gradient norm = 7.893368210090889e-06\n",
      "Iteration 213 : x = [10.03896259  3.48851985] f(x) = 0.15954015150130868 gradient norm = 7.863135143261938e-06\n",
      "Iteration 214 : x = [10.03965107  3.48813999] f(x) = 0.15954014533022284 gradient norm = 7.833131344854099e-06\n",
      "Iteration 215 : x = [10.04033688  3.48776153] f(x) = 0.1595401392060979 gradient norm = 7.803354242773012e-06\n",
      "Iteration 216 : x = [10.04102007  3.48738445] f(x) = 0.1595401331284019 gradient norm = 7.773801303016873e-06\n",
      "Iteration 217 : x = [10.04170063  3.48700875] f(x) = 0.1595401270966111 gradient norm = 7.744470028976445e-06\n",
      "Iteration 218 : x = [10.04237859  3.48663441] f(x) = 0.15954012111020938 gradient norm = 7.715357960750727e-06\n",
      "Iteration 219 : x = [10.04305398  3.48626142] f(x) = 0.1595401151686883 gradient norm = 7.686462674477522e-06\n",
      "Iteration 220 : x = [10.0437268   3.48588977] f(x) = 0.15954010927154696 gradient norm = 7.657781781678515e-06\n",
      "Iteration 221 : x = [10.04439709  3.48551945] f(x) = 0.15954010341829186 gradient norm = 7.629312928618705e-06\n",
      "Iteration 222 : x = [10.04506486  3.48515046] f(x) = 0.15954009760843677 gradient norm = 7.601053795679212e-06\n",
      "Iteration 223 : x = [10.04573012  3.48478279] f(x) = 0.15954009184150247 gradient norm = 7.573002096744096e-06\n",
      "Iteration 224 : x = [10.0463929   3.48441641] f(x) = 0.1595400861170169 gradient norm = 7.545155578600122e-06\n",
      "Iteration 225 : x = [10.04705321  3.48405134] f(x) = 0.15954008043451468 gradient norm = 7.517512020349262e-06\n",
      "Iteration 226 : x = [10.04771107  3.48368754] f(x) = 0.15954007479353727 gradient norm = 7.490069232833844e-06\n",
      "Iteration 227 : x = [10.04836651  3.48332503] f(x) = 0.15954006919363273 gradient norm = 7.462825058073583e-06\n",
      "Iteration 228 : x = [10.04901953  3.48296378] f(x) = 0.15954006363435558 gradient norm = 7.4357773687152195e-06\n",
      "Iteration 229 : x = [10.04967016  3.48260379] f(x) = 0.15954005811526678 gradient norm = 7.40892406749277e-06\n",
      "Iteration 230 : x = [10.0503184   3.48224505] f(x) = 0.15954005263593352 gradient norm = 7.382263086700017e-06\n",
      "Iteration 231 : x = [10.05096429  3.48188755] f(x) = 0.15954004719592915 gradient norm = 7.35579238767355e-06\n",
      "Iteration 232 : x = [10.05160784  3.48153129] f(x) = 0.1595400417948331 gradient norm = 7.329509960286496e-06\n",
      "Iteration 233 : x = [10.05224906  3.48117625] f(x) = 0.1595400364322307 gradient norm = 7.3034138224531395e-06\n",
      "Iteration 234 : x = [10.05288797  3.48082242] f(x) = 0.15954003110771314 gradient norm = 7.2775020196437035e-06\n",
      "Iteration 235 : x = [10.05352458  3.4804698 ] f(x) = 0.1595400258208773 gradient norm = 7.251772624408773e-06\n",
      "Iteration 236 : x = [10.05415892  3.48011837] f(x) = 0.15954002057132585 gradient norm = 7.226223735913995e-06\n",
      "Iteration 237 : x = [10.054791    3.47976814] f(x) = 0.15954001535866677 gradient norm = 7.200853479484087e-06\n",
      "Iteration 238 : x = [10.05542083  3.47941909] f(x) = 0.15954001018251368 gradient norm = 7.175660006156139e-06\n",
      "Iteration 239 : x = [10.05604843  3.47907122] f(x) = 0.1595400050424854 gradient norm = 7.150641492242092e-06\n",
      "Iteration 240 : x = [10.05667382  3.47872451] f(x) = 0.15953999993820614 gradient norm = 7.125796138899939e-06\n",
      "Iteration 241 : x = [10.057297    3.47837895] f(x) = 0.1595399948693052 gradient norm = 7.10112217171394e-06\n",
      "Iteration 242 : x = [10.05791801  3.47803455] f(x) = 0.15953998983541698 gradient norm = 7.0766178402828375e-06\n",
      "Iteration 243 : x = [10.05853684  3.47769129] f(x) = 0.15953998483618084 gradient norm = 7.052281417816817e-06\n",
      "Iteration 244 : x = [10.05915353  3.47734917] f(x) = 0.1595399798712411 gradient norm = 7.028111200742102e-06\n",
      "Iteration 245 : x = [10.05976807  3.47700817] f(x) = 0.15953997494024688 gradient norm = 7.004105508313814e-06\n",
      "Iteration 246 : x = [10.06038049  3.47666829] f(x) = 0.15953997004285211 gradient norm = 6.980262682236273e-06\n",
      "Iteration 247 : x = [10.0609908   3.47632952] f(x) = 0.15953996517871524 gradient norm = 6.956581086290942e-06\n",
      "Iteration 248 : x = [10.06159901  3.47599186] f(x) = 0.1595399603474994 gradient norm = 6.933059105971689e-06\n",
      "Iteration 249 : x = [10.06220515  3.4756553 ] f(x) = 0.15953995554887226 gradient norm = 6.90969514812743e-06\n",
      "Iteration 250 : x = [10.06280921  3.47531983] f(x) = 0.15953995078250585 gradient norm = 6.886487640611299e-06\n",
      "Iteration 251 : x = [10.06341123  3.47498544] f(x) = 0.15953994604807664 gradient norm = 6.8634350319372935e-06\n",
      "Iteration 252 : x = [10.0640112   3.47465212] f(x) = 0.15953994134526528 gradient norm = 6.84053579094318e-06\n",
      "Iteration 253 : x = [10.06460915  3.47431988] f(x) = 0.15953993667375682 gradient norm = 6.817788406460186e-06\n",
      "Iteration 254 : x = [10.06520509  3.47398869] f(x) = 0.1595399320332403 gradient norm = 6.7951913869889885e-06\n",
      "Iteration 255 : x = [10.06579902  3.47365857] f(x) = 0.1595399274234088 gradient norm = 6.772743260381926e-06\n",
      "Iteration 256 : x = [10.06639098  3.47332949] f(x) = 0.15953992284395963 gradient norm = 6.750442573531515e-06\n",
      "Iteration 257 : x = [10.06698096  3.47300145] f(x) = 0.15953991829459394 gradient norm = 6.728287892064765e-06\n",
      "Iteration 258 : x = [10.06756898  3.47267445] f(x) = 0.15953991377501664 gradient norm = 6.706277800043437e-06\n",
      "Iteration 259 : x = [10.06815505  3.47234847] f(x) = 0.15953990928493672 gradient norm = 6.684410899670033e-06\n",
      "Iteration 260 : x = [10.06873919  3.47202352] f(x) = 0.15953990482406671 gradient norm = 6.662685810999337e-06\n",
      "Iteration 261 : x = [10.06932141  3.47169958] f(x) = 0.1595399003921229 gradient norm = 6.641101171655325e-06\n",
      "Iteration 262 : x = [10.06990172  3.47137665] f(x) = 0.15953989598882537 gradient norm = 6.619655636553783e-06\n",
      "Iteration 263 : x = [10.07048013  3.47105472] f(x) = 0.15953989161389756 gradient norm = 6.5983478776296885e-06\n",
      "Iteration 264 : x = [10.07105666  3.47073379] f(x) = 0.15953988726706658 gradient norm = 6.57717658357003e-06\n",
      "Iteration 265 : x = [10.07163132  3.47041385] f(x) = 0.15953988294806298 gradient norm = 6.5561404595516125e-06\n",
      "Iteration 266 : x = [10.07220411  3.4700949 ] f(x) = 0.15953987865662078 gradient norm = 6.535238226983496e-06\n",
      "Iteration 267 : x = [10.07277506  3.46977692] f(x) = 0.1595398743924772 gradient norm = 6.514468623254606e-06\n",
      "Iteration 268 : x = [10.07334417  3.46945991] f(x) = 0.15953987015537294 gradient norm = 6.493830401485799e-06\n",
      "Iteration 269 : x = [10.07391146  3.46914387] f(x) = 0.1595398659450519 gradient norm = 6.473322330286502e-06\n",
      "Iteration 270 : x = [10.07447694  3.46882878] f(x) = 0.15953986176126117 gradient norm = 6.452943193516056e-06\n",
      "Iteration 271 : x = [10.07504061  3.46851465] f(x) = 0.15953985760375106 gradient norm = 6.4326917900490325e-06\n",
      "Iteration 272 : x = [10.07560249  3.46820147] f(x) = 0.15953985347227492 gradient norm = 6.412566933545262e-06\n",
      "Iteration 273 : x = [10.0761626   3.46788923] f(x) = 0.15953984936658916 gradient norm = 6.392567452224115e-06\n",
      "Iteration 274 : x = [10.07672093  3.46757793] f(x) = 0.1595398452864533 gradient norm = 6.3726921886423636e-06\n",
      "Iteration 275 : x = [10.07727751  3.46726755] f(x) = 0.15953984123162968 gradient norm = 6.352939999476587e-06\n",
      "Iteration 276 : x = [10.07783234  3.4669581 ] f(x) = 0.15953983720188372 gradient norm = 6.333309755309429e-06\n",
      "Iteration 277 : x = [10.07838544  3.46664957] f(x) = 0.15953983319698364 gradient norm = 6.313800340419557e-06\n",
      "Iteration 278 : x = [10.07893682  3.46634196] f(x) = 0.1595398292167004 gradient norm = 6.294410652575401e-06\n",
      "Iteration 279 : x = [10.07948647  3.46603525] f(x) = 0.15953982526080795 gradient norm = 6.275139602832887e-06\n",
      "Iteration 280 : x = [10.08003443  3.46572944] f(x) = 0.15953982132908284 gradient norm = 6.255986115336381e-06\n",
      "Iteration 281 : x = [10.0805807   3.46542453] f(x) = 0.15953981742130435 gradient norm = 6.236949127123619e-06\n",
      "Iteration 282 : x = [10.08112528  3.46512052] f(x) = 0.15953981353725455 gradient norm = 6.218027587933713e-06\n",
      "Iteration 283 : x = [10.08166819  3.46481739] f(x) = 0.15953980967671794 gradient norm = 6.199220460018775e-06\n",
      "Iteration 284 : x = [10.08220943  3.46451514] f(x) = 0.1595398058394818 gradient norm = 6.180526717959002e-06\n",
      "Iteration 285 : x = [10.08274903  3.46421376] f(x) = 0.15953980202533571 gradient norm = 6.1619453484804845e-06\n",
      "Iteration 286 : x = [10.08328698  3.46391326] f(x) = 0.15953979823407208 gradient norm = 6.143475350277112e-06\n",
      "Iteration 287 : x = [10.08382331  3.46361363] f(x) = 0.15953979446548552 gradient norm = 6.12511573383464e-06\n",
      "Iteration 288 : x = [10.08435801  3.46331485] f(x) = 0.15953979071937327 gradient norm = 6.106865521258552e-06\n",
      "Iteration 289 : x = [10.08489109  3.46301693] f(x) = 0.15953978699553484 gradient norm = 6.088723746104566e-06\n",
      "Iteration 290 : x = [10.08542258  3.46271986] f(x) = 0.1595397832937722 gradient norm = 6.070689453212182e-06\n",
      "Iteration 291 : x = [10.08595247  3.46242364] f(x) = 0.1595397796138895 gradient norm = 6.052761698541189e-06\n",
      "Iteration 292 : x = [10.08648078  3.46212826] f(x) = 0.15953977595569335 gradient norm = 6.034939549010758e-06\n",
      "Iteration 293 : x = [10.08700751  3.46183371] f(x) = 0.15953977231899263 gradient norm = 6.017222082341699e-06\n",
      "Iteration 294 : x = [10.08753268  3.46154   ] f(x) = 0.15953976870359837 gradient norm = 5.999608386901027e-06\n",
      "Iteration 295 : x = [10.08805629  3.46124711] f(x) = 0.15953976510932374 gradient norm = 5.982097561549492e-06\n",
      "Iteration 296 : x = [10.08857835  3.46095504] f(x) = 0.1595397615359842 gradient norm = 5.964688715491588e-06\n",
      "Iteration 297 : x = [10.08909888  3.46066379] f(x) = 0.1595397579833973 gradient norm = 5.9473809681280735e-06\n",
      "Iteration 298 : x = [10.08961788  3.46037335] f(x) = 0.15953975445138277 gradient norm = 5.930173448911183e-06\n",
      "Iteration 299 : x = [10.09013536  3.46008372] f(x) = 0.15953975093976222 gradient norm = 5.913065297201984e-06\n",
      "Iteration 300 : x = [10.09065132  3.45979489] f(x) = 0.15953974744835944 gradient norm = 5.896055662130543e-06\n",
      "Iteration 301 : x = [10.09116579  3.45950687] f(x) = 0.1595397439770003 gradient norm = 5.879143702458079e-06\n",
      "Iteration 302 : x = [10.09167876  3.45921963] f(x) = 0.1595397405255125 gradient norm = 5.862328586441735e-06\n",
      "Iteration 303 : x = [10.09219025  3.45893319] f(x) = 0.15953973709372585 gradient norm = 5.845609491701418e-06\n",
      "Iteration 304 : x = [10.09270026  3.45864753] f(x) = 0.15953973368147195 gradient norm = 5.828985605088816e-06\n",
      "Iteration 305 : x = [10.0932088   3.45836265] f(x) = 0.15953973028858442 gradient norm = 5.812456122558996e-06\n",
      "Iteration 306 : x = [10.09371588  3.45807854] f(x) = 0.15953972691489873 gradient norm = 5.796020249043518e-06\n",
      "Iteration 307 : x = [10.09422151  3.45779521] f(x) = 0.15953972356025212 gradient norm = 5.7796771983263055e-06\n",
      "Iteration 308 : x = [10.0947257   3.45751265] f(x) = 0.15953972022448373 gradient norm = 5.763426192921028e-06\n",
      "Iteration 309 : x = [10.09522845  3.45723085] f(x) = 0.15953971690743454 gradient norm = 5.74726646395087e-06\n",
      "Iteration 310 : x = [10.09572978  3.45694981] f(x) = 0.15953971360894723 gradient norm = 5.7311972510299745e-06\n",
      "Iteration 311 : x = [10.09622968  3.45666953] f(x) = 0.15953971032886624 gradient norm = 5.715217802147307e-06\n",
      "Iteration 312 : x = [10.09672818  3.45639   ] f(x) = 0.15953970706703777 gradient norm = 5.6993273735518054e-06\n",
      "Iteration 313 : x = [10.09722527  3.45611121] f(x) = 0.1595397038233097 gradient norm = 5.6835252296398426e-06\n",
      "Iteration 314 : x = [10.09772097  3.45583317] f(x) = 0.15953970059753156 gradient norm = 5.667810642844451e-06\n",
      "Iteration 315 : x = [10.09821528  3.45555586] f(x) = 0.15953969738955462 gradient norm = 5.652182893526148e-06\n",
      "Iteration 316 : x = [10.09870821  3.45527929] f(x) = 0.1595396941992317 gradient norm = 5.636641269865783e-06\n",
      "Iteration 317 : x = [10.09919977  3.45500345] f(x) = 0.15953969102641727 gradient norm = 5.621185067758948e-06\n",
      "Iteration 318 : x = [10.09968997  3.45472834] f(x) = 0.1595396878709674 gradient norm = 5.605813590712103e-06\n",
      "Iteration 319 : x = [10.1001788   3.45445395] f(x) = 0.15953968473273966 gradient norm = 5.590526149740562e-06\n",
      "Iteration 320 : x = [10.10066629  3.45418028] f(x) = 0.15953968161159326 gradient norm = 5.575322063267751e-06\n",
      "Iteration 321 : x = [10.10115244  3.45390733] f(x) = 0.15953967850738893 gradient norm = 5.560200657026431e-06\n",
      "Iteration 322 : x = [10.10163725  3.45363509] f(x) = 0.15953967541998879 gradient norm = 5.545161263961364e-06\n",
      "Iteration 323 : x = [10.10212073  3.45336355] f(x) = 0.15953967234925656 gradient norm = 5.530203224133322e-06\n",
      "Iteration 324 : x = [10.1026029   3.45309272] f(x) = 0.15953966929505736 gradient norm = 5.515325884625034e-06\n",
      "Iteration 325 : x = [10.10308375  3.45282259] f(x) = 0.15953966625725785 gradient norm = 5.500528599448244e-06\n",
      "Iteration 326 : x = [10.10356329  3.45255315] f(x) = 0.15953966323572596 gradient norm = 5.485810729452514e-06\n",
      "Iteration 327 : x = [10.10404154  3.45228441] f(x) = 0.1595396602303312 gradient norm = 5.4711716422351114e-06\n",
      "Iteration 328 : x = [10.10451849  3.45201636] f(x) = 0.15953965724094432 gradient norm = 5.4566107120528314e-06\n",
      "Iteration 329 : x = [10.10499416  3.45174899] f(x) = 0.15953965426743755 gradient norm = 5.442127319734665e-06\n",
      "Iteration 330 : x = [10.10546855  3.45148231] f(x) = 0.1595396513096844 gradient norm = 5.427720852596158e-06\n",
      "Iteration 331 : x = [10.10594167  3.4512163 ] f(x) = 0.15953964836755977 gradient norm = 5.413390704354941e-06\n",
      "Iteration 332 : x = [10.10641352  3.45095097] f(x) = 0.15953964544093985 gradient norm = 5.39913627504777e-06\n",
      "Iteration 333 : x = [10.10688412  3.45068631] f(x) = 0.15953964252970207 gradient norm = 5.384956970948601e-06\n",
      "Iteration 334 : x = [10.10735347  3.45042231] f(x) = 0.15953963963372525 gradient norm = 5.370852204488118e-06\n",
      "Iteration 335 : x = [10.10782157  3.45015899] f(x) = 0.15953963675288943 gradient norm = 5.356821394174402e-06\n",
      "Iteration 336 : x = [10.10828843  3.44989632] f(x) = 0.1595396338870759 gradient norm = 5.342863964514863e-06\n",
      "Iteration 337 : x = [10.10875406  3.44963431] f(x) = 0.15953963103616717 gradient norm = 5.32897934593935e-06\n",
      "Iteration 338 : x = [10.10921847  3.44937296] f(x) = 0.159539628200047 gradient norm = 5.3151669747245e-06\n",
      "Iteration 339 : x = [10.10968166  3.44911225] f(x) = 0.15953962537860025 gradient norm = 5.301426292919117e-06\n",
      "Iteration 340 : x = [10.11014364  3.4488522 ] f(x) = 0.15953962257171317 gradient norm = 5.2877567482707505e-06\n",
      "Iteration 341 : x = [10.11060441  3.44859278] f(x) = 0.15953961977927297 gradient norm = 5.274157794153546e-06\n",
      "Iteration 342 : x = [10.11106398  3.44833401] f(x) = 0.15953961700116817 gradient norm = 5.26062888949681e-06\n",
      "Iteration 343 : x = [10.11152235  3.44807588] f(x) = 0.15953961423728827 gradient norm = 5.2471694987150835e-06\n",
      "Iteration 344 : x = [10.11197954  3.44781838] f(x) = 0.1595396114875241 gradient norm = 5.233779091638886e-06\n",
      "Iteration 345 : x = [10.11243555  3.44756151] f(x) = 0.15953960875176745 gradient norm = 5.220457143446879e-06\n",
      "Iteration 346 : x = [10.11289039  3.44730528] f(x) = 0.1595396060299112 gradient norm = 5.207203134598688e-06\n",
      "Iteration 347 : x = [10.11334405  3.44704966] f(x) = 0.15953960332184952 gradient norm = 5.1940165507689796e-06\n",
      "Iteration 348 : x = [10.11379655  3.44679467] f(x) = 0.15953960062747738 gradient norm = 5.180896882782436e-06\n",
      "Iteration 349 : x = [10.11424789  3.4465403 ] f(x) = 0.15953959794669095 gradient norm = 5.167843626549608e-06\n",
      "Iteration 350 : x = [10.11469809  3.44628654] f(x) = 0.1595395952793874 gradient norm = 5.15485628300395e-06\n",
      "Iteration 351 : x = [10.11514713  3.4460334 ] f(x) = 0.15953959262546502 gradient norm = 5.1419343580394905e-06\n",
      "Iteration 352 : x = [10.11559504  3.44578086] f(x) = 0.159539589984823 gradient norm = 5.129077362449711e-06\n",
      "Iteration 353 : x = [10.11604182  3.44552893] f(x) = 0.15953958735736162 gradient norm = 5.116284811867165e-06\n",
      "Iteration 354 : x = [10.11648746  3.44527761] f(x) = 0.1595395847429821 gradient norm = 5.103556226703958e-06\n",
      "Iteration 355 : x = [10.11693198  3.44502689] f(x) = 0.15953958214158667 gradient norm = 5.090891132093142e-06\n",
      "Iteration 356 : x = [10.11737539  3.44477676] f(x) = 0.15953957955307854 gradient norm = 5.078289057831094e-06\n",
      "Iteration 357 : x = [10.11781769  3.44452723] f(x) = 0.15953957697736187 gradient norm = 5.065749538320584e-06\n",
      "Iteration 358 : x = [10.11825887  3.44427829] f(x) = 0.15953957441434172 gradient norm = 5.053272112514651e-06\n",
      "Iteration 359 : x = [10.11869896  3.44402994] f(x) = 0.15953957186392415 gradient norm = 5.040856323861393e-06\n",
      "Iteration 360 : x = [10.11913796  3.44378218] f(x) = 0.15953956932601607 gradient norm = 5.028501720249572e-06\n",
      "Iteration 361 : x = [10.11957586  3.443535  ] f(x) = 0.15953956680052536 gradient norm = 5.016207853954863e-06\n",
      "Iteration 362 : x = [10.12001268  3.4432884 ] f(x) = 0.15953956428736082 gradient norm = 5.003974281587027e-06\n",
      "Iteration 363 : x = [10.12044843  3.44304238] f(x) = 0.15953956178643205 gradient norm = 4.991800564037753e-06\n",
      "Iteration 364 : x = [10.12088309  3.44279693] f(x) = 0.15953955929764962 gradient norm = 4.979686266429351e-06\n",
      "Iteration 365 : x = [10.12131669  3.44255206] f(x) = 0.1595395568209249 gradient norm = 4.967630958064095e-06\n",
      "Iteration 366 : x = [10.12174923  3.44230776] f(x) = 0.15953955435617015 gradient norm = 4.955634212374173e-06\n",
      "Iteration 367 : x = [10.12218071  3.44206402] f(x) = 0.15953955190329847 gradient norm = 4.94369560687271e-06\n",
      "Iteration 368 : x = [10.12261114  3.44182084] f(x) = 0.15953954946222382 gradient norm = 4.9318147231050694e-06\n",
      "Iteration 369 : x = [10.12304052  3.44157823] f(x) = 0.15953954703286094 gradient norm = 4.919991146601149e-06\n",
      "Iteration 370 : x = [10.12346886  3.44133618] f(x) = 0.15953954461512537 gradient norm = 4.908224466828171e-06\n",
      "Iteration 371 : x = [10.12389616  3.44109468] f(x) = 0.15953954220893363 gradient norm = 4.896514277144236e-06\n",
      "Iteration 372 : x = [10.12432243  3.44085374] f(x) = 0.1595395398142028 gradient norm = 4.884860174752616e-06\n",
      "Iteration 373 : x = [10.12474767  3.44061335] f(x) = 0.15953953743085086 gradient norm = 4.873261760656352e-06\n",
      "Iteration 374 : x = [10.12517189  3.4403735 ] f(x) = 0.15953953505879662 gradient norm = 4.861718639613971e-06\n",
      "Iteration 375 : x = [10.12559509  3.4401342 ] f(x) = 0.1595395326979595 gradient norm = 4.850230420095339e-06\n",
      "Iteration 376 : x = [10.12601728  3.43989545] f(x) = 0.1595395303482599 gradient norm = 4.838796714238508e-06\n",
      "Iteration 377 : x = [10.12643846  3.43965723] f(x) = 0.15953952800961882 gradient norm = 4.827417137806912e-06\n",
      "Iteration 378 : x = [10.12685864  3.43941956] f(x) = 0.159539525681958 gradient norm = 4.816091310147358e-06\n",
      "Iteration 379 : x = [10.12727782  3.43918242] f(x) = 0.15953952336520003 gradient norm = 4.80481885414853e-06\n",
      "Iteration 380 : x = [10.127696    3.43894581] f(x) = 0.15953952105926802 gradient norm = 4.7935993961998355e-06\n",
      "Iteration 381 : x = [10.1281132   3.43870973] f(x) = 0.15953951876408604 gradient norm = 4.782432566151278e-06\n",
      "Iteration 382 : x = [10.12852941  3.43847418] f(x) = 0.15953951647957867 gradient norm = 4.771317997273462e-06\n",
      "Iteration 383 : x = [10.12894465  3.43823916] f(x) = 0.15953951420567133 gradient norm = 4.760255326218347e-06\n",
      "Iteration 384 : x = [10.12935891  3.43800466] f(x) = 0.1595395119422901 gradient norm = 4.749244192980575e-06\n",
      "Iteration 385 : x = [10.12977219  3.43777068] f(x) = 0.15953950968936162 gradient norm = 4.738284240859198e-06\n",
      "Iteration 386 : x = [10.13018452  3.43753722] f(x) = 0.15953950744681342 gradient norm = 4.727375116419955e-06\n",
      "Iteration 387 : x = [10.13059588  3.43730428] f(x) = 0.15953950521457352 gradient norm = 4.716516469458218e-06\n",
      "Iteration 388 : x = [10.13100628  3.43707185] f(x) = 0.15953950299257064 gradient norm = 4.705707952962197e-06\n",
      "Iteration 389 : x = [10.13141574  3.43683993] f(x) = 0.15953950078073426 gradient norm = 4.694949223076836e-06\n",
      "Iteration 390 : x = [10.13182424  3.43660853] f(x) = 0.15953949857899438 gradient norm = 4.684239939068115e-06\n",
      "Iteration 391 : x = [10.1322318   3.43637763] f(x) = 0.15953949638728174 gradient norm = 4.673579763287804e-06\n",
      "Iteration 392 : x = [10.13263842  3.43614723] f(x) = 0.15953949420552757 gradient norm = 4.6629683611388355e-06\n",
      "Iteration 393 : x = [10.13304411  3.43591733] f(x) = 0.15953949203366385 gradient norm = 4.652405401040951e-06\n",
      "Iteration 394 : x = [10.13344886  3.43568794] f(x) = 0.15953948987162314 gradient norm = 4.641890554396967e-06\n",
      "Iteration 395 : x = [10.13385269  3.43545905] f(x) = 0.15953948771933862 gradient norm = 4.6314234955592895e-06\n",
      "Iteration 396 : x = [10.1342556   3.43523065] f(x) = 0.15953948557674408 gradient norm = 4.621003901797232e-06\n",
      "Iteration 397 : x = [10.13465759  3.43500274] f(x) = 0.15953948344377383 gradient norm = 4.610631453264375e-06\n",
      "Iteration 398 : x = [10.13505867  3.43477532] f(x) = 0.15953948132036289 gradient norm = 4.6003058329665465e-06\n",
      "Iteration 399 : x = [10.13545883  3.4345484 ] f(x) = 0.15953947920644676 gradient norm = 4.590026726730315e-06\n",
      "Iteration 400 : x = [10.13585809  3.43432196] f(x) = 0.15953947710196156 gradient norm = 4.5797938231717375e-06\n",
      "Iteration 401 : x = [10.13625645  3.434096  ] f(x) = 0.159539475006844 gradient norm = 4.569606813665513e-06\n",
      "Iteration 402 : x = [10.13665391  3.43387053] f(x) = 0.15953947292103135 gradient norm = 4.559465392314709e-06\n",
      "Iteration 403 : x = [10.13705048  3.43364554] f(x) = 0.1595394708444614 gradient norm = 4.5493692559208e-06\n",
      "Iteration 404 : x = [10.13744616  3.43342103] f(x) = 0.15953946877707254 gradient norm = 4.539318103953891e-06\n",
      "Iteration 405 : x = [10.13784095  3.43319699] f(x) = 0.15953946671880362 gradient norm = 4.529311638523875e-06\n",
      "Iteration 406 : x = [10.13823487  3.43297343] f(x) = 0.1595394646695941 gradient norm = 4.51934956435124e-06\n",
      "Iteration 407 : x = [10.1386279   3.43275034] f(x) = 0.15953946262938407 gradient norm = 4.5094315887388975e-06\n",
      "Iteration 408 : x = [10.13902006  3.43252772] f(x) = 0.1595394605981139 gradient norm = 4.499557421544024e-06\n",
      "Iteration 409 : x = [10.13941135  3.43230557] f(x) = 0.1595394585757247 gradient norm = 4.4897267751503354e-06\n",
      "Iteration 410 : x = [10.13980178  3.43208389] f(x) = 0.15953945656215798 gradient norm = 4.479939364440796e-06\n",
      "Iteration 411 : x = [10.14019134  3.43186267] f(x) = 0.15953945455735585 gradient norm = 4.470194906770595e-06\n",
      "Iteration 412 : x = [10.14058005  3.43164191] f(x) = 0.15953945256126087 gradient norm = 4.460493121940483e-06\n",
      "Iteration 413 : x = [10.1409679   3.43142161] f(x) = 0.15953945057381605 gradient norm = 4.450833732170483e-06\n",
      "Iteration 414 : x = [10.1413549   3.43120177] f(x) = 0.159539448594965 gradient norm = 4.441216462074082e-06\n",
      "Iteration 415 : x = [10.14174105  3.43098239] f(x) = 0.15953944662465172 gradient norm = 4.4316410386322915e-06\n",
      "Iteration 416 : x = [10.14212636  3.43076346] f(x) = 0.15953944466282077 gradient norm = 4.4221071911686425e-06\n",
      "Iteration 417 : x = [10.14251083  3.43054498] f(x) = 0.1595394427094172 gradient norm = 4.412614651324057e-06\n",
      "Iteration 418 : x = [10.14289447  3.43032695] f(x) = 0.15953944076438645 gradient norm = 4.403163153032205e-06\n",
      "Iteration 419 : x = [10.14327727  3.43010937] f(x) = 0.15953943882767446 gradient norm = 4.393752432495171e-06\n",
      "Iteration 420 : x = [10.14365925  3.42989224] f(x) = 0.15953943689922767 gradient norm = 4.384382228159493e-06\n",
      "Iteration 421 : x = [10.14404039  3.42967555] f(x) = 0.159539434978993 gradient norm = 4.375052280692199e-06\n",
      "Iteration 422 : x = [10.14442072  3.42945931] f(x) = 0.15953943306691767 gradient norm = 4.365762332957675e-06\n",
      "Iteration 423 : x = [10.14480023  3.4292435 ] f(x) = 0.15953943116294952 gradient norm = 4.356512129994295e-06\n",
      "Iteration 424 : x = [10.14517893  3.42902814] f(x) = 0.1595394292670368 gradient norm = 4.347301418991728e-06\n",
      "Iteration 425 : x = [10.14555681  3.42881321] f(x) = 0.1595394273791281 gradient norm = 4.338129949268218e-06\n",
      "Iteration 426 : x = [10.14593389  3.42859872] f(x) = 0.15953942549917255 gradient norm = 4.328997472248495e-06\n",
      "Iteration 427 : x = [10.14631016  3.42838466] f(x) = 0.15953942362711965 gradient norm = 4.319903741441605e-06\n",
      "Iteration 428 : x = [10.14668563  3.42817103] f(x) = 0.15953942176291944 gradient norm = 4.3108485124193365e-06\n",
      "Iteration 429 : x = [10.14706031  3.42795784] f(x) = 0.15953941990652218 gradient norm = 4.301831542794564e-06\n",
      "Iteration 430 : x = [10.14743419  3.42774507] f(x) = 0.15953941805787866 gradient norm = 4.292852592200281e-06\n",
      "Iteration 431 : x = [10.14780728  3.42753272] f(x) = 0.15953941621694018 gradient norm = 4.283911422268554e-06\n",
      "Iteration 432 : x = [10.14817958  3.42732081] f(x) = 0.1595394143836583 gradient norm = 4.2750077966098625e-06\n",
      "Iteration 433 : x = [10.1485511   3.42710931] f(x) = 0.15953941255798496 gradient norm = 4.266141480792718e-06\n",
      "Iteration 434 : x = [10.14892184  3.42689824] f(x) = 0.15953941073987263 gradient norm = 4.257312242323494e-06\n",
      "Iteration 435 : x = [10.1492918   3.42668758] f(x) = 0.15953940892927412 gradient norm = 4.248519850626502e-06\n",
      "Iteration 436 : x = [10.14966099  3.42647735] f(x) = 0.15953940712614267 gradient norm = 4.239764077024343e-06\n",
      "Iteration 437 : x = [10.15002941  3.42626753] f(x) = 0.15953940533043176 gradient norm = 4.231044694718458e-06\n",
      "Iteration 438 : x = [10.15039706  3.42605812] f(x) = 0.15953940354209542 gradient norm = 4.222361478769965e-06\n",
      "Iteration 439 : x = [10.15076394  3.42584913] f(x) = 0.15953940176108802 gradient norm = 4.213714206080672e-06\n",
      "Iteration 440 : x = [10.15113007  3.42564054] f(x) = 0.15953939998736424 gradient norm = 4.205102655374422e-06\n",
      "Iteration 441 : x = [10.15149543  3.42543237] f(x) = 0.1595393982208792 gradient norm = 4.196526607178493e-06\n",
      "Iteration 442 : x = [10.15186005  3.4252246 ] f(x) = 0.15953939646158832 gradient norm = 4.187985843805355e-06\n",
      "Iteration 443 : x = [10.15222391  3.42501724] f(x) = 0.15953939470944747 gradient norm = 4.17948014933476e-06\n",
      "Iteration 444 : x = [10.15258702  3.42481029] f(x) = 0.15953939296441286 gradient norm = 4.1710093095956795e-06\n",
      "Iteration 445 : x = [10.15294938  3.42460374] f(x) = 0.15953939122644098 gradient norm = 4.162573112148869e-06\n",
      "Iteration 446 : x = [10.15331101  3.42439758] f(x) = 0.15953938949548874 gradient norm = 4.154171346269301e-06\n",
      "Iteration 447 : x = [10.15367189  3.42419183] f(x) = 0.1595393877715134 gradient norm = 4.145803802929201e-06\n",
      "Iteration 448 : x = [10.15403204  3.42398648] f(x) = 0.15953938605447252 gradient norm = 4.1374702747808155e-06\n",
      "Iteration 449 : x = [10.15439145  3.42378152] f(x) = 0.15953938434432405 gradient norm = 4.129170556139729e-06\n",
      "Iteration 450 : x = [10.15475014  3.42357696] f(x) = 0.15953938264102632 gradient norm = 4.120904442968291e-06\n",
      "Iteration 451 : x = [10.15510809  3.42337278] f(x) = 0.15953938094453787 gradient norm = 4.112671732859214e-06\n",
      "Iteration 452 : x = [10.15546533  3.42316901] f(x) = 0.15953937925481765 gradient norm = 4.104472225019342e-06\n",
      "Iteration 453 : x = [10.15582184  3.42296562] f(x) = 0.15953937757182496 gradient norm = 4.096305720253716e-06\n",
      "Iteration 454 : x = [10.15617763  3.42276262] f(x) = 0.1595393758955194 gradient norm = 4.088172020949708e-06\n",
      "Iteration 455 : x = [10.15653271  3.42256   ] f(x) = 0.1595393742258608 gradient norm = 4.080070931061342e-06\n",
      "Iteration 456 : x = [10.15688707  3.42235777] f(x) = 0.15953937256280953 gradient norm = 4.072002256094046e-06\n",
      "Iteration 457 : x = [10.15724072  3.42215593] f(x) = 0.15953937090632608 gradient norm = 4.063965803089141e-06\n",
      "Iteration 458 : x = [10.15759367  3.42195447] f(x) = 0.1595393692563713 gradient norm = 4.055961380608948e-06\n",
      "Iteration 459 : x = [10.15794591  3.42175339] f(x) = 0.1595393676129064 gradient norm = 4.047988798721837e-06\n",
      "Iteration 460 : x = [10.15829745  3.42155269] f(x) = 0.15953936597589283 gradient norm = 4.040047868987394e-06\n",
      "Iteration 461 : x = [10.15864829  3.42135236] f(x) = 0.15953936434529242 gradient norm = 4.032138404442034e-06\n",
      "Iteration 462 : x = [10.15899844  3.42115242] f(x) = 0.15953936272106725 gradient norm = 4.024260219584494e-06\n",
      "Iteration 463 : x = [10.15934789  3.42095284] f(x) = 0.15953936110317968 gradient norm = 4.0164131303616434e-06\n",
      "Iteration 464 : x = [10.15969666  3.42075364] f(x) = 0.1595393594915924 gradient norm = 4.008596954154471e-06\n",
      "Iteration 465 : x = [10.16004473  3.42055482] f(x) = 0.1595393578862684 gradient norm = 4.000811509764094e-06\n",
      "Iteration 466 : x = [10.16039212  3.42035636] f(x) = 0.15953935628717092 gradient norm = 3.993056617398115e-06\n",
      "Iteration 467 : x = [10.16073883  3.42015827] f(x) = 0.15953935469426356 gradient norm = 3.9853320986570205e-06\n",
      "Iteration 468 : x = [10.16108486  3.41996056] f(x) = 0.15953935310751008 gradient norm = 3.977637776520795e-06\n",
      "Iteration 469 : x = [10.16143021  3.4197632 ] f(x) = 0.15953935152687462 gradient norm = 3.969973475335585e-06\n",
      "Iteration 470 : x = [10.16177489  3.41956622] f(x) = 0.15953934995232164 gradient norm = 3.962339020800683e-06\n",
      "Iteration 471 : x = [10.1621189   3.41936959] f(x) = 0.1595393483838157 gradient norm = 3.954734239955442e-06\n",
      "Iteration 472 : x = [10.16246223  3.41917333] f(x) = 0.15953934682132181 gradient norm = 3.947158961166628e-06\n",
      "Iteration 473 : x = [10.1628049   3.41897743] f(x) = 0.15953934526480518 gradient norm = 3.939613014115632e-06\n",
      "Iteration 474 : x = [10.16314691  3.41878189] f(x) = 0.15953934371423126 gradient norm = 3.93209622978595e-06\n",
      "Iteration 475 : x = [10.16348826  3.4185867 ] f(x) = 0.1595393421695658 gradient norm = 3.924608440450925e-06\n",
      "Iteration 476 : x = [10.16382895  3.41839188] f(x) = 0.15953934063077477 gradient norm = 3.9171494796613995e-06\n",
      "Iteration 477 : x = [10.16416898  3.4181974 ] f(x) = 0.15953933909782456 gradient norm = 3.909719182233582e-06\n",
      "Iteration 478 : x = [10.16450835  3.41800329] f(x) = 0.15953933757068156 gradient norm = 3.902317384237243e-06\n",
      "Iteration 479 : x = [10.16484708  3.41780952] f(x) = 0.1595393360493126 gradient norm = 3.894943922983722e-06\n",
      "Iteration 480 : x = [10.16518516  3.41761611] f(x) = 0.15953933453368468 gradient norm = 3.887598637014364e-06\n",
      "Iteration 481 : x = [10.16552259  3.41742305] f(x) = 0.1595393330237652 gradient norm = 3.880281366088867e-06\n",
      "Iteration 482 : x = [10.16585938  3.41723033] f(x) = 0.15953933151952154 gradient norm = 3.872991951173885e-06\n",
      "Iteration 483 : x = [10.16619553  3.41703796] f(x) = 0.15953933002092158 gradient norm = 3.865730234431712e-06\n",
      "Iteration 484 : x = [10.16653104  3.41684594] f(x) = 0.15953932852793323 gradient norm = 3.8584960592091695e-06\n",
      "Iteration 485 : x = [10.16686591  3.41665427] f(x) = 0.1595393270405249 gradient norm = 3.851289270026428e-06\n",
      "Iteration 486 : x = [10.16720015  3.41646293] f(x) = 0.15953932555866496 gradient norm = 3.844109712566191e-06\n",
      "Iteration 487 : x = [10.16753376  3.41627194] f(x) = 0.1595393240823222 gradient norm = 3.8369572336628685e-06\n",
      "Iteration 488 : x = [10.16786674  3.41608129] f(x) = 0.15953932261146558 gradient norm = 3.8298316812918225e-06\n",
      "Iteration 489 : x = [10.16819909  3.41589098] f(x) = 0.15953932114606428 gradient norm = 3.822732904558864e-06\n",
      "Iteration 490 : x = [10.16853082  3.41570101] f(x) = 0.15953931968608775 gradient norm = 3.8156607536898e-06\n",
      "Iteration 491 : x = [10.16886193  3.41551138] f(x) = 0.1595393182315057 gradient norm = 3.808615080020036e-06\n",
      "Iteration 492 : x = [10.16919241  3.41532208] f(x) = 0.15953931678228792 gradient norm = 3.8015957359844438e-06\n",
      "Iteration 493 : x = [10.16952228  3.41513311] f(x) = 0.1595393153384046 gradient norm = 3.794602575107153e-06\n",
      "Iteration 494 : x = [10.16985154  3.41494448] f(x) = 0.15953931389982598 gradient norm = 3.7876354519916646e-06\n",
      "Iteration 495 : x = [10.17018018  3.41475619] f(x) = 0.15953931246652275 gradient norm = 3.7806942223108315e-06\n",
      "Iteration 496 : x = [10.17050821  3.41456822] f(x) = 0.15953931103846553 gradient norm = 3.773778742797203e-06\n",
      "Iteration 497 : x = [10.17083564  3.41438058] f(x) = 0.15953930961562537 gradient norm = 3.7668888712332266e-06\n",
      "Iteration 498 : x = [10.17116246  3.41419328] f(x) = 0.1595393081979735 gradient norm = 3.7600244664418154e-06\n",
      "Iteration 499 : x = [10.17148867  3.4140063 ] f(x) = 0.15953930678548123 gradient norm = 3.7531853882768017e-06\n",
      "Iteration 500 : x = [10.17181428  3.41381964] f(x) = 0.15953930537812025 gradient norm = 3.746371497613548e-06\n",
      "Iteration 501 : x = [10.1721393   3.41363331] f(x) = 0.15953930397586244 gradient norm = 3.7395826563397834e-06\n",
      "Iteration 502 : x = [10.17246372  3.41344731] f(x) = 0.15953930257867965 gradient norm = 3.7328187273463386e-06\n",
      "Iteration 503 : x = [10.17278754  3.41326163] f(x) = 0.15953930118654427 gradient norm = 3.726079574518137e-06\n",
      "Iteration 504 : x = [10.17311077  3.41307626] f(x) = 0.1595392997994287 gradient norm = 3.7193650627252936e-06\n",
      "Iteration 505 : x = [10.17343341  3.41289122] f(x) = 0.15953929841730558 gradient norm = 3.712675057814098e-06\n",
      "Iteration 506 : x = [10.17375546  3.4127065 ] f(x) = 0.15953929704014772 gradient norm = 3.706009426598406e-06\n",
      "Iteration 507 : x = [10.17407693  3.4125221 ] f(x) = 0.15953929566792818 gradient norm = 3.6993680368508067e-06\n",
      "Iteration 508 : x = [10.17439781  3.41233801] f(x) = 0.15953929430062014 gradient norm = 3.692750757294194e-06\n",
      "Iteration 509 : x = [10.17471811  3.41215424] f(x) = 0.1595392929381971 gradient norm = 3.686157457593174e-06\n",
      "Iteration 510 : x = [10.17503783  3.41197079] f(x) = 0.15953929158063257 gradient norm = 3.679588008345681e-06\n",
      "Iteration 511 : x = [10.17535698  3.41178765] f(x) = 0.15953929022790042 gradient norm = 3.6730422810746657e-06\n",
      "Iteration 512 : x = [10.17567555  3.41160482] f(x) = 0.15953928887997462 gradient norm = 3.666520148219927e-06\n",
      "Iteration 513 : x = [10.17599354  3.4114223 ] f(x) = 0.15953928753682933 gradient norm = 3.6600214831298855e-06\n",
      "Iteration 514 : x = [10.17631097  3.41124009] f(x) = 0.15953928619843902 gradient norm = 3.6535461600535744e-06\n",
      "Iteration 515 : x = [10.17662782  3.4110582 ] f(x) = 0.15953928486477803 gradient norm = 3.6470940541327394e-06\n",
      "Iteration 516 : x = [10.17694411  3.41087661] f(x) = 0.15953928353582128 gradient norm = 3.6406650413937978e-06\n",
      "Iteration 517 : x = [10.17725983  3.41069532] f(x) = 0.15953928221154354 gradient norm = 3.634258998740243e-06\n",
      "Iteration 518 : x = [10.17757499  3.41051435] f(x) = 0.15953928089191993 gradient norm = 3.6278758039447687e-06\n",
      "Iteration 519 : x = [10.17788959  3.41033367] f(x) = 0.15953927957692576 gradient norm = 3.621515335641699e-06\n",
      "Iteration 520 : x = [10.17820363  3.41015331] f(x) = 0.1595392782665364 gradient norm = 3.615177473319445e-06\n",
      "Iteration 521 : x = [10.17851711  3.40997324] f(x) = 0.15953927696072745 gradient norm = 3.608862097313025e-06\n",
      "Iteration 522 : x = [10.17883004  3.40979348] f(x) = 0.1595392756594748 gradient norm = 3.6025690887966486e-06\n",
      "Iteration 523 : x = [10.17914242  3.40961401] f(x) = 0.15953927436275428 gradient norm = 3.5962983297764064e-06\n",
      "Iteration 524 : x = [10.17945424  3.40943485] f(x) = 0.15953927307054205 gradient norm = 3.590049703083005e-06\n",
      "Iteration 525 : x = [10.17976552  3.40925599] f(x) = 0.15953927178281435 gradient norm = 3.5838230923646416e-06\n",
      "Iteration 526 : x = [10.18007624  3.40907742] f(x) = 0.15953927049954772 gradient norm = 3.577618382079898e-06\n",
      "Iteration 527 : x = [10.18038643  3.40889915] f(x) = 0.15953926922071873 gradient norm = 3.5714354574907205e-06\n",
      "Iteration 528 : x = [10.18069606  3.40872117] f(x) = 0.15953926794630416 gradient norm = 3.565274204655427e-06\n",
      "Iteration 529 : x = [10.18100516  3.40854349] f(x) = 0.15953926667628096 gradient norm = 3.559134510421931e-06\n",
      "Iteration 530 : x = [10.18131372  3.40836611] f(x) = 0.1595392654106262 gradient norm = 3.5530162624208327e-06\n",
      "Iteration 531 : x = [10.18162174  3.40818901] f(x) = 0.1595392641493172 gradient norm = 3.5469193490587537e-06\n",
      "Iteration 532 : x = [10.18192923  3.40801221] f(x) = 0.15953926289233133 gradient norm = 3.5408436595116195e-06\n",
      "Iteration 533 : x = [10.18223618  3.40783569] f(x) = 0.15953926163964618 gradient norm = 3.5347890837181246e-06\n",
      "Iteration 534 : x = [10.1825426   3.40765947] f(x) = 0.15953926039123953 gradient norm = 3.528755512373129e-06\n",
      "Iteration 535 : x = [10.18284849  3.40748354] f(x) = 0.15953925914708914 gradient norm = 3.5227428369213094e-06\n",
      "Iteration 536 : x = [10.18315385  3.40730789] f(x) = 0.1595392579071731 gradient norm = 3.5167509495505924e-06\n",
      "Iteration 537 : x = [10.18345868  3.40713253] f(x) = 0.15953925667146965 gradient norm = 3.510779743186063e-06\n",
      "Iteration 538 : x = [10.18376299  3.40695745] f(x) = 0.15953925543995706 gradient norm = 3.504829111483389e-06\n",
      "Iteration 539 : x = [10.18406678  3.40678266] f(x) = 0.15953925421261386 gradient norm = 3.4988989488229273e-06\n",
      "Iteration 540 : x = [10.18437004  3.40660815] f(x) = 0.15953925298941868 gradient norm = 3.4929891503033632e-06\n",
      "Iteration 541 : x = [10.18467279  3.40643393] f(x) = 0.15953925177035028 gradient norm = 3.487099611735745e-06\n",
      "Iteration 542 : x = [10.18497502  3.40625999] f(x) = 0.15953925055538754 gradient norm = 3.4812302296374576e-06\n",
      "Iteration 543 : x = [10.18527673  3.40608632] f(x) = 0.1595392493445096 gradient norm = 3.47538090122616e-06\n",
      "Iteration 544 : x = [10.18557793  3.40591294] f(x) = 0.15953924813769563 gradient norm = 3.469551524414086e-06\n",
      "Iteration 545 : x = [10.18587862  3.40573984] f(x) = 0.15953924693492497 gradient norm = 3.463741997802005e-06\n",
      "Iteration 546 : x = [10.1861788   3.40556701] f(x) = 0.1595392457361771 gradient norm = 3.4579522206735954e-06\n",
      "Iteration 547 : x = [10.18647847  3.40539446] f(x) = 0.15953924454143167 gradient norm = 3.4521820929896424e-06\n",
      "Iteration 548 : x = [10.18677763  3.40522219] f(x) = 0.15953924335066844 gradient norm = 3.4464315153823873e-06\n",
      "Iteration 549 : x = [10.18707628  3.4050502 ] f(x) = 0.15953924216386728 gradient norm = 3.440700389149959e-06\n",
      "Iteration 550 : x = [10.18737444  3.40487847] f(x) = 0.15953924098100827 gradient norm = 3.4349886162508204e-06\n",
      "Iteration 551 : x = [10.18767209  3.40470702] f(x) = 0.15953923980207158 gradient norm = 3.429296099298178e-06\n",
      "Iteration 552 : x = [10.18796924  3.40453585] f(x) = 0.15953923862703745 gradient norm = 3.4236227415546765e-06\n",
      "Iteration 553 : x = [10.18826589  3.40436494] f(x) = 0.15953923745588636 gradient norm = 3.4179684469269126e-06\n",
      "Iteration 554 : x = [10.18856205  3.4041943 ] f(x) = 0.1595392362885989 gradient norm = 3.412333119960203e-06\n",
      "Iteration 555 : x = [10.18885771  3.40402394] f(x) = 0.15953923512515567 gradient norm = 3.406716665833167e-06\n",
      "Iteration 556 : x = [10.18915288  3.40385384] f(x) = 0.1595392339655376 gradient norm = 3.401118990352641e-06\n",
      "Iteration 557 : x = [10.18944756  3.40368401] f(x) = 0.15953923280972557 gradient norm = 3.3955399999483977e-06\n",
      "Iteration 558 : x = [10.18974174  3.40351445] f(x) = 0.15953923165770065 gradient norm = 3.3899796016680627e-06\n",
      "Iteration 559 : x = [10.19003544  3.40334516] f(x) = 0.1595392305094441 gradient norm = 3.3844377031720458e-06\n",
      "Iteration 560 : x = [10.19032865  3.40317613] f(x) = 0.15953922936493722 gradient norm = 3.378914212728538e-06\n",
      "Iteration 561 : x = [10.19062138  3.40300736] f(x) = 0.15953922822416142 gradient norm = 3.37340903920843e-06\n",
      "Iteration 562 : x = [10.19091362  3.40283886] f(x) = 0.15953922708709833 gradient norm = 3.3679220920805385e-06\n",
      "Iteration 563 : x = [10.19120538  3.40267062] f(x) = 0.1595392259537296 gradient norm = 3.3624532814066197e-06\n",
      "Iteration 564 : x = [10.19149666  3.40250264] f(x) = 0.159539224824037 gradient norm = 3.3570025178365623e-06\n",
      "Iteration 565 : x = [10.19178747  3.40233493] f(x) = 0.15953922369800258 gradient norm = 3.351569712603604e-06\n",
      "Iteration 566 : x = [10.19207779  3.40216747] f(x) = 0.1595392225756083 gradient norm = 3.3461547775196293e-06\n",
      "Iteration 567 : x = [10.19236764  3.40200027] f(x) = 0.15953922145683636 gradient norm = 3.3407576249703854e-06\n",
      "Iteration 568 : x = [10.19265702  3.40183334] f(x) = 0.15953922034166904 gradient norm = 3.3353781679109775e-06\n",
      "Iteration 569 : x = [10.19294592  3.40166666] f(x) = 0.15953921923008874 gradient norm = 3.3300163198611364e-06\n",
      "Iteration 570 : x = [10.19323435  3.40150023] f(x) = 0.15953921812207797 gradient norm = 3.324671994900737e-06\n",
      "Iteration 571 : x = [10.19352232  3.40133406] f(x) = 0.1595392170176193 gradient norm = 3.3193451076652236e-06\n",
      "Iteration 572 : x = [10.19380981  3.40116815] f(x) = 0.15953921591669556 gradient norm = 3.3140355733412413e-06\n",
      "Iteration 573 : x = [10.19409684  3.40100249] f(x) = 0.15953921481928957 gradient norm = 3.3087433076620776e-06\n",
      "Iteration 574 : x = [10.19438341  3.40083709] f(x) = 0.1595392137253843 gradient norm = 3.303468226903422e-06\n",
      "Iteration 575 : x = [10.19466951  3.40067194] f(x) = 0.15953921263496276 gradient norm = 3.2982102478788797e-06\n",
      "Iteration 576 : x = [10.19495515  3.40050704] f(x) = 0.15953921154800818 gradient norm = 3.2929692879357933e-06\n",
      "Iteration 577 : x = [10.19524033  3.40034239] f(x) = 0.1595392104645039 gradient norm = 3.287745264950907e-06\n",
      "Iteration 578 : x = [10.19552505  3.40017799] f(x) = 0.15953920938443322 gradient norm = 3.2825380973261356e-06\n",
      "Iteration 579 : x = [10.19580931  3.40001384] f(x) = 0.1595392083077797 gradient norm = 3.277347703984534e-06\n",
      "Iteration 580 : x = [10.19609312  3.39984994] f(x) = 0.15953920723452691 gradient norm = 3.272174004365945e-06\n",
      "Iteration 581 : x = [10.19637647  3.39968629] f(x) = 0.15953920616465866 gradient norm = 3.267016918423007e-06\n",
      "Iteration 582 : x = [10.19665937  3.39952289] f(x) = 0.1595392050981586 gradient norm = 3.2618763666171686e-06\n",
      "Iteration 583 : x = [10.19694182  3.39935973] f(x) = 0.15953920403501082 gradient norm = 3.256752269914515e-06\n",
      "Iteration 584 : x = [10.19722382  3.39919682] f(x) = 0.15953920297519925 gradient norm = 3.2516445497818246e-06\n",
      "Iteration 585 : x = [10.19750537  3.39903415] f(x) = 0.15953920191870802 gradient norm = 3.24655312818277e-06\n",
      "Iteration 586 : x = [10.19778648  3.39887172] f(x) = 0.15953920086552134 gradient norm = 3.2414779275738185e-06\n",
      "Iteration 587 : x = [10.19806714  3.39870954] f(x) = 0.1595391998156236 gradient norm = 3.236418870900416e-06\n",
      "Iteration 588 : x = [10.19834735  3.39854761] f(x) = 0.15953919876899916 gradient norm = 3.231375881593191e-06\n",
      "Iteration 589 : x = [10.19862712  3.39838591] f(x) = 0.1595391977256326 gradient norm = 3.2263488835641467e-06\n",
      "Iteration 590 : x = [10.19890645  3.39822446] f(x) = 0.15953919668550845 gradient norm = 3.2213378012028743e-06\n",
      "Iteration 591 : x = [10.19918534  3.39806324] f(x) = 0.15953919564861155 gradient norm = 3.216342559372795e-06\n",
      "Iteration 592 : x = [10.1994638   3.39790227] f(x) = 0.15953919461492658 gradient norm = 3.2113630834075337e-06\n",
      "Iteration 593 : x = [10.19974181  3.39774153] f(x) = 0.15953919358443855 gradient norm = 3.2063992991072217e-06\n",
      "Iteration 594 : x = [10.20001939  3.39758103] f(x) = 0.1595391925571324 gradient norm = 3.2014511327348828e-06\n",
      "Iteration 595 : x = [10.20029654  3.39742077] f(x) = 0.15953919153299326 gradient norm = 3.1965185110128204e-06\n",
      "Iteration 596 : x = [10.20057325  3.39726075] f(x) = 0.1595391905120063 gradient norm = 3.191601361119042e-06\n",
      "Iteration 597 : x = [10.20084953  3.39710096] f(x) = 0.1595391894941568 gradient norm = 3.1866996106838423e-06\n",
      "Iteration 598 : x = [10.20112538  3.39694141] f(x) = 0.15953918847943016 gradient norm = 3.181813187786108e-06\n",
      "Iteration 599 : x = [10.2014008   3.39678209] f(x) = 0.1595391874678118 gradient norm = 3.1769420209500813e-06\n",
      "Iteration 600 : x = [10.20167579  3.396623  ] f(x) = 0.15953918645928727 gradient norm = 3.172086039141787e-06\n",
      "Iteration 601 : x = [10.20195036  3.39646415] f(x) = 0.1595391854538423 gradient norm = 3.1672451717656725e-06\n",
      "Iteration 602 : x = [10.20222451  3.39630553] f(x) = 0.15953918445146253 gradient norm = 3.1624193486612404e-06\n",
      "Iteration 603 : x = [10.20249822  3.39614714] f(x) = 0.1595391834521338 gradient norm = 3.1576085000997394e-06\n",
      "Iteration 604 : x = [10.20277152  3.39598899] f(x) = 0.15953918245584206 gradient norm = 3.152812556780795e-06\n",
      "Iteration 605 : x = [10.2030444   3.39583106] f(x) = 0.15953918146257326 gradient norm = 3.148031449829184e-06\n",
      "Iteration 606 : x = [10.20331685  3.39567336] f(x) = 0.15953918047231347 gradient norm = 3.143265110791619e-06\n",
      "Iteration 607 : x = [10.20358889  3.39551589] f(x) = 0.1595391794850489 gradient norm = 3.138513471633443e-06\n",
      "Iteration 608 : x = [10.20386051  3.39535865] f(x) = 0.15953917850076577 gradient norm = 3.1337764647355297e-06\n",
      "Iteration 609 : x = [10.20413172  3.39520164] f(x) = 0.15953917751945043 gradient norm = 3.1290540228910733e-06\n",
      "Iteration 610 : x = [10.20440251  3.39504485] f(x) = 0.1595391765410893 gradient norm = 3.1243460793024584e-06\n",
      "Iteration 611 : x = [10.20467289  3.39488829] f(x) = 0.15953917556566885 gradient norm = 3.11965256757826e-06\n",
      "Iteration 612 : x = [10.20494285  3.39473196] f(x) = 0.15953917459317568 gradient norm = 3.1149734217299957e-06\n",
      "Iteration 613 : x = [10.20521241  3.39457585] f(x) = 0.15953917362359646 gradient norm = 3.110308576169214e-06\n",
      "Iteration 614 : x = [10.20548155  3.39441996] f(x) = 0.15953917265691794 gradient norm = 3.105657965704457e-06\n",
      "Iteration 615 : x = [10.20575029  3.3942643 ] f(x) = 0.15953917169312695 gradient norm = 3.1010215255382095e-06\n",
      "Iteration 616 : x = [10.20601862  3.39410886] f(x) = 0.15953917073221038 gradient norm = 3.096399191264059e-06\n",
      "Iteration 617 : x = [10.20628655  3.39395364] f(x) = 0.15953916977415522 gradient norm = 3.0917908988635814e-06\n",
      "Iteration 618 : x = [10.20655407  3.39379864] f(x) = 0.15953916881894853 gradient norm = 3.087196584703615e-06\n",
      "Iteration 619 : x = [10.20682119  3.39364386] f(x) = 0.1595391678665775 gradient norm = 3.082616185533258e-06\n",
      "Iteration 620 : x = [10.2070879   3.39348931] f(x) = 0.15953916691702927 gradient norm = 3.078049638481063e-06\n",
      "Iteration 621 : x = [10.20735422  3.39333497] f(x) = 0.15953916597029116 gradient norm = 3.0734968810521547e-06\n",
      "Iteration 622 : x = [10.20762014  3.39318085] f(x) = 0.1595391650263506 gradient norm = 3.0689578511255043e-06\n",
      "Iteration 623 : x = [10.20788565  3.39302695] f(x) = 0.15953916408519495 gradient norm = 3.064432486951056e-06\n",
      "Iteration 624 : x = [10.20815077  3.39287327] f(x) = 0.15953916314681177 gradient norm = 3.0599207271470543e-06\n",
      "Iteration 625 : x = [10.2084155  3.3927198] f(x) = 0.15953916221118866 gradient norm = 3.0554225106972484e-06\n",
      "Iteration 626 : x = [10.20867983  3.39256655] f(x) = 0.1595391612783133 gradient norm = 3.0509377769481993e-06\n",
      "Iteration 627 : x = [10.20894376  3.39241351] f(x) = 0.15953916034817345 gradient norm = 3.046466465606607e-06\n",
      "Iteration 628 : x = [10.20920731  3.39226069] f(x) = 0.15953915942075686 gradient norm = 3.0420085167366584e-06\n",
      "Iteration 629 : x = [10.20947046  3.39210809] f(x) = 0.15953915849605146 gradient norm = 3.0375638707573812e-06\n",
      "Iteration 630 : x = [10.20973323  3.3919557 ] f(x) = 0.15953915757404524 gradient norm = 3.033132468440001e-06\n",
      "Iteration 631 : x = [10.2099956   3.39180352] f(x) = 0.1595391566547262 gradient norm = 3.028714250905398e-06\n",
      "Iteration 632 : x = [10.21025759  3.39165155] f(x) = 0.15953915573808247 gradient norm = 3.024309159621481e-06\n",
      "Iteration 633 : x = [10.21051919  3.39149979] f(x) = 0.15953915482410222 gradient norm = 3.019917136400743e-06\n",
      "Iteration 634 : x = [10.2107804   3.39134825] f(x) = 0.15953915391277362 gradient norm = 3.0155381233976033e-06\n",
      "Iteration 635 : x = [10.21104123  3.39119691] f(x) = 0.15953915300408508 gradient norm = 3.0111720631060316e-06\n",
      "Iteration 636 : x = [10.21130168  3.39104579] f(x) = 0.1595391520980249 gradient norm = 3.00681889835696e-06\n",
      "Iteration 637 : x = [10.21156175  3.39089488] f(x) = 0.15953915119458165 gradient norm = 3.002478572315894e-06\n",
      "Iteration 638 : x = [10.21182143  3.39074417] f(x) = 0.15953915029374371 gradient norm = 2.9981510284804987e-06\n",
      "Iteration 639 : x = [10.21208074  3.39059367] f(x) = 0.15953914939549974 gradient norm = 2.9938362106781006e-06\n",
      "Iteration 640 : x = [10.21233966  3.39044338] f(x) = 0.15953914849983836 gradient norm = 2.9895340630633313e-06\n",
      "Iteration 641 : x = [10.21259821  3.3902933 ] f(x) = 0.15953914760674828 gradient norm = 2.9852445301158184e-06\n",
      "Iteration 642 : x = [10.21285639  3.39014342] f(x) = 0.15953914671621838 gradient norm = 2.9809675566377213e-06\n",
      "Iteration 643 : x = [10.21311419  3.38999375] f(x) = 0.15953914582823742 gradient norm = 2.976703087751482e-06\n",
      "Iteration 644 : x = [10.21337161  3.38984428] f(x) = 0.15953914494279425 gradient norm = 2.972451068897463e-06\n",
      "Iteration 645 : x = [10.21362866  3.38969502] f(x) = 0.15953914405987799 gradient norm = 2.968211445831669e-06\n",
      "Iteration 646 : x = [10.21388534  3.38954596] f(x) = 0.15953914317947762 gradient norm = 2.9639841646235273e-06\n",
      "Iteration 647 : x = [10.21414165  3.3893971 ] f(x) = 0.1595391423015822 gradient norm = 2.9597691716535474e-06\n",
      "Iteration 648 : x = [10.21439759  3.38924845] f(x) = 0.15953914142618095 gradient norm = 2.9555664136111425e-06\n",
      "Iteration 649 : x = [10.21465316  3.3891    ] f(x) = 0.15953914055326313 gradient norm = 2.9513758374924075e-06\n",
      "Iteration 650 : x = [10.21490836  3.38895175] f(x) = 0.15953913968281794 gradient norm = 2.9471973905978977e-06\n",
      "Iteration 651 : x = [10.2151632  3.3888037] f(x) = 0.15953913881483478 gradient norm = 2.9430310205304835e-06\n",
      "Iteration 652 : x = [10.21541767  3.38865585] f(x) = 0.15953913794930308 gradient norm = 2.9388766751932164e-06\n",
      "Iteration 653 : x = [10.21567177  3.38850821] f(x) = 0.15953913708621234 gradient norm = 2.934734302787112e-06\n",
      "Iteration 654 : x = [10.21592552  3.38836076] f(x) = 0.15953913622555202 gradient norm = 2.9306038518090495e-06\n",
      "Iteration 655 : x = [10.2161789   3.38821351] f(x) = 0.1595391353673118 gradient norm = 2.926485271049768e-06\n",
      "Iteration 656 : x = [10.21643192  3.38806646] f(x) = 0.15953913451148125 gradient norm = 2.9223785095916322e-06\n",
      "Iteration 657 : x = [10.21668458  3.3879196 ] f(x) = 0.15953913365805014 gradient norm = 2.918283516806681e-06\n",
      "Iteration 658 : x = [10.21693688  3.38777295] f(x) = 0.15953913280700818 gradient norm = 2.9142002423545187e-06\n",
      "Iteration 659 : x = [10.21718882  3.38762649] f(x) = 0.15953913195834532 gradient norm = 2.910128636180256e-06\n",
      "Iteration 660 : x = [10.21744041  3.38748022] f(x) = 0.15953913111205137 gradient norm = 2.9060686485125797e-06\n",
      "Iteration 661 : x = [10.21769163  3.38733415] f(x) = 0.15953913026811622 gradient norm = 2.9020202298617323e-06\n",
      "Iteration 662 : x = [10.21794251  3.38718828] f(x) = 0.15953912942652998 gradient norm = 2.897983331017435e-06\n",
      "Iteration 663 : x = [10.21819303  3.3870426 ] f(x) = 0.15953912858728267 gradient norm = 2.893957903047054e-06\n",
      "Iteration 664 : x = [10.2184432   3.38689711] f(x) = 0.1595391277503644 gradient norm = 2.8899438972935824e-06\n",
      "Iteration 665 : x = [10.21869301  3.38675182] f(x) = 0.15953912691576533 gradient norm = 2.8859412653736617e-06\n",
      "Iteration 666 : x = [10.21894247  3.38660672] f(x) = 0.15953912608347573 gradient norm = 2.881949959175798e-06\n",
      "Iteration 667 : x = [10.21919159  3.38646181] f(x) = 0.15953912525348585 gradient norm = 2.8779699308583516e-06\n",
      "Iteration 668 : x = [10.21944035  3.38631709] f(x) = 0.15953912442578594 gradient norm = 2.8740011328476684e-06\n",
      "Iteration 669 : x = [10.21968877  3.38617256] f(x) = 0.15953912360036657 gradient norm = 2.870043517836263e-06\n",
      "Iteration 670 : x = [10.21993684  3.38602823] f(x) = 0.15953912277721805 gradient norm = 2.866097038780903e-06\n",
      "Iteration 671 : x = [10.22018457  3.38588408] f(x) = 0.15953912195633094 gradient norm = 2.8621616489008493e-06\n",
      "Iteration 672 : x = [10.22043194  3.38574013] f(x) = 0.15953912113769572 gradient norm = 2.8582373016759337e-06\n",
      "Iteration 673 : x = [10.22067898  3.38559636] f(x) = 0.15953912032130313 gradient norm = 2.8543239508448186e-06\n",
      "Iteration 674 : x = [10.22092567  3.38545278] f(x) = 0.15953911950714364 gradient norm = 2.8504215504032244e-06\n",
      "Iteration 675 : x = [10.22117202  3.38530939] f(x) = 0.15953911869520807 gradient norm = 2.8465300546020763e-06\n",
      "Iteration 676 : x = [10.22141803  3.38516619] f(x) = 0.1595391178854872 gradient norm = 2.842649417945786e-06\n",
      "Iteration 677 : x = [10.2216637   3.38502317] f(x) = 0.1595391170779718 gradient norm = 2.8387795951905447e-06\n",
      "Iteration 678 : x = [10.22190903  3.38488034] f(x) = 0.15953911627265271 gradient norm = 2.834920541342482e-06\n",
      "Iteration 679 : x = [10.22215402  3.3847377 ] f(x) = 0.15953911546952085 gradient norm = 2.8310722116560816e-06\n",
      "Iteration 680 : x = [10.22239867  3.38459524] f(x) = 0.15953911466856724 gradient norm = 2.827234561632365e-06\n",
      "Iteration 681 : x = [10.22264299  3.38445296] f(x) = 0.15953911386978284 gradient norm = 2.8234075470172294e-06\n",
      "Iteration 682 : x = [10.22288697  3.38431087] f(x) = 0.1595391130731587 gradient norm = 2.8195911237998216e-06\n",
      "Iteration 683 : x = [10.22313061  3.38416897] f(x) = 0.15953911227868597 gradient norm = 2.8157852482108075e-06\n",
      "Iteration 684 : x = [10.22337393  3.38402725] f(x) = 0.15953911148635583 gradient norm = 2.8119898767207493e-06\n",
      "Iteration 685 : x = [10.22361691  3.38388571] f(x) = 0.1595391106961594 gradient norm = 2.8082049660384935e-06\n",
      "Iteration 686 : x = [10.22385956  3.38374435] f(x) = 0.15953910990808795 gradient norm = 2.8044304731095253e-06\n",
      "Iteration 687 : x = [10.22410187  3.38360317] f(x) = 0.15953910912213284 gradient norm = 2.800666355114285e-06\n",
      "Iteration 688 : x = [10.22434386  3.38346218] f(x) = 0.15953910833828544 gradient norm = 2.7969125694667766e-06\n",
      "Iteration 689 : x = [10.22458552  3.38332137] f(x) = 0.15953910755653708 gradient norm = 2.7931690738127147e-06\n",
      "Iteration 690 : x = [10.22482685  3.38318073] f(x) = 0.15953910677687924 gradient norm = 2.7894358260281707e-06\n",
      "Iteration 691 : x = [10.22506785  3.38304028] f(x) = 0.1595391059993034 gradient norm = 2.7857127842179103e-06\n",
      "Iteration 692 : x = [10.22530853  3.38290001] f(x) = 0.1595391052238011 gradient norm = 2.7819999067138837e-06\n",
      "Iteration 693 : x = [10.22554888  3.38275991] f(x) = 0.1595391044503639 gradient norm = 2.778297152073683e-06\n",
      "Iteration 694 : x = [10.22578891  3.38261999] f(x) = 0.1595391036789835 gradient norm = 2.7746044790789785e-06\n",
      "Iteration 695 : x = [10.22602861  3.38248026] f(x) = 0.1595391029096515 gradient norm = 2.7709218467341093e-06\n",
      "Iteration 696 : x = [10.22626799  3.3823407 ] f(x) = 0.15953910214235967 gradient norm = 2.767249214264489e-06\n",
      "Iteration 697 : x = [10.22650705  3.38220131] f(x) = 0.15953910137709976 gradient norm = 2.7635865411151824e-06\n",
      "Iteration 698 : x = [10.22674579  3.3820621 ] f(x) = 0.1595391006138635 gradient norm = 2.7599337869493566e-06\n",
      "Iteration 699 : x = [10.2269842   3.38192307] f(x) = 0.1595390998526429 gradient norm = 2.7562909116469527e-06\n",
      "Iteration 700 : x = [10.2272223   3.38178422] f(x) = 0.15953909909342975 gradient norm = 2.7526578753031117e-06\n",
      "Iteration 701 : x = [10.22746008  3.38164554] f(x) = 0.159539098336216 gradient norm = 2.749034638226822e-06\n",
      "Iteration 702 : x = [10.22769754  3.38150703] f(x) = 0.15953909758099363 gradient norm = 2.7454211609393944e-06\n",
      "Iteration 703 : x = [10.22793469  3.3813687 ] f(x) = 0.15953909682775472 gradient norm = 2.7418174041731786e-06\n",
      "Iteration 704 : x = [10.22817152  3.38123054] f(x) = 0.15953909607649128 gradient norm = 2.738223328870039e-06\n",
      "Iteration 705 : x = [10.22840803  3.38109256] f(x) = 0.15953909532719546 gradient norm = 2.7346388961800395e-06\n",
      "Iteration 706 : x = [10.22864423  3.38095475] f(x) = 0.15953909457985935 gradient norm = 2.7310640674600196e-06\n",
      "Iteration 707 : x = [10.22888012  3.38081711] f(x) = 0.15953909383447523 gradient norm = 2.7274988042722707e-06\n",
      "Iteration 708 : x = [10.22911569  3.38067964] f(x) = 0.15953909309103526 gradient norm = 2.723943068383135e-06\n",
      "Iteration 709 : x = [10.22935095  3.38054234] f(x) = 0.15953909234953179 gradient norm = 2.720396821761643e-06\n",
      "Iteration 710 : x = [10.2295859   3.38040522] f(x) = 0.15953909160995705 gradient norm = 2.7168600265782637e-06\n",
      "Iteration 711 : x = [10.22982055  3.38026826] f(x) = 0.15953909087230353 gradient norm = 2.7133326452034595e-06\n",
      "Iteration 712 : x = [10.23005488  3.38013148] f(x) = 0.15953909013656353 gradient norm = 2.7098146402064364e-06\n",
      "Iteration 713 : x = [10.2302889   3.37999486] f(x) = 0.15953908940272948 gradient norm = 2.7063059743538604e-06\n",
      "Iteration 714 : x = [10.23052262  3.37985842] f(x) = 0.1595390886707939 gradient norm = 2.7028066106084994e-06\n",
      "Iteration 715 : x = [10.23075603  3.37972214] f(x) = 0.1595390879407493 gradient norm = 2.6993165121279718e-06\n",
      "Iteration 716 : x = [10.23098913  3.37958603] f(x) = 0.15953908721258825 gradient norm = 2.695835642263478e-06\n",
      "Iteration 717 : x = [10.23122193  3.37945009] f(x) = 0.15953908648630333 gradient norm = 2.6923639645584937e-06\n",
      "Iteration 718 : x = [10.23145443  3.37931432] f(x) = 0.15953908576188716 gradient norm = 2.688901442747602e-06\n",
      "Iteration 719 : x = [10.23168662  3.37917871] f(x) = 0.15953908503933245 gradient norm = 2.68544804075511e-06\n",
      "Iteration 720 : x = [10.23191851  3.37904327] f(x) = 0.15953908431863192 gradient norm = 2.6820037226939373e-06\n",
      "Iteration 721 : x = [10.2321501  3.378908 ] f(x) = 0.15953908359977828 gradient norm = 2.678568452864325e-06\n",
      "Iteration 722 : x = [10.23238138  3.37877289] f(x) = 0.1595390828827644 gradient norm = 2.6751421957526636e-06\n",
      "Iteration 723 : x = [10.23261237  3.37863795] f(x) = 0.159539082167583 gradient norm = 2.67172491603021e-06\n",
      "Iteration 724 : x = [10.23284306  3.37850318] f(x) = 0.159539081454227 gradient norm = 2.6683165785519797e-06\n",
      "Iteration 725 : x = [10.23307344  3.37836856] f(x) = 0.1595390807426893 gradient norm = 2.6649171483554765e-06\n",
      "Iteration 726 : x = [10.23330353  3.37823411] f(x) = 0.15953908003296285 gradient norm = 2.661526590659565e-06\n",
      "Iteration 727 : x = [10.23353333  3.37809983] f(x) = 0.1595390793250406 gradient norm = 2.6581448708632904e-06\n",
      "Iteration 728 : x = [10.23376282  3.37796571] f(x) = 0.15953907861891556 gradient norm = 2.6547719545447088e-06\n",
      "Iteration 729 : x = [10.23399202  3.37783175] f(x) = 0.1595390779145808 gradient norm = 2.6514078074597582e-06\n",
      "Iteration 730 : x = [10.23422093  3.37769795] f(x) = 0.1595390772120294 gradient norm = 2.648052395541019e-06\n",
      "Iteration 731 : x = [10.23444954  3.37756432] f(x) = 0.15953907651125443 gradient norm = 2.644705684896735e-06\n",
      "Iteration 732 : x = [10.23467786  3.37743084] f(x) = 0.15953907581224913 gradient norm = 2.641367641809584e-06\n",
      "Iteration 733 : x = [10.23490589  3.37729753] f(x) = 0.15953907511500665 gradient norm = 2.6380382327355547e-06\n",
      "Iteration 734 : x = [10.23513362  3.37716438] f(x) = 0.1595390744195202 gradient norm = 2.634717424302852e-06\n",
      "Iteration 735 : x = [10.23536107  3.37703139] f(x) = 0.15953907372578305 gradient norm = 2.6314051833108507e-06\n",
      "Iteration 736 : x = [10.23558822  3.37689856] f(x) = 0.15953907303378848 gradient norm = 2.6281014767289647e-06\n",
      "Iteration 737 : x = [10.23581508  3.37676589] f(x) = 0.15953907234352985 gradient norm = 2.624806271695482e-06\n",
      "Iteration 738 : x = [10.23604166  3.37663337] f(x) = 0.15953907165500048 gradient norm = 2.6215195355166766e-06\n",
      "Iteration 739 : x = [10.23626795  3.37650102] f(x) = 0.1595390709681938 gradient norm = 2.618241235665538e-06\n",
      "Iteration 740 : x = [10.23649395  3.37636882] f(x) = 0.15953907028310327 gradient norm = 2.6149713397808223e-06\n",
      "Iteration 741 : x = [10.23671966  3.37623679] f(x) = 0.1595390695997223 gradient norm = 2.611709815666019e-06\n",
      "Iteration 742 : x = [10.23694509  3.37610491] f(x) = 0.15953906891804437 gradient norm = 2.6084566312882614e-06\n",
      "Iteration 743 : x = [10.23717023  3.37597318] f(x) = 0.15953906823806308 gradient norm = 2.6052117547772583e-06\n",
      "Iteration 744 : x = [10.23739509  3.37584162] f(x) = 0.15953906755977193 gradient norm = 2.601975154424342e-06\n",
      "Iteration 745 : x = [10.23761967  3.37571021] f(x) = 0.15953906688316458 gradient norm = 2.5987467986813943e-06\n",
      "Iteration 746 : x = [10.23784396  3.37557895] f(x) = 0.1595390662082346 gradient norm = 2.595526656159889e-06\n",
      "Iteration 747 : x = [10.23806797  3.37544785] f(x) = 0.15953906553497565 gradient norm = 2.5923146956298382e-06\n",
      "Iteration 748 : x = [10.2382917   3.37531691] f(x) = 0.15953906486338146 gradient norm = 2.589110886018785e-06\n",
      "Iteration 749 : x = [10.23851515  3.37518612] f(x) = 0.1595390641934457 gradient norm = 2.585915196410868e-06\n",
      "Iteration 750 : x = [10.23873832  3.37505549] f(x) = 0.15953906352516223 gradient norm = 2.5827275960457953e-06\n",
      "Iteration 751 : x = [10.23896121  3.37492501] f(x) = 0.1595390628585247 gradient norm = 2.579548054317888e-06\n",
      "Iteration 752 : x = [10.23918382  3.37479468] f(x) = 0.15953906219352706 gradient norm = 2.5763765407751207e-06\n",
      "Iteration 753 : x = [10.23940615  3.37466451] f(x) = 0.15953906153016306 gradient norm = 2.5732130251181394e-06\n",
      "Iteration 754 : x = [10.23962821  3.37453449] f(x) = 0.15953906086842662 gradient norm = 2.5700574771993034e-06\n",
      "Iteration 755 : x = [10.23984999  3.37440462] f(x) = 0.15953906020831163 gradient norm = 2.566909867021786e-06\n",
      "Iteration 756 : x = [10.24007149  3.3742749 ] f(x) = 0.15953905954981207 gradient norm = 2.563770164738576e-06\n",
      "Iteration 757 : x = [10.24029272  3.37414534] f(x) = 0.1595390588929219 gradient norm = 2.5606383406516096e-06\n",
      "Iteration 758 : x = [10.24051367  3.37401592] f(x) = 0.15953905823763503 gradient norm = 2.5575143652107723e-06\n",
      "Iteration 759 : x = [10.24073436  3.37388666] f(x) = 0.15953905758394563 gradient norm = 2.554398209013057e-06\n",
      "Iteration 760 : x = [10.24095476  3.37375755] f(x) = 0.1595390569318477 gradient norm = 2.551289842801598e-06\n",
      "Iteration 761 : x = [10.2411749   3.37362859] f(x) = 0.15953905628133533 gradient norm = 2.5481892374647706e-06\n",
      "Iteration 762 : x = [10.24139476  3.37349978] f(x) = 0.15953905563240262 gradient norm = 2.5450963640353085e-06\n",
      "Iteration 763 : x = [10.24161436  3.37337112] f(x) = 0.15953905498504378 gradient norm = 2.542011193689425e-06\n",
      "Iteration 764 : x = [10.24183368  3.3732426 ] f(x) = 0.15953905433925292 gradient norm = 2.5389336977459147e-06\n",
      "Iteration 765 : x = [10.24205273  3.37311424] f(x) = 0.1595390536950243 gradient norm = 2.535863847665283e-06\n",
      "Iteration 766 : x = [10.24227152  3.37298602] f(x) = 0.15953905305235208 gradient norm = 2.5328016150488087e-06\n",
      "Iteration 767 : x = [10.24249003  3.37285795] f(x) = 0.1595390524112306 gradient norm = 2.529746971637808e-06\n",
      "Iteration 768 : x = [10.24270828  3.37273003] f(x) = 0.15953905177165412 gradient norm = 2.5266998893126862e-06\n",
      "Iteration 769 : x = [10.24292627  3.37260226] f(x) = 0.15953905113361694 gradient norm = 2.5236603400920625e-06\n",
      "Iteration 770 : x = [10.24314398  3.37247464] f(x) = 0.1595390504971135 gradient norm = 2.5206282961320124e-06\n",
      "Iteration 771 : x = [10.24336143  3.37234716] f(x) = 0.15953904986213804 gradient norm = 2.5176037297251734e-06\n",
      "Iteration 772 : x = [10.24357862  3.37221982] f(x) = 0.1595390492286851 gradient norm = 2.5145866132998705e-06\n",
      "Iteration 773 : x = [10.24379554  3.37209264] f(x) = 0.15953904859674897 gradient norm = 2.511576919419389e-06\n",
      "Iteration 774 : x = [10.2440122   3.37196559] f(x) = 0.15953904796632423 gradient norm = 2.5085746207810786e-06\n",
      "Iteration 775 : x = [10.24422859  3.3718387 ] f(x) = 0.1595390473374053 gradient norm = 2.505579690215546e-06\n",
      "Iteration 776 : x = [10.24444472  3.37171195] f(x) = 0.1595390467099867 gradient norm = 2.5025921006858884e-06\n",
      "Iteration 777 : x = [10.24466059  3.37158534] f(x) = 0.15953904608406297 gradient norm = 2.4996118252868182e-06\n",
      "Iteration 778 : x = [10.2448762   3.37145887] f(x) = 0.1595390454596287 gradient norm = 2.4966388372439244e-06\n",
      "Iteration 779 : x = [10.24509155  3.37133255] f(x) = 0.15953904483667844 gradient norm = 2.4936731099128844e-06\n",
      "Iteration 780 : x = [10.24530664  3.37120638] f(x) = 0.15953904421520684 gradient norm = 2.490714616778611e-06\n",
      "Iteration 781 : x = [10.24552147  3.37108035] f(x) = 0.15953904359520849 gradient norm = 2.487763331454544e-06\n",
      "Iteration 782 : x = [10.24573605  3.37095446] f(x) = 0.15953904297667815 gradient norm = 2.484819227681812e-06\n",
      "Iteration 783 : x = [10.24595036  3.37082871] f(x) = 0.15953904235961047 gradient norm = 2.4818822793285494e-06\n",
      "Iteration 784 : x = [10.24616442  3.3707031 ] f(x) = 0.1595390417440002 gradient norm = 2.478952460389002e-06\n",
      "Iteration 785 : x = [10.24637822  3.37057764] f(x) = 0.159539041129842 gradient norm = 2.476029744982919e-06\n",
      "Iteration 786 : x = [10.24659176  3.37045232] f(x) = 0.15953904051713066 gradient norm = 2.4731141073547087e-06\n",
      "Iteration 787 : x = [10.24680505  3.37032713] f(x) = 0.15953903990586107 gradient norm = 2.4702055218726376e-06\n",
      "Iteration 788 : x = [10.24701809  3.37020209] f(x) = 0.15953903929602797 gradient norm = 2.467303963028265e-06\n",
      "Iteration 789 : x = [10.24723087  3.37007719] f(x) = 0.15953903868762628 gradient norm = 2.464409405435534e-06\n",
      "Iteration 790 : x = [10.2474434   3.36995243] f(x) = 0.15953903808065076 gradient norm = 2.461521823830117e-06\n",
      "Iteration 791 : x = [10.24765567  3.36982781] f(x) = 0.15953903747509643 gradient norm = 2.4586411930686663e-06\n",
      "Iteration 792 : x = [10.2478677   3.36970333] f(x) = 0.1595390368709581 gradient norm = 2.455767488128138e-06\n",
      "Iteration 793 : x = [10.24807947  3.36957899] f(x) = 0.15953903626823082 gradient norm = 2.4529006841049866e-06\n",
      "Iteration 794 : x = [10.24829099  3.36945478] f(x) = 0.15953903566690944 gradient norm = 2.4500407562145775e-06\n",
      "Iteration 795 : x = [10.24850226  3.36933072] f(x) = 0.15953903506698905 gradient norm = 2.4471876797903477e-06\n",
      "Iteration 796 : x = [10.24871327  3.36920679] f(x) = 0.15953903446846462 gradient norm = 2.4443414302832154e-06\n",
      "Iteration 797 : x = [10.24892405  3.369083  ] f(x) = 0.15953903387133125 gradient norm = 2.441501983260778e-06\n",
      "Iteration 798 : x = [10.24913457  3.36895935] f(x) = 0.1595390332755839 gradient norm = 2.4386693144067472e-06\n",
      "Iteration 799 : x = [10.24934484  3.36883583] f(x) = 0.15953903268121777 gradient norm = 2.435843399520133e-06\n",
      "Iteration 800 : x = [10.24955487  3.36871245] f(x) = 0.15953903208822787 gradient norm = 2.4330242145146994e-06\n",
      "Iteration 801 : x = [10.24976465  3.36858921] f(x) = 0.1595390314966094 gradient norm = 2.430211735418145e-06\n",
      "Iteration 802 : x = [10.24997418  3.36846611] f(x) = 0.15953903090635752 gradient norm = 2.4274059383715184e-06\n",
      "Iteration 803 : x = [10.25018347  3.36834314] f(x) = 0.15953903031746733 gradient norm = 2.4246067996285377e-06\n",
      "Iteration 804 : x = [10.25039251  3.3682203 ] f(x) = 0.1595390297299341 gradient norm = 2.4218142955549537e-06\n",
      "Iteration 805 : x = [10.25060131  3.3680976 ] f(x) = 0.1595390291437531 gradient norm = 2.419028402627806e-06\n",
      "Iteration 806 : x = [10.25080986  3.36797504] f(x) = 0.15953902855891947 gradient norm = 2.4162490974348413e-06\n",
      "Iteration 807 : x = [10.25101818  3.36785261] f(x) = 0.15953902797542857 gradient norm = 2.4134763566738724e-06\n",
      "Iteration 808 : x = [10.25122624  3.36773031] f(x) = 0.15953902739327563 gradient norm = 2.41071015715208e-06\n",
      "Iteration 809 : x = [10.25143407  3.36760815] f(x) = 0.159539026812456 gradient norm = 2.4079504757854165e-06\n",
      "Iteration 810 : x = [10.25164165  3.36748612] f(x) = 0.15953902623296498 gradient norm = 2.4051972895979736e-06\n",
      "Iteration 811 : x = [10.251849    3.36736423] f(x) = 0.15953902565479797 gradient norm = 2.4024505757213085e-06\n",
      "Iteration 812 : x = [10.2520561   3.36724247] f(x) = 0.1595390250779503 gradient norm = 2.3997103113938562e-06\n",
      "Iteration 813 : x = [10.25226296  3.36712084] f(x) = 0.15953902450241744 gradient norm = 2.396976473960295e-06\n",
      "Iteration 814 : x = [10.25246959  3.36699934] f(x) = 0.15953902392819475 gradient norm = 2.3942490408709124e-06\n",
      "Iteration 815 : x = [10.25267597  3.36687798] f(x) = 0.15953902335527775 gradient norm = 2.3915279896810794e-06\n",
      "Iteration 816 : x = [10.25288212  3.36675674] f(x) = 0.1595390227836618 gradient norm = 2.3888132980504837e-06\n",
      "Iteration 817 : x = [10.25308803  3.36663564] f(x) = 0.15953902221334246 gradient norm = 2.3861049437426816e-06\n",
      "Iteration 818 : x = [10.2532937   3.36651467] f(x) = 0.15953902164431522 gradient norm = 2.3834029046243597e-06\n",
      "Iteration 819 : x = [10.25349914  3.36639383] f(x) = 0.15953902107657558 gradient norm = 2.380707158664878e-06\n",
      "Iteration 820 : x = [10.25370434  3.36627312] f(x) = 0.15953902051011912 gradient norm = 2.3780176839355888e-06\n",
      "Iteration 821 : x = [10.2539093   3.36615254] f(x) = 0.1595390199449414 gradient norm = 2.375334458609242e-06\n",
      "Iteration 822 : x = [10.25411403  3.3660321 ] f(x) = 0.15953901938103804 gradient norm = 2.3726574609594364e-06\n",
      "Iteration 823 : x = [10.25431853  3.36591178] f(x) = 0.1595390188184046 gradient norm = 2.3699866693600216e-06\n",
      "Iteration 824 : x = [10.25452279  3.36579159] f(x) = 0.15953901825703676 gradient norm = 2.3673220622845658e-06\n",
      "Iteration 825 : x = [10.25472682  3.36567153] f(x) = 0.1595390176969301 gradient norm = 2.3646636183057217e-06\n",
      "Iteration 826 : x = [10.25493061  3.36555159] f(x) = 0.15953901713808036 gradient norm = 2.362011316094719e-06\n",
      "Iteration 827 : x = [10.25513418  3.36543179] f(x) = 0.15953901658048317 gradient norm = 2.359365134420701e-06\n",
      "Iteration 828 : x = [10.25533751  3.36531212] f(x) = 0.1595390160241343 gradient norm = 2.3567250521502603e-06\n",
      "Iteration 829 : x = [10.25554061  3.36519257] f(x) = 0.15953901546902946 gradient norm = 2.354091048246859e-06\n",
      "Iteration 830 : x = [10.25574348  3.36507315] f(x) = 0.1595390149151644 gradient norm = 2.3514631017702775e-06\n",
      "Iteration 831 : x = [10.25594612  3.36495386] f(x) = 0.15953901436253484 gradient norm = 2.3488411918760268e-06\n",
      "Iteration 832 : x = [10.25614853  3.36483469] f(x) = 0.1595390138111366 gradient norm = 2.346225297814868e-06\n",
      "Iteration 833 : x = [10.25635071  3.36471565] f(x) = 0.15953901326096553 gradient norm = 2.3436153989321865e-06\n",
      "Iteration 834 : x = [10.25655267  3.36459674] f(x) = 0.1595390127120174 gradient norm = 2.34101147466756e-06\n",
      "Iteration 835 : x = [10.25675439  3.36447796] f(x) = 0.1595390121642881 gradient norm = 2.3384135045541e-06\n",
      "Iteration 836 : x = [10.25695589  3.3643593 ] f(x) = 0.15953901161777345 gradient norm = 2.3358214682180264e-06\n",
      "Iteration 837 : x = [10.25715716  3.36424076] f(x) = 0.15953901107246934 gradient norm = 2.333235345378134e-06\n",
      "Iteration 838 : x = [10.25735821  3.36412235] f(x) = 0.1595390105283717 gradient norm = 2.3306551158451613e-06\n",
      "Iteration 839 : x = [10.25755903  3.36400407] f(x) = 0.15953900998547643 gradient norm = 2.328080759521415e-06\n",
      "Iteration 840 : x = [10.25775962  3.36388591] f(x) = 0.15953900944377947 gradient norm = 2.3255122564001324e-06\n",
      "Iteration 841 : x = [10.25795999  3.36376788] f(x) = 0.1595390089032768 gradient norm = 2.322949586565082e-06\n",
      "Iteration 842 : x = [10.25816014  3.36364996] f(x) = 0.1595390083639643 gradient norm = 2.3203927301899107e-06\n",
      "Iteration 843 : x = [10.25836006  3.36353218] f(x) = 0.1595390078258381 gradient norm = 2.3178416675378114e-06\n",
      "Iteration 844 : x = [10.25855976  3.36341452] f(x) = 0.1595390072888941 gradient norm = 2.3152963789608592e-06\n",
      "Iteration 845 : x = [10.25875923  3.36329698] f(x) = 0.15953900675312846 gradient norm = 2.312756844899609e-06\n",
      "Iteration 846 : x = [10.25895849  3.36317956] f(x) = 0.1595390062185371 gradient norm = 2.310223045882565e-06\n",
      "Iteration 847 : x = [10.25915752  3.36306227] f(x) = 0.15953900568511611 gradient norm = 2.3076949625257183e-06\n",
      "Iteration 848 : x = [10.25935633  3.3629451 ] f(x) = 0.15953900515286162 gradient norm = 2.3051725755320033e-06\n",
      "Iteration 849 : x = [10.25955492  3.36282805] f(x) = 0.15953900462176968 gradient norm = 2.302655865690876e-06\n",
      "Iteration 850 : x = [10.25975329  3.36271112] f(x) = 0.1595390040918364 gradient norm = 2.3001448138777587e-06\n",
      "Iteration 851 : x = [10.25995144  3.36259431] f(x) = 0.15953900356305803 gradient norm = 2.297639401053646e-06\n",
      "Iteration 852 : x = [10.26014937  3.36247763] f(x) = 0.1595390030354306 gradient norm = 2.2951396082645546e-06\n",
      "Iteration 853 : x = [10.26034708  3.36236107] f(x) = 0.15953900250895026 gradient norm = 2.2926454166410755e-06\n",
      "Iteration 854 : x = [10.26054457  3.36224463] f(x) = 0.15953900198361332 gradient norm = 2.290156807397936e-06\n",
      "Iteration 855 : x = [10.26074185  3.36212831] f(x) = 0.15953900145941588 gradient norm = 2.2876737618334607e-06\n",
      "Iteration 856 : x = [10.26093891  3.36201211] f(x) = 0.1595390009363542 gradient norm = 2.2851962613292096e-06\n",
      "Iteration 857 : x = [10.26113575  3.36189603] f(x) = 0.15953900041442448 gradient norm = 2.282724287349401e-06\n",
      "Iteration 858 : x = [10.26133237  3.36178007] f(x) = 0.15953899989362302 gradient norm = 2.280257821440554e-06\n",
      "Iteration 859 : x = [10.26152878  3.36166423] f(x) = 0.1595389993739461 gradient norm = 2.2777968452309638e-06\n",
      "Iteration 860 : x = [10.26172498  3.36154851] f(x) = 0.15953899885539 gradient norm = 2.2753413404302903e-06\n",
      "Iteration 861 : x = [10.26192096  3.3614329 ] f(x) = 0.15953899833795096 gradient norm = 2.2728912888290784e-06\n",
      "Iteration 862 : x = [10.26211672  3.36131742] f(x) = 0.1595389978216253 gradient norm = 2.2704466722983794e-06\n",
      "Iteration 863 : x = [10.26231227  3.36120206] f(x) = 0.1595389973064095 gradient norm = 2.2680074727892176e-06\n",
      "Iteration 864 : x = [10.26250761  3.36108681] f(x) = 0.15953899679229971 gradient norm = 2.2655736723322133e-06\n",
      "Iteration 865 : x = [10.26270274  3.36097168] f(x) = 0.15953899627929244 gradient norm = 2.2631452530371057e-06\n",
      "Iteration 866 : x = [10.26289765  3.36085667] f(x) = 0.1595389957673841 gradient norm = 2.260722197092352e-06\n",
      "Iteration 867 : x = [10.26309235  3.36074178] f(x) = 0.15953899525657092 gradient norm = 2.2583044867646975e-06\n",
      "Iteration 868 : x = [10.26328684  3.360627  ] f(x) = 0.15953899474684943 gradient norm = 2.2558921043986734e-06\n",
      "Iteration 869 : x = [10.26348112  3.36051234] f(x) = 0.1595389942382161 gradient norm = 2.25348503241633e-06\n",
      "Iteration 870 : x = [10.26367518  3.3603978 ] f(x) = 0.15953899373066727 gradient norm = 2.251083253316639e-06\n",
      "Iteration 871 : x = [10.26386904  3.36028338] f(x) = 0.15953899322419948 gradient norm = 2.248686749675135e-06\n",
      "Iteration 872 : x = [10.26406269  3.36016907] f(x) = 0.15953899271880917 gradient norm = 2.2462955041435875e-06\n",
      "Iteration 873 : x = [10.26425613  3.36005487] f(x) = 0.15953899221449286 gradient norm = 2.2439094994494527e-06\n",
      "Iteration 874 : x = [10.26444936  3.3599408 ] f(x) = 0.15953899171124705 gradient norm = 2.2415287183955515e-06\n",
      "Iteration 875 : x = [10.26464238  3.35982684] f(x) = 0.15953899120906823 gradient norm = 2.239153143859591e-06\n",
      "Iteration 876 : x = [10.26483519  3.35971299] f(x) = 0.159538990707953 gradient norm = 2.2367827587938247e-06\n",
      "Iteration 877 : x = [10.2650278   3.35959926] f(x) = 0.15953899020789783 gradient norm = 2.2344175462246256e-06\n",
      "Iteration 878 : x = [10.2652202   3.35948564] f(x) = 0.1595389897088994 gradient norm = 2.232057489252061e-06\n",
      "Iteration 879 : x = [10.26541239  3.35937214] f(x) = 0.1595389892109542 gradient norm = 2.229702571049513e-06\n",
      "Iteration 880 : x = [10.26560438  3.35925875] f(x) = 0.15953898871405886 gradient norm = 2.227352774863286e-06\n",
      "Iteration 881 : x = [10.26579616  3.35914548] f(x) = 0.15953898821820997 gradient norm = 2.225008084012205e-06\n",
      "Iteration 882 : x = [10.26598773  3.35903232] f(x) = 0.15953898772340422 gradient norm = 2.2226684818872486e-06\n",
      "Iteration 883 : x = [10.2661791   3.35891927] f(x) = 0.1595389872296382 gradient norm = 2.2203339519511174e-06\n",
      "Iteration 884 : x = [10.26637027  3.35880634] f(x) = 0.15953898673690856 gradient norm = 2.2180044777378616e-06\n",
      "Iteration 885 : x = [10.26656124  3.35869352] f(x) = 0.159538986245212 gradient norm = 2.215680042852522e-06\n",
      "Iteration 886 : x = [10.266752    3.35858081] f(x) = 0.1595389857545452 gradient norm = 2.213360630970754e-06\n",
      "Iteration 887 : x = [10.26694255  3.35846822] f(x) = 0.15953898526490487 gradient norm = 2.2110462258383957e-06\n",
      "Iteration 888 : x = [10.26713291  3.35835574] f(x) = 0.15953898477628767 gradient norm = 2.2087368112711284e-06\n",
      "Iteration 889 : x = [10.26732306  3.35824337] f(x) = 0.15953898428869037 gradient norm = 2.2064323711540973e-06\n",
      "Iteration 890 : x = [10.26751301  3.35813111] f(x) = 0.15953898380210974 gradient norm = 2.2041328894415942e-06\n",
      "Iteration 891 : x = [10.26770276  3.35801896] f(x) = 0.15953898331654245 gradient norm = 2.2018383501565497e-06\n",
      "Iteration 892 : x = [10.26789231  3.35790693] f(x) = 0.15953898283198542 gradient norm = 2.199548737390313e-06\n",
      "Iteration 893 : x = [10.26808166  3.357795  ] f(x) = 0.15953898234843522 gradient norm = 2.197264035302209e-06\n",
      "Iteration 894 : x = [10.26827081  3.35768319] f(x) = 0.15953898186588883 gradient norm = 2.194984228119211e-06\n",
      "Iteration 895 : x = [10.26845976  3.35757149] f(x) = 0.15953898138434294 gradient norm = 2.1927093001355325e-06\n",
      "Iteration 896 : x = [10.26864851  3.35745989] f(x) = 0.15953898090379445 gradient norm = 2.19043923571232e-06\n",
      "Iteration 897 : x = [10.26883707  3.35734841] f(x) = 0.1595389804242402 gradient norm = 2.188174019277306e-06\n",
      "Iteration 898 : x = [10.26902542  3.35723704] f(x) = 0.15953897994567698 gradient norm = 2.1859136353244057e-06\n",
      "Iteration 899 : x = [10.26921358  3.35712578] f(x) = 0.15953897946810172 gradient norm = 2.1836580684133685e-06\n",
      "Iteration 900 : x = [10.26940154  3.35701463] f(x) = 0.15953897899151126 gradient norm = 2.181407303169494e-06\n",
      "Iteration 901 : x = [10.2695893   3.35690358] f(x) = 0.15953897851590249 gradient norm = 2.1791613242832225e-06\n",
      "Iteration 902 : x = [10.26977687  3.35679265] f(x) = 0.15953897804127232 gradient norm = 2.1769201165098177e-06\n",
      "Iteration 903 : x = [10.26996424  3.35668183] f(x) = 0.1595389775676177 gradient norm = 2.1746836646690084e-06\n",
      "Iteration 904 : x = [10.27015141  3.35657111] f(x) = 0.15953897709493547 gradient norm = 2.1724519536447158e-06\n",
      "Iteration 905 : x = [10.27033839  3.3564605 ] f(x) = 0.15953897662322267 gradient norm = 2.1702249683845804e-06\n",
      "Iteration 906 : x = [10.27052518  3.35635   ] f(x) = 0.15953897615247623 gradient norm = 2.1680026938997486e-06\n",
      "Iteration 907 : x = [10.27071177  3.35623961] f(x) = 0.1595389756826931 gradient norm = 2.165785115264493e-06\n",
      "Iteration 908 : x = [10.27089816  3.35612933] f(x) = 0.15953897521387025 gradient norm = 2.1635722176159e-06\n",
      "Iteration 909 : x = [10.27108437  3.35601915] f(x) = 0.1595389747460047 gradient norm = 2.1613639861534843e-06\n",
      "Iteration 910 : x = [10.27127038  3.35590908] f(x) = 0.15953897427909344 gradient norm = 2.1591604061389542e-06\n",
      "Iteration 911 : x = [10.27145619  3.35579912] f(x) = 0.15953897381313353 gradient norm = 2.1569614628958195e-06\n",
      "Iteration 912 : x = [10.27164182  3.35568926] f(x) = 0.15953897334812192 gradient norm = 2.154767141809073e-06\n",
      "Iteration 913 : x = [10.27182725  3.35557951] f(x) = 0.15953897288405575 gradient norm = 2.1525774283248983e-06\n",
      "Iteration 914 : x = [10.27201249  3.35546987] f(x) = 0.159538972420932 gradient norm = 2.1503923079503294e-06\n",
      "Iteration 915 : x = [10.27219754  3.35536033] f(x) = 0.15953897195874783 gradient norm = 2.1482117662529255e-06\n",
      "Iteration 916 : x = [10.2723824  3.3552509] f(x) = 0.1595389714975002 gradient norm = 2.1460357888604907e-06\n",
      "Iteration 917 : x = [10.27256707  3.35514158] f(x) = 0.15953897103718628 gradient norm = 2.143864361460726e-06\n",
      "Iteration 918 : x = [10.27275155  3.35503236] f(x) = 0.15953897057780317 gradient norm = 2.1416974698009427e-06\n",
      "Iteration 919 : x = [10.27293584  3.35492325] f(x) = 0.1595389701193479 gradient norm = 2.1395350996877323e-06\n",
      "Iteration 920 : x = [10.27311994  3.35481424] f(x) = 0.1595389696618178 gradient norm = 2.1373772369866766e-06\n",
      "Iteration 921 : x = [10.27330386  3.35470533] f(x) = 0.1595389692052098 gradient norm = 2.135223867622041e-06\n",
      "Iteration 922 : x = [10.27348758  3.35459654] f(x) = 0.15953896874952114 gradient norm = 2.133074977576436e-06\n",
      "Iteration 923 : x = [10.27367112  3.35448784] f(x) = 0.15953896829474903 gradient norm = 2.13093055289062e-06\n",
      "Iteration 924 : x = [10.27385446  3.35437925] f(x) = 0.15953896784089058 gradient norm = 2.128790579663037e-06\n",
      "Iteration 925 : x = [10.27403763  3.35427076] f(x) = 0.159538967387943 gradient norm = 2.1266550440496394e-06\n",
      "Iteration 926 : x = [10.2742206   3.35416238] f(x) = 0.15953896693590347 gradient norm = 2.124523932263586e-06\n",
      "Iteration 927 : x = [10.27440339  3.3540541 ] f(x) = 0.1595389664847692 gradient norm = 2.1223972305748754e-06\n",
      "Iteration 928 : x = [10.27458599  3.35394593] f(x) = 0.1595389660345375 gradient norm = 2.1202749253101215e-06\n",
      "Iteration 929 : x = [10.27476841  3.35383785] f(x) = 0.15953896558520547 gradient norm = 2.1181570028522655e-06\n",
      "Iteration 930 : x = [10.27495064  3.35372989] f(x) = 0.15953896513677046 gradient norm = 2.116043449640219e-06\n",
      "Iteration 931 : x = [10.27513269  3.35362202] f(x) = 0.15953896468922968 gradient norm = 2.1139342521686594e-06\n",
      "Iteration 932 : x = [10.27531455  3.35351425] f(x) = 0.15953896424258038 gradient norm = 2.1118293969876626e-06\n",
      "Iteration 933 : x = [10.27549623  3.35340659] f(x) = 0.15953896379681987 gradient norm = 2.1097288707025107e-06\n",
      "Iteration 934 : x = [10.27567772  3.35329903] f(x) = 0.15953896335194542 gradient norm = 2.107632659973325e-06\n",
      "Iteration 935 : x = [10.27585904  3.35319157] f(x) = 0.1595389629079544 gradient norm = 2.1055407515148513e-06\n",
      "Iteration 936 : x = [10.27604017  3.35308422] f(x) = 0.15953896246484403 gradient norm = 2.1034531320961337e-06\n",
      "Iteration 937 : x = [10.27622111  3.35297696] f(x) = 0.15953896202261164 gradient norm = 2.101369788540259e-06\n",
      "Iteration 938 : x = [10.27640188  3.35286981] f(x) = 0.15953896158125466 gradient norm = 2.0992907077240952e-06\n",
      "Iteration 939 : x = [10.27658246  3.35276276] f(x) = 0.15953896114077032 gradient norm = 2.097215876577985e-06\n",
      "Iteration 940 : x = [10.27676286  3.35265581] f(x) = 0.15953896070115606 gradient norm = 2.095145282085482e-06\n",
      "Iteration 941 : x = [10.27694308  3.35254896] f(x) = 0.15953896026240916 gradient norm = 2.0930789112831624e-06\n",
      "Iteration 942 : x = [10.27712312  3.35244221] f(x) = 0.15953895982452707 gradient norm = 2.0910167512602096e-06\n",
      "Iteration 943 : x = [10.27730298  3.35233556] f(x) = 0.1595389593875072 gradient norm = 2.0889587891582267e-06\n",
      "Iteration 944 : x = [10.27748266  3.35222901] f(x) = 0.15953895895134687 gradient norm = 2.0869050121710196e-06\n",
      "Iteration 945 : x = [10.27766216  3.35212256] f(x) = 0.15953895851604352 gradient norm = 2.0848554075442316e-06\n",
      "Iteration 946 : x = [10.27784148  3.35201621] f(x) = 0.1595389580815946 gradient norm = 2.0828099625751728e-06\n",
      "Iteration 947 : x = [10.27802062  3.35190996] f(x) = 0.15953895764799744 gradient norm = 2.080768664612498e-06\n",
      "Iteration 948 : x = [10.27819958  3.3518038 ] f(x) = 0.15953895721524958 gradient norm = 2.07873150105597e-06\n",
      "Iteration 949 : x = [10.27837837  3.35169775] f(x) = 0.15953895678334848 gradient norm = 2.07669845935619e-06\n",
      "Iteration 950 : x = [10.27855698  3.3515918 ] f(x) = 0.1595389563522915 gradient norm = 2.074669527014381e-06\n",
      "Iteration 951 : x = [10.27873541  3.35148594] f(x) = 0.15953895592207626 gradient norm = 2.072644691582092e-06\n",
      "Iteration 952 : x = [10.27891366  3.35138019] f(x) = 0.1595389554927001 gradient norm = 2.070623940660949e-06\n",
      "Iteration 953 : x = [10.27909174  3.35127453] f(x) = 0.15953895506416058 gradient norm = 2.0686072619024314e-06\n",
      "Iteration 954 : x = [10.27926964  3.35116897] f(x) = 0.1595389546364552 gradient norm = 2.066594643007602e-06\n",
      "Iteration 955 : x = [10.27944736  3.35106351] f(x) = 0.15953895420958142 gradient norm = 2.0645860717268823e-06\n",
      "Iteration 956 : x = [10.27962491  3.35095814] f(x) = 0.15953895378353677 gradient norm = 2.0625815358597287e-06\n",
      "Iteration 957 : x = [10.27980228  3.35085288] f(x) = 0.15953895335831889 gradient norm = 2.0605810232545106e-06\n",
      "Iteration 958 : x = [10.27997948  3.35074771] f(x) = 0.15953895293392523 gradient norm = 2.0585845218081513e-06\n",
      "Iteration 959 : x = [10.28015651  3.35064264] f(x) = 0.15953895251035335 gradient norm = 2.0565920194659743e-06\n",
      "Iteration 960 : x = [10.28033336  3.35053766] f(x) = 0.15953895208760077 gradient norm = 2.0546035042213795e-06\n",
      "Iteration 961 : x = [10.28051003  3.35043278] f(x) = 0.15953895166566512 gradient norm = 2.0526189641156973e-06\n",
      "Iteration 962 : x = [10.28068653  3.350328  ] f(x) = 0.15953895124454395 gradient norm = 2.050638387237887e-06\n",
      "Iteration 963 : x = [10.28086286  3.35022332] f(x) = 0.1595389508242349 gradient norm = 2.0486617617242962e-06\n",
      "Iteration 964 : x = [10.28103902  3.35011873] f(x) = 0.15953895040473545 gradient norm = 2.046689075758454e-06\n",
      "Iteration 965 : x = [10.281215    3.35001423] f(x) = 0.15953894998604337 gradient norm = 2.044720317570854e-06\n",
      "Iteration 966 : x = [10.28139082  3.34990984] f(x) = 0.15953894956815617 gradient norm = 2.04275547543866e-06\n",
      "Iteration 967 : x = [10.28156646  3.34980553] f(x) = 0.1595389491510715 gradient norm = 2.040794537685515e-06\n",
      "Iteration 968 : x = [10.28174193  3.34970133] f(x) = 0.15953894873478697 gradient norm = 2.038837492681332e-06\n",
      "Iteration 969 : x = [10.28191723  3.34959722] f(x) = 0.15953894831930032 gradient norm = 2.0368843288420327e-06\n",
      "Iteration 970 : x = [10.28209235  3.3494932 ] f(x) = 0.15953894790460907 gradient norm = 2.034935034629318e-06\n",
      "Iteration 971 : x = [10.28226731  3.34938928] f(x) = 0.159538947490711 gradient norm = 2.0329895985504554e-06\n",
      "Iteration 972 : x = [10.2824421   3.34928545] f(x) = 0.15953894707760372 gradient norm = 2.031048009158068e-06\n",
      "Iteration 973 : x = [10.28261671  3.34918172] f(x) = 0.15953894666528493 gradient norm = 2.029110255049891e-06\n",
      "Iteration 974 : x = [10.28279116  3.34907808] f(x) = 0.15953894625375234 gradient norm = 2.0271763248685623e-06\n",
      "Iteration 975 : x = [10.28296544  3.34897454] f(x) = 0.15953894584300363 gradient norm = 2.0252462073013694e-06\n",
      "Iteration 976 : x = [10.28313955  3.34887109] f(x) = 0.15953894543303648 gradient norm = 2.0233198910800866e-06\n",
      "Iteration 977 : x = [10.28331349  3.34876773] f(x) = 0.15953894502384866 gradient norm = 2.021397364980737e-06\n",
      "Iteration 978 : x = [10.28348727  3.34866447] f(x) = 0.1595389446154379 gradient norm = 2.019478617823329e-06\n",
      "Iteration 979 : x = [10.28366087  3.3485613 ] f(x) = 0.1595389442078019 gradient norm = 2.017563638471708e-06\n",
      "Iteration 980 : x = [10.28383431  3.34845823] f(x) = 0.15953894380093844 gradient norm = 2.0156524158333206e-06\n",
      "Iteration 981 : x = [10.28400758  3.34835524] f(x) = 0.15953894339484526 gradient norm = 2.0137449388589452e-06\n",
      "Iteration 982 : x = [10.28418069  3.34825236] f(x) = 0.15953894298952012 gradient norm = 2.0118411965426096e-06\n",
      "Iteration 983 : x = [10.28435363  3.34814956] f(x) = 0.15953894258496076 gradient norm = 2.009941177921255e-06\n",
      "Iteration 984 : x = [10.2845264   3.34804685] f(x) = 0.15953894218116502 gradient norm = 2.00804487207456e-06\n",
      "Iteration 985 : x = [10.28469901  3.34794424] f(x) = 0.15953894177813066 gradient norm = 2.0061522681247866e-06\n",
      "Iteration 986 : x = [10.28487145  3.34784172] f(x) = 0.15953894137585548 gradient norm = 2.0042633552365083e-06\n",
      "Iteration 987 : x = [10.28504373  3.34773929] f(x) = 0.15953894097433727 gradient norm = 2.0023781226164373e-06\n",
      "Iteration 988 : x = [10.28521584  3.34763696] f(x) = 0.15953894057357385 gradient norm = 2.000496559513226e-06\n",
      "Iteration 989 : x = [10.28538779  3.34753471] f(x) = 0.15953894017356304 gradient norm = 1.9986186552172388e-06\n",
      "Iteration 990 : x = [10.28555957  3.34743256] f(x) = 0.15953893977430275 gradient norm = 1.996744399060361e-06\n",
      "Iteration 991 : x = [10.28573119  3.3473305 ] f(x) = 0.15953893937579072 gradient norm = 1.994873780415815e-06\n",
      "Iteration 992 : x = [10.28590265  3.34722853] f(x) = 0.15953893897802482 gradient norm = 1.9930067886979216e-06\n",
      "Iteration 993 : x = [10.28607394  3.34712665] f(x) = 0.15953893858100293 gradient norm = 1.991143413361971e-06\n",
      "Iteration 994 : x = [10.28624507  3.34702486] f(x) = 0.15953893818472292 gradient norm = 1.9892836439039347e-06\n",
      "Iteration 995 : x = [10.28641604  3.34692316] f(x) = 0.15953893778918263 gradient norm = 1.9874274698603333e-06\n",
      "Iteration 996 : x = [10.28658684  3.34682155] f(x) = 0.15953893739437996 gradient norm = 1.985574880808052e-06\n",
      "Iteration 997 : x = [10.28675749  3.34672004] f(x) = 0.1595389370003128 gradient norm = 1.9837258663640723e-06\n",
      "Iteration 998 : x = [10.28692797  3.34661861] f(x) = 0.15953893660697901 gradient norm = 1.9818804161853657e-06\n",
      "Iteration 999 : x = [10.28709829  3.34651727] f(x) = 0.1595389362143766 gradient norm = 1.980038519968644e-06\n"
     ]
    }
   ],
   "source": [
    "step_sizes = [0.1,1,10,100]\n",
    "starting_points = [[2,5],[1,0.5],[0.5,1]]\n",
    "\n",
    "for x_init in starting_points:\n",
    "    print(\"\\n--------------- Starting point:\", x_init, \"---------------\")\n",
    "    for alpha in step_sizes:\n",
    "        print(\"\\n\\tStep size:\", alpha)\n",
    "        gradient_descent(dataset1, x_init, alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can notice that for $\\alpha = 0.1$, we never reach convergence, and so, hit the max number of iteration (i.e. $max_iter = 1000$); as the step size is too small and progress is very slow.  \n",
    "Instead, with $\\alpha = 1$, the convergence is reached after a very big number of iteration: $723$.\n",
    "Continuing increasing the value of $\\alpha$, we reduce the number of iterations needed in order to reach convergence; in fact, with $\\alpha = 10$ convergence is reached after $68$ iterations, and with $\\alpha = 100$ convergence is reached after only 3 iterations.\n",
    "\n",
    "This behavior suggests that larger step sizes accelerate convergence. However, in general, using very large $\\alpha$ can cause instability or divergence, so it is very important to find an appropriate value for $\\alpha$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8. Plot the bell curve with the optimal parameters on top of the point cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 : x = [2. 5.] f(x) = 0.04037643540736778 gradient norm = 0.017863549100416345\n",
      "Iteration 1 : x = [2.01158942 4.98640619] f(x) = 0.04006309913390959 gradient norm = 0.01723261186881376\n",
      "Iteration 2 : x = [2.02219061 4.97282025] f(x) = 0.03977102293968484 gradient norm = 0.016679799162598628\n",
      "Iteration 3 : x = [2.03187963 4.95924311] f(x) = 0.03949693976448002 gradient norm = 0.016197739077489226\n",
      "Iteration 4 : x = [2.04072742 4.94567538] f(x) = 0.0392380629356495 gradient norm = 0.015779298058660757\n",
      "Iteration 5 : x = [2.0488     4.93211737] f(x) = 0.03899202008335923 gradient norm = 0.015417663834878814\n",
      "Iteration 6 : x = [2.05615874 4.91856918] f(x) = 0.038756795077792845 gradient norm = 0.015106413931172773\n",
      "Iteration 7 : x = [2.06286055 4.90503074] f(x) = 0.03853067728596525 gradient norm = 0.01483956747443785\n",
      "Iteration 8 : x = [2.06895822 4.89150184] f(x) = 0.038312217430111116 gradient norm = 0.01461161938800308\n",
      "Iteration 9 : x = [2.07450057 4.87798216] f(x) = 0.03810018934347399 gradient norm = 0.014417557454639568\n",
      "Iteration 10 : x = [2.07953279 4.86447132] f(x) = 0.03789355695270152 gradient norm = 0.014252863879552581\n",
      "Iteration 11 : x = [2.08409661 4.85096889] f(x) = 0.037691445861420265 gradient norm = 0.014113503774129952\n",
      "Iteration 12 : x = [2.08823053 4.83747438] f(x) = 0.037493118961382334 gradient norm = 0.013995903377601697\n",
      "Iteration 13 : x = [2.09197009 4.82398732] f(x) = 0.03729795555188683 gradient norm = 0.013896920883428015\n",
      "Iteration 14 : x = [2.09534804 4.81050719] f(x) = 0.03710543350224288 gradient norm = 0.013813812527948055\n",
      "Iteration 15 : x = [2.09839454 4.7970335 ] f(x) = 0.03691511404403798 gradient norm = 0.013744196228997797\n",
      "Iteration 16 : x = [2.10113735 4.78356576] f(x) = 0.03672662882877245 gradient norm = 0.013686014619683343\n",
      "Iteration 17 : x = [2.10360202 4.77010351] f(x) = 0.036539668931382996 gradient norm = 0.013637498874061986\n",
      "Iteration 18 : x = [2.10581203 4.75664627] f(x) = 0.036353975521020675 gradient norm = 0.01359713431072103\n",
      "Iteration 19 : x = [2.10778896 4.74319362] f(x) = 0.036169331957134954 gradient norm = 0.013563628410442846\n",
      "Iteration 20 : x = [2.10955264 4.72974514] f(x) = 0.03598555710156826 gradient norm = 0.013535881603340315\n",
      "Iteration 21 : x = [2.11112128 4.71630046] f(x) = 0.035802499666209554 gradient norm = 0.01351296096704958\n",
      "Iteration 22 : x = [2.11251158 4.70285921] f(x) = 0.03562003344107776 gradient norm = 0.013494076823154462\n",
      "Iteration 23 : x = [2.11373887 4.68942106] f(x) = 0.03543805326981659 gradient norm = 0.013478562113943856\n",
      "Iteration 24 : x = [2.11481722 4.67598571] f(x) = 0.035256471658802566 gradient norm = 0.013465854375493209\n",
      "Iteration 25 : x = [2.11575951 4.66255286] f(x) = 0.0350752159227109 gradient norm = 0.013455480086395034\n",
      "Iteration 26 : x = [2.11657755 4.64912227] f(x) = 0.0348942257837454 gradient norm = 0.013447041156132484\n",
      "Iteration 27 : x = [2.11728215 4.6356937 ] f(x) = 0.03471345135409516 gradient norm = 0.013440203316545933\n",
      "Iteration 28 : x = [2.11788323 4.62226695] f(x) = 0.03453285144178459 gradient norm = 0.01343468618901216\n",
      "Iteration 29 : x = [2.11838986 4.60884182] f(x) = 0.034352392129161906 gradient norm = 0.013430254815048441\n",
      "Iteration 30 : x = [2.11881033 4.59541815] f(x) = 0.03417204558102696 gradient norm = 0.013426712456332123\n",
      "Iteration 31 : x = [2.11915225 4.58199579] f(x) = 0.0339917890460144 gradient norm = 0.013423894489678576\n",
      "Iteration 32 : x = [2.11942257 4.56857462] f(x) = 0.03381160402047846 gradient norm = 0.01342166324206705\n",
      "Iteration 33 : x = [2.11962762 4.55515452] f(x) = 0.03363147554891256 gradient norm = 0.013419903629528145\n",
      "Iteration 34 : x = [2.11977323 4.5417354 ] f(x) = 0.033451391638999614 gradient norm = 0.013418519481127683\n",
      "Iteration 35 : x = [2.1198647 4.5283172] f(x) = 0.03327134277283318 gradient norm = 0.013417430445152121\n",
      "Iteration 36 : x = [2.11990687 4.51489983] f(x) = 0.033091321498765584 gradient norm = 0.013416569388831862\n",
      "Iteration 37 : x = [2.11990418 4.50148326] f(x) = 0.032911322090805786 gradient norm = 0.013415880215544494\n",
      "Iteration 38 : x = [2.11986067 4.48806745] f(x) = 0.03273134026457321 gradient norm = 0.013415316034500618\n",
      "Iteration 39 : x = [2.11978003 4.47465238] f(x) = 0.03255137294057275 gradient norm = 0.013414837627543906\n",
      "Iteration 40 : x = [2.11966562 4.46123803] f(x) = 0.0323714180470391 gradient norm = 0.013414412166028674\n",
      "Iteration 41 : x = [2.11952053 4.4478244 ] f(x) = 0.032191474355848154 gradient norm = 0.013414012137909728\n",
      "Iteration 42 : x = [2.11934755 4.43441151] f(x) = 0.032011541346045 gradient norm = 0.013413614451326153\n",
      "Iteration 43 : x = [2.11914924 4.42099936] f(x) = 0.03183161909042284 gradient norm = 0.013413199686210476\n",
      "Iteration 44 : x = [2.11892794 4.40758798] f(x) = 0.0316517081613308 gradient norm = 0.013412751469924825\n",
      "Iteration 45 : x = [2.11868576 4.39417742] f(x) = 0.03147180955251295 gradient norm = 0.013412255956722137\n",
      "Iteration 46 : x = [2.11842464 4.38076771] f(x) = 0.03129192461430534 gradient norm = 0.013411701394047437\n",
      "Iteration 47 : x = [2.11814635 4.36735889] f(x) = 0.031112054999957055 gradient norm = 0.0134110777614154\n",
      "Iteration 48 : x = [2.11785249 4.35395103] f(x) = 0.03093220262120996 gradient norm = 0.013410376469897508\n",
      "Iteration 49 : x = [2.11754451 4.34054419] f(x) = 0.03075236961158054 gradient norm = 0.013409590112189201\n",
      "Iteration 50 : x = [2.11722377 4.32713844] f(x) = 0.030572558296044997 gradient norm = 0.013408712254858238\n",
      "Iteration 51 : x = [2.11689145 4.31373385] f(x) = 0.03039277116604553 gradient norm = 0.013407737265746638\n",
      "Iteration 52 : x = [2.11654868 4.30033049] f(x) = 0.03021301085891572 gradient norm = 0.013406660170651055\n",
      "Iteration 53 : x = [2.11619644 4.28692846] f(x) = 0.030033280140974294 gradient norm = 0.013405476534372775\n",
      "Iteration 54 : x = [2.11583565 4.27352784] f(x) = 0.029853581893662235 gradient norm = 0.01340418236203948\n",
      "Iteration 55 : x = [2.11546714 4.26012872] f(x) = 0.029673919102203686 gradient norm = 0.013402774017279821\n",
      "Iteration 56 : x = [2.11509166 4.24673121] f(x) = 0.029494294846358335 gradient norm = 0.013401248154400256\n",
      "Iteration 57 : x = [2.1147099 4.2333354] f(x) = 0.02931471229290658 gradient norm = 0.013399601662189056\n",
      "Iteration 58 : x = [2.11432248 4.2199414 ] f(x) = 0.02913517468956916 gradient norm = 0.013397831617369757\n",
      "Iteration 59 : x = [2.11392995 4.20654932] f(x) = 0.02895568536011397 gradient norm = 0.01339593524605811\n",
      "Iteration 60 : x = [2.11353285 4.19315927] f(x) = 0.028776247700444967 gradient norm = 0.013393909891853838\n",
      "Iteration 61 : x = [2.11313162 4.17977137] f(x) = 0.02859686517550268 gradient norm = 0.013391752989429219\n",
      "Iteration 62 : x = [2.11272669 4.16638574] f(x) = 0.028417541316835646 gradient norm = 0.013389462042669572\n",
      "Iteration 63 : x = [2.11231846 4.15300251] f(x) = 0.028238279720725862 gradient norm = 0.013387034606580766\n",
      "Iteration 64 : x = [2.11190725 4.13962179] f(x) = 0.028059084046771484 gradient norm = 0.013384468272312844\n",
      "Iteration 65 : x = [2.11149339 4.12624372] f(x) = 0.027879958016846857 gradient norm = 0.013381760654759775\n",
      "Iteration 66 : x = [2.11107717 4.11286843] f(x) = 0.027700905414373707 gradient norm = 0.013378909382288019\n",
      "Iteration 67 : x = [2.11065885 4.09949607] f(x) = 0.027521930083848508 gradient norm = 0.013375912088223236\n",
      "Iteration 68 : x = [2.11023865 4.08612676] f(x) = 0.027343035930581135 gradient norm = 0.013372766403788513\n",
      "Iteration 69 : x = [2.10981679 4.07276065] f(x) = 0.027164226920606962 gradient norm = 0.013369469952240276\n",
      "Iteration 70 : x = [2.10939347 4.05939788] f(x) = 0.02698550708074195 gradient norm = 0.013366020343992263\n",
      "Iteration 71 : x = [2.10896886 4.0460386 ] f(x) = 0.026806880498754685 gradient norm = 0.013362415172554157\n",
      "Iteration 72 : x = [2.10854311 4.03268297] f(x) = 0.02662835132363471 gradient norm = 0.013358652011141926\n",
      "Iteration 73 : x = [2.10811638 4.01933114] f(x) = 0.02644992376593916 gradient norm = 0.013354728409841816\n",
      "Iteration 74 : x = [2.10768878 4.00598326] f(x) = 0.0262716020982038 gradient norm = 0.01335064189323074\n",
      "Iteration 75 : x = [2.10726044 3.99263949] f(x) = 0.02609339065540603 gradient norm = 0.013346389958372918\n",
      "Iteration 76 : x = [2.10683146 3.9793    ] f(x) = 0.025915293835470154 gradient norm = 0.013341970073126902\n",
      "Iteration 77 : x = [2.10640195 3.96596494] f(x) = 0.025737316099806604 gradient norm = 0.013337379674708761\n",
      "Iteration 78 : x = [2.10597197 3.95263449] f(x) = 0.0255594619738782 gradient norm = 0.013332616168466883\n",
      "Iteration 79 : x = [2.10554162 3.93930882] f(x) = 0.02538173604778784 gradient norm = 0.01332767692683201\n",
      "Iteration 80 : x = [2.10511097 3.92598811] f(x) = 0.025204142976882556 gradient norm = 0.013322559288412495\n",
      "Iteration 81 : x = [2.10468007 3.91267252] f(x) = 0.0250266874823701 gradient norm = 0.013317260557210445\n",
      "Iteration 82 : x = [2.10424899 3.89936224] f(x) = 0.0248493743519445 gradient norm = 0.013311778001938794\n",
      "Iteration 83 : x = [2.10381777 3.88605745] f(x) = 0.02467220844041759 gradient norm = 0.013306108855423023\n",
      "Iteration 84 : x = [2.10338647 3.87275833] f(x) = 0.024495194670354187 gradient norm = 0.013300250314074443\n",
      "Iteration 85 : x = [2.10295513 3.85946507] f(x) = 0.024318338032708293 gradient norm = 0.01329419953742436\n",
      "Iteration 86 : x = [2.10252378 3.84617787] f(x) = 0.02414164358745888 gradient norm = 0.013287953647710495\n",
      "Iteration 87 : x = [2.10209246 3.83289692] f(x) = 0.023965116464243073 gradient norm = 0.01328150972950893\n",
      "Iteration 88 : x = [2.10166119 3.81962242] f(x) = 0.023788761862985393 gradient norm = 0.013274864829405946\n",
      "Iteration 89 : x = [2.10123002 3.80635456] f(x) = 0.023612585054521542 gradient norm = 0.013268015955705644\n",
      "Iteration 90 : x = [2.10079896 3.79309354] f(x) = 0.02343659138121538 gradient norm = 0.013260960078169896\n",
      "Iteration 91 : x = [2.10036803 3.77983959] f(x) = 0.02326078625756781 gradient norm = 0.013253694127788086\n",
      "Iteration 92 : x = [2.09993726 3.7665929 ] f(x) = 0.02308517517081648 gradient norm = 0.013246214996574862\n",
      "Iteration 93 : x = [2.09950666 3.75335368] f(x) = 0.022909763681524795 gradient norm = 0.013238519537394414\n",
      "Iteration 94 : x = [2.09907626 3.74012216] f(x) = 0.02273455742415957 gradient norm = 0.013230604563810424\n",
      "Iteration 95 : x = [2.09864605 3.72689855] f(x) = 0.022559562107655712 gradient norm = 0.013222466849961232\n",
      "Iteration 96 : x = [2.09821606 3.71368308] f(x) = 0.02238478351596713 gradient norm = 0.01321410313045985\n",
      "Iteration 97 : x = [2.0977863  3.70047597] f(x) = 0.02221022750860253 gradient norm = 0.013205510100318984\n",
      "Iteration 98 : x = [2.09735677 3.68727744] f(x) = 0.02203590002114515 gradient norm = 0.013196684414901285\n",
      "Iteration 99 : x = [2.09692749 3.67408774] f(x) = 0.02186180706575497 gradient norm = 0.013187622689895213\n",
      "Iteration 100 : x = [2.09649846 3.6609071 ] f(x) = 0.021687954731652602 gradient norm = 0.013178321501317163\n",
      "Iteration 101 : x = [2.0960697  3.64773576] f(x) = 0.021514349185583294 gradient norm = 0.013168777385540568\n",
      "Iteration 102 : x = [2.0956412  3.63457395] f(x) = 0.021340996672260068 gradient norm = 0.013158986839352802\n",
      "Iteration 103 : x = [2.09521297 3.62142193] f(x) = 0.021167903514784644 gradient norm = 0.0131489463200408\n",
      "Iteration 104 : x = [2.09478501 3.60827995] f(x) = 0.020995076115044788 gradient norm = 0.013138652245506447\n",
      "Iteration 105 : x = [2.09435734 3.59514826] f(x) = 0.0208225209540869 gradient norm = 0.013128100994412884\n",
      "Iteration 106 : x = [2.09392994 3.58202712] f(x) = 0.02065024459246247 gradient norm = 0.013117288906362719\n",
      "Iteration 107 : x = [2.09350283 3.56891679] f(x) = 0.02047825367054685 gradient norm = 0.013106212282109626\n",
      "Iteration 108 : x = [2.09307601 3.55581753] f(x) = 0.020306554908829096 gradient norm = 0.01309486738380437\n",
      "Iteration 109 : x = [2.09264947 3.54272961] f(x) = 0.020135155108171432 gradient norm = 0.013083250435276774\n",
      "Iteration 110 : x = [2.09222322 3.52965331] f(x) = 0.019964061150036603 gradient norm = 0.013071357622354932\n",
      "Iteration 111 : x = [2.09179725 3.51658889] f(x) = 0.01979327999668188 gradient norm = 0.013059185093223045\n",
      "Iteration 112 : x = [2.09137158 3.50353664] f(x) = 0.01962281869131795 gradient norm = 0.013046728958819505\n",
      "Iteration 113 : x = [2.09094619 3.49049685] f(x) = 0.01945268435823113 gradient norm = 0.013033985293276516\n",
      "Iteration 114 : x = [2.09052108 3.4774698 ] f(x) = 0.01928288420286727 gradient norm = 0.01302095013440301\n",
      "Iteration 115 : x = [2.09009626 3.46445578] f(x) = 0.019113425511875632 gradient norm = 0.013007619484212292\n",
      "Iteration 116 : x = [2.08967172 3.45145509] f(x) = 0.018944315653111065 gradient norm = 0.012993989309496072\n",
      "Iteration 117 : x = [2.08924747 3.43846803] f(x) = 0.01877556207559263 gradient norm = 0.012980055542446522\n",
      "Iteration 118 : x = [2.08882349 3.4254949 ] f(x) = 0.018607172309416966 gradient norm = 0.012965814081328042\n",
      "Iteration 119 : x = [2.08839979 3.41253601] f(x) = 0.018439153965624507 gradient norm = 0.012951260791200419\n",
      "Iteration 120 : x = [2.08797635 3.39959168] f(x) = 0.018271514736016726 gradient norm = 0.01293639150469508\n",
      "Iteration 121 : x = [2.08755319 3.38666221] f(x) = 0.018104262392922354 gradient norm = 0.012921202022846237\n",
      "Iteration 122 : x = [2.0871303  3.37374793] f(x) = 0.017937404788910923 gradient norm = 0.012905688115978668\n",
      "Iteration 123 : x = [2.08670767 3.36084916] f(x) = 0.017770949856451303 gradient norm = 0.012889845524653894\n",
      "Iteration 124 : x = [2.08628529 3.34796624] f(x) = 0.017604905607513568 gradient norm = 0.012873669960676605\n",
      "Iteration 125 : x = [2.08586318 3.33509949] f(x) = 0.01743928013311185 gradient norm = 0.01285715710816314\n",
      "Iteration 126 : x = [2.08544131 3.32224926] f(x) = 0.017274081602786394 gradient norm = 0.012840302624673821\n",
      "Iteration 127 : x = [2.08501968 3.30941588] f(x) = 0.01710931826402254 gradient norm = 0.012823102142411074\n",
      "Iteration 128 : x = [2.0845983 3.2965997] f(x) = 0.016944998441604568 gradient norm = 0.012805551269485033\n",
      "Iteration 129 : x = [2.08417716 3.28380108] f(x) = 0.016781130536902302 gradient norm = 0.012787645591248691\n",
      "Iteration 130 : x = [2.08375624 3.27102036] f(x) = 0.016617723027088322 gradient norm = 0.012769380671704236\n",
      "Iteration 131 : x = [2.08333555 3.25825791] f(x) = 0.016454784464283535 gradient norm = 0.012750752054982594\n",
      "Iteration 132 : x = [2.08291508 3.24551409] f(x) = 0.016292323474628993 gradient norm = 0.012731755266897911\n",
      "Iteration 133 : x = [2.08249482 3.23278928] f(x) = 0.016130348757281726 gradient norm = 0.012712385816578879\n",
      "Iteration 134 : x = [2.08207477 3.22008383] f(x) = 0.01596886908333242 gradient norm = 0.012692639198178705\n",
      "Iteration 135 : x = [2.08165493 3.20739814] f(x) = 0.015807893294642626 gradient norm = 0.012672510892665492\n",
      "Iteration 136 : x = [2.08123527 3.19473258] f(x) = 0.015647430302599408 gradient norm = 0.012651996369694867\n",
      "Iteration 137 : x = [2.08081581 3.18208754] f(x) = 0.015487489086785147 gradient norm = 0.012631091089566546\n",
      "Iteration 138 : x = [2.08039653 3.16946341] f(x) = 0.015328078693560239 gradient norm = 0.012609790505266541\n",
      "Iteration 139 : x = [2.07997742 3.15686058] f(x) = 0.015169208234556635 gradient norm = 0.01258809006459686\n",
      "Iteration 140 : x = [2.07955848 3.14427947] f(x) = 0.015010886885079917 gradient norm = 0.012565985212393974\n",
      "Iteration 141 : x = [2.0791397  3.13172046] f(x) = 0.014853123882417716 gradient norm = 0.012543471392838013\n",
      "Iteration 142 : x = [2.07872107 3.11918398] f(x) = 0.0146959285240525 gradient norm = 0.012520544051853918\n",
      "Iteration 143 : x = [2.07830259 3.10667043] f(x) = 0.014539310165776401 gradient norm = 0.012497198639606223\n",
      "Iteration 144 : x = [2.07788425 3.09418023] f(x) = 0.014383278219706171 gradient norm = 0.01247343061308861\n",
      "Iteration 145 : x = [2.07746604 3.08171382] f(x) = 0.014227842152196189 gradient norm = 0.012449235438809832\n",
      "Iteration 146 : x = [2.07704795 3.0692716 ] f(x) = 0.014073011481647387 gradient norm = 0.012424608595576926\n",
      "Iteration 147 : x = [2.07662997 3.05685403] f(x) = 0.013918795776210415 gradient norm = 0.012399545577377075\n",
      "Iteration 148 : x = [2.0762121  3.04446153] f(x) = 0.013765204651380957 gradient norm = 0.01237404189635899\n",
      "Iteration 149 : x = [2.07579433 3.03209454] f(x) = 0.013612247767485442 gradient norm = 0.012348093085914823\n",
      "Iteration 150 : x = [2.07537665 3.01975351] f(x) = 0.013459934827055433 gradient norm = 0.012321694703863352\n",
      "Iteration 151 : x = [2.07495904 3.0074389 ] f(x) = 0.01330827557208904 gradient norm = 0.012294842335735074\n",
      "Iteration 152 : x = [2.07454151 2.99515114] f(x) = 0.013157279781197764 gradient norm = 0.012267531598159888\n",
      "Iteration 153 : x = [2.07412404 2.98289072] f(x) = 0.013006957266637238 gradient norm = 0.012239758142357495\n",
      "Iteration 154 : x = [2.07370663 2.97065808] f(x) = 0.012857317871220667 gradient norm = 0.012211517657731093\n",
      "Iteration 155 : x = [2.07328927 2.9584537 ] f(x) = 0.012708371465113465 gradient norm = 0.012182805875564048\n",
      "Iteration 156 : x = [2.07287194 2.94627804] f(x) = 0.012560127942508189 gradient norm = 0.012153618572819776\n",
      "Iteration 157 : x = [2.07245464 2.93413159] f(x) = 0.012412597218178592 gradient norm = 0.012123951576044355\n",
      "Iteration 158 : x = [2.07203735 2.92201482] f(x) = 0.01226578922391197 gradient norm = 0.012093800765371393\n",
      "Iteration 159 : x = [2.07162008 2.90992822] f(x) = 0.012119713904819118 gradient norm = 0.012063162078628597\n",
      "Iteration 160 : x = [2.07120281 2.89787228] f(x) = 0.011974381215521294 gradient norm = 0.01203203151554497\n",
      "Iteration 161 : x = [2.07078554 2.88584748] f(x) = 0.011829801116213763 gradient norm = 0.012000405142057663\n",
      "Iteration 162 : x = [2.07036824 2.87385434] f(x) = 0.011685983568605738 gradient norm = 0.011968279094717024\n",
      "Iteration 163 : x = [2.06995092 2.86189333] f(x) = 0.011542938531736616 gradient norm = 0.011935649585188324\n",
      "Iteration 164 : x = [2.06953357 2.84996498] f(x) = 0.011400675957668742 gradient norm = 0.011902512904848225\n",
      "Iteration 165 : x = [2.06911618 2.83806979] f(x) = 0.011259205787056966 gradient norm = 0.011868865429473978\n",
      "Iteration 166 : x = [2.06869873 2.82620827] f(x) = 0.011118537944595577 gradient norm = 0.011834703624022854\n",
      "Iteration 167 : x = [2.06828123 2.81438093] f(x) = 0.010978682334343485 gradient norm = 0.011800024047499238\n",
      "Iteration 168 : x = [2.06786365 2.8025883 ] f(x) = 0.010839648834928491 gradient norm = 0.011764823357906335\n",
      "Iteration 169 : x = [2.067446   2.79083089] f(x) = 0.010701447294632098 gradient norm = 0.011729098317279314\n",
      "Iteration 170 : x = [2.06702826 2.77910923] f(x) = 0.01056408752635625 gradient norm = 0.011692845796796228\n",
      "Iteration 171 : x = [2.06661043 2.76742386] f(x) = 0.010427579302473775 gradient norm = 0.011656062781962942\n",
      "Iteration 172 : x = [2.0661925  2.75577529] f(x) = 0.010291932349564645 gradient norm = 0.011618746377867695\n",
      "Iteration 173 : x = [2.06577447 2.74416407] f(x) = 0.010157156343040204 gradient norm = 0.01158089381450096\n",
      "Iteration 174 : x = [2.06535631 2.73259072] f(x) = 0.010023260901658188 gradient norm = 0.011542502452135514\n",
      "Iteration 175 : x = [2.06493803 2.7210558 ] f(x) = 0.009890255581931181 gradient norm = 0.01150356978676169\n",
      "Iteration 176 : x = [2.06451962 2.70955984] f(x) = 0.009758149872431872 gradient norm = 0.01146409345557205\n",
      "Iteration 177 : x = [2.06410108 2.69810339] f(x) = 0.009626953187998489 gradient norm = 0.011424071242489736\n",
      "Iteration 178 : x = [2.06368239 2.686687  ] f(x) = 0.009496674863844269 gradient norm = 0.01138350108373413\n",
      "Iteration 179 : x = [2.06326355 2.6753112 ] f(x) = 0.009367324149575095 gradient norm = 0.011342381073417172\n",
      "Iteration 180 : x = [2.06284455 2.66397656] f(x) = 0.009238910203119696 gradient norm = 0.011300709469163412\n",
      "Iteration 181 : x = [2.0624254  2.65268363] f(x) = 0.009111442084577173 gradient norm = 0.011258484697746417\n",
      "Iteration 182 : x = [2.06200607 2.64143296] f(x) = 0.008984928749987029 gradient norm = 0.01121570536073377\n",
      "Iteration 183 : x = [2.06158658 2.6302251 ] f(x) = 0.008859379045027085 gradient norm = 0.01117237024013272\n",
      "Iteration 184 : x = [2.06116691 2.61906062] f(x) = 0.008734801698644991 gradient norm = 0.011128478304027948\n",
      "Iteration 185 : x = [2.06074706 2.60794006] f(x) = 0.008611205316629561 gradient norm = 0.011084028712202742\n",
      "Iteration 186 : x = [2.06032702 2.59686399] f(x) = 0.008488598375128303 gradient norm = 0.011039020821734531\n",
      "Iteration 187 : x = [2.0599068  2.58583297] f(x) = 0.008366989214117888 gradient norm = 0.010993454192555156\n",
      "Iteration 188 : x = [2.05948639 2.57484756] f(x) = 0.008246386030834772 gradient norm = 0.010947328592966451\n",
      "Iteration 189 : x = [2.05906579 2.56390831] f(x) = 0.008126796873173293 gradient norm = 0.01090064400510064\n",
      "Iteration 190 : x = [2.05864499 2.5530158 ] f(x) = 0.008008229633059109 gradient norm = 0.010853400630315597\n",
      "Iteration 191 : x = [2.058224   2.54217056] f(x) = 0.007890692039805993 gradient norm = 0.010805598894513992\n",
      "Iteration 192 : x = [2.05780282 2.53137318] f(x) = 0.007774191653464421 gradient norm = 0.010757239453375566\n",
      "Iteration 193 : x = [2.05738144 2.52062419] f(x) = 0.007658735858170653 gradient norm = 0.01070832319749134\n",
      "Iteration 194 : x = [2.05695987 2.50992417] f(x) = 0.007544331855505303 gradient norm = 0.010658851257388276\n",
      "Iteration 195 : x = [2.05653811 2.49927367] f(x) = 0.007430986657870668 gradient norm = 0.010608825008432828\n",
      "Iteration 196 : x = [2.05611615 2.48867324] f(x) = 0.007318707081896378 gradient norm = 0.010558246075601555\n",
      "Iteration 197 : x = [2.05569401 2.47812343] f(x) = 0.007207499741883222 gradient norm = 0.010507116338106819\n",
      "Iteration 198 : x = [2.05527168 2.46762481] f(x) = 0.007097371043295133 gradient norm = 0.010455437933865427\n",
      "Iteration 199 : x = [2.05484917 2.45717791] f(x) = 0.006988327176309669 gradient norm = 0.010403213263798044\n",
      "Iteration 200 : x = [2.05442649 2.44678329] f(x) = 0.0068803741094374685 gradient norm = 0.010350444995947007\n",
      "Iteration 201 : x = [2.05400363 2.43644148] f(x) = 0.006773517583221366 gradient norm = 0.010297136069400258\n",
      "Iteration 202 : x = [2.05358062 2.42615304] f(x) = 0.006667763104025971 gradient norm = 0.01024328969800894\n",
      "Iteration 203 : x = [2.05315744 2.4159185 ] f(x) = 0.006563115937928794 gradient norm = 0.010188909373886395\n",
      "Iteration 204 : x = [2.05273411 2.40573838] f(x) = 0.006459581104723932 gradient norm = 0.010133998870676193\n",
      "Iteration 205 : x = [2.05231065 2.39561324] f(x) = 0.006357163372049595 gradient norm = 0.010078562246577012\n",
      "Iteration 206 : x = [2.05188705 2.38554358] f(x) = 0.006255867249650736 gradient norm = 0.010022603847112344\n",
      "Iteration 207 : x = [2.05146333 2.37552994] f(x) = 0.006155696983788102 gradient norm = 0.00996612830763301\n",
      "Iteration 208 : x = [2.0510395  2.36557282] f(x) = 0.00605665655180504 gradient norm = 0.00990914055554092\n",
      "Iteration 209 : x = [2.05061558 2.35567276] f(x) = 0.005958749656863393 gradient norm = 0.00985164581222254\n",
      "Iteration 210 : x = [2.05019157 2.34583024] f(x) = 0.005861979722859766 gradient norm = 0.009793649594680971\n",
      "Iteration 211 : x = [2.04976748 2.33604578] f(x) = 0.005766349889533347 gradient norm = 0.009735157716855817\n",
      "Iteration 212 : x = [2.04934335 2.32631986] f(x) = 0.0056718630077763465 gradient norm = 0.009676176290620429\n",
      "Iteration 213 : x = [2.04891916 2.31665299] f(x) = 0.0055785216351580715 gradient norm = 0.009616711726446498\n",
      "Iteration 214 : x = [2.04849496 2.30704564] f(x) = 0.0054863280316733 gradient norm = 0.009556770733726504\n",
      "Iteration 215 : x = [2.04807075 2.29749829] f(x) = 0.0053952841557255785 gradient norm = 0.009496360320744945\n",
      "Iteration 216 : x = [2.04764655 2.2880114 ] f(x) = 0.005305391660355726 gradient norm = 0.009435487794289973\n",
      "Iteration 217 : x = [2.04722238 2.27858546] f(x) = 0.005216651889725548 gradient norm = 0.009374160758897422\n",
      "Iteration 218 : x = [2.04679826 2.26922089] f(x) = 0.0051290658758664735 gradient norm = 0.009312387115720182\n",
      "Iteration 219 : x = [2.04637421 2.25991817] f(x) = 0.005042634335702497 gradient norm = 0.00925017506101623\n",
      "Iteration 220 : x = [2.04595026 2.25067771] f(x) = 0.004957357668356344 gradient norm = 0.009187533084249506\n",
      "Iteration 221 : x = [2.04552643 2.24149996] f(x) = 0.004873235952747409 gradient norm = 0.009124469965798646\n",
      "Iteration 222 : x = [2.04510273 2.23238533] f(x) = 0.004790268945489599 gradient norm = 0.009060994774269191\n",
      "Iteration 223 : x = [2.04467921 2.22333424] f(x) = 0.00470845607909666 gradient norm = 0.008997116863405872\n",
      "Iteration 224 : x = [2.04425587 2.21434709] f(x) = 0.0046277964605020375 gradient norm = 0.008932845868602381\n",
      "Iteration 225 : x = [2.04383276 2.20542427] f(x) = 0.004548288869899835 gradient norm = 0.00886819170300686\n",
      "Iteration 226 : x = [2.04340989 2.19656617] f(x) = 0.004469931759912859 gradient norm = 0.008803164553222423\n",
      "Iteration 227 : x = [2.0429873  2.18777315] f(x) = 0.004392723255093014 gradient norm = 0.008737774874602759\n",
      "Iteration 228 : x = [2.04256501 2.17904559] f(x) = 0.004316661151758817 gradient norm = 0.008672033386143987\n",
      "Iteration 229 : x = [2.04214306 2.17038382] f(x) = 0.00424174291817407 gradient norm = 0.008605951064974854\n",
      "Iteration 230 : x = [2.04172147 2.16178821] f(x) = 0.004167965695071048 gradient norm = 0.008539539140448313\n",
      "Iteration 231 : x = [2.04130029 2.15325906] f(x) = 0.004095326296520887 gradient norm = 0.008472809087838649\n",
      "Iteration 232 : x = [2.04087953 2.1447967 ] f(x) = 0.004023821211153067 gradient norm = 0.008405772621649179\n",
      "Iteration 233 : x = [2.04045925 2.13640144] f(x) = 0.003953446603725271 gradient norm = 0.008338441688536717\n",
      "Iteration 234 : x = [2.04003946 2.12807358] f(x) = 0.0038841983170439997 gradient norm = 0.008270828459859898\n",
      "Iteration 235 : x = [2.03962022 2.11981338] f(x) = 0.003816071874235648 gradient norm = 0.00820294532385952\n",
      "Iteration 236 : x = [2.03920154 2.11162113] f(x) = 0.003749062481366985 gradient norm = 0.008134804877480098\n",
      "Iteration 237 : x = [2.03878348 2.10349707] f(x) = 0.0036831650304131203 gradient norm = 0.0080664199178427\n",
      "Iteration 238 : x = [2.03836606 2.09544146] f(x) = 0.003618374102570357 gradient norm = 0.007997803433380307\n",
      "Iteration 239 : x = [2.03794933 2.08745452] f(x) = 0.003554683971910449 gradient norm = 0.007928968594647685\n",
      "Iteration 240 : x = [2.03753333 2.07953647] f(x) = 0.0034920886093720853 gradient norm = 0.007859928744818792\n",
      "Iteration 241 : x = [2.0371181  2.07168752] f(x) = 0.003430581687084589 gradient norm = 0.007790697389885724\n",
      "Iteration 242 : x = [2.03670366 2.06390785] f(x) = 0.003370156583018078 gradient norm = 0.007721288188573861\n",
      "Iteration 243 : x = [2.03629008 2.05619765] f(x) = 0.003310806385953581 gradient norm = 0.0076517149419889725\n",
      "Iteration 244 : x = [2.03587739 2.04855707] f(x) = 0.0032525239007658337 gradient norm = 0.007581991583012613\n",
      "Iteration 245 : x = [2.03546562 2.04098627] f(x) = 0.003195301654010774 gradient norm = 0.007512132165462967\n",
      "Iteration 246 : x = [2.03505484 2.03348538] f(x) = 0.003139131899809089 gradient norm = 0.007442150853039151\n",
      "Iteration 247 : x = [2.03464506 2.02605452] f(x) = 0.0030840066260163475 gradient norm = 0.007372061908067317\n",
      "Iteration 248 : x = [2.03423635 2.01869379] f(x) = 0.0030299175606698144 gradient norm = 0.007301879680067857\n",
      "Iteration 249 : x = [2.03382874 2.0114033 ] f(x) = 0.002976856178701172 gradient norm = 0.0072316185941633014\n",
      "Iteration 250 : x = [2.03342229 2.00418311] f(x) = 0.002924813708903955 gradient norm = 0.007161293139347091\n",
      "Iteration 251 : x = [2.03301702 1.99703329] f(x) = 0.0028737811411438624 gradient norm = 0.007090917856633815\n",
      "Iteration 252 : x = [2.03261299 1.9899539 ] f(x) = 0.002823749233799564 gradient norm = 0.0070205073271119335\n",
      "Iteration 253 : x = [2.03221024 1.98294495] f(x) = 0.002774708521421174 gradient norm = 0.006950076159920131\n",
      "Iteration 254 : x = [2.03180883 1.97600648] f(x) = 0.00272664932259305 gradient norm = 0.0068796389801689005\n",
      "Iteration 255 : x = [2.03140878 1.96913848] f(x) = 0.002679561747987229 gradient norm = 0.006809210416828944\n",
      "Iteration 256 : x = [2.03101015 1.96234095] f(x) = 0.00263343570859335 gradient norm = 0.006738805090608196\n",
      "Iteration 257 : x = [2.03061299 1.95561386] f(x) = 0.0025882609241106662 gradient norm = 0.006668437601839249\n",
      "Iteration 258 : x = [2.03021734 1.94895717] f(x) = 0.002544026931487392 gradient norm = 0.006598122518398914\n",
      "Iteration 259 : x = [2.02982324 1.94237082] f(x) = 0.0025007230935924453 gradient norm = 0.006527874363681601\n",
      "Iteration 260 : x = [2.02943074 1.93585476] f(x) = 0.0024583386080043994 gradient norm = 0.0064577076046479776\n",
      "Iteration 261 : x = [2.02903989 1.92940889] f(x) = 0.0024168625159023504 gradient norm = 0.006387636639970177\n",
      "Iteration 262 : x = [2.02865072 1.92303312] f(x) = 0.0023762837110432554 gradient norm = 0.006317675788294433\n",
      "Iteration 263 : x = [2.02826329 1.91672734] f(x) = 0.002336590948810295 gradient norm = 0.006247839276641809\n",
      "Iteration 264 : x = [2.02787764 1.91049141] f(x) = 0.002297772855316742 gradient norm = 0.006178141228967078\n",
      "Iteration 265 : x = [2.02749382 1.9043252 ] f(x) = 0.0022598179365499087 gradient norm = 0.006108595654895483\n",
      "Iteration 266 : x = [2.02711186 1.89822856] f(x) = 0.002222714587539772 gradient norm = 0.00603921643865642\n",
      "Iteration 267 : x = [2.02673181 1.89220131] f(x) = 0.002186451101537044 gradient norm = 0.005970017328232635\n",
      "Iteration 268 : x = [2.02635372 1.88624328] f(x) = 0.0021510156791855906 gradient norm = 0.005901011924742714\n",
      "Iteration 269 : x = [2.02597762 1.88035427] f(x) = 0.0021163964376743286 gradient norm = 0.0058322136720741\n",
      "Iteration 270 : x = [2.02560357 1.87453406] f(x) = 0.0020825814198539645 gradient norm = 0.005763635846782978\n",
      "Iteration 271 : x = [2.02523159 1.86878244] f(x) = 0.002049558603304259 gradient norm = 0.005695291548276704\n",
      "Iteration 272 : x = [2.02486173 1.86309917] f(x) = 0.0020173159093377813 gradient norm = 0.005627193689293549\n",
      "Iteration 273 : x = [2.02449404 1.857484  ] f(x) = 0.001985841211926516 gradient norm = 0.005559354986693682\n",
      "Iteration 274 : x = [2.02412855 1.85193668] f(x) = 0.0019551223465380753 gradient norm = 0.005491787952574438\n",
      "Iteration 275 : x = [2.0237653  1.84645691] f(x) = 0.0019251471188686873 gradient norm = 0.005424504885721999\n",
      "Iteration 276 : x = [2.02340432 1.84104443] f(x) = 0.001895903313460584 gradient norm = 0.005357517863410606\n",
      "Iteration 277 : x = [2.02304567 1.83569893] f(x) = 0.0018673787021919281 gradient norm = 0.005290838733559598\n",
      "Iteration 278 : x = [2.02268936 1.83042011] f(x) = 0.0018395610526278745 gradient norm = 0.005224479107257366\n",
      "Iteration 279 : x = [2.02233545 1.82520763] f(x) = 0.0018124381362219625 gradient norm = 0.005158450351660628\n",
      "Iteration 280 : x = [2.02198396 1.82006117] f(x) = 0.001785997736357504 gradient norm = 0.0050927635832760795\n",
      "Iteration 281 : x = [2.02163493 1.81498038] f(x) = 0.0017602276562192942 gradient norm = 0.005027429661630781\n",
      "Iteration 282 : x = [2.02128839 1.80996491] f(x) = 0.0017351157264864742 gradient norm = 0.004962459183336466\n",
      "Iteration 283 : x = [2.02094437 1.80501439] f(x) = 0.0017106498128380166 gradient norm = 0.00489786247655197\n",
      "Iteration 284 : x = [2.02060291 1.80012844] f(x) = 0.0016868178232629116 gradient norm = 0.004833649595847077\n",
      "Iteration 285 : x = [2.02026403 1.79530668] f(x) = 0.0016636077151677214 gradient norm = 0.004769830317469998\n",
      "Iteration 286 : x = [2.01992777 1.79054872] f(x) = 0.0016410075022748145 gradient norm = 0.004706414135019792\n",
      "Iteration 287 : x = [2.01959415 1.78585415] f(x) = 0.0016190052613051992 gradient norm = 0.004643410255524063\n",
      "Iteration 288 : x = [2.0192632  1.78122255] f(x) = 0.0015975891384405166 gradient norm = 0.004580827595921399\n",
      "Iteration 289 : x = [2.01893495 1.77665349] f(x) = 0.0015767473555593368 gradient norm = 0.004518674779946979\n",
      "Iteration 290 : x = [2.01860942 1.77214656] f(x) = 0.0015564682162435798 gradient norm = 0.004456960135419094\n",
      "Iteration 291 : x = [2.01828664 1.7677013 ] f(x) = 0.0015367401115514256 gradient norm = 0.004395691691923274\n",
      "Iteration 292 : x = [2.01796662 1.76331728] f(x) = 0.0015175515255537344 gradient norm = 0.004334877178890051\n",
      "Iteration 293 : x = [2.0176494  1.75899402] f(x) = 0.0014988910406315717 gradient norm = 0.004274524024061545\n",
      "Iteration 294 : x = [2.01733499 1.75473108] f(x) = 0.001480747342533002 gradient norm = 0.004214639352341263\n",
      "Iteration 295 : x = [2.0170234  1.75052797] f(x) = 0.001463109225187909 gradient norm = 0.004155229985020894\n",
      "Iteration 296 : x = [2.01671467 1.74638423] f(x) = 0.0014459655952801373 gradient norm = 0.004096302439377093\n",
      "Iteration 297 : x = [2.01640881 1.74229936] f(x) = 0.0014293054765767874 gradient norm = 0.004037862928630713\n",
      "Iteration 298 : x = [2.01610582 1.73827288] f(x) = 0.0014131180140150288 gradient norm = 0.003979917362260276\n",
      "Iteration 299 : x = [2.01580574 1.73430429] f(x) = 0.0013973924775472798 gradient norm = 0.003922471346660913\n",
      "Iteration 300 : x = [2.01550857 1.73039309] f(x) = 0.0013821182657460995 gradient norm = 0.003865530186139573\n",
      "Iteration 301 : x = [2.01521432 1.72653878] f(x) = 0.001367284909170593 gradient norm = 0.0038090988842367445\n",
      "Iteration 302 : x = [2.01492301 1.72274083] f(x) = 0.0013528820734965575 gradient norm = 0.0037531821453645107\n",
      "Iteration 303 : x = [2.01463464 1.71899875] f(x) = 0.0013388995624130438 gradient norm = 0.0036977843767504117\n",
      "Iteration 304 : x = [2.01434923 1.71531199] f(x) = 0.0013253273202883664 gradient norm = 0.0036429096906762303\n",
      "Iteration 305 : x = [2.01406679 1.71168005] f(x) = 0.0013121554346089996 gradient norm = 0.0035885619070004466\n",
      "Iteration 306 : x = [2.01378731 1.70810239] f(x) = 0.0012993741381951193 gradient norm = 0.0035347445559529684\n",
      "Iteration 307 : x = [2.01351081 1.70457847] f(x) = 0.0012869738111968923 gradient norm = 0.0034814608811903625\n",
      "Iteration 308 : x = [2.0132373  1.70110777] f(x) = 0.0012749449828759075 gradient norm = 0.0034287138430997926\n",
      "Iteration 309 : x = [2.01296677 1.69768975] f(x) = 0.0012632783331764216 gradient norm = 0.0033765061223395496\n",
      "Iteration 310 : x = [2.01269922 1.69432386] f(x) = 0.0012519646940913473 gradient norm = 0.0033248401236041416\n",
      "Iteration 311 : x = [2.01243467 1.69100956] f(x) = 0.0012409950508281379 gradient norm = 0.0032737179796016383\n",
      "Iteration 312 : x = [2.01217311 1.68774631] f(x) = 0.001230360542779938 gradient norm = 0.003223141555231095\n",
      "Iteration 313 : x = [2.01191454 1.68453356] f(x) = 0.0012200524643075459 gradient norm = 0.0031731124519477653\n",
      "Iteration 314 : x = [2.01165895 1.68137075] f(x) = 0.0012100622653378934 gradient norm = 0.0031236320123039112\n",
      "Iteration 315 : x = [2.01140635 1.67825735] f(x) = 0.0012003815517849024 gradient norm = 0.0030747013246530115\n",
      "Iteration 316 : x = [2.01115674 1.6751928 ] f(x) = 0.0011910020857986861 gradient norm = 0.0030263212280053488\n",
      "Iteration 317 : x = [2.0109101  1.67217654] f(x) = 0.0011819157858491524 gradient norm = 0.0029784923170229527\n",
      "Iteration 318 : x = [2.01066643 1.66920804] f(x) = 0.0011731147266501717 gradient norm = 0.0029312149471421352\n",
      "Iteration 319 : x = [2.01042574 1.66628672] f(x) = 0.0011645911389305064 gradient norm = 0.0028844892398119447\n",
      "Iteration 320 : x = [2.01018799 1.66341205] f(x) = 0.0011563374090577444 gradient norm = 0.0028383150878370836\n",
      "Iteration 321 : x = [2.0099532  1.66058346] f(x) = 0.0011483460785215163 gradient norm = 0.0027926921608140455\n",
      "Iteration 322 : x = [2.00972135 1.65780041] f(x) = 0.0011406098432822655 gradient norm = 0.002747619910649463\n",
      "Iteration 323 : x = [2.00949244 1.65506234] f(x) = 0.001133121552991835 gradient norm = 0.002703097577149872\n",
      "Iteration 324 : x = [2.00926644 1.65236871] f(x) = 0.001125874210092116 gradient norm = 0.0026591241936724315\n",
      "Iteration 325 : x = [2.00904335 1.64971896] f(x) = 0.0011188609687979574 gradient norm = 0.002615698592826329\n",
      "Iteration 326 : x = [2.00882316 1.64711254] f(x) = 0.0011120751339704798 gradient norm = 0.0025728194122149814\n",
      "Iteration 327 : x = [2.00860586 1.64454892] f(x) = 0.0011055101598868866 gradient norm = 0.002530485100209403\n",
      "Iteration 328 : x = [2.00839142 1.64202753] f(x) = 0.0010991596489127644 gradient norm = 0.002488693921743413\n",
      "Iteration 329 : x = [2.00817984 1.63954785] f(x) = 0.0010930173500827965 gradient norm = 0.002447443964121694\n",
      "Iteration 330 : x = [2.00797111 1.63710932] f(x) = 0.0010870771575957078 gradient norm = 0.002406733142832105\n",
      "Iteration 331 : x = [2.00776519 1.63471141] f(x) = 0.0010813331092291514 gradient norm = 0.0023665592073538514\n",
      "Iteration 332 : x = [2.00756209 1.63235359] f(x) = 0.001075779384680128 gradient norm = 0.002326919746953615\n",
      "Iteration 333 : x = [2.00736177 1.63003531] f(x) = 0.001070410303836413 gradient norm = 0.0022878121964619545\n",
      "Iteration 334 : x = [2.00716423 1.62775604] f(x) = 0.0010652203249843356 gradient norm = 0.002249233842022749\n",
      "Iteration 335 : x = [2.00696944 1.62551525] f(x) = 0.0010602040429581077 gradient norm = 0.002211181826808723\n",
      "Iteration 336 : x = [2.00677739 1.62331243] f(x) = 0.0010553561872357696 gradient norm = 0.002173653156696457\n",
      "Iteration 337 : x = [2.00658806 1.62114704] f(x) = 0.0010506716199866757 gradient norm = 0.002136644705894709\n",
      "Iteration 338 : x = [2.00640143 1.61901856] f(x) = 0.0010461453340752768 gradient norm = 0.002100153222520097\n",
      "Iteration 339 : x = [2.00621747 1.61692648] f(x) = 0.0010417724510258233 gradient norm = 0.0020641753341146137\n",
      "Iteration 340 : x = [2.00603617 1.61487028] f(x) = 0.0010375482189524448 gradient norm = 0.002028707553099813\n",
      "Iteration 341 : x = [2.0058575  1.61284945] f(x) = 0.0010334680104589036 gradient norm = 0.0019937462821627097\n",
      "Iteration 342 : x = [2.00568144 1.6108635 ] f(x) = 0.001029527320512172 gradient norm = 0.001959287819568942\n",
      "Iteration 343 : x = [2.00550798 1.6089119 ] f(x) = 0.0010257217642938093 gradient norm = 0.0019253283643989273\n",
      "Iteration 344 : x = [2.00533709 1.60699417] f(x) = 0.0010220470750329652 gradient norm = 0.0018918640217031333\n",
      "Iteration 345 : x = [2.00516874 1.60510982] f(x) = 0.0010184991018246667 gradient norm = 0.0018588908075728586\n",
      "Iteration 346 : x = [2.00500291 1.60325834] f(x) = 0.001015073807436894 gradient norm = 0.0018264046541232467\n",
      "Iteration 347 : x = [2.00483959 1.60143925] f(x) = 0.0010117672661097905 gradient norm = 0.001794401414385581\n",
      "Iteration 348 : x = [2.00467874 1.59965207] f(x) = 0.0010085756613501854 gradient norm = 0.0017628768671060738\n",
      "Iteration 349 : x = [2.00452034 1.59789632] f(x) = 0.0010054952837244703 gradient norm = 0.0017318267214488133\n",
      "Iteration 350 : x = [2.00436437 1.59617153] f(x) = 0.0010025225286527004 gradient norm = 0.001701246621600677\n",
      "Iteration 351 : x = [2.00421081 1.59447723] f(x) = 0.0009996538942066435 gradient norm = 0.0016711321512763058\n",
      "Iteration 352 : x = [2.00405962 1.59281295] f(x) = 0.0009968859789143644 gradient norm = 0.0016414788381215349\n",
      "Iteration 353 : x = [2.00391079 1.59117824] f(x) = 0.000994215479573761 gradient norm = 0.0016122821580138553\n",
      "Iteration 354 : x = [2.00376429 1.58957262] f(x) = 0.0009916391890773583 gradient norm = 0.0015835375392587502\n",
      "Iteration 355 : x = [2.00362009 1.58799567] f(x) = 0.000989153994250495 gradient norm = 0.0015552403666809734\n",
      "Iteration 356 : x = [2.00347817 1.58644691] f(x) = 0.0009867568737049232 gradient norm = 0.001527385985610024\n",
      "Iteration 357 : x = [2.00333851 1.58492593] f(x) = 0.0009844448957096986 gradient norm = 0.0014999697057593215\n",
      "Iteration 358 : x = [2.00320107 1.58343227] f(x) = 0.00098221521608112 gradient norm = 0.0014729868049987267\n",
      "Iteration 359 : x = [2.00306584 1.5819655 ] f(x) = 0.0009800650760933348 gradient norm = 0.0014464325330202728\n",
      "Iteration 360 : x = [2.00293278 1.5805252 ] f(x) = 0.000977991800411123 gradient norm = 0.0014203021148971508\n",
      "Iteration 361 : x = [2.00280188 1.57911094] f(x) = 0.0009759927950462508 gradient norm = 0.0013945907545361428\n",
      "Iteration 362 : x = [2.0026731  1.57772231] f(x) = 0.0009740655453386621 gradient norm = 0.0013692936380238477\n",
      "Iteration 363 : x = [2.00254643 1.57635889] f(x) = 0.0009722076139636826 gradient norm = 0.0013444059368672226\n",
      "Iteration 364 : x = [2.00242183 1.57502027] f(x) = 0.0009704166389662912 gradient norm = 0.0013199228111290804\n",
      "Iteration 365 : x = [2.00229928 1.57370605] f(x) = 0.0009686903318234261 gradient norm = 0.0012958394124593013\n",
      "Iteration 366 : x = [2.00217875 1.57241583] f(x) = 0.0009670264755351855 gradient norm = 0.0012721508870226833\n",
      "Iteration 367 : x = [2.00206022 1.57114921] f(x) = 0.0009654229227456942 gradient norm = 0.0012488523783244282\n",
      "Iteration 368 : x = [2.00194367 1.56990581] f(x) = 0.0009638775938943219 gradient norm = 0.0012259390299343691\n",
      "Iteration 369 : x = [2.00182906 1.56868524] f(x) = 0.0009623884753978469 gradient norm = 0.0012034059881111847\n",
      "Iteration 370 : x = [2.00171637 1.56748712] f(x) = 0.0009609536178640848 gradient norm = 0.0011812484043278828\n",
      "Iteration 371 : x = [2.00160558 1.56631108] f(x) = 0.0009595711343374213 gradient norm = 0.001159461437699942\n",
      "Iteration 372 : x = [2.00149666 1.56515674] f(x) = 0.0009582391985766131 gradient norm = 0.0011380402573176027\n",
      "Iteration 373 : x = [2.00138959 1.56402375] f(x) = 0.0009569560433651604 gradient norm = 0.0011169800444837947\n",
      "Iteration 374 : x = [2.00128433 1.56291174] f(x) = 0.0009557199588544735 gradient norm = 0.0010962759948593527\n",
      "Iteration 375 : x = [2.00118088 1.56182036] f(x) = 0.0009545292909400094 gradient norm = 0.0010759233205171255\n",
      "Iteration 376 : x = [2.00107919 1.56074925] f(x) = 0.000953382439670487 gradient norm = 0.0010559172519066995\n",
      "Iteration 377 : x = [2.00097925 1.55969807] f(x) = 0.0009522778576902335 gradient norm = 0.0010362530397315063\n",
      "Iteration 378 : x = [2.00088103 1.55866649] f(x) = 0.0009512140487146658 gradient norm = 0.0010169259567400606\n",
      "Iteration 379 : x = [2.00078451 1.55765415] f(x) = 0.0009501895660388631 gradient norm = 0.000997931299433157\n",
      "Iteration 380 : x = [2.00068967 1.55666074] f(x) = 0.0009492030110791343 gradient norm = 0.0009792643896888904\n",
      "Iteration 381 : x = [2.00059647 1.55568592] f(x) = 0.0009482530319474512 gradient norm = 0.0009609205763073716\n",
      "Iteration 382 : x = [2.00050489 1.55472937] f(x) = 0.0009473383220585646 gradient norm = 0.0009428952364769695\n",
      "Iteration 383 : x = [2.00041492 1.55379078] f(x) = 0.0009464576187696016 gradient norm = 0.000925183777164085\n",
      "Iteration 384 : x = [2.00032653 1.55286983] f(x) = 0.0009456097020518899 gradient norm = 0.0009077816364282559\n",
      "Iteration 385 : x = [2.00023969 1.55196621] f(x) = 0.0009447933931947328 gradient norm = 0.0008906842846645923\n",
      "Iteration 386 : x = [2.00015438 1.55107962] f(x) = 0.000944007553540835 gradient norm = 0.0008738872257754468\n",
      "Iteration 387 : x = [2.00007058 1.55020976] f(x) = 0.0009432510832530293 gradient norm = 0.0008573859982732102\n",
      "Iteration 388 : x = [1.99998826 1.54935633] f(x) = 0.0009425229201119636 gradient norm = 0.0008411761763161857\n",
      "Iteration 389 : x = [1.99990741 1.54851905] f(x) = 0.0009418220383443531 gradient norm = 0.0008252533706794348\n",
      "Iteration 390 : x = [1.999828   1.54769763] f(x) = 0.0009411474474814008 gradient norm = 0.000809613229662484\n",
      "Iteration 391 : x = [1.99975    1.54689178] f(x) = 0.0009404981912469699 gradient norm = 0.0007942514399358128\n",
      "Iteration 392 : x = [1.9996734  1.54610123] f(x) = 0.0009398733464750621 gradient norm = 0.0007791637273279628\n",
      "Iteration 393 : x = [1.99959818 1.54532571] f(x) = 0.0009392720220561614 gradient norm = 0.0007643458575551255\n",
      "Iteration 394 : x = [1.9995243  1.54456494] f(x) = 0.0009386933579119701 gradient norm = 0.0007497936368950928\n",
      "Iteration 395 : x = [1.99945176 1.54381866] f(x) = 0.0009381365239980655 gradient norm = 0.0007355029128072859\n",
      "Iteration 396 : x = [1.99938053 1.54308662] f(x) = 0.0009376007193339908 gradient norm = 0.0007214695745007679\n",
      "Iteration 397 : x = [1.99931059 1.54236855] f(x) = 0.0009370851710602861 gradient norm = 0.0007076895534519212\n",
      "Iteration 398 : x = [1.99924192 1.5416642 ] f(x) = 0.0009365891335219615 gradient norm = 0.0006941588238735965\n",
      "Iteration 399 : x = [1.99917449 1.54097332] f(x) = 0.0009361118873778975 gradient norm = 0.000680873403137367\n",
      "Iteration 400 : x = [1.9991083  1.54029567] f(x) = 0.0009356527387356699 gradient norm = 0.0006678293521506653\n",
      "Iteration 401 : x = [1.99904331 1.53963101] f(x) = 0.0009352110183112838 gradient norm = 0.0006550227756903931\n",
      "Iteration 402 : x = [1.99897951 1.53897911] f(x) = 0.0009347860806132899 gradient norm = 0.0006424498226946373\n",
      "Iteration 403 : x = [1.99891688 1.53833972] f(x) = 0.0009343773031507802 gradient norm = 0.0006301066865141374\n",
      "Iteration 404 : x = [1.9988554  1.53771262] f(x) = 0.0009339840856647324 gradient norm = 0.0006179896051249867\n",
      "Iteration 405 : x = [1.99879505 1.53709758] f(x) = 0.0009336058493821882 gradient norm = 0.0006060948613041552\n",
      "Iteration 406 : x = [1.99873581 1.53649439] f(x) = 0.0009332420362927544 gradient norm = 0.0005944187827693369\n",
      "Iteration 407 : x = [1.99867766 1.53590282] f(x) = 0.0009328921084469009 gradient norm = 0.0005829577422845213\n",
      "Iteration 408 : x = [1.99862059 1.53532266] f(x) = 0.0009325555472755552 gradient norm = 0.000571708157732789\n",
      "Iteration 409 : x = [1.99856458 1.5347537 ] f(x) = 0.0009322318529304768 gradient norm = 0.0005606664921576734\n",
      "Iteration 410 : x = [1.9985096  1.53419574] f(x) = 0.0009319205436449092 gradient norm = 0.0005498292537745023\n",
      "Iteration 411 : x = [1.99845565 1.53364856] f(x) = 0.0009316211551140149 gradient norm = 0.0005391929959530105\n",
      "Iteration 412 : x = [1.9984027  1.53311198] f(x) = 0.0009313332398945858 gradient norm = 0.0005287543171724964\n",
      "Iteration 413 : x = [1.99835074 1.53258578] f(x) = 0.000931056366823554 gradient norm = 0.0005185098609508508\n",
      "Iteration 414 : x = [1.99829975 1.53206979] f(x) = 0.0009307901204548084 gradient norm = 0.0005084563157486186\n",
      "Iteration 415 : x = [1.99824971 1.5315638 ] f(x) = 0.000930534100513846 gradient norm = 0.0004985904148493048\n",
      "Iteration 416 : x = [1.99820061 1.53106763] f(x) = 0.0009302879213697857 gradient norm = 0.00048890893621711\n",
      "Iteration 417 : x = [1.99815243 1.5305811 ] f(x) = 0.0009300512115242765 gradient norm = 0.0004794087023331678\n",
      "Iteration 418 : x = [1.99810515 1.53010403] f(x) = 0.0009298236131168508 gradient norm = 0.0004700865800114115\n",
      "Iteration 419 : x = [1.99805876 1.52963624] f(x) = 0.0009296047814462699 gradient norm = 0.0004609394801951214\n",
      "Iteration 420 : x = [1.99801325 1.52917755] f(x) = 0.0009293943845074155 gradient norm = 0.00045196435773518404\n",
      "Iteration 421 : x = [1.99796859 1.5287278 ] f(x) = 0.0009291921025433048 gradient norm = 0.00044315821115103993\n",
      "Iteration 422 : x = [1.99792478 1.52828681] f(x) = 0.0009289976276117886 gradient norm = 0.0004345180823752852\n",
      "Iteration 423 : x = [1.99788179 1.52785442] f(x) = 0.0009288106631665283 gradient norm = 0.0004260410564828759\n",
      "Iteration 424 : x = [1.99783962 1.52743047] f(x) = 0.0009286309236518314 gradient norm = 0.00041772426140584056\n",
      "Iteration 425 : x = [1.99779825 1.5270148 ] f(x) = 0.0009284581341109525 gradient norm = 0.00040956486763430724\n",
      "Iteration 426 : x = [1.99775766 1.52660726] f(x) = 0.0009282920298074581 gradient norm = 0.00040156008790480477\n",
      "Iteration 427 : x = [1.99771785 1.52620767] f(x) = 0.0009281323558592777 gradient norm = 0.000393707176876513\n",
      "Iteration 428 : x = [1.99767879 1.52581591] f(x) = 0.0009279788668850607 gradient norm = 0.00038600343079634917\n",
      "Iteration 429 : x = [1.99764047 1.52543181] f(x) = 0.0009278313266624708 gradient norm = 0.00037844618715363683\n",
      "Iteration 430 : x = [1.99760289 1.52505524] f(x) = 0.0009276895077980618 gradient norm = 0.00037103282432498927\n",
      "Iteration 431 : x = [1.99756602 1.52468604] f(x) = 0.0009275531914083763 gradient norm = 0.0003637607612102421\n",
      "Iteration 432 : x = [1.99752986 1.52432408] f(x) = 0.0009274221668119321 gradient norm = 0.00035662745686002874\n",
      "Iteration 433 : x = [1.99749438 1.52396922] f(x) = 0.0009272962312317559 gradient norm = 0.00034963041009566356\n",
      "Iteration 434 : x = [1.99745959 1.52362133] f(x) = 0.0009271751895081373 gradient norm = 0.00034276715912196957\n",
      "Iteration 435 : x = [1.99742546 1.52328026] f(x) = 0.0009270588538212905 gradient norm = 0.0003360352811336406\n",
      "Iteration 436 : x = [1.99739199 1.5229459 ] f(x) = 0.0009269470434236041 gradient norm = 0.0003294323919157443\n",
      "Iteration 437 : x = [1.99735916 1.52261811] f(x) = 0.0009268395843811824 gradient norm = 0.0003229561454388516\n",
      "Iteration 438 : x = [1.99732697 1.52229676] f(x) = 0.0009267363093243851 gradient norm = 0.0003166042334494217\n",
      "Iteration 439 : x = [1.99729539 1.52198173] f(x) = 0.0009266370572070674 gradient norm = 0.0003103743850558503\n",
      "Iteration 440 : x = [1.99726442 1.52167291] f(x) = 0.000926541673074258 gradient norm = 0.0003042643663107623\n",
      "Iteration 441 : x = [1.99723404 1.52137017] f(x) = 0.0009264500078379855 gradient norm = 0.0002982719797899567\n",
      "Iteration 442 : x = [1.99720425 1.52107338] f(x) = 0.0009263619180610019 gradient norm = 0.00029239506416847206\n",
      "Iteration 443 : x = [1.99717504 1.52078245] f(x) = 0.0009262772657481393 gradient norm = 0.00028663149379416737\n",
      "Iteration 444 : x = [1.99714639 1.52049726] f(x) = 0.0009261959181450517 gradient norm = 0.0002809791782593292\n",
      "Iteration 445 : x = [1.99711829 1.52021769] f(x) = 0.0009261177475440986 gradient norm = 0.0002754360619705462\n",
      "Iteration 446 : x = [1.99709074 1.51994363] f(x) = 0.0009260426310971337 gradient norm = 0.00027000012371736443\n",
      "Iteration 447 : x = [1.99706373 1.51967499] f(x) = 0.0009259704506349734 gradient norm = 0.00026466937623997617\n",
      "Iteration 448 : x = [1.99703723 1.51941165] f(x) = 0.0009259010924933149 gradient norm = 0.00025944186579634836\n",
      "Iteration 449 : x = [1.99701125 1.51915351] f(x) = 0.0009258344473448946 gradient norm = 0.00025431567172907397\n",
      "Iteration 450 : x = [1.99698577 1.51890047] f(x) = 0.0009257704100376753 gradient norm = 0.0002492889060322739\n",
      "Iteration 451 : x = [1.99696079 1.51865244] f(x) = 0.0009257088794388568 gradient norm = 0.0002443597129188313\n",
      "Iteration 452 : x = [1.9969363  1.51840931] f(x) = 0.0009256497582845145 gradient norm = 0.00023952626838825004\n",
      "Iteration 453 : x = [1.99691228 1.51817099] f(x) = 0.0009255929530346725 gradient norm = 0.0002347867797953671\n",
      "Iteration 454 : x = [1.99688873 1.51793739] f(x) = 0.0009255383737336312 gradient norm = 0.00023013948542021864\n",
      "Iteration 455 : x = [1.99686563 1.51770841] f(x) = 0.0009254859338753585 gradient norm = 0.00022558265403923707\n",
      "Iteration 456 : x = [1.99684299 1.51748397] f(x) = 0.0009254355502737869 gradient norm = 0.00022111458449806525\n",
      "Iteration 457 : x = [1.99682079 1.51726397] f(x) = 0.0009253871429378266 gradient norm = 0.00021673360528615555\n",
      "Iteration 458 : x = [1.99679902 1.51704833] f(x) = 0.0009253406349509521 gradient norm = 0.00021243807411333766\n",
      "Iteration 459 : x = [1.99677768 1.51683697] f(x) = 0.0009252959523551897 gradient norm = 0.00020822637748862212\n",
      "Iteration 460 : x = [1.99675675 1.5166298 ] f(x) = 0.0009252530240393543 gradient norm = 0.0002040969303013176\n",
      "Iteration 461 : x = [1.99673623 1.51642673] f(x) = 0.0009252117816313972 gradient norm = 0.00020004817540470257\n",
      "Iteration 462 : x = [1.99671612 1.5162277 ] f(x) = 0.0009251721593947052 gradient norm = 0.00019607858320237054\n",
      "Iteration 463 : x = [1.9966964  1.51603261] f(x) = 0.0009251340941282265 gradient norm = 0.00019218665123740141\n",
      "Iteration 464 : x = [1.99667706 1.5158414 ] f(x) = 0.0009250975250702762 gradient norm = 0.0001883709037845021\n",
      "Iteration 465 : x = [1.9966581  1.51565399] f(x) = 0.0009250623938059045 gradient norm = 0.000184629891445244\n",
      "Iteration 466 : x = [1.99663952 1.5154703 ] f(x) = 0.0009250286441776898 gradient norm = 0.0001809621907465044\n",
      "Iteration 467 : x = [1.9966213  1.51529025] f(x) = 0.0009249962221998378 gradient norm = 0.00017736640374223735\n",
      "Iteration 468 : x = [1.99660344 1.51511379] f(x) = 0.0009249650759754772 gradient norm = 0.00017384115761867342\n",
      "Iteration 469 : x = [1.99658592 1.51494083] f(x) = 0.0009249351556170267 gradient norm = 0.0001703851043030251\n",
      "Iteration 470 : x = [1.99656876 1.51477131] f(x) = 0.0009249064131695258 gradient norm = 0.000166996920075824\n",
      "Iteration 471 : x = [1.99655193 1.51460517] f(x) = 0.0009248788025368317 gradient norm = 0.00016367530518692375\n",
      "Iteration 472 : x = [1.99653543 1.51444233] f(x) = 0.0009248522794105685 gradient norm = 0.00016041898347528\n",
      "Iteration 473 : x = [1.99651925 1.51428272] f(x) = 0.0009248268012017339 gradient norm = 0.00015722670199255225\n",
      "Iteration 474 : x = [1.9965034 1.5141263] f(x) = 0.0009248023269748692 gradient norm = 0.00015409723063059997\n",
      "Iteration 475 : x = [1.99648785 1.51397299] f(x) = 0.0009247788173846949 gradient norm = 0.0001510293617529278\n",
      "Iteration 476 : x = [1.99647261 1.51382273] f(x) = 0.0009247562346151297 gradient norm = 0.0001480219098301174\n",
      "Iteration 477 : x = [1.99645768 1.51367546] f(x) = 0.0009247345423205996 gradient norm = 0.0001450737110793085\n",
      "Iteration 478 : x = [1.99644303 1.51353113] f(x) = 0.0009247137055695532 gradient norm = 0.00014218362310773378\n",
      "Iteration 479 : x = [1.99642868 1.51338967] f(x) = 0.0009246936907901138 gradient norm = 0.00013935052456041773\n",
      "Iteration 480 : x = [1.99641461 1.51325103] f(x) = 0.0009246744657177721 gradient norm = 0.0001365733147719551\n",
      "Iteration 481 : x = [1.99640081 1.51311516] f(x) = 0.0009246559993450638 gradient norm = 0.000133850913422496\n",
      "Iteration 482 : x = [1.99638729 1.51298199] f(x) = 0.0009246382618731426 gradient norm = 0.00013118226019789506\n",
      "Iteration 483 : x = [1.99637404 1.51285148] f(x) = 0.0009246212246651914 gradient norm = 0.00012856631445408995\n",
      "Iteration 484 : x = [1.99636105 1.51272357] f(x) = 0.0009246048602015978 gradient norm = 0.00012600205488566278\n",
      "Iteration 485 : x = [1.99634831 1.51259822] f(x) = 0.0009245891420368277 gradient norm = 0.00012348847919864853\n",
      "Iteration 486 : x = [1.99633583 1.51247536] f(x) = 0.0009245740447579414 gradient norm = 0.00012102460378756535\n",
      "Iteration 487 : x = [1.99632359 1.51235496] f(x) = 0.0009245595439446812 gradient norm = 0.00011860946341667956\n",
      "Iteration 488 : x = [1.9963116  1.51223696] f(x) = 0.0009245456161310809 gradient norm = 0.00011624211090548277\n",
      "Iteration 489 : x = [1.99629984 1.51212131] f(x) = 0.000924532238768539 gradient norm = 0.0001139216168184338\n",
      "Iteration 490 : x = [1.99628832 1.51200797] f(x) = 0.0009245193901902942 gradient norm = 0.00011164706915889017\n",
      "Iteration 491 : x = [1.99627702 1.5118969 ] f(x) = 0.0009245070495772618 gradient norm = 0.00010941757306723889\n",
      "Iteration 492 : x = [1.99626595 1.51178804] f(x) = 0.0009244951969251733 gradient norm = 0.00010723225052327936\n",
      "Iteration 493 : x = [1.9962551  1.51168136] f(x) = 0.0009244838130129693 gradient norm = 0.00010509024005272214\n",
      "Iteration 494 : x = [1.99624446 1.51157681] f(x) = 0.0009244728793724057 gradient norm = 0.00010299069643789897\n",
      "Iteration 495 : x = [1.99623404 1.51147435] f(x) = 0.000924462378258822 gradient norm = 0.00010093279043262443\n",
      "Iteration 496 : x = [1.99622382 1.51137393] f(x) = 0.0009244522926230281 gradient norm = 9.891570848113914e-05\n",
      "Iteration 497 : x = [1.9962138  1.51127553] f(x) = 0.0009244426060842734 gradient norm = 9.693865244122436e-05\n",
      "Iteration 498 : x = [1.99620399 1.51117909] f(x) = 0.0009244333029042495 gradient norm = 9.5000839311333e-05\n",
      "Iteration 499 : x = [1.99619437 1.51108457] f(x) = 0.0009244243679620927 gradient norm = 9.31015009618214e-05\n",
      "Iteration 500 : x = [1.99618493 1.51099195] f(x) = 0.0009244157867303489 gradient norm = 9.123988387018975e-05\n",
      "Iteration 501 : x = [1.99617569 1.51090118] f(x) = 0.0009244075452518621 gradient norm = 8.941524886031923e-05\n",
      "Iteration 502 : x = [1.99616663 1.51081223] f(x) = 0.0009243996301175517 gradient norm = 8.762687084568687e-05\n",
      "Iteration 503 : x = [1.99615775 1.51072505] f(x) = 0.0009243920284450469 gradient norm = 8.58740385765076e-05\n",
      "Iteration 504 : x = [1.99614905 1.51063962] f(x) = 0.0009243847278581465 gradient norm = 8.41560543907883e-05\n",
      "Iteration 505 : x = [1.99614052 1.5105559 ] f(x) = 0.0009243777164670673 gradient norm = 8.24722339692457e-05\n",
      "Iteration 506 : x = [1.99613216 1.51047385] f(x) = 0.0009243709828494586 gradient norm = 8.082190609406775e-05\n",
      "Iteration 507 : x = [1.99612396 1.51039344] f(x) = 0.0009243645160321481 gradient norm = 7.920441241147691e-05\n",
      "Iteration 508 : x = [1.99611593 1.51031465] f(x) = 0.0009243583054735938 gradient norm = 7.761910719802744e-05\n",
      "Iteration 509 : x = [1.99610806 1.51023743] f(x) = 0.0009243523410470157 gradient norm = 7.606535713068508e-05\n",
      "Iteration 510 : x = [1.99610035 1.51016175] f(x) = 0.0009243466130241779 gradient norm = 7.454254106054297e-05\n",
      "Iteration 511 : x = [1.99609279 1.5100876 ] f(x) = 0.0009243411120598016 gradient norm = 7.305004979021713e-05\n",
      "Iteration 512 : x = [1.99608538 1.51001492] f(x) = 0.00092433582917658 gradient norm = 7.158728585485596e-05\n",
      "Iteration 513 : x = [1.99607811 1.5099437 ] f(x) = 0.0009243307557507767 gradient norm = 7.015366330668892e-05\n",
      "Iteration 514 : x = [1.996071   1.50987391] f(x) = 0.0009243258834983781 gradient norm = 6.874860750314707e-05\n",
      "Iteration 515 : x = [1.99606402 1.50980552] f(x) = 0.0009243212044617884 gradient norm = 6.737155489846281e-05\n",
      "Iteration 516 : x = [1.99605718 1.5097385 ] f(x) = 0.0009243167109970392 gradient norm = 6.602195283869988e-05\n",
      "Iteration 517 : x = [1.99605048 1.50967281] f(x) = 0.0009243123957614944 gradient norm = 6.469925936022648e-05\n",
      "Iteration 518 : x = [1.99604392 1.50960845] f(x) = 0.0009243082517020362 gradient norm = 6.340294299153525e-05\n",
      "Iteration 519 : x = [1.99603748 1.50954537] f(x) = 0.0009243042720437092 gradient norm = 6.213248255839889e-05\n",
      "Iteration 520 : x = [1.99603117 1.50948356] f(x) = 0.0009243004502788043 gradient norm = 6.0887366992300964e-05\n",
      "Iteration 521 : x = [1.99602499 1.50942299] f(x) = 0.0009242967801563725 gradient norm = 5.966709514214031e-05\n",
      "Iteration 522 : x = [1.99601893 1.50936363] f(x) = 0.0009242932556721422 gradient norm = 5.847117558908774e-05\n",
      "Iteration 523 : x = [1.996013   1.50930546] f(x) = 0.0009242898710588318 gradient norm = 5.7299126464663436e-05\n",
      "Iteration 524 : x = [1.99600718 1.50924846] f(x) = 0.000924286620776841 gradient norm = 5.6150475271888105e-05\n",
      "Iteration 525 : x = [1.99600148 1.5091926 ] f(x) = 0.0009242834995053023 gradient norm = 5.502475870952242e-05\n",
      "Iteration 526 : x = [1.99599589 1.50913786] f(x) = 0.0009242805021334836 gradient norm = 5.392152249935931e-05\n",
      "Iteration 527 : x = [1.99599041 1.50908422] f(x) = 0.0009242776237525279 gradient norm = 5.284032121648522e-05\n",
      "Iteration 528 : x = [1.99598504 1.50903165] f(x) = 0.0009242748596475106 gradient norm = 5.178071812250486e-05\n",
      "Iteration 529 : x = [1.99597978 1.50898014] f(x) = 0.0009242722052898138 gradient norm = 5.074228500167832e-05\n",
      "Iteration 530 : x = [1.99597463 1.50892966] f(x) = 0.0009242696563297928 gradient norm = 4.972460199992702e-05\n",
      "Iteration 531 : x = [1.99596958 1.50888019] f(x) = 0.0009242672085897332 gradient norm = 4.872725746666306e-05\n",
      "Iteration 532 : x = [1.99596462 1.50883171] f(x) = 0.0009242648580570808 gradient norm = 4.7749847799410285e-05\n",
      "Iteration 533 : x = [1.99595977 1.50878421] f(x) = 0.0009242626008779395 gradient norm = 4.679197729116292e-05\n",
      "Iteration 534 : x = [1.99595502 1.50873766] f(x) = 0.0009242604333508206 gradient norm = 4.58532579804636e-05\n",
      "Iteration 535 : x = [1.99595036 1.50869205] f(x) = 0.0009242583519206387 gradient norm = 4.493330950413756e-05\n",
      "Iteration 536 : x = [1.99594579 1.50864734] f(x) = 0.0009242563531729421 gradient norm = 4.40317589526574e-05\n",
      "Iteration 537 : x = [1.99594132 1.50860354] f(x) = 0.0009242544338283712 gradient norm = 4.3148240728085145e-05\n",
      "Iteration 538 : x = [1.99593693 1.50856062] f(x) = 0.0009242525907373296 gradient norm = 4.2282396404587655e-05\n",
      "Iteration 539 : x = [1.99593263 1.50851855] f(x) = 0.0009242508208748695 gradient norm = 4.143387459139639e-05\n",
      "Iteration 540 : x = [1.99592842 1.50847733] f(x) = 0.0009242491213357757 gradient norm = 4.060233079833333e-05\n",
      "Iteration 541 : x = [1.99592429 1.50843694] f(x) = 0.0009242474893298386 gradient norm = 3.9787427303666324e-05\n",
      "Iteration 542 : x = [1.99592025 1.50839736] f(x) = 0.0009242459221773216 gradient norm = 3.898883302442159e-05\n",
      "Iteration 543 : x = [1.99591628 1.50835857] f(x) = 0.0009242444173045965 gradient norm = 3.8206223389045956e-05\n",
      "Iteration 544 : x = [1.9959124  1.50832057] f(x) = 0.000924242972239958 gradient norm = 3.7439280212337544e-05\n",
      "Iteration 545 : x = [1.99590859 1.50828332] f(x) = 0.0009242415846095978 gradient norm = 3.6687691572719226e-05\n",
      "Iteration 546 : x = [1.99590486 1.50824682] f(x) = 0.0009242402521337401 gradient norm = 3.595115169170668e-05\n",
      "Iteration 547 : x = [1.9959012  1.50821106] f(x) = 0.0009242389726229266 gradient norm = 3.5229360815622305e-05\n",
      "Iteration 548 : x = [1.99589762 1.50817601] f(x) = 0.0009242377439744503 gradient norm = 3.452202509944734e-05\n",
      "Iteration 549 : x = [1.99589411 1.50814167] f(x) = 0.0009242365641689261 gradient norm = 3.382885649282829e-05\n",
      "Iteration 550 : x = [1.99589067 1.50810801] f(x) = 0.0009242354312669997 gradient norm = 3.314957262817601e-05\n",
      "Iteration 551 : x = [1.9958873  1.50807504] f(x) = 0.0009242343434061827 gradient norm = 3.24838967108419e-05\n",
      "Iteration 552 : x = [1.99588399 1.50804272] f(x) = 0.0009242332987978155 gradient norm = 3.1831557411305665e-05\n",
      "Iteration 553 : x = [1.99588075 1.50801106] f(x) = 0.0009242322957241494 gradient norm = 3.1192288759385125e-05\n",
      "Iteration 554 : x = [1.99587758 1.50798002] f(x) = 0.0009242313325355388 gradient norm = 3.056583004038077e-05\n",
      "Iteration 555 : x = [1.99587447 1.50794962] f(x) = 0.0009242304076477518 gradient norm = 2.9951925693191312e-05\n",
      "Iteration 556 : x = [1.99587142 1.50791982] f(x) = 0.0009242295195393809 gradient norm = 2.935032521028151e-05\n",
      "Iteration 557 : x = [1.99586844 1.50789062] f(x) = 0.0009242286667493571 gradient norm = 2.8760783039551693e-05\n",
      "Iteration 558 : x = [1.99586551 1.50786201] f(x) = 0.0009242278478745642 gradient norm = 2.8183058488034756e-05\n",
      "Iteration 559 : x = [1.99586264 1.50783397] f(x) = 0.000924227061567543 gradient norm = 2.7616915627371945e-05\n",
      "Iteration 560 : x = [1.99585983 1.5078065 ] f(x) = 0.0009242263065342915 gradient norm = 2.7062123201106417e-05\n",
      "Iteration 561 : x = [1.99585708 1.50777958] f(x) = 0.0009242255815321457 gradient norm = 2.651845453366067e-05\n",
      "Iteration 562 : x = [1.99585438 1.5077532 ] f(x) = 0.00092422488536775 gradient norm = 2.5985687441082526e-05\n",
      "Iteration 563 : x = [1.99585174 1.50772735] f(x) = 0.0009242242168951026 gradient norm = 2.5463604143432252e-05\n",
      "Iteration 564 : x = [1.99584915 1.50770202] f(x) = 0.0009242235750136817 gradient norm = 2.495199117884742e-05\n",
      "Iteration 565 : x = [1.99584661 1.50767719] f(x) = 0.0009242229586666443 gradient norm = 2.445063931920115e-05\n",
      "Iteration 566 : x = [1.99584412 1.50765287] f(x) = 0.0009242223668390946 gradient norm = 2.3959343487396104e-05\n",
      "Iteration 567 : x = [1.99584168 1.50762904] f(x) = 0.0009242217985564237 gradient norm = 2.3477902676183576e-05\n",
      "Iteration 568 : x = [1.99583929 1.50760568] f(x) = 0.000924221252882714 gradient norm = 2.3006119868563622e-05\n",
      "Iteration 569 : x = [1.99583695 1.50758279] f(x) = 0.000924220728919204 gradient norm = 2.2543801959652685e-05\n",
      "Iteration 570 : x = [1.99583465 1.50756037] f(x) = 0.0009242202258028172 gradient norm = 2.2090759680064237e-05\n",
      "Iteration 571 : x = [1.9958324  1.50753839] f(x) = 0.000924219742704748 gradient norm = 2.1646807520758058e-05\n",
      "Iteration 572 : x = [1.9958302  1.50751686] f(x) = 0.0009242192788291035 gradient norm = 2.121176365928737e-05\n",
      "Iteration 573 : x = [1.99582804 1.50749575] f(x) = 0.000924218833411596 gradient norm = 2.0785449887478604e-05\n",
      "Iteration 574 : x = [1.99582593 1.50747508] f(x) = 0.0009242184057182952 gradient norm = 2.036769154049248e-05\n",
      "Iteration 575 : x = [1.99582385 1.50745482] f(x) = 0.0009242179950444188 gradient norm = 1.99583174272212e-05\n",
      "Iteration 576 : x = [1.99582182 1.50743496] f(x) = 0.0009242176007131814 gradient norm = 1.955715976204225e-05\n",
      "Iteration 577 : x = [1.99581983 1.5074155 ] f(x) = 0.00092421722207468 gradient norm = 1.9164054097867284e-05\n",
      "Iteration 578 : x = [1.99581788 1.50739644] f(x) = 0.0009242168585048328 gradient norm = 1.8778839260478654e-05\n",
      "Iteration 579 : x = [1.99581597 1.50737776] f(x) = 0.0009242165094043497 gradient norm = 1.8401357284120613e-05\n",
      "Iteration 580 : x = [1.99581409 1.50735945] f(x) = 0.000924216174197752 gradient norm = 1.8031453348346592e-05\n",
      "Iteration 581 : x = [1.99581226 1.50734152] f(x) = 0.0009242158523324273 gradient norm = 1.7668975716056095e-05\n",
      "Iteration 582 : x = [1.99581046 1.50732394] f(x) = 0.0009242155432777216 gradient norm = 1.7313775672747863e-05\n",
      "Iteration 583 : x = [1.99580869 1.50730671] f(x) = 0.0009242152465240686 gradient norm = 1.696570746692107e-05\n",
      "Iteration 584 : x = [1.99580697 1.50728984] f(x) = 0.000924214961582152 gradient norm = 1.66246282516564e-05\n",
      "Iteration 585 : x = [1.99580527 1.5072733 ] f(x) = 0.000924214687982103 gradient norm = 1.629039802730291e-05\n",
      "Iteration 586 : x = [1.99580361 1.50725709] f(x) = 0.0009242144252727273 gradient norm = 1.5962879585266277e-05\n",
      "Iteration 587 : x = [1.99580199 1.50724121] f(x) = 0.0009242141730207654 gradient norm = 1.5641938452913325e-05\n",
      "Iteration 588 : x = [1.9958004  1.50722565] f(x) = 0.0009242139308101781 gradient norm = 1.5327442839523868e-05\n",
      "Iteration 589 : x = [1.99579884 1.50721041] f(x) = 0.0009242136982414656 gradient norm = 1.5019263583274615e-05\n",
      "Iteration 590 : x = [1.99579731 1.50719546] f(x) = 0.0009242134749310084 gradient norm = 1.4717274099298155e-05\n",
      "Iteration 591 : x = [1.99579581 1.50718082] f(x) = 0.0009242132605104396 gradient norm = 1.4421350328699725e-05\n",
      "Iteration 592 : x = [1.99579434 1.50716648] f(x) = 0.000924213054626036 gradient norm = 1.4131370688584414e-05\n",
      "Iteration 593 : x = [1.9957929  1.50715242] f(x) = 0.000924212856938139 gradient norm = 1.3847216023073993e-05\n",
      "Iteration 594 : x = [1.99579149 1.50713864] f(x) = 0.0009242126671205953 gradient norm = 1.3568769555246355e-05\n",
      "Iteration 595 : x = [1.99579011 1.50712515] f(x) = 0.00092421248486022 gradient norm = 1.3295916840018728e-05\n",
      "Iteration 596 : x = [1.99578875 1.50711192] f(x) = 0.0009242123098562816 gradient norm = 1.3028545717970485e-05\n",
      "Iteration 597 : x = [1.99578742 1.50709896] f(x) = 0.0009242121418200086 gradient norm = 1.2766546270037003e-05\n",
      "Iteration 598 : x = [1.99578612 1.50708626] f(x) = 0.0009242119804741131 gradient norm = 1.2509810773096867e-05\n",
      "Iteration 599 : x = [1.99578485 1.50707381] f(x) = 0.0009242118255523336 gradient norm = 1.2258233656432856e-05\n",
      "Iteration 600 : x = [1.9957836  1.50706162] f(x) = 0.0009242116767990001 gradient norm = 1.2011711459031795e-05\n",
      "Iteration 601 : x = [1.99578238 1.50704967] f(x) = 0.0009242115339686101 gradient norm = 1.1770142787742883e-05\n",
      "Iteration 602 : x = [1.99578118 1.50703796] f(x) = 0.0009242113968254272 gradient norm = 1.1533428276219711e-05\n",
      "Iteration 603 : x = [1.99578    1.50702649] f(x) = 0.0009242112651430895 gradient norm = 1.1301470544686903e-05\n",
      "Iteration 604 : x = [1.99577885 1.50701524] f(x) = 0.0009242111387042411 gradient norm = 1.1074174160489176e-05\n",
      "Iteration 605 : x = [1.99577772 1.50700423] f(x) = 0.0009242110173001719 gradient norm = 1.0851445599425702e-05\n",
      "Iteration 606 : x = [1.99577662 1.50699343] f(x) = 0.0009242109007304744 gradient norm = 1.063319320780643e-05\n",
      "Iteration 607 : x = [1.99577554 1.50698285] f(x) = 0.0009242107888027132 gradient norm = 1.0419327165308052e-05\n",
      "Iteration 608 : x = [1.99577447 1.50697249] f(x) = 0.000924210681332109 gradient norm = 1.0209759448504265e-05\n",
      "Iteration 609 : x = [1.99577343 1.50696233] f(x) = 0.0009242105781412344 gradient norm = 1.0004403795142564e-05\n",
      "Iteration 610 : x = [1.99577242 1.50695238] f(x) = 0.0009242104790597205 gradient norm = 9.80317566911804e-06\n",
      "Iteration 611 : x = [1.99577142 1.50694263] f(x) = 0.000924210383923977 gradient norm = 9.605992226128538e-06\n",
      "Iteration 612 : x = [1.99577044 1.50693307] f(x) = 0.0009242102925769227 gradient norm = 9.412772280018046e-06\n",
      "Iteration 613 : x = [1.99576948 1.50692371] f(x) = 0.000924210204867727 gradient norm = 9.223436269763387e-06\n",
      "Iteration 614 : x = [1.99576854 1.50691453] f(x) = 0.0009242101206515609 gradient norm = 9.037906227118215e-06\n",
      "Iteration 615 : x = [1.99576762 1.50690554] f(x) = 0.0009242100397893581 gradient norm = 8.856105744916383e-06\n",
      "Iteration 616 : x = [1.99576672 1.50689673] f(x) = 0.0009242099621475865 gradient norm = 8.677959945954723e-06\n",
      "Iteration 617 : x = [1.99576583 1.5068881 ] f(x) = 0.0009242098875980279 gradient norm = 8.503395452532753e-06\n",
      "Iteration 618 : x = [1.99576497 1.50687964] f(x) = 0.0009242098160175667 gradient norm = 8.332340356570204e-06\n",
      "Iteration 619 : x = [1.99576412 1.50687135] f(x) = 0.0009242097472879865 gradient norm = 8.164724190316022e-06\n",
      "Iteration 620 : x = [1.99576328 1.50686323] f(x) = 0.0009242096812957774 gradient norm = 8.00047789763355e-06\n",
      "Iteration 621 : x = [1.99576247 1.50685527] f(x) = 0.0009242096179319445 gradient norm = 7.83953380586552e-06\n",
      "Iteration 622 : x = [1.99576167 1.50684747] f(x) = 0.000924209557091832 gradient norm = 7.681825598237197e-06\n",
      "Iteration 623 : x = [1.99576089 1.50683983] f(x) = 0.0009242094986749509 gradient norm = 7.527288286815208e-06\n",
      "Iteration 624 : x = [1.99576012 1.50683234] f(x) = 0.0009242094425848101 gradient norm = 7.375858186009499e-06\n",
      "Iteration 625 : x = [1.99575937 1.506825  ] f(x) = 0.0009242093887287593 gradient norm = 7.227472886573627e-06\n",
      "Iteration 626 : x = [1.99575863 1.50681781] f(x) = 0.0009242093370178377 gradient norm = 7.082071230138809e-06\n",
      "Iteration 627 : x = [1.99575791 1.50681077] f(x) = 0.0009242092873666234 gradient norm = 6.939593284258023e-06\n",
      "Iteration 628 : x = [1.9957572  1.50680387] f(x) = 0.000924209239693096 gradient norm = 6.799980317905416e-06\n",
      "Iteration 629 : x = [1.99575651 1.5067971 ] f(x) = 0.0009242091939185005 gradient norm = 6.6631747775248295e-06\n",
      "Iteration 630 : x = [1.99575583 1.50679047] f(x) = 0.0009242091499672159 gradient norm = 6.5291202634900325e-06\n",
      "Iteration 631 : x = [1.99575517 1.50678398] f(x) = 0.0009242091077666323 gradient norm = 6.397761507068215e-06\n",
      "Iteration 632 : x = [1.99575451 1.50677761] f(x) = 0.0009242090672470305 gradient norm = 6.269044347820911e-06\n",
      "Iteration 633 : x = [1.99575388 1.50677138] f(x) = 0.0009242090283414657 gradient norm = 6.142915711472945e-06\n",
      "Iteration 634 : x = [1.99575325 1.50676527] f(x) = 0.0009242089909856597 gradient norm = 6.019323588210405e-06\n",
      "Iteration 635 : x = [1.99575264 1.50675928] f(x) = 0.0009242089551178926 gradient norm = 5.898217011382902e-06\n",
      "Iteration 636 : x = [1.99575204 1.50675341] f(x) = 0.0009242089206789018 gradient norm = 5.779546036691127e-06\n",
      "Iteration 637 : x = [1.99575145 1.50674766] f(x) = 0.0009242088876117839 gradient norm = 5.663261721712561e-06\n",
      "Iteration 638 : x = [1.99575087 1.50674203] f(x) = 0.000924208855861902 gradient norm = 5.549316105903449e-06\n",
      "Iteration 639 : x = [1.9957503  1.50673651] f(x) = 0.0009242088253767943 gradient norm = 5.437662190938202e-06\n",
      "Iteration 640 : x = [1.99574975 1.5067311 ] f(x) = 0.0009242087961060864 gradient norm = 5.328253921477997e-06\n",
      "Iteration 641 : x = [1.99574921 1.5067258 ] f(x) = 0.0009242087680014112 gradient norm = 5.221046166311464e-06\n",
      "Iteration 642 : x = [1.99574867 1.5067206 ] f(x) = 0.000924208741016327 gradient norm = 5.115994699874343e-06\n",
      "Iteration 643 : x = [1.99574815 1.50671551] f(x) = 0.0009242087151062414 gradient norm = 5.013056184095545e-06\n",
      "Iteration 644 : x = [1.99574764 1.50671053] f(x) = 0.0009242086902283373 gradient norm = 4.912188150700311e-06\n",
      "Iteration 645 : x = [1.99574714 1.50670564] f(x) = 0.0009242086663415031 gradient norm = 4.8133489837499906e-06\n",
      "Iteration 646 : x = [1.99574665 1.50670085] f(x) = 0.0009242086434062631 gradient norm = 4.716497902605747e-06\n",
      "Iteration 647 : x = [1.99574617 1.50669616] f(x) = 0.0009242086213847151 gradient norm = 4.621594945215223e-06\n",
      "Iteration 648 : x = [1.9957457  1.50669156] f(x) = 0.0009242086002404656 gradient norm = 4.528600951711852e-06\n",
      "Iteration 649 : x = [1.99574524 1.50668706] f(x) = 0.0009242085799385695 gradient norm = 4.437477548367042e-06\n",
      "Iteration 650 : x = [1.99574479 1.50668264] f(x) = 0.0009242085604454744 gradient norm = 4.348187131835776e-06\n",
      "Iteration 651 : x = [1.99574434 1.50667832] f(x) = 0.0009242085417289634 gradient norm = 4.260692853745408e-06\n",
      "Iteration 652 : x = [1.99574391 1.50667408] f(x) = 0.0009242085237581032 gradient norm = 4.174958605561811e-06\n",
      "Iteration 653 : x = [1.99574348 1.50666993] f(x) = 0.0009242085065031923 gradient norm = 4.0909490037895025e-06\n",
      "Iteration 654 : x = [1.99574307 1.50666586] f(x) = 0.0009242084899357107 gradient norm = 4.008629375426629e-06\n",
      "Iteration 655 : x = [1.99574266 1.50666187] f(x) = 0.0009242084740282765 gradient norm = 3.927965743746066e-06\n",
      "Iteration 656 : x = [1.99574226 1.50665796] f(x) = 0.0009242084587545966 gradient norm = 3.848924814336231e-06\n",
      "Iteration 657 : x = [1.99574186 1.50665413] f(x) = 0.0009242084440894253 gradient norm = 3.7714739614444938e-06\n",
      "Iteration 658 : x = [1.99574148 1.50665038] f(x) = 0.0009242084300085234 gradient norm = 3.695581214563773e-06\n",
      "Iteration 659 : x = [1.9957411 1.5066467] f(x) = 0.0009242084164886154 gradient norm = 3.6212152453112235e-06\n",
      "Iteration 660 : x = [1.99574073 1.5066431 ] f(x) = 0.0009242084035073543 gradient norm = 3.5483453545486867e-06\n",
      "Iteration 661 : x = [1.99574037 1.50663957] f(x) = 0.0009242083910432823 gradient norm = 3.4769414597713013e-06\n",
      "Iteration 662 : x = [1.99574002 1.50663611] f(x) = 0.0009242083790757963 gradient norm = 3.4069740827678e-06\n",
      "Iteration 663 : x = [1.99573967 1.50663272] f(x) = 0.0009242083675851145 gradient norm = 3.3384143374733414e-06\n",
      "Iteration 664 : x = [1.99573933 1.5066294 ] f(x) = 0.0009242083565522423 gradient norm = 3.2712339181299536e-06\n",
      "Iteration 665 : x = [1.995739   1.50662615] f(x) = 0.0009242083459589413 gradient norm = 3.20540508760789e-06\n",
      "Iteration 666 : x = [1.99573867 1.50662296] f(x) = 0.0009242083357877011 gradient norm = 3.140900666062969e-06\n",
      "Iteration 667 : x = [1.99573835 1.50661983] f(x) = 0.000924208326021707 gradient norm = 3.0776940197069153e-06\n",
      "Iteration 668 : x = [1.99573804 1.50661677] f(x) = 0.0009242083166448147 gradient norm = 3.015759049884681e-06\n",
      "Iteration 669 : x = [1.99573773 1.50661377] f(x) = 0.0009242083076415236 gradient norm = 2.9550701823388127e-06\n",
      "Iteration 670 : x = [1.99573743 1.50661083] f(x) = 0.0009242082989969495 gradient norm = 2.8956023566772494e-06\n",
      "Iteration 671 : x = [1.99573713 1.50660795] f(x) = 0.0009242082906968015 gradient norm = 2.8373310160883296e-06\n",
      "Iteration 672 : x = [1.99573684 1.50660513] f(x) = 0.0009242082827273587 gradient norm = 2.7802320972153127e-06\n",
      "Iteration 673 : x = [1.99573656 1.50660236] f(x) = 0.0009242082750754453 gradient norm = 2.7242820202705405e-06\n",
      "Iteration 674 : x = [1.99573628 1.50659965] f(x) = 0.0009242082677284112 gradient norm = 2.6694576793338414e-06\n",
      "Iteration 675 : x = [1.99573601 1.506597  ] f(x) = 0.0009242082606741099 gradient norm = 2.6157364328347343e-06\n",
      "Iteration 676 : x = [1.99573574 1.5065944 ] f(x) = 0.0009242082539008796 gradient norm = 2.5630960942443047e-06\n",
      "Iteration 677 : x = [1.99573548 1.50659185] f(x) = 0.0009242082473975217 gradient norm = 2.511514922941495e-06\n",
      "Iteration 678 : x = [1.99573523 1.50658935] f(x) = 0.0009242082411532849 gradient norm = 2.460971615255764e-06\n",
      "Iteration 679 : x = [1.99573498 1.5065869 ] f(x) = 0.0009242082351578448 gradient norm = 2.4114452957123653e-06\n",
      "Iteration 680 : x = [1.99573473 1.5065845 ] f(x) = 0.0009242082294012897 gradient norm = 2.3629155084270585e-06\n",
      "Iteration 681 : x = [1.99573449 1.50658215] f(x) = 0.0009242082238741023 gradient norm = 2.315362208690778e-06\n",
      "Iteration 682 : x = [1.99573425 1.50657985] f(x) = 0.0009242082185671438 gradient norm = 2.2687657547083824e-06\n",
      "Iteration 683 : x = [1.99573402 1.50657759] f(x) = 0.0009242082134716405 gradient norm = 2.2231068995165453e-06\n",
      "Iteration 684 : x = [1.9957338  1.50657538] f(x) = 0.0009242082085791671 gradient norm = 2.1783667830579935e-06\n",
      "Iteration 685 : x = [1.99573357 1.50657321] f(x) = 0.000924208203881635 gradient norm = 2.134526924407132e-06\n",
      "Iteration 686 : x = [1.99573336 1.50657109] f(x) = 0.0009242081993712767 gradient norm = 2.091569214168437e-06\n",
      "Iteration 687 : x = [1.99573314 1.50656901] f(x) = 0.0009242081950406357 gradient norm = 2.0494759070109627e-06\n",
      "Iteration 688 : x = [1.99573293 1.50656697] f(x) = 0.0009242081908825504 gradient norm = 2.008229614346684e-06\n",
      "Iteration 689 : x = [1.99573273 1.50656497] f(x) = 0.0009242081868901471 gradient norm = 1.967813297186582e-06\n",
      "Iteration 690 : x = [1.99573253 1.50656301] f(x) = 0.0009242081830568235 gradient norm = 1.928210259117893e-06\n",
      "Iteration 691 : x = [1.99573233 1.5065611 ] f(x) = 0.0009242081793762418 gradient norm = 1.8894041394061073e-06\n",
      "Iteration 692 : x = [1.99573214 1.50655922] f(x) = 0.0009242081758423162 gradient norm = 1.85137890627626e-06\n",
      "Iteration 693 : x = [1.99573195 1.50655737] f(x) = 0.0009242081724492036 gradient norm = 1.814118850286144e-06\n",
      "Iteration 694 : x = [1.99573177 1.50655557] f(x) = 0.0009242081691912937 gradient norm = 1.77760857786488e-06\n",
      "Iteration 695 : x = [1.99573158 1.5065538 ] f(x) = 0.0009242081660631989 gradient norm = 1.7418330049698293e-06\n",
      "Iteration 696 : x = [1.99573141 1.50655207] f(x) = 0.0009242081630597471 gradient norm = 1.7067773508615199e-06\n",
      "Iteration 697 : x = [1.99573123 1.50655037] f(x) = 0.0009242081601759725 gradient norm = 1.672427132003825e-06\n",
      "Iteration 698 : x = [1.99573106 1.50654871] f(x) = 0.0009242081574071059 gradient norm = 1.6387681561172685e-06\n",
      "Iteration 699 : x = [1.9957309  1.50654708] f(x) = 0.0009242081547485694 gradient norm = 1.605786516307778e-06\n",
      "Iteration 700 : x = [1.99573073 1.50654548] f(x) = 0.0009242081521959672 gradient norm = 1.5734685853423757e-06\n",
      "Iteration 701 : x = [1.99573057 1.50654391] f(x) = 0.0009242081497450775 gradient norm = 1.5418010100266255e-06\n",
      "Iteration 702 : x = [1.99573041 1.50654238] f(x) = 0.0009242081473918484 gradient norm = 1.5107707056966108e-06\n",
      "Iteration 703 : x = [1.99573026 1.50654088] f(x) = 0.0009242081451323886 gradient norm = 1.4803648508294837e-06\n",
      "Iteration 704 : x = [1.99573011 1.50653941] f(x) = 0.0009242081429629613 gradient norm = 1.4505708817534092e-06\n",
      "Iteration 705 : x = [1.99572996 1.50653796] f(x) = 0.0009242081408799797 gradient norm = 1.421376487469052e-06\n",
      "Iteration 706 : x = [1.99572982 1.50653655] f(x) = 0.0009242081388799993 gradient norm = 1.3927696045697498e-06\n",
      "Iteration 707 : x = [1.99572967 1.50653516] f(x) = 0.0009242081369597126 gradient norm = 1.3647384122598348e-06\n",
      "Iteration 708 : x = [1.99572954 1.5065338 ] f(x) = 0.0009242081351159441 gradient norm = 1.3372713274876065e-06\n",
      "Iteration 709 : x = [1.9957294  1.50653247] f(x) = 0.0009242081333456454 gradient norm = 1.310357000173065e-06\n",
      "Iteration 710 : x = [1.99572927 1.50653117] f(x) = 0.0009242081316458888 gradient norm = 1.2839843085076412e-06\n",
      "Iteration 711 : x = [1.99572913 1.50652989] f(x) = 0.0009242081300138633 gradient norm = 1.2581423543818117e-06\n",
      "Iteration 712 : x = [1.99572901 1.50652864] f(x) = 0.0009242081284468706 gradient norm = 1.2328204588868028e-06\n",
      "Iteration 713 : x = [1.99572888 1.50652742] f(x) = 0.0009242081269423189 gradient norm = 1.2080081578992557e-06\n",
      "Iteration 714 : x = [1.99572876 1.50652621] f(x) = 0.0009242081254977202 gradient norm = 1.1836951977805771e-06\n",
      "Iteration 715 : x = [1.99572864 1.50652504] f(x) = 0.0009242081241106857 gradient norm = 1.1598715311290826e-06\n",
      "Iteration 716 : x = [1.99572852 1.50652388] f(x) = 0.0009242081227789218 gradient norm = 1.1365273126444741e-06\n",
      "Iteration 717 : x = [1.9957284  1.50652275] f(x) = 0.0009242081215002264 gradient norm = 1.113652895064345e-06\n",
      "Iteration 718 : x = [1.99572829 1.50652164] f(x) = 0.0009242081202724845 gradient norm = 1.0912388251864569e-06\n",
      "Iteration 719 : x = [1.99572818 1.50652056] f(x) = 0.0009242081190936656 gradient norm = 1.0692758399518713e-06\n",
      "Iteration 720 : x = [1.99572807 1.50651949] f(x) = 0.000924208117961821 gradient norm = 1.0477548626432962e-06\n",
      "Iteration 721 : x = [1.99572796 1.50651845] f(x) = 0.0009242081168750781 gradient norm = 1.0266669991282017e-06\n",
      "Iteration 722 : x = [1.99572786 1.50651743] f(x) = 0.0009242081158316401 gradient norm = 1.006003534193525e-06\n",
      "Iteration 723 : x = [1.99572776 1.50651643] f(x) = 0.0009242081148297814 gradient norm = 9.857559279292378e-07\n",
      "Completed in 723 iterations\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_bell_curve(dataset, x_optimal):\n",
    "    x_optimal_str = \"x=[\" + str(round(x_optimal[0], 2)) + \",\" + str(round(x_optimal[1], 2)) + \"]\"\n",
    "    z = dataset[:, 0]\n",
    "    y = dataset[:, 1]\n",
    "    \n",
    "    # Generate points for smooth curve\n",
    "    z_range = np.linspace(min(z), max(z), 100)\n",
    "    m_zx_optimal = np.exp(-((z_range - x_optimal[0]) ** 2) / x_optimal[1])\n",
    "\n",
    "    plt.scatter(z, y, label=\"Data Points\", color=\"blue\", alpha=0.6)\n",
    "    plt.plot(z_range, m_zx_optimal, \n",
    "    label=\"Bell Curve for optimal \" + x_optimal_str, color=\"red\")\n",
    "    plt.xlabel(\"z\")\n",
    "    plt.ylabel(\"y\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Choosen 1 as alpha since from previous results it seems to be the best (and most precise) step size\n",
    "x_optimal= gradient_descent(dataset1, starting_points[0], 1)\n",
    "\n",
    "# Plot the optimal bell curve\n",
    "plot_bell_curve(dataset1, x_optimal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 9. Import the second file `dataset2.csv` and store its content into another numpy `nd.array`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2 = np.loadtxt(\"dataset2.csv\", skiprows=2, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 10. Plot this point cloud, with the first column on the x-axis and the second column one the y-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x2 = dataset2[:, 0] # First column from the dataset\n",
    "g2 = dataset2[:, 1] # Second column from the dataset\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(x2, g2, color='blue')\n",
    "plt.xlabel(\"z\")\n",
    "plt.ylabel(\"g(z)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 11. Run the gradient descent algorithm with step size $\\alpha = 10$ until convergence starting from 3 different initialisation points:\n",
    "- $x^{(0)}=(0,5)$\n",
    "- $x^{(0)}=(-1,1)$\n",
    "- $x^{(0)}=(1,1)$\n",
    "\n",
    "For each _initialisation point_, plot the bell curve with the parameters found by `GD`, on top of the data points. Comment the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 : x = [0. 5.] f(x) = 0.14135012406053682 gradient norm = 0.020093399643110035\n",
      "Iteration 1 : x = [-0.10151616  5.17340398] f(x) = 0.13730944840288023 gradient norm = 0.020148950846539247\n",
      "Iteration 2 : x = [-0.22228218  5.33469127] f(x) = 0.13326948213172574 gradient norm = 0.019901529782508403\n",
      "Iteration 3 : x = [-0.35636688  5.48175718] f(x) = 0.12938681716742734 gradient norm = 0.018997250026586907\n",
      "Iteration 4 : x = [-0.49441374  5.61226624] f(x) = 0.12593018003865505 gradient norm = 0.01723487797824291\n",
      "Iteration 5 : x = [-0.62510397  5.72462356] f(x) = 0.12316345569092717 gradient norm = 0.014719778272506314\n",
      "Iteration 6 : x = [-0.73818768  5.81885339] f(x) = 0.1211997559834867 gradient norm = 0.011856984251267876\n",
      "Iteration 7 : x = [-0.82752697  5.89681042] f(x) = 0.11995206069303109 gradient norm = 0.009150018845403497\n",
      "Iteration 8 : x = [-0.89214491  5.96159318] f(x) = 0.11921567284610081 gradient norm = 0.006971605531754349\n",
      "Iteration 9 : x = [-0.93494126  6.01662773] f(x) = 0.11878463831815336 gradient norm = 0.005468127582731644\n",
      "Iteration 10 : x = [-0.96049838  6.06496897] f(x) = 0.11851219214773615 gradient norm = 0.004588320448795914\n",
      "Iteration 11 : x = [-0.97338341  6.10900582] f(x) = 0.11831311001305136 gradient norm = 0.004164325344509237\n",
      "Iteration 12 : x = [-0.97734747  6.15045997] f(x) = 0.11814382688520197 gradient norm = 0.004011089576672942\n",
      "Iteration 13 : x = [-0.97516692  6.19051155] f(x) = 0.11798371661382234 gradient norm = 0.003994776619955235\n",
      "Iteration 14 : x = [-0.96877825  6.22994515] f(x) = 0.11782341027218955 gradient norm = 0.004040986761454688\n",
      "Iteration 15 : x = [-0.9594875   6.26927249] f(x) = 0.11765872061223963 gradient norm = 0.00411402951320264\n",
      "Iteration 16 : x = [-0.94816019  6.30882266] f(x) = 0.11748777266222299 gradient norm = 0.00419788158497667\n",
      "Iteration 17 : x = [-0.93536593  6.34880425] f(x) = 0.11730971832189799 gradient norm = 0.004285440291580813\n",
      "Iteration 18 : x = [-0.92147998  6.38934658] f(x) = 0.1171241768699447 gradient norm = 0.00437345490435353\n",
      "Iteration 19 : x = [-0.90675171  6.43052654] f(x) = 0.1169309953627797 gradient norm = 0.004460306240066729\n",
      "Iteration 20 : x = [-0.89134959  6.47238592] f(x) = 0.1167301473324598 gradient norm = 0.004545062009300627\n",
      "Iteration 21 : x = [-0.87539049  6.51494254] f(x) = 0.11652169078237909 gradient norm = 0.004627079005757186\n",
      "Iteration 22 : x = [-0.85895873  6.5581974 ] f(x) = 0.11630575147579444 gradient norm = 0.004705836448008117\n",
      "Iteration 23 : x = [-0.84211832  6.6021393 ] f(x) = 0.11608251686482027 gradient norm = 0.004780867161298689\n",
      "Iteration 24 : x = [-0.82492101  6.64674784] f(x) = 0.1158522342739463 gradient norm = 0.004851730641414508\n",
      "Iteration 25 : x = [-0.80741142  6.69199542] f(x) = 0.11561521048838475 gradient norm = 0.004918004411894545\n",
      "Iteration 26 : x = [-0.7896304   6.73784858] f(x) = 0.11537181142400796 gradient norm = 0.004979283609606418\n",
      "Iteration 27 : x = [-0.77161724  6.78426897] f(x) = 0.1151224612282749 gradient norm = 0.0050351844048229155\n",
      "Iteration 28 : x = [-0.75341099  6.83121404] f(x) = 0.11486764047178998 gradient norm = 0.005085349251386937\n",
      "Iteration 29 : x = [-0.73505128  6.87863766] f(x) = 0.11460788324780939 gradient norm = 0.005129452971093315\n",
      "Iteration 30 : x = [-0.71657881  6.92649052] f(x) = 0.11434377309204502 gradient norm = 0.005167209099865756\n",
      "Iteration 31 : x = [-0.69803546  6.97472069] f(x) = 0.11407593770578725 gradient norm = 0.00519837609895113\n",
      "Iteration 32 : x = [-0.67946432  7.023274  ] f(x) = 0.11380504252723914 gradient norm = 0.005222763107779135\n",
      "Iteration 33 : x = [-0.66090945  7.07209451] f(x) = 0.11353178325425174 gradient norm = 0.005240234950818914\n",
      "Iteration 34 : x = [-0.64241564  7.12112496] f(x) = 0.11325687747673686 gradient norm = 0.005250716138138919\n",
      "Iteration 35 : x = [-0.62402798  7.17030724] f(x) = 0.11298105562690455 gradient norm = 0.00525419363209556\n",
      "Iteration 36 : x = [-0.60579144  7.21958283] f(x) = 0.11270505149712479 gradient norm = 0.005250718196557814\n",
      "Iteration 37 : x = [-0.58775036  7.26889331] f(x) = 0.11242959260542384 gradient norm = 0.005240404201870853\n",
      "Iteration 38 : x = [-0.56994793  7.3181808 ] f(x) = 0.112155390704619 gradient norm = 0.0052234278270207905\n",
      "Iteration 39 : x = [-0.55242569  7.36738843] f(x) = 0.11188313273096406 gradient norm = 0.005200023676698669\n",
      "Iteration 40 : x = [-0.535223    7.41646075] f(x) = 0.11161347247128017 gradient norm = 0.0051704799101474075\n",
      "Iteration 41 : x = [-0.51837655  7.46534411] f(x) = 0.11134702319464364 gradient norm = 0.005135132054867856\n",
      "Iteration 42 : x = [-0.50191996  7.51398709] f(x) = 0.11108435144800932 gradient norm = 0.0050943557453086066\n",
      "Iteration 43 : x = [-0.48588341  7.56234073] f(x) = 0.11082597215810096 gradient norm = 0.005048558678960318\n",
      "Iteration 44 : x = [-0.47029331  7.61035889] f(x) = 0.11057234511884122 gradient norm = 0.004998172115454166\n",
      "Iteration 45 : x = [-0.45517212  7.65799839] f(x) = 0.11032387287928253 gradient norm = 0.004943642255763415\n",
      "Iteration 46 : x = [-0.44053819  7.70521923] f(x) = 0.11008089998608657 gradient norm = 0.004885421827986536\n",
      "Iteration 47 : x = [-0.42640574  7.75198469] f(x) = 0.10984371348117898 gradient norm = 0.004823962175166504\n",
      "Iteration 48 : x = [-0.41278489  7.7982614 ] f(x) = 0.10961254451236378 gradient norm = 0.004759706092787445\n",
      "Iteration 49 : x = [-0.39968175  7.84401933] f(x) = 0.10938757088433437 gradient norm = 0.0046930816039939555\n",
      "Iteration 50 : x = [-0.38709863  7.88923179] f(x) = 0.10916892036027066 gradient norm = 0.004624496794937947\n",
      "Iteration 51 : x = [-0.37503431  7.93387537] f(x) = 0.10895667451950612 gradient norm = 0.004554335766732909\n",
      "Iteration 52 : x = [-0.36348427  7.97792981] f(x) = 0.10875087298305332 gradient norm = 0.00448295569942264\n",
      "Iteration 53 : x = [-0.35244106  8.0213779 ] f(x) = 0.10855151783390125 gradient norm = 0.0044106849711718\n",
      "Iteration 54 : x = [-0.34189466  8.06420532] f(x) = 0.10835857808041714 gradient norm = 0.004337822235180003\n",
      "Iteration 55 : x = [-0.33183281  8.10640045] f(x) = 0.10817199403634307 gradient norm = 0.004264636328764146\n",
      "Iteration 56 : x = [-0.32224141  8.14795424] f(x) = 0.10799168151744291 gradient norm = 0.004191366873462289\n",
      "Iteration 57 : x = [-0.31310484  8.18885997] f(x) = 0.10781753578086663 gradient norm = 0.004118225420634256\n",
      "Iteration 58 : x = [-0.30440634  8.2291131 ] f(x) = 0.10764943515730484 gradient norm = 0.004045397001894519\n",
      "Iteration 59 : x = [-0.2961283   8.26871105] f(x) = 0.10748724434701638 gradient norm = 0.003973041955470558\n",
      "Iteration 60 : x = [-0.28825257  8.30765305] f(x) = 0.10733081736832153 gradient norm = 0.00390129791584866\n",
      "Iteration 61 : x = [-0.2807607   8.34593992] f(x) = 0.10718000016101994 gradient norm = 0.0038302818726622233\n",
      "Iteration 62 : x = [-0.27363416  8.38357392] f(x) = 0.10703463285757905 gradient norm = 0.0037600922238718287\n",
      "Iteration 63 : x = [-0.26685461  8.42055861] f(x) = 0.10689455174218847 gradient norm = 0.003690810766497356\n",
      "Iteration 64 : x = [-0.26040394  8.45689863] f(x) = 0.10675959092235587 gradient norm = 0.0036225045845531515\n",
      "Iteration 65 : x = [-0.25426454  8.49259964] f(x) = 0.10662958374013001 gradient norm = 0.003555227807876477\n",
      "Iteration 66 : x = [-0.24841931  8.52766811] f(x) = 0.10650436395076471 gradient norm = 0.0034890232270273413\n",
      "Iteration 67 : x = [-0.24285178  8.56211126] f(x) = 0.10638376669613919 gradient norm = 0.0034239237584237675\n",
      "Iteration 68 : x = [-0.23754617  8.59593693] f(x) = 0.10626762929889827 gradient norm = 0.0033599537605753325\n",
      "Iteration 69 : x = [-0.23248743  8.62915347] f(x) = 0.10615579190139234 gradient norm = 0.003297130206998916\n",
      "Iteration 70 : x = [-0.22766125  8.66176964] f(x) = 0.10604809797132396 gradient norm = 0.0032354637244911017\n",
      "Iteration 71 : x = [-0.22305408  8.69379458] f(x) = 0.10594439469372384 gradient norm = 0.003174959507235066\n",
      "Iteration 72 : x = [-0.21865315  8.72523768] f(x) = 0.105844533266618 gradient norm = 0.003115618118050928\n",
      "Iteration 73 : x = [-0.2144464   8.75610855] f(x) = 0.10574836911559117 gradient norm = 0.0030574361882282526\n",
      "Iteration 74 : x = [-0.21042252  8.78641697] f(x) = 0.1056557620404538 gradient norm = 0.0030004070270302397\n",
      "Iteration 75 : x = [-0.20657089  8.81617279] f(x) = 0.10556657630540375 gradient norm = 0.0029445211513057764\n",
      "Iteration 76 : x = [-0.20288157  8.84538596] f(x) = 0.10548068068245589 gradient norm = 0.0028897667448199538\n",
      "Iteration 77 : x = [-0.19934524  8.87406644] f(x) = 0.1053979484564802 gradient norm = 0.0028361300560110075\n",
      "Iteration 78 : x = [-0.19595321  8.90222416] f(x) = 0.10531825739894139 gradient norm = 0.00278359574196795\n",
      "Iteration 79 : x = [-0.19269735  8.92986905] f(x) = 0.10524148971634845 gradient norm = 0.0027321471655410027\n",
      "Iteration 80 : x = [-0.18957007  8.95701095] f(x) = 0.10516753197848902 gradient norm = 0.0026817666516723766\n",
      "Iteration 81 : x = [-0.18656429  8.98365964] f(x) = 0.10509627503072239 gradient norm = 0.0026324357082813266\n",
      "Iteration 82 : x = [-0.18367338  9.00982478] f(x) = 0.10502761389391861 gradient norm = 0.002584135216359946\n",
      "Iteration 83 : x = [-0.18089118  9.03551592] f(x) = 0.10496144765504932 gradient norm = 0.00253684559333429\n",
      "Iteration 84 : x = [-0.17821192  9.0607425 ] f(x) = 0.10489767935093645 gradient norm = 0.0024905469332156083\n",
      "Iteration 85 : x = [-0.17563021  9.0855138 ] f(x) = 0.10483621584724581 gradient norm = 0.0024452191266027294\n",
      "Iteration 86 : x = [-0.17314103  9.10983896] f(x) = 0.10477696771445376 gradient norm = 0.002400841963192817\n",
      "Iteration 87 : x = [-0.17073966  9.13372698] f(x) = 0.10471984910221195 gradient norm = 0.0023573952191068854\n",
      "Iteration 88 : x = [-0.1684217  9.1571867] f(x) = 0.10466477761328115 gradient norm = 0.002314858731032453\n",
      "Iteration 89 : x = [-0.16618305  9.18022678] f(x) = 0.10461167417798688 gradient norm = 0.002273212458922313\n",
      "Iteration 90 : x = [-0.16401984  9.20285575] f(x) = 0.10456046292996922 gradient norm = 0.0022324365387605175\n",
      "Iteration 91 : x = [-0.16192845  9.22508194] f(x) = 0.10451107108384361 gradient norm = 0.002192511326709237\n",
      "Iteration 92 : x = [-0.1599055   9.24691352] f(x) = 0.10446342881526294 gradient norm = 0.002153417435779323\n",
      "Iteration 93 : x = [-0.15794781  9.26835853] f(x) = 0.10441746914375964 gradient norm = 0.002115135766019184\n",
      "Iteration 94 : x = [-0.15605238  9.28942479] f(x) = 0.1043731278186592 gradient norm = 0.002077647529088125\n",
      "Iteration 95 : x = [-0.15421641  9.31011998] f(x) = 0.10433034320827765 gradient norm = 0.0020409342679688323\n",
      "Iteration 96 : x = [-0.15243725  9.33045163] f(x) = 0.10428905619255438 gradient norm = 0.00200497787247662\n",
      "Iteration 97 : x = [-0.15071241  9.35042708] f(x) = 0.10424921005921814 gradient norm = 0.001969760591138967\n",
      "Iteration 98 : x = [-0.14903955  9.37005352] f(x) = 0.10421075040354146 gradient norm = 0.001935265039945368\n",
      "Iteration 99 : x = [-0.14741646  9.38933799] f(x) = 0.10417362503170269 gradient norm = 0.001901474208403732\n",
      "Iteration 100 : x = [-0.14584105  9.40828735] f(x) = 0.10413778386774562 gradient norm = 0.0018683714632838533\n",
      "Iteration 101 : x = [-0.14431134  9.42690834] f(x) = 0.10410317886410314 gradient norm = 0.0018359405503798286\n",
      "Iteration 102 : x = [-0.14282548  9.44520752] f(x) = 0.1040697639156333 gradient norm = 0.0018041655945809983\n",
      "Iteration 103 : x = [-0.1413817   9.46319131] f(x) = 0.10403749477709884 gradient norm = 0.0017730310985039\n",
      "Iteration 104 : x = [-0.13997833  9.480866  ] f(x) = 0.10400632898401259 gradient norm = 0.0017425219399053342\n",
      "Iteration 105 : x = [-0.13861379  9.49823771] f(x) = 0.10397622577675908 gradient norm = 0.0017126233680684365\n",
      "Iteration 106 : x = [-0.13728658  9.51531244] f(x) = 0.10394714602789842 gradient norm = 0.0016833209993288446\n",
      "Iteration 107 : x = [-0.13599528  9.53209605] f(x) = 0.10391905217255192 gradient norm = 0.0016546008118864318\n",
      "Iteration 108 : x = [-0.13473854  9.54859426] f(x) = 0.10389190814176733 gradient norm = 0.0016264491400291754\n",
      "Iteration 109 : x = [-0.13351507  9.56481267] f(x) = 0.10386567929875865 gradient norm = 0.0015988526678790554\n",
      "Iteration 110 : x = [-0.13232367  9.58075674] f(x) = 0.10384033237791489 gradient norm = 0.0015717984227555312\n",
      "Iteration 111 : x = [-0.13116316  9.59643183] f(x) = 0.10381583542647299 gradient norm = 0.001545273768239248\n",
      "Iteration 112 : x = [-0.13003245  9.61184314] f(x) = 0.10379215774875009 gradient norm = 0.0015192663970076722\n",
      "Iteration 113 : x = [-0.12893047  9.62699579] f(x) = 0.10376926985283272 gradient norm = 0.0014937643235045106\n",
      "Iteration 114 : x = [-0.12785624  9.64189475] f(x) = 0.10374714339962152 gradient norm = 0.0014687558764962878\n",
      "Iteration 115 : x = [-0.12680879  9.65654491] f(x) = 0.10372575115413289 gradient norm = 0.0014442296915619618\n",
      "Iteration 116 : x = [-0.12578722  9.67095104] f(x) = 0.10370506693896221 gradient norm = 0.0014201747035549712\n",
      "Iteration 117 : x = [-0.12479064  9.68511777] f(x) = 0.10368506558981432 gradient norm = 0.0013965801390713312\n",
      "Iteration 118 : x = [-0.12381824  9.69904968] f(x) = 0.1036657229130118 gradient norm = 0.0013734355089524395\n",
      "Iteration 119 : x = [-0.1228692   9.71275121] f(x) = 0.10364701564489331 gradient norm = 0.0013507306008468769\n",
      "Iteration 120 : x = [-0.12194279  9.72622671] f(x) = 0.10362892141301833 gradient norm = 0.001328455471851626\n",
      "Iteration 121 : x = [-0.12103826  9.73948043] f(x) = 0.10361141869909676 gradient norm = 0.001306600441249871\n",
      "Iteration 122 : x = [-0.12015492  9.75251654] f(x) = 0.10359448680356588 gradient norm = 0.001285156083359529\n",
      "Iteration 123 : x = [-0.1192921   9.76533911] f(x) = 0.10357810581174 gradient norm = 0.00126411322050424\n",
      "Iteration 124 : x = [-0.11844917  9.7779521 ] f(x) = 0.10356225656146072 gradient norm = 0.0012434629161162233\n",
      "Iteration 125 : x = [-0.11762551  9.79035942] f(x) = 0.1035469206121793 gradient norm = 0.0012231964679785745\n",
      "Iteration 126 : x = [-0.11682054  9.80256487] f(x) = 0.10353208021540582 gradient norm = 0.001203305401612847\n",
      "Iteration 127 : x = [-0.11603368  9.81457217] f(x) = 0.10351771828646163 gradient norm = 0.0011837814638163443\n",
      "Iteration 128 : x = [-0.1152644   9.82638496] f(x) = 0.10350381837747508 gradient norm = 0.0011646166163522913\n",
      "Iteration 129 : x = [-0.11451218  9.83800681] f(x) = 0.10349036465156392 gradient norm = 0.0011458030297949722\n",
      "Iteration 130 : x = [-0.11377652  9.8494412 ] f(x) = 0.10347734185814851 gradient norm = 0.0011273330775309915\n",
      "Iteration 131 : x = [-0.11305694  9.86069154] f(x) = 0.10346473530934397 gradient norm = 0.0011091993299169889\n",
      "Iteration 132 : x = [-0.11235297  9.87176117] f(x) = 0.10345253085738192 gradient norm = 0.0010913945485935394\n",
      "Iteration 133 : x = [-0.11166417  9.88265336] f(x) = 0.10344071487301335 gradient norm = 0.0010739116809542575\n",
      "Iteration 134 : x = [-0.11099012  9.89337131] f(x) = 0.10342927422484788 gradient norm = 0.0010567438547687581\n",
      "Iteration 135 : x = [-0.1103304   9.90391813] f(x) = 0.10341819625958577 gradient norm = 0.0010398843729576362\n",
      "Iteration 136 : x = [-0.10968461  9.9142969 ] f(x) = 0.10340746878310228 gradient norm = 0.0010233267085172988\n",
      "Iteration 137 : x = [-0.10905238  9.92451062] f(x) = 0.10339708004234421 gradient norm = 0.0010070644995921938\n",
      "Iteration 138 : x = [-0.10843332  9.93456222] f(x) = 0.10338701870800168 gradient norm = 0.0009910915446917782\n",
      "Iteration 139 : x = [-0.1078271   9.94445458] f(x) = 0.10337727385791977 gradient norm = 0.0009754017980493064\n",
      "Iteration 140 : x = [-0.10723336  9.95419051] f(x) = 0.10336783496121585 gradient norm = 0.0009599893651194413\n",
      "Iteration 141 : x = [-0.10665178  9.96377277] f(x) = 0.10335869186307037 gradient norm = 0.0009448484982115316\n",
      "Iteration 142 : x = [-0.10608203  9.97320406] f(x) = 0.10334983477016046 gradient norm = 0.0009299735922553298\n",
      "Iteration 143 : x = [-0.1055238   9.98248703] f(x) = 0.10334125423670715 gradient norm = 0.0009153591806958567\n",
      "Iteration 144 : x = [-0.10497681  9.99162426] f(x) = 0.10333294115110798 gradient norm = 0.000900999931514096\n",
      "Iteration 145 : x = [-0.10444075 10.0006183 ] f(x) = 0.10332488672312928 gradient norm = 0.0008868906433701437\n",
      "Iteration 146 : x = [-0.10391536 10.00947163] f(x) = 0.10331708247163157 gradient norm = 0.0008730262418654939\n",
      "Iteration 147 : x = [-0.10340036 10.01818669] f(x) = 0.10330952021280553 gradient norm = 0.0008594017759211024\n",
      "Iteration 148 : x = [-0.10289549 10.02676586] f(x) = 0.1033021920488946 gradient norm = 0.0008460124142679285\n",
      "Iteration 149 : x = [-0.1024005 10.0352115] f(x) = 0.10329509035738271 gradient norm = 0.0008328534420466512\n",
      "Iteration 150 : x = [-0.10191515 10.04352588] f(x) = 0.10328820778062633 gradient norm = 0.0008199202575133548\n",
      "Iteration 151 : x = [-0.1014392  10.05171125] f(x) = 0.10328153721591139 gradient norm = 0.0008072083688479548\n",
      "Iteration 152 : x = [-0.10097243 10.05976983] f(x) = 0.10327507180591557 gradient norm = 0.0007947133910622804\n",
      "Iteration 153 : x = [-0.1005146  10.06770377] f(x) = 0.10326880492955866 gradient norm = 0.0007824310430046979\n",
      "Iteration 154 : x = [-0.10006551 10.07551518] f(x) = 0.10326273019322361 gradient norm = 0.0007703571444582793\n",
      "Iteration 155 : x = [-0.09962495 10.08320614] f(x) = 0.1032568414223318 gradient norm = 0.0007584876133295939\n",
      "Iteration 156 : x = [-0.09919272 10.09077869] f(x) = 0.10325113265325753 gradient norm = 0.0007468184629252357\n",
      "Iteration 157 : x = [-0.09876862 10.09823482] f(x) = 0.10324559812556632 gradient norm = 0.0007353457993132743\n",
      "Iteration 158 : x = [-0.09835247 10.1055765 ] f(x) = 0.10324023227456318 gradient norm = 0.0007240658187669309\n",
      "Iteration 159 : x = [-0.09794407 10.11280563] f(x) = 0.10323502972413787 gradient norm = 0.0007129748052877993\n",
      "Iteration 160 : x = [-0.09754326 10.1199241 ] f(x) = 0.10322998527989331 gradient norm = 0.000702069128206059\n",
      "Iteration 161 : x = [-0.09714985 10.12693376] f(x) = 0.10322509392254597 gradient norm = 0.0006913452398551316\n",
      "Iteration 162 : x = [-0.09676368 10.13383642] f(x) = 0.10322035080158594 gradient norm = 0.0006807996733183913\n",
      "Iteration 163 : x = [-0.09638459 10.14063385] f(x) = 0.10321575122918587 gradient norm = 0.000670429040245538\n",
      "Iteration 164 : x = [-0.09601242 10.14732781] f(x) = 0.10321129067434774 gradient norm = 0.0006602300287363483\n",
      "Iteration 165 : x = [-0.09564701 10.15391999] f(x) = 0.10320696475727838 gradient norm = 0.0006501994012895937\n",
      "Iteration 166 : x = [-0.09528822 10.16041207] f(x) = 0.10320276924398253 gradient norm = 0.000640333992814966\n",
      "Iteration 167 : x = [-0.09493589 10.16680571] f(x) = 0.1031987000410657 gradient norm = 0.0006306307087059307\n",
      "Iteration 168 : x = [-0.0945899  10.17310252] f(x) = 0.10319475319073738 gradient norm = 0.0006210865229714937\n",
      "Iteration 169 : x = [-0.0942501  10.17930409] f(x) = 0.1031909248660059 gradient norm = 0.0006116984764249258\n",
      "Iteration 170 : x = [-0.09391635 10.18541196] f(x) = 0.1031872113660576 gradient norm = 0.0006024636749275693\n",
      "Iteration 171 : x = [-0.09358853 10.19142767] f(x) = 0.10318360911181244 gradient norm = 0.0005933792876858862\n",
      "Iteration 172 : x = [-0.09326651 10.19735272] f(x) = 0.10318011464164828 gradient norm = 0.0005844425456000027\n",
      "Iteration 173 : x = [-0.09295017 10.20318858] f(x) = 0.10317672460728781 gradient norm = 0.0005756507396620295\n",
      "Iteration 174 : x = [-0.09263938 10.20893669] f(x) = 0.10317343576984003 gradient norm = 0.0005670012194025207\n",
      "Iteration 175 : x = [-0.09233404 10.21459847] f(x) = 0.10317024499599185 gradient norm = 0.0005584913913834676\n",
      "Iteration 176 : x = [-0.09203402 10.22017532] f(x) = 0.10316714925434164 gradient norm = 0.0005501187177362995\n",
      "Iteration 177 : x = [-0.09173922 10.22566861] f(x) = 0.10316414561187064 gradient norm = 0.0005418807147434146\n",
      "Iteration 178 : x = [-0.09144953 10.23107966] f(x) = 0.10316123123054556 gradient norm = 0.0005337749514617773\n",
      "Iteration 179 : x = [-0.09116485 10.23640982] f(x) = 0.10315840336404755 gradient norm = 0.0005257990483872292\n",
      "Iteration 180 : x = [-0.09088506 10.24166036] f(x) = 0.10315565935462243 gradient norm = 0.0005179506761581517\n",
      "Iteration 181 : x = [-0.09061008 10.24683256] f(x) = 0.10315299663004696 gradient norm = 0.0005102275542972015\n",
      "Iteration 182 : x = [-0.0903398  10.25192767] f(x) = 0.10315041270070711 gradient norm = 0.0005026274499898708\n",
      "Iteration 183 : x = [-0.09007414 10.25694692] f(x) = 0.10314790515678357 gradient norm = 0.0004951481768986606\n",
      "Iteration 184 : x = [-0.08981299 10.26189151] f(x) = 0.1031454716655396 gradient norm = 0.00048778759401172067\n",
      "Iteration 185 : x = [-0.08955627 10.26676263] f(x) = 0.10314310996870858 gradient norm = 0.00048054360452480445\n",
      "Iteration 186 : x = [-0.08930388 10.27156143] f(x) = 0.10314081787997614 gradient norm = 0.00047341415475549956\n",
      "Iteration 187 : x = [-0.08905576 10.27628906] f(x) = 0.10313859328255337 gradient norm = 0.00046639723308864616\n",
      "Iteration 188 : x = [-0.0888118  10.28094665] f(x) = 0.10313643412683812 gradient norm = 0.0004594908689519619\n",
      "Iteration 189 : x = [-0.08857194 10.2855353 ] f(x) = 0.10313433842816018 gradient norm = 0.00045269313182088667\n",
      "Iteration 190 : x = [-0.08833608 10.29005608] f(x) = 0.10313230426460779 gradient norm = 0.00044600213025170247\n",
      "Iteration 191 : x = [-0.08810415 10.29451007] f(x) = 0.1031303297749317 gradient norm = 0.000439416010942042\n",
      "Iteration 192 : x = [-0.08787608 10.2988983 ] f(x) = 0.10312841315652405 gradient norm = 0.0004329329578178919\n",
      "Iteration 193 : x = [-0.08765179 10.30322182] f(x) = 0.10312655266346958 gradient norm = 0.00042655119114623887\n",
      "Iteration 194 : x = [-0.08743122 10.30748162] f(x) = 0.10312474660466549 gradient norm = 0.0004202689666725586\n",
      "Iteration 195 : x = [-0.08721428 10.31167871] f(x) = 0.10312299334200814 gradient norm = 0.0004140845747823652\n",
      "Iteration 196 : x = [-0.08700091 10.31581406] f(x) = 0.10312129128864396 gradient norm = 0.00040799633968601834\n",
      "Iteration 197 : x = [-0.08679104 10.31988862] f(x) = 0.10311963890728121 gradient norm = 0.00040200261862611305\n",
      "Iteration 198 : x = [-0.08658461 10.32390334] f(x) = 0.103118034708562 gradient norm = 0.00039610180110669015\n",
      "Iteration 199 : x = [-0.08638155 10.32785915] f(x) = 0.1031164772494903 gradient norm = 0.0003902923081436119\n",
      "Iteration 200 : x = [-0.08618179 10.33175696] f(x) = 0.10311496513191548 gradient norm = 0.0003845725915354413\n",
      "Iteration 201 : x = [-0.08598529 10.33559766] f(x) = 0.10311349700106835 gradient norm = 0.0003789411331541558\n",
      "Iteration 202 : x = [-0.08579197 10.33938214] f(x) = 0.10311207154414806 gradient norm = 0.00037339644425512337\n",
      "Iteration 203 : x = [-0.08560179 10.34311126] f(x) = 0.10311068748895794 gradient norm = 0.00036793706480571313\n",
      "Iteration 204 : x = [-0.08541467 10.34678586] f(x) = 0.1031093436025886 gradient norm = 0.0003625615628319686\n",
      "Iteration 205 : x = [-0.08523057 10.3504068 ] f(x) = 0.10310803869014597 gradient norm = 0.00035726853378279953\n",
      "Iteration 206 : x = [-0.08504943 10.35397489] f(x) = 0.10310677159352359 gradient norm = 0.00035205659991114865\n",
      "Iteration 207 : x = [-0.08487119 10.35749094] f(x) = 0.1031055411902164 gradient norm = 0.0003469244096716013\n",
      "Iteration 208 : x = [-0.08469581 10.36095575] f(x) = 0.10310434639217542 gradient norm = 0.0003418706371339689\n",
      "Iteration 209 : x = [-0.08452323 10.3643701 ] f(x) = 0.1031031861447016 gradient norm = 0.00033689398141232787\n",
      "Iteration 210 : x = [-0.0843534  10.36773476] f(x) = 0.10310205942537673 gradient norm = 0.00033199316610905917\n",
      "Iteration 211 : x = [-0.08418627 10.37105048] f(x) = 0.10310096524303111 gradient norm = 0.00032716693877343767\n",
      "Iteration 212 : x = [-0.0840218  10.37431801] f(x) = 0.10309990263674605 gradient norm = 0.000322414070374342\n",
      "Iteration 213 : x = [-0.08385993 10.37753809] f(x) = 0.10309887067488983 gradient norm = 0.00031773335478663616\n",
      "Iteration 214 : x = [-0.08370062 10.38071142] f(x) = 0.1030978684541864 gradient norm = 0.0003131236082908416\n",
      "Iteration 215 : x = [-0.08354383 10.38383873] f(x) = 0.10309689509881514 gradient norm = 0.0003085836690856858\n",
      "Iteration 216 : x = [-0.08338951 10.38692071] f(x) = 0.10309594975954083 gradient norm = 0.00030411239681316077\n",
      "Iteration 217 : x = [-0.08323762 10.38995804] f(x) = 0.1030950316128729 gradient norm = 0.00029970867209570666\n",
      "Iteration 218 : x = [-0.08308811 10.39295139] f(x) = 0.10309413986025247 gradient norm = 0.00029537139608517936\n",
      "Iteration 219 : x = [-0.08294095 10.39590144] f(x) = 0.10309327372726657 gradient norm = 0.00029109949002323066\n",
      "Iteration 220 : x = [-0.08279608 10.39880883] f(x) = 0.10309243246288845 gradient norm = 0.0002868918948127991\n",
      "Iteration 221 : x = [-0.08265348 10.4016742 ] f(x) = 0.10309161533874299 gradient norm = 0.00028274757060037334\n",
      "Iteration 222 : x = [-0.08251311 10.40449819] f(x) = 0.10309082164839653 gradient norm = 0.000278665496368701\n",
      "Iteration 223 : x = [-0.08237492 10.40728141] f(x) = 0.10309005070666993 gradient norm = 0.00027464466953966844\n",
      "Iteration 224 : x = [-0.08223887 10.41002449] f(x) = 0.10308930184897439 gradient norm = 0.00027068410558702744\n",
      "Iteration 225 : x = [-0.08210494 10.41272801] f(x) = 0.10308857443066906 gradient norm = 0.00026678283765872664\n",
      "Iteration 226 : x = [-0.08197308 10.41539258] f(x) = 0.10308786782643958 gradient norm = 0.0002629399162085254\n",
      "Iteration 227 : x = [-0.08184326 10.41801877] f(x) = 0.10308718142969717 gradient norm = 0.0002591544086366578\n",
      "Iteration 228 : x = [-0.08171545 10.42060716] f(x) = 0.10308651465199706 gradient norm = 0.00025542539893928237\n",
      "Iteration 229 : x = [-0.0815896  10.42315832] f(x) = 0.10308586692247614 gradient norm = 0.000251751987366465\n",
      "Iteration 230 : x = [-0.08146569 10.42567279] f(x) = 0.10308523768730854 gradient norm = 0.0002481332900884529\n",
      "Iteration 231 : x = [-0.08134369 10.42815112] f(x) = 0.1030846264091792 gradient norm = 0.00024456843887001376\n",
      "Iteration 232 : x = [-0.08122356 10.43059385] f(x) = 0.10308403256677443 gradient norm = 0.00024105658075260631\n",
      "Iteration 233 : x = [-0.08110527 10.43300151] f(x) = 0.10308345565428856 gradient norm = 0.00023759687774416952\n",
      "Iteration 234 : x = [-0.08098879 10.43537462] f(x) = 0.10308289518094695 gradient norm = 0.00023418850651632118\n",
      "Iteration 235 : x = [-0.0808741 10.4377137] f(x) = 0.10308235067054432 gradient norm = 0.00023083065810873988\n",
      "Iteration 236 : x = [-0.08076115 10.44001924] f(x) = 0.10308182166099744 gradient norm = 0.00022752253764056647\n",
      "Iteration 237 : x = [-0.08064992 10.44229174] f(x) = 0.10308130770391269 gradient norm = 0.00022426336402860917\n",
      "Iteration 238 : x = [-0.08054039 10.4445317 ] f(x) = 0.10308080836416722 gradient norm = 0.00022105236971215413\n",
      "Iteration 239 : x = [-0.08043252 10.44673959] f(x) = 0.10308032321950342 gradient norm = 0.00021788880038424335\n",
      "Iteration 240 : x = [-0.08032628 10.44891589] f(x) = 0.1030798518601364 gradient norm = 0.00021477191472919413\n",
      "Iteration 241 : x = [-0.08022166 10.45106106] f(x) = 0.1030793938883742 gradient norm = 0.00021170098416622933\n",
      "Iteration 242 : x = [-0.08011863 10.45317556] f(x) = 0.10307894891824945 gradient norm = 0.00020867529259902917\n",
      "Iteration 243 : x = [-0.08001715 10.45525984] f(x) = 0.10307851657516343 gradient norm = 0.00020569413617106675\n",
      "Iteration 244 : x = [-0.0799172  10.45731435] f(x) = 0.10307809649554078 gradient norm = 0.00020275682302654653\n",
      "Iteration 245 : x = [-0.07981876 10.45933953] f(x) = 0.10307768832649561 gradient norm = 0.00019986267307681293\n",
      "Iteration 246 : x = [-0.07972181 10.46133581] f(x) = 0.10307729172550771 gradient norm = 0.00019701101777208513\n",
      "Iteration 247 : x = [-0.07962631 10.4633036 ] f(x) = 0.10307690636010934 gradient norm = 0.00019420119987837624\n",
      "Iteration 248 : x = [-0.07953225 10.46524333] f(x) = 0.10307653190758152 gradient norm = 0.00019143257325943542\n",
      "Iteration 249 : x = [-0.0794396  10.46715541] f(x) = 0.10307616805466024 gradient norm = 0.00018870450266362515\n",
      "Iteration 250 : x = [-0.07934834 10.46904025] f(x) = 0.10307581449725138 gradient norm = 0.00018601636351556262\n",
      "Iteration 251 : x = [-0.07925844 10.47089824] f(x) = 0.10307547094015507 gradient norm = 0.00018336754171242482\n",
      "Iteration 252 : x = [-0.0791699  10.47272978] f(x) = 0.10307513709679825 gradient norm = 0.00018075743342478841\n",
      "Iteration 253 : x = [-0.07908267 10.47453525] f(x) = 0.10307481268897567 gradient norm = 0.0001781854449018915\n",
      "Iteration 254 : x = [-0.07899675 10.47631503] f(x) = 0.10307449744659922 gradient norm = 0.00017565099228118432\n",
      "Iteration 255 : x = [-0.07891211 10.4780695 ] f(x) = 0.10307419110745471 gradient norm = 0.00017315350140209313\n",
      "Iteration 256 : x = [-0.07882873 10.47979902] f(x) = 0.1030738934169663 gradient norm = 0.00017069240762385815\n",
      "Iteration 257 : x = [-0.07874659 10.48150397] f(x) = 0.10307360412796826 gradient norm = 0.000168267155647347\n",
      "Iteration 258 : x = [-0.07866568 10.4831847 ] f(x) = 0.10307332300048386 gradient norm = 0.00016587719934075886\n",
      "Iteration 259 : x = [-0.07858596 10.48484155] f(x) = 0.10307304980151089 gradient norm = 0.00016352200156910464\n",
      "Iteration 260 : x = [-0.07850743 10.48647488] f(x) = 0.10307278430481409 gradient norm = 0.00016120103402737077\n",
      "Iteration 261 : x = [-0.07843006 10.48808504] f(x) = 0.10307252629072372 gradient norm = 0.00015891377707728013\n",
      "Iteration 262 : x = [-0.07835384 10.48967235] f(x) = 0.10307227554594026 gradient norm = 0.00015665971958754788\n",
      "Iteration 263 : x = [-0.07827875 10.49123714] f(x) = 0.10307203186334565 gradient norm = 0.00015443835877756147\n",
      "Iteration 264 : x = [-0.07820477 10.49277975] f(x) = 0.10307179504181942 gradient norm = 0.00015224920006437967\n",
      "Iteration 265 : x = [-0.07813188 10.4943005 ] f(x) = 0.10307156488606137 gradient norm = 0.00015009175691299258\n",
      "Iteration 266 : x = [-0.07806006 10.4957997 ] f(x) = 0.10307134120641916 gradient norm = 0.0001479655506897338\n",
      "Iteration 267 : x = [-0.0779893  10.49727766] f(x) = 0.10307112381872119 gradient norm = 0.00014587011051879104\n",
      "Iteration 268 : x = [-0.07791959 10.49873469] f(x) = 0.1030709125441146 gradient norm = 0.0001438049731417218\n",
      "Iteration 269 : x = [-0.0778509 10.5001711] f(x) = 0.10307070720890858 gradient norm = 0.0001417696827799146\n",
      "Iteration 270 : x = [-0.07778323 10.50158718] f(x) = 0.1030705076444218 gradient norm = 0.00013976379099991593\n",
      "Iteration 271 : x = [-0.07771654 10.50298323] f(x) = 0.10307031368683492 gradient norm = 0.00013778685658155667\n",
      "Iteration 272 : x = [-0.07765084 10.50435953] f(x) = 0.10307012517704753 gradient norm = 0.00013583844538880109\n",
      "Iteration 273 : x = [-0.0775861  10.50571637] f(x) = 0.10306994196053935 gradient norm = 0.00013391813024326874\n",
      "Iteration 274 : x = [-0.07752231 10.50705403] f(x) = 0.10306976388723554 gradient norm = 0.00013202549080035\n",
      "Iteration 275 : x = [-0.07745945 10.50837279] f(x) = 0.10306959081137626 gradient norm = 0.00013016011342786678\n",
      "Iteration 276 : x = [-0.07739752 10.50967292] f(x) = 0.10306942259139014 gradient norm = 0.00012832159108720065\n",
      "Iteration 277 : x = [-0.07733648 10.51095468] f(x) = 0.10306925908977144 gradient norm = 0.00012650952321685454\n",
      "Iteration 278 : x = [-0.07727634 10.51221835] f(x) = 0.103069100172961 gradient norm = 0.00012472351561835292\n",
      "Iteration 279 : x = [-0.07721708 10.51346417] f(x) = 0.10306894571123083 gradient norm = 0.00012296318034446998\n",
      "Iteration 280 : x = [-0.07715869 10.51469242] f(x) = 0.10306879557857204 gradient norm = 0.00012122813558969916\n",
      "Iteration 281 : x = [-0.07710114 10.51590333] f(x) = 0.10306864965258622 gradient norm = 0.00011951800558291845\n",
      "Iteration 282 : x = [-0.07704444 10.51709717] f(x) = 0.10306850781438007 gradient norm = 0.00011783242048220838\n",
      "Iteration 283 : x = [-0.07698856 10.51827416] f(x) = 0.10306836994846315 gradient norm = 0.00011617101627176078\n",
      "Iteration 284 : x = [-0.07693349 10.51943457] f(x) = 0.10306823594264873 gradient norm = 0.0001145334346608497\n",
      "Iteration 285 : x = [-0.07687922 10.52057862] f(x) = 0.10306810568795755 gradient norm = 0.00011291932298478454\n",
      "Iteration 286 : x = [-0.07682574 10.52170654] f(x) = 0.10306797907852452 gradient norm = 0.00011132833410783088\n",
      "Iteration 287 : x = [-0.07677304 10.52281858] f(x) = 0.10306785601150814 gradient norm = 0.00010976012632804508\n",
      "Iteration 288 : x = [-0.0767211  10.52391495] f(x) = 0.10306773638700278 gradient norm = 0.00010821436328395806\n",
      "Iteration 289 : x = [-0.07666992 10.52499588] f(x) = 0.10306762010795317 gradient norm = 0.00010669071386310349\n",
      "Iteration 290 : x = [-0.07661948 10.5260616 ] f(x) = 0.10306750708007197 gradient norm = 0.00010518885211231521\n",
      "Iteration 291 : x = [-0.07656977 10.52711231] f(x) = 0.10306739721175945 gradient norm = 0.00010370845714977187\n",
      "Iteration 292 : x = [-0.07652077 10.52814824] f(x) = 0.10306729041402551 gradient norm = 0.00010224921307874663\n",
      "Iteration 293 : x = [-0.07647249 10.52916959] f(x) = 0.10306718660041425 gradient norm = 0.00010081080890302002\n",
      "Iteration 294 : x = [-0.0764249  10.53017657] f(x) = 0.10306708568693057 gradient norm = 9.939293844391359e-05\n",
      "Iteration 295 : x = [-0.07637801 10.53116939] f(x) = 0.10306698759196918 gradient norm = 9.799530025892779e-05\n",
      "Iteration 296 : x = [-0.07633179 10.53214826] f(x) = 0.10306689223624528 gradient norm = 9.661759756192727e-05\n",
      "Iteration 297 : x = [-0.07628623 10.53311336] f(x) = 0.10306679954272782 gradient norm = 9.525953814484976e-05\n",
      "Iteration 298 : x = [-0.07624134 10.53406489] f(x) = 0.10306670943657434 gradient norm = 9.392083430090598e-05\n",
      "Iteration 299 : x = [-0.07619709 10.53500306] f(x) = 0.10306662184506779 gradient norm = 9.260120274922065e-05\n",
      "Iteration 300 : x = [-0.07615347 10.53592804] f(x) = 0.1030665366975555 gradient norm = 9.13003645609219e-05\n",
      "Iteration 301 : x = [-0.07611049 10.53684004] f(x) = 0.1030664539253895 gradient norm = 9.0018045086602e-05\n",
      "Iteration 302 : x = [-0.07606813 10.53773922] f(x) = 0.10306637346186888 gradient norm = 8.875397388514443e-05\n",
      "Iteration 303 : x = [-0.07602637 10.53862578] f(x) = 0.10306629524218391 gradient norm = 8.750788465388803e-05\n",
      "Iteration 304 : x = [-0.07598521 10.53949989] f(x) = 0.10306621920336152 gradient norm = 8.627951516009605e-05\n",
      "Iteration 305 : x = [-0.07594465 10.54036173] f(x) = 0.10306614528421251 gradient norm = 8.506860717369245e-05\n",
      "Iteration 306 : x = [-0.07590467 10.54121147] f(x) = 0.10306607342528055 gradient norm = 8.38749064012497e-05\n",
      "Iteration 307 : x = [-0.07586526 10.5420493 ] f(x) = 0.1030660035687921 gradient norm = 8.269816242120225e-05\n",
      "Iteration 308 : x = [-0.07582642 10.54287537] f(x) = 0.10306593565860846 gradient norm = 8.153812862024947e-05\n",
      "Iteration 309 : x = [-0.07578813 10.54368985] f(x) = 0.10306586964017882 gradient norm = 8.039456213093703e-05\n",
      "Iteration 310 : x = [-0.0757504  10.54449291] f(x) = 0.1030658054604946 gradient norm = 7.926722377036748e-05\n",
      "Iteration 311 : x = [-0.0757132  10.54528471] f(x) = 0.10306574306804553 gradient norm = 7.815587798005004e-05\n",
      "Iteration 312 : x = [-0.07567654 10.5460654 ] f(x) = 0.10306568241277661 gradient norm = 7.706029276683482e-05\n",
      "Iteration 313 : x = [-0.0756404  10.54683516] f(x) = 0.10306562344604654 gradient norm = 7.598023964492652e-05\n",
      "Iteration 314 : x = [-0.07560478 10.54759413] f(x) = 0.10306556612058733 gradient norm = 7.49154935789543e-05\n",
      "Iteration 315 : x = [-0.07556966 10.54834246] f(x) = 0.10306551039046498 gradient norm = 7.386583292805885e-05\n",
      "Iteration 316 : x = [-0.07553505 10.5490803 ] f(x) = 0.10306545621104146 gradient norm = 7.283103939100041e-05\n",
      "Iteration 317 : x = [-0.07550094 10.54980782] f(x) = 0.10306540353893767 gradient norm = 7.181089795224814e-05\n",
      "Iteration 318 : x = [-0.07546731 10.55052514] f(x) = 0.10306535233199748 gradient norm = 7.080519682904283e-05\n",
      "Iteration 319 : x = [-0.07543416 10.55123241] f(x) = 0.10306530254925306 gradient norm = 6.981372741939523e-05\n",
      "Iteration 320 : x = [-0.07540148 10.55192978] f(x) = 0.10306525415089071 gradient norm = 6.883628425102531e-05\n",
      "Iteration 321 : x = [-0.07536928 10.55261739] f(x) = 0.10306520709821819 gradient norm = 6.78726649312041e-05\n",
      "Iteration 322 : x = [-0.07533753 10.55329538] f(x) = 0.10306516135363274 gradient norm = 6.692267009748756e-05\n",
      "Iteration 323 : x = [-0.07530623 10.55396387] f(x) = 0.10306511688059004 gradient norm = 6.598610336931567e-05\n",
      "Iteration 324 : x = [-0.07527538 10.55462301] f(x) = 0.10306507364357403 gradient norm = 6.506277130048332e-05\n",
      "Iteration 325 : x = [-0.07524496 10.55527293] f(x) = 0.10306503160806792 gradient norm = 6.41524833324331e-05\n",
      "Iteration 326 : x = [-0.07521498 10.55591375] f(x) = 0.10306499074052548 gradient norm = 6.325505174836992e-05\n",
      "Iteration 327 : x = [-0.07518543 10.55654561] f(x) = 0.10306495100834359 gradient norm = 6.237029162818902e-05\n",
      "Iteration 328 : x = [-0.0751563  10.55716863] f(x) = 0.10306491237983563 gradient norm = 6.14980208041877e-05\n",
      "Iteration 329 : x = [-0.07512758 10.55778294] f(x) = 0.10306487482420516 gradient norm = 6.063805981754788e-05\n",
      "Iteration 330 : x = [-0.07509927 10.55838866] f(x) = 0.10306483831152079 gradient norm = 5.97902318755719e-05\n",
      "Iteration 331 : x = [-0.07507136 10.55898591] f(x) = 0.10306480281269174 gradient norm = 5.895436280967231e-05\n",
      "Iteration 332 : x = [-0.07504385 10.55957481] f(x) = 0.10306476829944382 gradient norm = 5.813028103407476e-05\n",
      "Iteration 333 : x = [-0.07501673 10.56015548] f(x) = 0.10306473474429652 gradient norm = 5.7317817505246176e-05\n",
      "Iteration 334 : x = [-0.07499    10.56072804] f(x) = 0.1030647021205403 gradient norm = 5.651680568202117e-05\n",
      "Iteration 335 : x = [-0.07496364 10.56129259] f(x) = 0.10306467040221487 gradient norm = 5.572708148639744e-05\n",
      "Iteration 336 : x = [-0.07493766 10.56184926] f(x) = 0.10306463956408798 gradient norm = 5.494848326502739e-05\n",
      "Iteration 337 : x = [-0.07491205 10.56239814] f(x) = 0.10306460958163481 gradient norm = 5.4180851751354844e-05\n",
      "Iteration 338 : x = [-0.07488679 10.56293936] f(x) = 0.10306458043101792 gradient norm = 5.34240300283976e-05\n",
      "Iteration 339 : x = [-0.0748619  10.56347302] f(x) = 0.10306455208906791 gradient norm = 5.267786349216815e-05\n",
      "Iteration 340 : x = [-0.07483736 10.56399923] f(x) = 0.10306452453326438 gradient norm = 5.194219981571508e-05\n",
      "Iteration 341 : x = [-0.07481317 10.56451809] f(x) = 0.10306449774171778 gradient norm = 5.1216888913776665e-05\n",
      "Iteration 342 : x = [-0.07478932 10.5650297 ] f(x) = 0.10306447169315142 gradient norm = 5.050178290802002e-05\n",
      "Iteration 343 : x = [-0.07476581 10.56553417] f(x) = 0.10306444636688439 gradient norm = 4.979673609288472e-05\n",
      "Iteration 344 : x = [-0.07474263 10.5660316 ] f(x) = 0.10306442174281447 gradient norm = 4.910160490199543e-05\n",
      "Iteration 345 : x = [-0.07471978 10.56652208] f(x) = 0.10306439780140192 gradient norm = 4.8416247875131396e-05\n",
      "Iteration 346 : x = [-0.07469725 10.56700572] f(x) = 0.1030643745236538 gradient norm = 4.7740525625752085e-05\n",
      "Iteration 347 : x = [-0.07467504 10.56748261] f(x) = 0.10306435189110817 gradient norm = 4.707430080908257e-05\n",
      "Iteration 348 : x = [-0.07465314 10.56795284] f(x) = 0.10306432988581951 gradient norm = 4.641743809070412e-05\n",
      "Iteration 349 : x = [-0.07463155 10.56841652] f(x) = 0.10306430849034386 gradient norm = 4.576980411569273e-05\n",
      "Iteration 350 : x = [-0.07461027 10.56887372] f(x) = 0.10306428768772496 gradient norm = 4.513126747825785e-05\n",
      "Iteration 351 : x = [-0.07458929 10.56932454] f(x) = 0.10306426746148033 gradient norm = 4.450169869188873e-05\n",
      "Iteration 352 : x = [-0.07456861 10.56976908] f(x) = 0.10306424779558801 gradient norm = 4.388097015999262e-05\n",
      "Iteration 353 : x = [-0.07454821 10.57020742] f(x) = 0.10306422867447346 gradient norm = 4.3268956147022593e-05\n",
      "Iteration 354 : x = [-0.07452811 10.57063964] f(x) = 0.10306421008299727 gradient norm = 4.2665532750074584e-05\n",
      "Iteration 355 : x = [-0.07450829 10.57106583] f(x) = 0.10306419200644264 gradient norm = 4.2070577870967077e-05\n",
      "Iteration 356 : x = [-0.07448874 10.57148608] f(x) = 0.10306417443050363 gradient norm = 4.1483971188757015e-05\n",
      "Iteration 357 : x = [-0.07446948 10.57190048] f(x) = 0.1030641573412736 gradient norm = 4.0905594132725455e-05\n",
      "Iteration 358 : x = [-0.07445048 10.57230909] f(x) = 0.10306414072523393 gradient norm = 4.033532985579583e-05\n",
      "Iteration 359 : x = [-0.07443175 10.57271201] f(x) = 0.10306412456924323 gradient norm = 3.97730632083862e-05\n",
      "Iteration 360 : x = [-0.07441329 10.57310931] f(x) = 0.10306410886052664 gradient norm = 3.921868071269766e-05\n",
      "Iteration 361 : x = [-0.07439509 10.57350107] f(x) = 0.10306409358666552 gradient norm = 3.867207053740399e-05\n",
      "Iteration 362 : x = [-0.07437714 10.57388738] f(x) = 0.10306407873558772 gradient norm = 3.8133122472771314e-05\n",
      "Iteration 363 : x = [-0.07435945 10.5742683 ] f(x) = 0.10306406429555746 gradient norm = 3.7601727906166794e-05\n",
      "Iteration 364 : x = [-0.074342   10.57464391] f(x) = 0.10306405025516611 gradient norm = 3.707777979796871e-05\n",
      "Iteration 365 : x = [-0.0743248  10.57501429] f(x) = 0.103064036603323 gradient norm = 3.6561172657864505e-05\n",
      "Iteration 366 : x = [-0.07430785 10.57537951] f(x) = 0.10306402332924658 gradient norm = 3.605180252153977e-05\n",
      "Iteration 367 : x = [-0.07429113 10.57573964] f(x) = 0.10306401042245555 gradient norm = 3.554956692772872e-05\n",
      "Iteration 368 : x = [-0.07427464 10.57609475] f(x) = 0.10306399787276066 gradient norm = 3.5054364895636425e-05\n",
      "Iteration 369 : x = [-0.07425839 10.57644492] f(x) = 0.10306398567025632 gradient norm = 3.456609690273304e-05\n",
      "Iteration 370 : x = [-0.07424237 10.57679021] f(x) = 0.1030639738053129 gradient norm = 3.408466486289386e-05\n",
      "Iteration 371 : x = [-0.07422657 10.57713069] f(x) = 0.10306396226856882 gradient norm = 3.3609972104894075e-05\n",
      "Iteration 372 : x = [-0.07421099 10.57746643] f(x) = 0.103063951050923 gradient norm = 3.314192335123895e-05\n",
      "Iteration 373 : x = [-0.07419564 10.57779749] f(x) = 0.10306394014352782 gradient norm = 3.268042469733928e-05\n",
      "Iteration 374 : x = [-0.07418049 10.57812394] f(x) = 0.10306392953778178 gradient norm = 3.222538359102144e-05\n",
      "Iteration 375 : x = [-0.07416557 10.57844585] f(x) = 0.1030639192253227 gradient norm = 3.1776708812347015e-05\n",
      "Iteration 376 : x = [-0.07415085 10.57876328] f(x) = 0.10306390919802105 gradient norm = 3.1334310453765975e-05\n",
      "Iteration 377 : x = [-0.07413633 10.57907628] f(x) = 0.10306389944797342 gradient norm = 3.0898099900582335e-05\n",
      "Iteration 378 : x = [-0.07412202 10.57938493] f(x) = 0.10306388996749631 gradient norm = 3.046798981172353e-05\n",
      "Iteration 379 : x = [-0.07410792 10.57968929] f(x) = 0.10306388074911968 gradient norm = 3.0043894100816097e-05\n",
      "Iteration 380 : x = [-0.07409401 10.5799894 ] f(x) = 0.10306387178558132 gradient norm = 2.962572791756173e-05\n",
      "Iteration 381 : x = [-0.07408029 10.58028534] f(x) = 0.10306386306982086 gradient norm = 2.9213407629398256e-05\n",
      "Iteration 382 : x = [-0.07406677 10.58057716] f(x) = 0.10306385459497416 gradient norm = 2.8806850803458733e-05\n",
      "Iteration 383 : x = [-0.07405344 10.58086492] f(x) = 0.10306384635436787 gradient norm = 2.8405976188809305e-05\n",
      "Iteration 384 : x = [-0.07404029 10.58114868] f(x) = 0.1030638383415141 gradient norm = 2.8010703698960303e-05\n",
      "Iteration 385 : x = [-0.07402733 10.58142849] f(x) = 0.10306383055010518 gradient norm = 2.7620954394658725e-05\n",
      "Iteration 386 : x = [-0.07401455 10.5817044 ] f(x) = 0.10306382297400866 gradient norm = 2.723665046694321e-05\n",
      "Iteration 387 : x = [-0.07400195 10.58197647] f(x) = 0.10306381560726248 gradient norm = 2.6857715220467284e-05\n",
      "Iteration 388 : x = [-0.07398952 10.58224476] f(x) = 0.10306380844407016 gradient norm = 2.6484073057077287e-05\n",
      "Iteration 389 : x = [-0.07397727 10.58250932] f(x) = 0.10306380147879615 gradient norm = 2.6115649459655976e-05\n",
      "Iteration 390 : x = [-0.0739652 10.5827702] f(x) = 0.10306379470596139 gradient norm = 2.575237097620018e-05\n",
      "Iteration 391 : x = [-0.07395329 10.58302745] f(x) = 0.1030637881202389 gradient norm = 2.5394165204161845e-05\n",
      "Iteration 392 : x = [-0.07394155 10.58328112] f(x) = 0.10306378171644973 gradient norm = 2.5040960775021483e-05\n",
      "Iteration 393 : x = [-0.07392997 10.58353126] f(x) = 0.10306377548955842 gradient norm = 2.4692687339104307e-05\n",
      "Iteration 394 : x = [-0.07391855 10.58377792] f(x) = 0.10306376943466955 gradient norm = 2.4349275550626638e-05\n",
      "Iteration 395 : x = [-0.0739073  10.58402115] f(x) = 0.10306376354702325 gradient norm = 2.401065705297823e-05\n",
      "Iteration 396 : x = [-0.0738962 10.584261 ] f(x) = 0.10306375782199195 gradient norm = 2.3676764464229426e-05\n",
      "Iteration 397 : x = [-0.07388525 10.58449752] f(x) = 0.10306375225507643 gradient norm = 2.3347531362855177e-05\n",
      "Iteration 398 : x = [-0.07387446 10.58473074] f(x) = 0.10306374684190212 gradient norm = 2.3022892273687463e-05\n",
      "Iteration 399 : x = [-0.07386382 10.58496073] f(x) = 0.10306374157821596 gradient norm = 2.270278265408303e-05\n",
      "Iteration 400 : x = [-0.07385333 10.58518751] f(x) = 0.1030637364598828 gradient norm = 2.2387138880289567e-05\n",
      "Iteration 401 : x = [-0.07384299 10.58541115] f(x) = 0.10306373148288213 gradient norm = 2.2075898234035292e-05\n",
      "Iteration 402 : x = [-0.07383279 10.58563167] f(x) = 0.10306372664330496 gradient norm = 2.1768998889320243e-05\n",
      "Iteration 403 : x = [-0.07382274 10.58584913] f(x) = 0.10306372193735065 gradient norm = 2.1466379899404484e-05\n",
      "Iteration 404 : x = [-0.07381282 10.58606356] f(x) = 0.10306371736132391 gradient norm = 2.1167981183992835e-05\n",
      "Iteration 405 : x = [-0.07380304 10.58627501] f(x) = 0.10306371291163195 gradient norm = 2.087374351662933e-05\n",
      "Iteration 406 : x = [-0.0737934  10.58648353] f(x) = 0.10306370858478153 gradient norm = 2.0583608512262557e-05\n",
      "Iteration 407 : x = [-0.0737839  10.58668915] f(x) = 0.10306370437737615 gradient norm = 2.0297518615015786e-05\n",
      "Iteration 408 : x = [-0.07377453 10.5868919 ] f(x) = 0.10306370028611354 gradient norm = 2.0015417086138983e-05\n",
      "Iteration 409 : x = [-0.07376528 10.58709185] f(x) = 0.10306369630778286 gradient norm = 1.973724799213741e-05\n",
      "Iteration 410 : x = [-0.07375617 10.58728901] f(x) = 0.10306369243926232 gradient norm = 1.946295619308448e-05\n",
      "Iteration 411 : x = [-0.07374719 10.58748343] f(x) = 0.10306368867751649 gradient norm = 1.9192487331113494e-05\n",
      "Iteration 412 : x = [-0.07373833 10.58767515] f(x) = 0.1030636850195941 gradient norm = 1.8925787819080378e-05\n",
      "Iteration 413 : x = [-0.07372959 10.58786421] f(x) = 0.10306368146262561 gradient norm = 1.866280482939784e-05\n",
      "Iteration 414 : x = [-0.07372098 10.58805063] f(x) = 0.10306367800382099 gradient norm = 1.8403486283036455e-05\n",
      "Iteration 415 : x = [-0.07371248 10.58823447] f(x) = 0.10306367464046741 gradient norm = 1.8147780838691466e-05\n",
      "Iteration 416 : x = [-0.07370411 10.58841576] f(x) = 0.10306367136992722 gradient norm = 1.7895637882116242e-05\n",
      "Iteration 417 : x = [-0.07369585 10.58859452] f(x) = 0.1030636681896358 gradient norm = 1.7647007515611752e-05\n",
      "Iteration 418 : x = [-0.07368771 10.58877081] f(x) = 0.10306366509709952 gradient norm = 1.7401840547680732e-05\n",
      "Iteration 419 : x = [-0.07367968 10.58894464] f(x) = 0.10306366208989377 gradient norm = 1.7160088482824148e-05\n",
      "Iteration 420 : x = [-0.07367176 10.58911606] f(x) = 0.10306365916566104 gradient norm = 1.6921703511502227e-05\n",
      "Iteration 421 : x = [-0.07366395 10.58928509] f(x) = 0.10306365632210916 gradient norm = 1.668663850023841e-05\n",
      "Iteration 422 : x = [-0.07365626 10.58945178] f(x) = 0.10306365355700933 gradient norm = 1.6454846981878678e-05\n",
      "Iteration 423 : x = [-0.07364867 10.58961616] f(x) = 0.10306365086819447 gradient norm = 1.6226283145988267e-05\n",
      "Iteration 424 : x = [-0.07364118 10.58977825] f(x) = 0.10306364825355742 gradient norm = 1.600090182940111e-05\n",
      "Iteration 425 : x = [-0.0736338  10.58993808] f(x) = 0.1030636457110494 gradient norm = 1.5778658506896927e-05\n",
      "Iteration 426 : x = [-0.07362652 10.5900957 ] f(x) = 0.10306364323867825 gradient norm = 1.5559509282026285e-05\n",
      "Iteration 427 : x = [-0.07361935 10.59025113] f(x) = 0.10306364083450696 gradient norm = 1.534341087807813e-05\n",
      "Iteration 428 : x = [-0.07361227 10.5904044 ] f(x) = 0.10306363849665216 gradient norm = 1.5130320629164392e-05\n",
      "Iteration 429 : x = [-0.0736053  10.59055555] f(x) = 0.10306363622328245 gradient norm = 1.4920196471449606e-05\n",
      "Iteration 430 : x = [-0.07359842 10.59070459] f(x) = 0.1030636340126172 gradient norm = 1.4712996934513435e-05\n",
      "Iteration 431 : x = [-0.07359163 10.59085156] f(x) = 0.10306363186292496 gradient norm = 1.4508681132826096e-05\n",
      "Iteration 432 : x = [-0.07358494 10.5909965 ] f(x) = 0.10306362977252226 gradient norm = 1.430720875736336e-05\n",
      "Iteration 433 : x = [-0.07357835 10.59113942] f(x) = 0.10306362773977204 gradient norm = 1.4108540067346927e-05\n",
      "Iteration 434 : x = [-0.07357184 10.59128035] f(x) = 0.1030636257630827 gradient norm = 1.391263588209215e-05\n",
      "Iteration 435 : x = [-0.07356543 10.59141933] f(x) = 0.1030636238409065 gradient norm = 1.3719457572993462e-05\n",
      "Iteration 436 : x = [-0.07355911 10.59155638] f(x) = 0.10306362197173853 gradient norm = 1.3528967055619885e-05\n",
      "Iteration 437 : x = [-0.07355287 10.59169152] f(x) = 0.10306362015411552 gradient norm = 1.3341126781919478e-05\n",
      "Iteration 438 : x = [-0.07354672 10.59182479] f(x) = 0.10306361838661462 gradient norm = 1.315589973255639e-05\n",
      "Iteration 439 : x = [-0.07354066 10.59195621] f(x) = 0.10306361666785234 gradient norm = 1.2973249409349577e-05\n",
      "Iteration 440 : x = [-0.07353468 10.59208581] f(x) = 0.10306361499648344 gradient norm = 1.279313982781746e-05\n",
      "Iteration 441 : x = [-0.07352878 10.5922136 ] f(x) = 0.1030636133711998 gradient norm = 1.2615535509847448e-05\n",
      "Iteration 442 : x = [-0.07352297 10.59233962] f(x) = 0.10306361179072954 gradient norm = 1.2440401476460388e-05\n",
      "Iteration 443 : x = [-0.07351724 10.5924639 ] f(x) = 0.1030636102538359 gradient norm = 1.2267703240690491e-05\n",
      "Iteration 444 : x = [-0.07351159 10.59258644] f(x) = 0.10306360875931624 gradient norm = 1.2097406800554257e-05\n",
      "Iteration 445 : x = [-0.07350601 10.59270729] f(x) = 0.10306360730600123 gradient norm = 1.1929478632146099e-05\n",
      "Iteration 446 : x = [-0.07350052 10.59282646] f(x) = 0.10306360589275385 gradient norm = 1.1763885682813098e-05\n",
      "Iteration 447 : x = [-0.0734951  10.59294397] f(x) = 0.10306360451846848 gradient norm = 1.1600595364445424e-05\n",
      "Iteration 448 : x = [-0.07348975 10.59305985] f(x) = 0.10306360318207002 gradient norm = 1.143957554685037e-05\n",
      "Iteration 449 : x = [-0.07348448 10.59317413] f(x) = 0.10306360188251311 gradient norm = 1.1280794551238807e-05\n",
      "Iteration 450 : x = [-0.07347929 10.59328682] f(x) = 0.10306360061878124 gradient norm = 1.1124221143793065e-05\n",
      "Iteration 451 : x = [-0.07347416 10.59339794] f(x) = 0.10306359938988603 gradient norm = 1.0969824529335885e-05\n",
      "Iteration 452 : x = [-0.07346911 10.59350752] f(x) = 0.10306359819486635 gradient norm = 1.0817574345098262e-05\n",
      "Iteration 453 : x = [-0.07346413 10.59361558] f(x) = 0.10306359703278764 gradient norm = 1.066744065455747e-05\n",
      "Iteration 454 : x = [-0.07345922 10.59372214] f(x) = 0.10306359590274117 gradient norm = 1.051939394138481e-05\n",
      "Iteration 455 : x = [-0.07345437 10.59382723] f(x) = 0.10306359480384326 gradient norm = 1.0373405103476211e-05\n",
      "Iteration 456 : x = [-0.07344959 10.59393085] f(x) = 0.10306359373523474 gradient norm = 1.0229445447063206e-05\n",
      "Iteration 457 : x = [-0.07344488 10.59403304] f(x) = 0.10306359269608001 gradient norm = 1.0087486680915906e-05\n",
      "Iteration 458 : x = [-0.07344024 10.5941338 ] f(x) = 0.10306359168556667 gradient norm = 9.947500910629715e-06\n",
      "Iteration 459 : x = [-0.07343566 10.59423317] f(x) = 0.10306359070290473 gradient norm = 9.809460632994224e-06\n",
      "Iteration 460 : x = [-0.07343114 10.59433116] f(x) = 0.103063589747326 gradient norm = 9.673338730437187e-06\n",
      "Iteration 461 : x = [-0.07342669 10.59442779] f(x) = 0.10306358881808349 gradient norm = 9.539108465562593e-06\n",
      "Iteration 462 : x = [-0.07342229 10.59452308] f(x) = 0.10306358791445082 gradient norm = 9.4067434757592e-06\n",
      "Iteration 463 : x = [-0.07341796 10.59461705] f(x) = 0.10306358703572173 gradient norm = 9.27621776788146e-06\n",
      "Iteration 464 : x = [-0.07341369 10.59470972] f(x) = 0.10306358618120937 gradient norm = 9.147505713027836e-06\n",
      "Iteration 465 : x = [-0.07340948 10.59480109] f(x) = 0.10306358535024597 gradient norm = 9.020582041368761e-06\n",
      "Iteration 466 : x = [-0.07340533 10.5948912 ] f(x) = 0.10306358454218204 gradient norm = 8.895421837066605e-06\n",
      "Iteration 467 : x = [-0.07340123 10.59498006] f(x) = 0.10306358375638619 gradient norm = 8.772000533264942e-06\n",
      "Iteration 468 : x = [-0.0733972  10.59506769] f(x) = 0.10306358299224433 gradient norm = 8.650293907150648e-06\n",
      "Iteration 469 : x = [-0.07339321 10.5951541 ] f(x) = 0.10306358224915935 gradient norm = 8.53027807508262e-06\n",
      "Iteration 470 : x = [-0.07338929 10.59523932] f(x) = 0.10306358152655067 gradient norm = 8.41192948779539e-06\n",
      "Iteration 471 : x = [-0.07338542 10.59532335] f(x) = 0.10306358082385368 gradient norm = 8.295224925674875e-06\n",
      "Iteration 472 : x = [-0.0733816  10.59540621] f(x) = 0.10306358014051932 gradient norm = 8.180141494093665e-06\n",
      "Iteration 473 : x = [-0.07337783 10.59548792] f(x) = 0.10306357947601381 gradient norm = 8.066656618819618e-06\n",
      "Iteration 474 : x = [-0.07337412 10.59556851] f(x) = 0.10306357882981798 gradient norm = 7.95474804149134e-06\n",
      "Iteration 475 : x = [-0.07337046 10.59564797] f(x) = 0.10306357820142699 gradient norm = 7.84439381515185e-06\n",
      "Iteration 476 : x = [-0.07336685 10.59572633] f(x) = 0.10306357759035006 gradient norm = 7.735572299855234e-06\n",
      "Iteration 477 : x = [-0.07336329 10.5958036 ] f(x) = 0.10306357699610982 gradient norm = 7.62826215832906e-06\n",
      "Iteration 478 : x = [-0.07335978 10.59587981] f(x) = 0.1030635764182421 gradient norm = 7.522442351706502e-06\n",
      "Iteration 479 : x = [-0.07335632 10.59595495] f(x) = 0.10306357585629555 gradient norm = 7.418092135311477e-06\n",
      "Iteration 480 : x = [-0.0733529  10.59602905] f(x) = 0.10306357530983133 gradient norm = 7.315191054511492e-06\n",
      "Iteration 481 : x = [-0.07334954 10.59610213] f(x) = 0.10306357477842257 gradient norm = 7.2137189406215695e-06\n",
      "Iteration 482 : x = [-0.07334622 10.59617419] f(x) = 0.10306357426165433 gradient norm = 7.113655906884047e-06\n",
      "Iteration 483 : x = [-0.07334295 10.59624525] f(x) = 0.10306357375912295 gradient norm = 7.014982344480443e-06\n",
      "Iteration 484 : x = [-0.07333972 10.59631532] f(x) = 0.10306357327043608 gradient norm = 6.917678918621078e-06\n",
      "Iteration 485 : x = [-0.07333654 10.59638443] f(x) = 0.10306357279521214 gradient norm = 6.821726564686648e-06\n",
      "Iteration 486 : x = [-0.0733334  10.59645257] f(x) = 0.10306357233307997 gradient norm = 6.727106484415461e-06\n",
      "Iteration 487 : x = [-0.0733303  10.59651977] f(x) = 0.10306357188367876 gradient norm = 6.633800142155406e-06\n",
      "Iteration 488 : x = [-0.07332725 10.59658604] f(x) = 0.10306357144665765 gradient norm = 6.541789261169243e-06\n",
      "Iteration 489 : x = [-0.07332424 10.59665139] f(x) = 0.1030635710216754 gradient norm = 6.45105581998573e-06\n",
      "Iteration 490 : x = [-0.07332127 10.59671583] f(x) = 0.10306357060840016 gradient norm = 6.361582048807918e-06\n",
      "Iteration 491 : x = [-0.07331835 10.59677938] f(x) = 0.10306357020650939 gradient norm = 6.2733504259700425e-06\n",
      "Iteration 492 : x = [-0.07331546 10.59684205] f(x) = 0.10306356981568925 gradient norm = 6.186343674451251e-06\n",
      "Iteration 493 : x = [-0.07331262 10.59690384] f(x) = 0.10306356943563469 gradient norm = 6.100544758429044e-06\n",
      "Iteration 494 : x = [-0.07330981 10.59696479] f(x) = 0.10306356906604895 gradient norm = 6.0159368798902044e-06\n",
      "Iteration 495 : x = [-0.07330704 10.59702488] f(x) = 0.10306356870664367 gradient norm = 5.9325034752875435e-06\n",
      "Iteration 496 : x = [-0.07330431 10.59708414] f(x) = 0.10306356835713817 gradient norm = 5.85022821224152e-06\n",
      "Iteration 497 : x = [-0.07330162 10.59714258] f(x) = 0.10306356801725977 gradient norm = 5.769094986295234e-06\n",
      "Iteration 498 : x = [-0.07329897 10.59720021] f(x) = 0.103063567686743 gradient norm = 5.689087917708415e-06\n",
      "Iteration 499 : x = [-0.07329635 10.59725704] f(x) = 0.10306356736533007 gradient norm = 5.610191348300498e-06\n",
      "Iteration 500 : x = [-0.07329377 10.59731309] f(x) = 0.10306356705277 gradient norm = 5.532389838337652e-06\n",
      "Iteration 501 : x = [-0.07329123 10.59736835] f(x) = 0.10306356674881889 gradient norm = 5.455668163472559e-06\n",
      "Iteration 502 : x = [-0.07328872 10.59742285] f(x) = 0.10306356645323957 gradient norm = 5.380011311710984e-06\n",
      "Iteration 503 : x = [-0.07328624 10.59747659] f(x) = 0.10306356616580128 gradient norm = 5.305404480433755e-06\n",
      "Iteration 504 : x = [-0.0732838  10.59752959] f(x) = 0.10306356588627971 gradient norm = 5.231833073455659e-06\n",
      "Iteration 505 : x = [-0.0732814  10.59758186] f(x) = 0.1030635656144568 gradient norm = 5.159282698135446e-06\n",
      "Iteration 506 : x = [-0.07327903 10.59763339] f(x) = 0.10306356535012041 gradient norm = 5.087739162511344e-06\n",
      "Iteration 507 : x = [-0.07327669 10.59768422] f(x) = 0.10306356509306425 gradient norm = 5.0171884724914745e-06\n",
      "Iteration 508 : x = [-0.07327438 10.59773434] f(x) = 0.10306356484308771 gradient norm = 4.947616829076279e-06\n",
      "Iteration 509 : x = [-0.0732721  10.59778376] f(x) = 0.10306356459999576 gradient norm = 4.879010625623307e-06\n",
      "Iteration 510 : x = [-0.07326986 10.5978325 ] f(x) = 0.10306356436359876 gradient norm = 4.811356445153198e-06\n",
      "Iteration 511 : x = [-0.07326765 10.59788056] f(x) = 0.10306356413371219 gradient norm = 4.744641057678246e-06\n",
      "Iteration 512 : x = [-0.07326547 10.59792796] f(x) = 0.10306356391015678 gradient norm = 4.678851417598978e-06\n",
      "Iteration 513 : x = [-0.07326331 10.5979747 ] f(x) = 0.10306356369275803 gradient norm = 4.6139746611046125e-06\n",
      "Iteration 514 : x = [-0.07326119 10.59802079] f(x) = 0.1030635634813463 gradient norm = 4.549998103636525e-06\n",
      "Iteration 515 : x = [-0.0732591  10.59806624] f(x) = 0.10306356327575675 gradient norm = 4.48690923736984e-06\n",
      "Iteration 516 : x = [-0.07325704 10.59811106] f(x) = 0.10306356307582895 gradient norm = 4.424695728743647e-06\n",
      "Iteration 517 : x = [-0.073255   10.59815526] f(x) = 0.10306356288140692 gradient norm = 4.363345416014267e-06\n",
      "Iteration 518 : x = [-0.073253   10.59819885] f(x) = 0.10306356269233896 gradient norm = 4.302846306851714e-06\n",
      "Iteration 519 : x = [-0.07325102 10.59824183] f(x) = 0.10306356250847765 gradient norm = 4.243186575967002e-06\n",
      "Iteration 520 : x = [-0.07324907 10.59828422] f(x) = 0.1030635623296795 gradient norm = 4.184354562776378e-06\n",
      "Iteration 521 : x = [-0.07324714 10.59832602] f(x) = 0.10306356215580506 gradient norm = 4.126338769090847e-06\n",
      "Iteration 522 : x = [-0.07324525 10.59836724] f(x) = 0.10306356198671872 gradient norm = 4.069127856845779e-06\n",
      "Iteration 523 : x = [-0.07324338 10.59840789] f(x) = 0.10306356182228854 gradient norm = 4.012710645862025e-06\n",
      "Iteration 524 : x = [-0.07324153 10.59844797] f(x) = 0.1030635616623863 gradient norm = 3.957076111633106e-06\n",
      "Iteration 525 : x = [-0.07323971 10.5984875 ] f(x) = 0.10306356150688727 gradient norm = 3.902213383149346e-06\n",
      "Iteration 526 : x = [-0.07323792 10.59852648] f(x) = 0.10306356135567014 gradient norm = 3.848111740748411e-06\n",
      "Iteration 527 : x = [-0.07323615 10.59856492] f(x) = 0.10306356120861704 gradient norm = 3.7947606140022846e-06\n",
      "Iteration 528 : x = [-0.07323441 10.59860283] f(x) = 0.10306356106561318 gradient norm = 3.7421495796269675e-06\n",
      "Iteration 529 : x = [-0.07323269 10.59864021] f(x) = 0.10306356092654709 gradient norm = 3.690268359425593e-06\n",
      "Iteration 530 : x = [-0.07323099 10.59867707] f(x) = 0.10306356079131028 gradient norm = 3.639106818262446e-06\n",
      "Iteration 531 : x = [-0.07322932 10.59871343] f(x) = 0.1030635606597973 gradient norm = 3.5886549620573652e-06\n",
      "Iteration 532 : x = [-0.07322767 10.59874927] f(x) = 0.10306356053190557 gradient norm = 3.5389029358192993e-06\n",
      "Iteration 533 : x = [-0.07322604 10.59878463] f(x) = 0.10306356040753537 gradient norm = 3.489841021700813e-06\n",
      "Iteration 534 : x = [-0.07322444 10.59881949] f(x) = 0.10306356028658964 gradient norm = 3.441459637080055e-06\n",
      "Iteration 535 : x = [-0.07322285 10.59885387] f(x) = 0.10306356016897418 gradient norm = 3.3937493326769204e-06\n",
      "Iteration 536 : x = [-0.07322129 10.59888777] f(x) = 0.10306356005459719 gradient norm = 3.3467007906781983e-06\n",
      "Iteration 537 : x = [-0.07321976 10.5989212 ] f(x) = 0.1030635599433695 gradient norm = 3.300304822912684e-06\n",
      "Iteration 538 : x = [-0.07321824 10.59895417] f(x) = 0.10306355983520436 gradient norm = 3.254552369031498e-06\n",
      "Iteration 539 : x = [-0.07321674 10.59898668] f(x) = 0.10306355973001745 gradient norm = 3.209434494733936e-06\n",
      "Iteration 540 : x = [-0.07321527 10.59901874] f(x) = 0.1030635596277267 gradient norm = 3.1649423899959895e-06\n",
      "Iteration 541 : x = [-0.07321381 10.59905035] f(x) = 0.10306355952825244 gradient norm = 3.121067367340475e-06\n",
      "Iteration 542 : x = [-0.07321238 10.59908153] f(x) = 0.10306355943151702 gradient norm = 3.0778008601264084e-06\n",
      "Iteration 543 : x = [-0.07321096 10.59911228] f(x) = 0.10306355933744503 gradient norm = 3.0351344208559453e-06\n",
      "Iteration 544 : x = [-0.07320957 10.5991426 ] f(x) = 0.10306355924596311 gradient norm = 2.993059719521827e-06\n",
      "Iteration 545 : x = [-0.07320819 10.5991725 ] f(x) = 0.10306355915699998 gradient norm = 2.951568541953921e-06\n",
      "Iteration 546 : x = [-0.07320684 10.59920198] f(x) = 0.10306355907048625 gradient norm = 2.9106527882191806e-06\n",
      "Iteration 547 : x = [-0.0732055  10.59923106] f(x) = 0.10306355898635444 gradient norm = 2.870304471010086e-06\n",
      "Iteration 548 : x = [-0.07320418 10.59925973] f(x) = 0.103063558904539 gradient norm = 2.8305157140851025e-06\n",
      "Iteration 549 : x = [-0.07320288 10.599288  ] f(x) = 0.10306355882497611 gradient norm = 2.7912787507155324e-06\n",
      "Iteration 550 : x = [-0.0732016  10.59931589] f(x) = 0.10306355874760376 gradient norm = 2.7525859221563886e-06\n",
      "Iteration 551 : x = [-0.07320033 10.59934338] f(x) = 0.10306355867236161 gradient norm = 2.7144296761408212e-06\n",
      "Iteration 552 : x = [-0.07319908 10.5993705 ] f(x) = 0.103063558599191 gradient norm = 2.6768025653943826e-06\n",
      "Iteration 553 : x = [-0.07319785 10.59939724] f(x) = 0.10306355852803492 gradient norm = 2.6396972461747694e-06\n",
      "Iteration 554 : x = [-0.07319664 10.59942361] f(x) = 0.10306355845883783 gradient norm = 2.603106476819132e-06\n",
      "Iteration 555 : x = [-0.07319544 10.59944961] f(x) = 0.10306355839154586 gradient norm = 2.5670231163306174e-06\n",
      "Iteration 556 : x = [-0.07319426 10.59947526] f(x) = 0.10306355832610647 gradient norm = 2.531440122966653e-06\n",
      "Iteration 557 : x = [-0.0731931  10.59950054] f(x) = 0.10306355826246871 gradient norm = 2.496350552863285e-06\n",
      "Iteration 558 : x = [-0.07319195 10.59952548] f(x) = 0.10306355820058297 gradient norm = 2.4617475586590154e-06\n",
      "Iteration 559 : x = [-0.07319082 10.59955007] f(x) = 0.10306355814040095 gradient norm = 2.4276243881628576e-06\n",
      "Iteration 560 : x = [-0.07318971 10.59957432] f(x) = 0.10306355808187581 gradient norm = 2.393974383017972e-06\n",
      "Iteration 561 : x = [-0.07318861 10.59959824] f(x) = 0.1030635580249619 gradient norm = 2.3607909773971247e-06\n",
      "Iteration 562 : x = [-0.07318752 10.59962182] f(x) = 0.10306355796961483 gradient norm = 2.328067696715082e-06\n",
      "Iteration 563 : x = [-0.07318645 10.59964508] f(x) = 0.10306355791579144 gradient norm = 2.2957981563538563e-06\n",
      "Iteration 564 : x = [-0.0731854  10.59966801] f(x) = 0.10306355786344984 gradient norm = 2.263976060412312e-06\n",
      "Iteration 565 : x = [-0.07318436 10.59969063] f(x) = 0.10306355781254917 gradient norm = 2.2325952004654543e-06\n",
      "Iteration 566 : x = [-0.07318333 10.59971293] f(x) = 0.10306355776304982 gradient norm = 2.201649454349009e-06\n",
      "Iteration 567 : x = [-0.07318232 10.59973492] f(x) = 0.10306355771491316 gradient norm = 2.1711327849586433e-06\n",
      "Iteration 568 : x = [-0.07318132 10.59975661] f(x) = 0.10306355766810167 gradient norm = 2.141039239061075e-06\n",
      "Iteration 569 : x = [-0.07318034 10.599778  ] f(x) = 0.10306355762257888 gradient norm = 2.1113629461329286e-06\n",
      "Iteration 570 : x = [-0.07317937 10.59979909] f(x) = 0.10306355757830928 gradient norm = 2.0820981172000867e-06\n",
      "Iteration 571 : x = [-0.07317841 10.59981989] f(x) = 0.1030635575352584 gradient norm = 2.0532390437058422e-06\n",
      "Iteration 572 : x = [-0.07317747 10.5998404 ] f(x) = 0.10306355749339265 gradient norm = 2.0247800963924357e-06\n",
      "Iteration 573 : x = [-0.07317654 10.59986062] f(x) = 0.10306355745267944 gradient norm = 1.9967157241961035e-06\n",
      "Iteration 574 : x = [-0.07317562 10.59988057] f(x) = 0.10306355741308698 gradient norm = 1.969040453159144e-06\n",
      "Iteration 575 : x = [-0.07317472 10.59990024] f(x) = 0.10306355737458449 gradient norm = 1.9417488853487893e-06\n",
      "Iteration 576 : x = [-0.07317382 10.59991964] f(x) = 0.10306355733714184 gradient norm = 1.914835697810668e-06\n",
      "Iteration 577 : x = [-0.07317294 10.59993877] f(x) = 0.10306355730073002 gradient norm = 1.8882956415193995e-06\n",
      "Iteration 578 : x = [-0.07317208 10.59995763] f(x) = 0.10306355726532053 gradient norm = 1.8621235403444936e-06\n",
      "Iteration 579 : x = [-0.07317122 10.59997623] f(x) = 0.10306355723088581 gradient norm = 1.8363142900428856e-06\n",
      "Iteration 580 : x = [-0.07317038 10.59999457] f(x) = 0.10306355719739894 gradient norm = 1.8108628572573353e-06\n",
      "Iteration 581 : x = [-0.07316954 10.60001266] f(x) = 0.103063557164834 gradient norm = 1.7857642785266105e-06\n",
      "Iteration 582 : x = [-0.07316872 10.6000305 ] f(x) = 0.10306355713316545 gradient norm = 1.761013659314314e-06\n",
      "Iteration 583 : x = [-0.07316792 10.60004809] f(x) = 0.10306355710236863 gradient norm = 1.7366061730522563e-06\n",
      "Iteration 584 : x = [-0.07316712 10.60006544] f(x) = 0.10306355707241963 gradient norm = 1.7125370601887643e-06\n",
      "Iteration 585 : x = [-0.07316633 10.60008255] f(x) = 0.10306355704329503 gradient norm = 1.6888016272647934e-06\n",
      "Iteration 586 : x = [-0.07316555 10.60009942] f(x) = 0.10306355701497218 gradient norm = 1.6653952459845125e-06\n",
      "Iteration 587 : x = [-0.07316479 10.60011606] f(x) = 0.10306355698742894 gradient norm = 1.6423133523144994e-06\n",
      "Iteration 588 : x = [-0.07316403 10.60013246] f(x) = 0.10306355696064394 gradient norm = 1.6195514455897826e-06\n",
      "Iteration 589 : x = [-0.07316329 10.60014864] f(x) = 0.10306355693459626 gradient norm = 1.597105087628783e-06\n",
      "Iteration 590 : x = [-0.07316256 10.60016459] f(x) = 0.10306355690926555 gradient norm = 1.5749699018732e-06\n",
      "Iteration 591 : x = [-0.07316183 10.60018033] f(x) = 0.10306355688463212 gradient norm = 1.5531415725153366e-06\n",
      "Iteration 592 : x = [-0.07316112 10.60019584] f(x) = 0.10306355686067681 gradient norm = 1.531615843665665e-06\n",
      "Iteration 593 : x = [-0.07316042 10.60021114] f(x) = 0.10306355683738089 gradient norm = 1.5103885185176837e-06\n",
      "Iteration 594 : x = [-0.07315972 10.60022623] f(x) = 0.10306355681472625 gradient norm = 1.4894554585222056e-06\n",
      "Iteration 595 : x = [-0.07315904 10.60024111] f(x) = 0.1030635567926952 gradient norm = 1.4688125825784264e-06\n",
      "Iteration 596 : x = [-0.07315836 10.60025578] f(x) = 0.1030635567712706 gradient norm = 1.4484558662403265e-06\n",
      "Iteration 597 : x = [-0.0731577  10.60027025] f(x) = 0.10306355675043576 gradient norm = 1.428381340916369e-06\n",
      "Iteration 598 : x = [-0.07315704 10.60028452] f(x) = 0.10306355673017442 gradient norm = 1.4085850931094021e-06\n",
      "Iteration 599 : x = [-0.07315639 10.60029859] f(x) = 0.1030635567104708 gradient norm = 1.3890632636360578e-06\n",
      "Iteration 600 : x = [-0.07315576 10.60031247] f(x) = 0.1030635566913095 gradient norm = 1.369812046879627e-06\n",
      "Iteration 601 : x = [-0.07315513 10.60032615] f(x) = 0.1030635566726757 gradient norm = 1.3508276900456376e-06\n",
      "Iteration 602 : x = [-0.07315451 10.60033964] f(x) = 0.1030635566545548 gradient norm = 1.3321064924187377e-06\n",
      "Iteration 603 : x = [-0.07315389 10.60035295] f(x) = 0.10306355663693267 gradient norm = 1.3136448046522176e-06\n",
      "Iteration 604 : x = [-0.07315329 10.60036607] f(x) = 0.10306355661979563 gradient norm = 1.295439028042242e-06\n",
      "Iteration 605 : x = [-0.0731527  10.60037901] f(x) = 0.10306355660313027 gradient norm = 1.277485613830072e-06\n",
      "Iteration 606 : x = [-0.07315211 10.60039178] f(x) = 0.1030635565869237 gradient norm = 1.2597810625069972e-06\n",
      "Iteration 607 : x = [-0.07315153 10.60040436] f(x) = 0.10306355657116316 gradient norm = 1.2423219231273228e-06\n",
      "Iteration 608 : x = [-0.07315096 10.60041677] f(x) = 0.10306355655583645 gradient norm = 1.2251047926370748e-06\n",
      "Iteration 609 : x = [-0.0731504  10.60042901] f(x) = 0.10306355654093166 gradient norm = 1.208126315206167e-06\n",
      "Iteration 610 : x = [-0.07314984 10.60044108] f(x) = 0.1030635565264371 gradient norm = 1.1913831815670968e-06\n",
      "Iteration 611 : x = [-0.07314929 10.60045298] f(x) = 0.10306355651234153 gradient norm = 1.1748721283831955e-06\n",
      "Iteration 612 : x = [-0.07314876 10.60046471] f(x) = 0.10306355649863394 gradient norm = 1.1585899375918408e-06\n",
      "Iteration 613 : x = [-0.07314822 10.60047629] f(x) = 0.10306355648530363 gradient norm = 1.1425334357864736e-06\n",
      "Iteration 614 : x = [-0.0731477 10.6004877] f(x) = 0.10306355647234026 gradient norm = 1.1266994935943568e-06\n",
      "Iteration 615 : x = [-0.07314718 10.60049896] f(x) = 0.10306355645973375 gradient norm = 1.1110850250640283e-06\n",
      "Iteration 616 : x = [-0.07314667 10.60051006] f(x) = 0.10306355644747413 gradient norm = 1.0956869870617795e-06\n",
      "Iteration 617 : x = [-0.07314617 10.600521  ] f(x) = 0.10306355643555204 gradient norm = 1.0805023786768416e-06\n",
      "Iteration 618 : x = [-0.07314567 10.60053179] f(x) = 0.10306355642395806 gradient norm = 1.0655282406308428e-06\n",
      "Iteration 619 : x = [-0.07314518 10.60054244] f(x) = 0.10306355641268324 gradient norm = 1.0507616547100614e-06\n",
      "Iteration 620 : x = [-0.0731447  10.60055294] f(x) = 0.10306355640171878 gradient norm = 1.0361997431839331e-06\n",
      "Iteration 621 : x = [-0.07314422 10.60056329] f(x) = 0.10306355639105606 gradient norm = 1.0218396682454708e-06\n",
      "Iteration 622 : x = [-0.07314375 10.60057349] f(x) = 0.10306355638068684 gradient norm = 1.0076786314626134e-06\n",
      "Iteration 623 : x = [-0.07314329 10.60058356] f(x) = 0.10306355637060305 gradient norm = 9.9371387322513e-07\n",
      "Completed in 623 iterations\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 : x = [-1.  1.] f(x) = 0.18395431735259418 gradient norm = 0.11191632576370375\n",
      "Iteration 1 : x = [-2.08371425  1.27944557] f(x) = 0.10581170640010047 gradient norm = 0.014533434540522227\n",
      "Iteration 2 : x = [-1.9445212   1.32124709] f(x) = 0.10554181240765605 gradient norm = 0.013541076486363305\n",
      "Iteration 3 : x = [-2.06950544  1.37335291] f(x) = 0.10533815845642597 gradient norm = 0.012298530873743876\n",
      "Iteration 4 : x = [-1.94821869  1.39372231] f(x) = 0.10519008132794666 gradient norm = 0.010940745493440008\n",
      "Iteration 5 : x = [-2.05230479  1.42742805] f(x) = 0.10506889983975025 gradient norm = 0.009534855691058336\n",
      "Iteration 6 : x = [-1.95756673  1.43820059] f(x) = 0.10498031891199325 gradient norm = 0.00819845744155715\n",
      "Iteration 7 : x = [-2.03644657  1.46054876] f(x) = 0.10491112882733016 gradient norm = 0.006950154096849396\n",
      "Iteration 8 : x = [-1.96721559  1.46667536] f(x) = 0.1048620394072604 gradient norm = 0.005841927772929973\n",
      "Iteration 9 : x = [-2.02368794  1.48163149] f(x) = 0.10482568695100643 gradient norm = 0.004863093986213192\n",
      "Iteration 10 : x = [-1.97520277  1.48539401] f(x) = 0.10480054733899144 gradient norm = 0.00402588167431588\n",
      "Iteration 11 : x = [-2.01418389  1.49545605] f(x) = 0.10478266736420899 gradient norm = 0.003310763011467659\n",
      "Iteration 12 : x = [-1.98116949  1.49793893] f(x) = 0.10477052315975412 gradient norm = 0.0027125933235504058\n",
      "Iteration 13 : x = [-2.0074302   1.50473538] f(x) = 0.10476212374727094 gradient norm = 0.002212415219266451\n",
      "Iteration 14 : x = [-1.98537398  1.50646781] f(x) = 0.10475648667469598 gradient norm = 0.0017999232229912966\n",
      "Iteration 15 : x = [-2.00277385  1.51107396] f(x) = 0.10475265914690819 gradient norm = 0.0014598014574930096\n",
      "Iteration 16 : x = [-1.98822972  1.51232704] f(x) = 0.10475010963055408 gradient norm = 0.0011819179700741835\n",
      "Iteration 17 : x = [-1.99962664  1.51545806] f(x) = 0.10474839848686751 gradient norm = 0.0009549280125643732\n",
      "Iteration 18 : x = [-1.99012217  1.5163821 ] f(x) = 0.10474726350386337 gradient norm = 0.0007706395176184627\n",
      "Iteration 19 : x = [-1.99752719  1.51851613] f(x) = 0.10474650681422126 gradient norm = 0.0006210537009954265\n",
      "Iteration 20 : x = [-1.99135476  1.519203  ] f(x) = 0.10474600579023617 gradient norm = 0.0005001265276759045\n",
      "Iteration 21 : x = [-1.99613875  1.52066112] f(x) = 0.10474567280912707 gradient norm = 0.0004023894580279948\n",
      "Iteration 22 : x = [-1.99214747  1.5211724 ] f(x) = 0.10474545230480513 gradient norm = 0.00032360578375706996\n",
      "Iteration 23 : x = [-1.99522559  1.522171  ] f(x) = 0.1047453058461439 gradient norm = 0.00026011193073808046\n",
      "Iteration 24 : x = [-1.99265235  1.52255077] f(x) = 0.10474520870647461 gradient norm = 0.00020902913407823583\n",
      "Iteration 25 : x = [-1.99462708  1.52323616] f(x) = 0.10474514410721852 gradient norm = 0.00016793660025760215\n",
      "Iteration 26 : x = [-1.99297139  1.5235172 ] f(x) = 0.10474510114665425 gradient norm = 0.00013491665951238614\n",
      "Iteration 27 : x = [-1.99423553  1.52398859] f(x) = 0.10474507250467267 gradient norm = 0.00010838482434113405\n",
      "Iteration 28 : x = [-1.99317165  1.52419566] f(x) = 0.10474505339031265 gradient norm = 8.708008063574777e-05\n",
      "Iteration 29 : x = [-1.99397959  1.5245205 ] f(x) = 0.10474504060263108 gradient norm = 6.99721256827415e-05\n",
      "Iteration 30 : x = [-1.99329656  1.52467242] f(x) = 0.1047450320340136 gradient norm = 5.623881005647098e-05\n",
      "Iteration 31 : x = [-1.9938123   1.52489668] f(x) = 0.10474502627825133 gradient norm = 4.521321674300483e-05\n",
      "Iteration 32 : x = [-1.99337401  1.52500768] f(x) = 0.10474502240442542 gradient norm = 3.636235076236311e-05\n",
      "Iteration 33 : x = [-1.99370289  1.52516278] f(x) = 0.10474501979079817 gradient norm = 2.9255841623418632e-05\n",
      "Iteration 34 : x = [-1.99342171  1.52524357] f(x) = 0.10474501802364258 gradient norm = 2.3549428321291532e-05\n",
      "Iteration 35 : x = [-1.99363127  1.52535101] f(x) = 0.10474501682593275 gradient norm = 1.8965946023622753e-05\n",
      "Iteration 36 : x = [-1.9934509   1.52540962] f(x) = 0.10474501601238513 gradient norm = 1.5283557036639413e-05\n",
      "Iteration 37 : x = [-1.99358433  1.52548415] f(x) = 0.10474501545849654 gradient norm = 1.2323981220822762e-05\n",
      "Iteration 38 : x = [-1.99346861  1.52552655] f(x) = 0.10474501508057396 gradient norm = 9.94446493177666e-06\n",
      "Iteration 39 : x = [-1.99355351  1.52557833] f(x) = 0.10474501482214718 gradient norm = 8.030403524350425e-06\n",
      "Iteration 40 : x = [-1.99347926  1.52560891] f(x) = 0.10474501464506673 gradient norm = 6.489994249945277e-06\n",
      "Iteration 41 : x = [-1.99353324  1.52564493] f(x) = 0.10474501452347872 gradient norm = 5.2495741394022695e-06\n",
      "Iteration 42 : x = [-1.99348559  1.52566694] f(x) = 0.10474501443983218 gradient norm = 4.250111689256374e-06\n",
      "Iteration 43 : x = [-1.99351989  1.52569203] f(x) = 0.10474501438218005 gradient norm = 3.4442454008288407e-06\n",
      "Iteration 44 : x = [-1.99348929  1.52570783] f(x) = 0.10474501434237425 gradient norm = 2.7940024083133854e-06\n",
      "Iteration 45 : x = [-1.99351107  1.52572533] f(x) = 0.10474501431484422 gradient norm = 2.2689110799630964e-06\n",
      "Iteration 46 : x = [-1.99349142  1.52573666] f(x) = 0.10474501429577418 gradient norm = 1.844525601207191e-06\n",
      "Iteration 47 : x = [-1.99350524  1.52574887] f(x) = 0.10474501428254467 gradient norm = 1.501220499120459e-06\n",
      "Iteration 48 : x = [-1.99349261  1.52575698] f(x) = 0.10474501427335417 gradient norm = 1.2232396033765269e-06\n",
      "Iteration 49 : x = [-1.99350137  1.52576551] f(x) = 0.10474501426696119 gradient norm = 9.97924965353855e-07\n",
      "Completed in 49 iterations\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 : x = [1. 1.] f(x) = 0.199034207539511 gradient norm = 0.0930768634063689\n",
      "Iteration 1 : x = [1.89744464 1.24682658] f(x) = 0.13452863059804931 gradient norm = 0.016321196313797463\n",
      "Iteration 2 : x = [2.04039009 1.32559678] f(x) = 0.13352015995482439 gradient norm = 0.008603081410078971\n",
      "Iteration 3 : x = [1.96999041 1.3750456 ] f(x) = 0.1331426165937911 gradient norm = 0.005070791717080222\n",
      "Iteration 4 : x = [1.99759011 1.4175844 ] f(x) = 0.13296698982434868 gradient norm = 0.0035145695043324594\n",
      "Iteration 5 : x = [1.98284172 1.44948589] f(x) = 0.1328658711776901 gradient norm = 0.0027005847392469265\n",
      "Iteration 6 : x = [1.98700007 1.47616966] f(x) = 0.1328014919494827 gradient norm = 0.0021799499677382854\n",
      "Iteration 7 : x = [1.98347405 1.49768211] f(x) = 0.1327584215089513 gradient norm = 0.001797879493912532\n",
      "Iteration 8 : x = [1.98347057 1.5156609 ] f(x) = 0.13272884379492372 gradient norm = 0.0014991210653124679\n",
      "Iteration 9 : x = [1.98224133 1.53060163] f(x) = 0.1327081875078877 gradient norm = 0.0012588127897815314\n",
      "Iteration 10 : x = [1.9817053  1.54317834] f(x) = 0.13269358306991166 gradient norm = 0.0010625334343872129\n",
      "Iteration 11 : x = [1.98104488 1.55378313] f(x) = 0.1326831568521968 gradient norm = 0.0009005778986270784\n",
      "Iteration 12 : x = [1.98056472 1.5627761 ] f(x) = 0.13267565468632603 gradient norm = 0.0007658992114228852\n",
      "Iteration 13 : x = [1.9801214  1.57042225] f(x) = 0.1326702213330035 gradient norm = 0.0006531976592956847\n",
      "Iteration 14 : x = [1.97975492 1.57694394] f(x) = 0.13266626494259298 gradient norm = 0.0005583944481037939\n",
      "Iteration 15 : x = [1.97943537 1.58251873] f(x) = 0.13266337092836814 gradient norm = 0.0004782987680001\n",
      "Iteration 16 : x = [1.97916287 1.58729395] f(x) = 0.13266124591074652 gradient norm = 0.0004103798649551308\n",
      "Iteration 17 : x = [1.97892768 1.59139101] f(x) = 0.1326596804959483 gradient norm = 0.0003526071852415695\n",
      "Iteration 18 : x = [1.97872546 1.59491128] f(x) = 0.13265852414566331 gradient norm = 0.00030333504877801684\n",
      "Iteration 19 : x = [1.97855105 1.59793961] f(x) = 0.13265766796489373 gradient norm = 0.00026121805158846046\n",
      "Iteration 20 : x = [1.97840065 1.60054746] f(x) = 0.13265703276705007 gradient norm = 0.00022514790740912164\n",
      "Iteration 21 : x = [1.97827083 1.60279519] f(x) = 0.1326565607097105 gradient norm = 0.00019420561591297606\n",
      "Iteration 22 : x = [1.97815871 1.60473401] f(x) = 0.13265620937858053 gradient norm = 0.00016762474059410634\n",
      "Iteration 23 : x = [1.97806183 1.60640745] f(x) = 0.13265594756957 gradient norm = 0.00014476287207066847\n",
      "Iteration 24 : x = [1.97797809 1.60785266] f(x) = 0.1326557522607152 gradient norm = 0.0001250792026097632\n",
      "Iteration 25 : x = [1.97790568 1.60910135] f(x) = 0.13265560642523347 gradient norm = 0.00010811672317460003\n",
      "Iteration 26 : x = [1.97784305 1.6101807 ] f(x) = 0.13265549744383046 gradient norm = 9.348795823596263e-05\n",
      "Iteration 27 : x = [1.97778886 1.61111401] f(x) = 0.1326554159468472 gradient norm = 8.086343833122563e-05\n",
      "Iteration 28 : x = [1.97774196 1.61192128] f(x) = 0.13265535496656422 gradient norm = 6.996231310717593e-05\n",
      "Iteration 29 : x = [1.97770137 1.61261973] f(x) = 0.13265530931446878 gradient norm = 6.054465399592169e-05\n",
      "Iteration 30 : x = [1.97766623 1.61322415] f(x) = 0.13265527512243538 gradient norm = 5.24051025633075e-05\n",
      "Iteration 31 : x = [1.9776358  1.61374732] f(x) = 0.13265524950380797 gradient norm = 4.53675994915405e-05\n",
      "Iteration 32 : x = [1.97760945 1.61420023] f(x) = 0.13265523030249607 gradient norm = 3.928098802822766e-05\n",
      "Iteration 33 : x = [1.97758663 1.61459238] f(x) = 0.13265521590686952 gradient norm = 3.401533008499409e-05\n",
      "Iteration 34 : x = [1.97756687 1.61493196] f(x) = 0.13265520511148687 gradient norm = 2.9458806896719012e-05\n",
      "Iteration 35 : x = [1.97754974 1.61522605] f(x) = 0.13265519701421383 gradient norm = 2.551510203378087e-05\n",
      "Iteration 36 : x = [1.97753491 1.61548076] f(x) = 0.132655190939578 gradient norm = 2.2101184593387732e-05\n",
      "Iteration 37 : x = [1.97752207 1.6157014 ] f(x) = 0.1326551863816068 gradient norm = 1.9145426032673e-05\n",
      "Iteration 38 : x = [1.97751093 1.61589253] f(x) = 0.13265518296115553 gradient norm = 1.6585996409158204e-05\n",
      "Iteration 39 : x = [1.97750129 1.61605811] f(x) = 0.1326551803940271 gradient norm = 1.436949554903001e-05\n",
      "Iteration 40 : x = [1.97749293 1.61620156] f(x) = 0.1326551784671361 gradient norm = 1.2449782455138189e-05\n",
      "Iteration 41 : x = [1.97748569 1.61632585] f(x) = 0.13265517702067758 gradient norm = 1.0786972533960358e-05\n",
      "Iteration 42 : x = [1.97747942 1.61643354] f(x) = 0.13265517593478005 gradient norm = 9.346577295767088e-06\n",
      "Iteration 43 : x = [1.97747398 1.61652685] f(x) = 0.1326551751195106 gradient norm = 8.098765317686568e-06\n",
      "Iteration 44 : x = [1.97746927 1.6166077 ] f(x) = 0.13265517450738717 gradient norm = 7.0177266493798385e-06\n",
      "Iteration 45 : x = [1.97746519 1.61667776] f(x) = 0.13265517404776714 gradient norm = 6.08112563532305e-06\n",
      "Iteration 46 : x = [1.97746165 1.61673846] f(x) = 0.13265517370264077 gradient norm = 5.269629442704163e-06\n",
      "Iteration 47 : x = [1.97745859 1.61679107] f(x) = 0.13265517344347724 gradient norm = 4.5665015113429775e-06\n",
      "Iteration 48 : x = [1.97745593 1.61683666] f(x) = 0.1326551732488588 gradient norm = 3.957250753280909e-06\n",
      "Iteration 49 : x = [1.97745363 1.61687616] f(x) = 0.13265517310270622 gradient norm = 3.429328682438056e-06\n",
      "Iteration 50 : x = [1.97745163 1.6169104 ] f(x) = 0.13265517299294724 gradient norm = 2.9718677942877834e-06\n",
      "Iteration 51 : x = [1.9774499  1.61694007] f(x) = 0.13265517291051776 gradient norm = 2.5754554787141964e-06\n",
      "Iteration 52 : x = [1.9774484  1.61696578] f(x) = 0.13265517284861167 gradient norm = 2.2319385657855237e-06\n",
      "Iteration 53 : x = [1.97744711 1.61698806] f(x) = 0.13265517280211825 gradient norm = 1.934254298204996e-06\n",
      "Iteration 54 : x = [1.97744598 1.61700737] f(x) = 0.1326551727671998 gradient norm = 1.6762841154854793e-06\n",
      "Iteration 55 : x = [1.977445  1.6170241] f(x) = 0.13265517274097421 gradient norm = 1.45272713978911e-06\n",
      "Iteration 56 : x = [1.97744416 1.61703861] f(x) = 0.1326551727212773 gradient norm = 1.2589906850608656e-06\n",
      "Iteration 57 : x = [1.97744343 1.61705118] f(x) = 0.1326551727064836 gradient norm = 1.0910954811580007e-06\n",
      "Iteration 58 : x = [1.97744279 1.61706207] f(x) = 0.1326551726953725 gradient norm = 9.455936219593377e-07\n",
      "Completed in 58 iterations\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "initialisation_points = [[0,5], [-1,1], [1,1]]\n",
    "\n",
    "for x_init in initialisation_points:\n",
    "    x_optimal = gradient_descent(dataset2, x_init, 10)\n",
    "    plot_bell_curve(dataset2, x_optimal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the 3 graphs we notice that the first, $x^{(0)}=(0,5))$, has a very wide curve centered with respect to the _Data Points_. This suggests that the algorithm has converse in a **global minimum**.  \n",
    "In contrast, the second and third graphs are much narrower and precisely follow, respectively, the first and second peaks of _Data Points_ showing that the algorithm has converse at **local limits**. In fact, these two curves, follow the trend of their respective region very well, but fail to represent the global distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 12. Plot in 3D the surface of the objective function for $x \\in [−10, 10] \\times [0.2, 10]$, for the first and the second data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_3d_surface(dataset):\n",
    "    x1_range = np.linspace(-10, 10, 100)\n",
    "    x2_range = np.linspace(0.2, 10, 100)\n",
    "    X1, X2 = np.meshgrid(x1_range, x2_range)\n",
    "    \n",
    "    # Compute F using a simple for loop\n",
    "    Z = np.zeros_like(X1)\n",
    "    for i in range(X1.shape[0]):\n",
    "        for j in range(X1.shape[1]):\n",
    "            Z[i, j] = f([X1[i, j], X2[i, j]], dataset)\n",
    "\n",
    "    fig, ax = plt.subplots(subplot_kw={\"projection\": \"3d\"})\n",
    "    surface = ax.plot_surface(X1, X2, Z, cmap='plasma')\n",
    "\n",
    "    # Add color bar and labels\n",
    "    fig.colorbar(surface, pad=0.1)\n",
    "    ax.set_xlabel('x1')\n",
    "    ax.set_ylabel('x2')\n",
    "    ax.set_zlabel('f(x)')\n",
    "    plt.show()\n",
    "\n",
    "plot_3d_surface(dataset1)\n",
    "plot_3d_surface(dataset2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Problem 2** (Newton’s algorithm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From _Problem 2 of Assignment 2_ we know that the gradient of $f(x)=100(y-x^2)^2+(x-1)^2$ where $x=(x,y)$ is\n",
    "$$\n",
    "\\bigtriangledown f(x) = \n",
    "    \\begin{bmatrix} \n",
    "        \\frac{\\partial f}{\\partial x} \\\\\n",
    "        \\frac{\\partial f}{\\partial y}\n",
    "    \\end{bmatrix}\n",
    "    = \n",
    "    \\begin{bmatrix} \n",
    "        -400x(y-x^2)+2(x − 1) \\\\\n",
    "        200(y-x^2)\n",
    "    \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "From _Problem 2 of Assignment 2_ we take also the code for `grad_f` and the `gradient_descent` algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_f(x): # From Problem 2 of Assignment 2\n",
    "    # considering that the function must be defined as f(x); unpack the input vector as 2 dimensions\n",
    "    x1 = x[0]\n",
    "    x2 = x[1]\n",
    "    # calculate the gradient of the function\n",
    "    df_dx1 = 400*x1**3 - 400*x1*x2 + 2*x1 - 2\n",
    "    df_dx2 = 200*x2 - 200*x1**2\n",
    "    # return the gradient as a vector\n",
    "    return np.array([df_dx1, df_dx2])\n",
    "\n",
    "def gradient_descent(f, gradient, alpha, x_start, max_iter=1000, tol=1e-6):\n",
    "    # I have passed the function f because is requested to be passed as an argument,\n",
    "    #  but onestly, according to the Gradient Descent Algorithm given in the lecture notes, \n",
    "    #  i don't understand why the function f is needed, since we only need the gradient of f.\n",
    "    k = 0\n",
    "    x_k = x_start\n",
    "    g_k = gradient(x_k)\n",
    "    iterates = [x_k]\n",
    "    while np.linalg.norm(g_k) > tol and k < max_iter:\n",
    "        x_k = x_k - alpha * g_k\n",
    "        g_k = gradient(x_k)\n",
    "        k += 1\n",
    "        iterates.append(x_k)\n",
    "    return iterates, k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the formula for **Multivariate Newton’s step** \n",
    "$$\n",
    "x^{(k+1)} = x^{(k)} + d_N = x^{(k)} - \\left[ \\nabla^2 f(x^{(k)}) \\right]^{-1} \\nabla f(x^{(k)}).\n",
    "$$\n",
    "since we already have $\\nabla f(x)$ we have to compute $\\nabla^2 f(x^{(k)})$ that is the _Hessian matrix_\n",
    "$$\n",
    "\\nabla^2 f(x) = H(x) = \\begin{pmatrix}\n",
    "\\frac{\\partial^2 f}{\\partial x_1^2} & \\frac{\\partial^2 f}{\\partial x_1 \\partial x_2} & \\cdots & \\frac{\\partial^2 f}{\\partial x_1 \\partial x_n} \\\\\n",
    "\\frac{\\partial^2 f}{\\partial x_2 \\partial x_1} & \\frac{\\partial^2 f}{\\partial x_2^2} & \\cdots & \\frac{\\partial^2 f}{\\partial x_2 \\partial x_n} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "\\frac{\\partial^2 f}{\\partial x_n \\partial x_1} & \\frac{\\partial^2 f}{\\partial x_n \\partial x_2} & \\cdots & \\frac{\\partial^2 f}{\\partial x_n^2}\n",
    "\\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the components of $H(x)$ are computed as:\n",
    "- $\\frac{\\partial^2 f}{\\partial x^2} = -400y+1200x^2+2$\n",
    "- $\\frac{\\partial^2 f}{\\partial x \\partial y} = \\frac{\\partial^2 f}{\\partial x} (\\frac{\\partial^2 f}{\\partial y}) = \\frac{\\partial^2 f}{\\partial x} 200(y-x^2) = -400x$\n",
    "- $\\frac{\\partial^2 f}{\\partial y^2} = 200$\n",
    "\n",
    "resulting in \n",
    "$$\n",
    "\\nabla^2 f(x) = H(x) =  \n",
    "    \\begin{pmatrix}\n",
    "        -400y+1200x^2+2 & -400x \\\\\n",
    "        -400x & 200\n",
    "    \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "So, the implementation of the _Newton's algorithm_ is the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hess_f(x):\n",
    "    d2f_dx2 = 1200 * x[0]**2 - 400 * x[1] + 2\n",
    "    d2f_dxdy = -400 * x[0]\n",
    "    d2f_dy2 = 200\n",
    "    return np.array([\n",
    "        [d2f_dx2, d2f_dxdy],\n",
    "        [d2f_dxdy, d2f_dy2]\n",
    "    ])\n",
    "\n",
    "def newton_method(x0, tol=1e-6, max_iter=1000):\n",
    "    x = x0\n",
    "    for k in range(max_iter):\n",
    "        grad = grad_f(x)\n",
    "        if np.linalg.norm(grad) < tol:\n",
    "            break\n",
    "        hess = hess_f(x)\n",
    "        d = np.linalg.solve(hess, -grad)\n",
    "        x = x + d\n",
    "    return x, k + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run both algorithms and compare the number of iterations needed to converge for both algorithms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum of Newton's Method: [1. 1.]  found after 6 iterations\n",
      "Minimum of Gradient Descent: [1.00000112 1.00000224]  found after 32273 iterations\n"
     ]
    }
   ],
   "source": [
    "x_min_newton, iterations_newton = newton_method(np.array([2.0, 2.0]))\n",
    "print(\"Minimum of Newton's Method:\", x_min_newton, \" found after\", iterations_newton, \"iterations\")\n",
    "x_gd, iterations_gd = gradient_descent(f, grad_f, 0.001, [2.0, 2.0], 100000)\n",
    "print(\"Minimum of Gradient Descent:\", x_gd[-1], \" found after\", iterations_gd, \"iterations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We note that _Newton's method_ performs much better than the _Gradient Descent_ algorithm in that it reaches the minimum of the function in far fewer iterations.\n",
    "There is also to mention the fact that _Newton's method_ reaches a “stable” minimum in very few iterations, while _Gradient Descent_ reaches an approximate minimum in a few thousand iterations (with an average $\\alpha$ value) by reaching the maximum number of iterations allowed, while to have a “stable” value without reaching the maximum number of iterations, tens of thousands of iterations are needed.\n",
    "\n",
    "This makes us say that _Newton's method_ is more complex since it requires computation of the Hessian matrix, but this extra “cost” is amply compensated by the performance of the algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Problem 3** (Newton and Line Search)\n",
    "We consider the bivariate function\n",
    "$$\n",
    "f(x) = 4x_1^2-3x_1+x_2^2+2x_2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Define a function that computes $f (x)$ for any $x = (x_1, x_2)$ and evaluate it at $x(0) = (0, 0)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f(x) with x=(0,0) = 0\n"
     ]
    }
   ],
   "source": [
    "def f(x):\n",
    "    x1, x2 = x[0], x[1]     # Extract x1 and x2 from x\n",
    "    return 4 * x1**2 - 3 * x1 + x2**2 + 2 * x2\n",
    "\n",
    "print('f(x) with x=(0,0) =', f([0,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Define a function that computes the gradient of $f$ , $\\nabla f (x)$ for any $x = (x1, x2)$ and evaluate it at $x(0) = (0, 0)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the partial derivate with respect to $x_1$ is\n",
    "$$\n",
    "    \\frac{\\partial f}{\\partial x_1} = 2\\cdot 4x_1 - 3 = 8x_1 -3\n",
    "$$\n",
    "and the partial derivate with respect to $x_2$ is\n",
    "$$\n",
    "    \\frac{\\partial f}{\\partial x_2} = 2\\cdot x_2 +2 = 2x_2 +2\n",
    "$$\n",
    "\n",
    "The gradient of $f$ results to be\n",
    "$$\n",
    "    \\nabla f(x) = \\begin{bmatrix}\n",
    "        8x_1 -3\\\\\n",
    "        2x_2 +2\n",
    "    \\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient of f(x) with x=(0,0) = [-3  2]\n"
     ]
    }
   ],
   "source": [
    "def grad_f(x):\n",
    "    x1, x2 = x[0], x[1]     # Extract x1 and x2 from x\n",
    "    df_dx1 = 8*x1 - 3\n",
    "    df_dx2 = 2*x2 + 2\n",
    "    return np.array([df_dx1, df_dx2])\n",
    "\n",
    "print('Gradient of f(x) with x=(0,0) =', grad_f([0,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Define a function that computes the Hessian of $f$ , $\\nabla ^2f (x)$ for any $x = (x1, x2)$ and evaluate it at $x(0) = (0, 0)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $\\frac{\\partial^2 f}{\\partial x_1^2} = 8$\n",
    "- $\\frac{\\partial^2 f}{\\partial x_2^2} = 2$\n",
    "\n",
    "Since the partial derivate of $x_1$ does not contains $x_2$ and viceversa, $\\frac{\\partial^2 f}{\\partial x_1 \\partial x_2} = \\frac{\\partial^2 f}{\\partial x_2 \\partial x_1} = 0$ resulting into\n",
    "$$\n",
    "H(x) = \\nabla^2 f(x) =  \n",
    "    \\begin{pmatrix}\n",
    "        8 & 0 \\\\\n",
    "        0 & 2\n",
    "    \\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hessian of f(x) with x=(0,0) = [[8 0]\n",
      " [0 2]]\n"
     ]
    }
   ],
   "source": [
    "def hessian_f(x):\n",
    "    # Since there is no x_2 in df_dx1 and no x_1 in df_dx2, the second order derivates are constant, \n",
    "    # and so the Hessian matrix is constant.\n",
    "\n",
    "    # x1, x2 = x[0], x[1]     # Extract x1 and x2 from x\n",
    "\n",
    "    d2f_dx1 = 8\n",
    "    d2f_dx2 = 2\n",
    "    d2f_dxdy = 0\n",
    "    d2f_dydx = 0\n",
    "    \n",
    "    return np.array([[d2f_dx1, d2f_dxdy], [d2f_dydx, d2f_dx2]])\n",
    "\n",
    "print('Hessian of f(x) with x=(0,0) =', hessian_f([0,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Compute the Newton’s direction $d_N$ at the point $x^{(0)} = (0, 0)$ and check if it is descent direction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the Newton's direction $d_N$ is defined as\n",
    "$$\n",
    "d_N = -\\frac{1}{2} Q^{-1} g = -[\\nabla^2 f (x^{(k)})]^{-1} \\nabla f(x^{(k)})\n",
    "$$\n",
    "\n",
    "and knowing that $\\nabla f([0,0]) = \\begin{bmatrix}\n",
    "    -3\\\\\n",
    "    2\n",
    "\\end{bmatrix}$, we can rewrite the formula using $\\nabla f(x)$ and $H(x) = \\nabla^2 f(x)$ computed before as\n",
    "$$\n",
    "    d_N = \n",
    "        - \\begin{pmatrix}\n",
    "        8 & 0 \\\\\n",
    "        0 & 2\n",
    "        \\end{pmatrix}^{-1} \n",
    "    \\cdot  \n",
    "        \\begin{bmatrix}\n",
    "            -3\\\\\n",
    "            2\n",
    "        \\end{bmatrix} \n",
    "    = \n",
    "        - \\begin{pmatrix}\n",
    "            \\frac{1}{8} & 0 \\\\\n",
    "            0 & \\frac{1}{2}\n",
    "        \\end{pmatrix}\n",
    "    \\cdot \n",
    "        \\begin{bmatrix}\n",
    "            -3\\\\\n",
    "            2\n",
    "        \\end{bmatrix} \n",
    "    = \n",
    "        \\begin{bmatrix}\n",
    "            \\frac{3}{8} \\\\\n",
    "            -1\n",
    "        \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Then knowing that $\\nabla f (x^{(k)})^T d^{(k)} \\lt 0$ if $d^{(k)}$ is descent direction, we can verify if $d_N$ is descent direction (with $x^{(0)} = (0,0)$) by computing\n",
    "$$\n",
    "    \\begin{bmatrix}\n",
    "        -3\\\\\n",
    "        2\n",
    "    \\end{bmatrix}^T \\begin{bmatrix}\n",
    "            \\frac{3}{8} \\\\\n",
    "            -1\n",
    "        \\end{bmatrix} = -3 * \\frac{3}{8} + 2 * (-1) = -\\frac{9}{8} - 2 = -\\frac{25}{8} = \\nabla f (x^{(k)})^T d^{(k)} \\lt 0\n",
    "$$\n",
    "And since $\\nabla f (x^{(k)})^T d^{(k)} = -\\frac{25}{8}$ is indeed $\\lt 0$ we know that $d_N$ is descent direction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. Define a function `line_search` that computes the value of the line search objective function, in the Newton’s direction for a given (anchor) point $x$ and any step size $\\alpha$:\n",
    "$$\n",
    "    h(\\alpha) = f(x + \\alpha d_N)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_search(f, x, alpha, d_N):\n",
    "    return f(x + alpha * d_N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6. Plot the graph of the function $h(\\alpha)$ for $\\alpha \\in [0, 2.5]$ and $x = x^{(0)} = (0, 0)$. What would be the value of $\\alpha$ in exact line search? (give an approximate value using the previous plot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x0 = np.array([0.0, 0.0])               # Anchor point\n",
    "dN = np.array([3/8, -1])                # Newton's direction\n",
    "alphas = np.linspace(0, 2.5, 250)\n",
    "\n",
    "h_vals = []\n",
    "\n",
    "for alpha in alphas:\n",
    "    h_vals.append(line_search(f, x0, alpha, dN))\n",
    "\n",
    "plt.plot(alphas, h_vals, label='h(alpha)=f(x + alpha*d_N)')\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('h(alpha)')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value of $\\alpha$ in the exact line search (i.e. $\\min_{\\alpha > 0} h(x)$), according to the plot, seems to be at $\\alpha \\approx 1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7. We now want to find a step size $\\alpha$ that verifies the Wolfe conditions. Define a function `first_wolfe` that compute $\\ell(\\alpha)$ defined as\n",
    "$$\n",
    "    \\ell (\\alpha) = f(x^{(0)}) + \\alpha \\eta \\nabla f(x^{(0)})^T d_N\n",
    "$$\n",
    "with relaxation parameter $\\eta = 0.2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_wolfe(f, x, alpha, grad_f, d_N, eta = 0.2):\n",
    "    return f(x) + alpha * eta * grad_f(x).dot(d_N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8. Plot the graph of $\\ell(\\alpha)$ for $\\alpha \\in [0, 2.5]$ on top of the graph of $h(\\alpha)$. What would be acceptable values of $\\alpha$ according to the first Wolfe conditions? You can give an approximate value given the plot or, optionally, find the value $\\alpha^*$ at which $h(\\alpha)$ intersects $\\ell(\\alpha)$. Hint: you can use the function `fsolve` from the `package scipy.optimize`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "l_vals = []\n",
    "for alpha in alphas:\n",
    "    l_vals.append(first_wolfe(f, x0, alpha, grad_f, dN))\n",
    "\n",
    "plt.plot(alphas, h_vals, label='h(alpha)')\n",
    "plt.plot(alphas, l_vals, '--', label='l(alpha)')\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('vals(alpha)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The acceptable values of $\\alpha$, according to the first Wolfe conditions ($h(\\alpha)$ should be no larger than $\\ell(\\alpha)$, i.e. $h(\\alpha)\\le \\ell(\\alpha)$), are $\\alpha \\approx [0, 1.6]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 9. We now consider the second Wolfe condition:\n",
    "$$\n",
    "\\nabla f(x^{(0)} + \\alpha d_N)^T d_N \\geq \\bar{\\eta} \\nabla f(x^{(0)})^T d_N\n",
    "$$\n",
    "with $\\bar{\\eta} = 0.7$. First explain why this condition is equivalent to:\n",
    "$$\n",
    "\\frac{\\nabla f(x^{(0)} + \\alpha d_N)^T d_N}{\\nabla f(x^{(0)})^T d_N} \\leq \\bar{\\eta}\n",
    "$$\n",
    "\n",
    "Second, define a function `second_wolfe` that compute the ratio\n",
    "$$\n",
    "    r(\\alpha) = \\frac{\\nabla f(x^{(0)} + \\alpha d_N)^T d_N}{\\nabla f(x^{(0)})^T d_N}\n",
    "$$\n",
    "for any $\\alpha$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting from $\\nabla f(x^{(0)} + \\alpha d_N)^T d_N \\geq \\bar{\\eta} \\nabla f(x^{(0)})^T d_N$ we can devide both sides with $\\nabla f(x^{(0)})^T d_N$ in order to isolate $\\bar{\\eta}$, and since $d_N$ is descent (see Problem 3.4) $\\nabla f(x^{(0)})^T d_N$ will be negative, requiring also to flipt the sign of the inequality resulting into\n",
    "$$\n",
    "    \\frac{\\nabla f(x^{(0)} + \\alpha d_N)^T d_N}{\\nabla f(x^{(0)})^T d_N} \\leq \\bar{\\eta} = \\bar{\\eta} \\cdot 1 = \\bar{\\eta} \\frac{\\nabla f(x^{(0)})^T d_N}{\\nabla f(x^{(0)})^T d_N} \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def second_wolfe(f, x, alpha, grad_f, d_N):\n",
    "    nominator = grad_f(x + alpha * d_N).dot(d_N)\n",
    "    denominator = grad_f(x).dot(d_N)\n",
    "\n",
    "    ratio = nominator / denominator\n",
    "    return ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 10. Plot the graph of $r(\\alpha)$ for $\\alpha \\in [0, 2.5]$ on top of the graph of $h(\\alpha)$ and $\\ell(\\alpha)$. What would be the acceptable values of $\\alpha$ according to both Wolfe conditions? You can give an approximate value given the plot or, optionally, find the value $\\alpha^*$ at which $r(\\alpha) = \\bar{\\eta}$. Hint: you can use the function `fsolve` from the `package scipy.optimize`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "r_vals = []\n",
    "for alpha in alphas:\n",
    "    r_vals.append(second_wolfe(f, x0, alpha, grad_f, dN))\n",
    "\n",
    "eta_bar = 0.7\n",
    "plt.axhline(y=eta_bar, color='r', linestyle=':', label='eta_bar')\n",
    "\n",
    "plt.plot(alphas, h_vals, label='h(alpha)')\n",
    "plt.plot(alphas, l_vals, '--', label='l(alpha)')\n",
    "plt.plot(alphas, r_vals, '-.', label='r(alpha)')\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('vals(alpha)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to both Wolfe conditions ($h(\\alpha)\\le \\ell(\\alpha)$ and $r(\\alpha)\\le \\bar{\\eta})=0.7$), from the plot we can say that the accepted values of $\\alpha$ are:\n",
    "$$\n",
    "\\alpha =  \\{h(\\alpha)\\le \\ell(\\alpha)\\} \\cap \\{r(\\alpha)\\le \\bar{\\eta}\\} \\approx [0.0, 1.6] \\cap [0.3, 2.5] = [0.3, 1.6]\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
